{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 20\n",
    "CLOUD_SINGLE = True\n",
    "DATA_SMALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_md' not in globals() or 'test_md' not in globals():\n",
    "    train_md, test_md = loadMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 8\n",
      "DataSet 6 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.251 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.684 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.887 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.492 time per batch: 0.167\n",
      "ver 20, iter 0, fold 0, val ll: 0.0652, cor: 0.8369, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.774 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.199 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.364 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.939 time per batch: 0.170\n",
      "ver 20, iter 1, fold 0, val ll: 0.0653, cor: 0.8367, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.355 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.519 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.645 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.213 time per batch: 0.166\n",
      "ver 20, iter 2, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.344 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.736 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.872 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.430 time per batch: 0.167\n",
      "ver 20, iter 3, fold 0, val ll: 0.0651, cor: 0.8372, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.551 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.750 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.862 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.307 time per batch: 0.167\n",
      "ver 20, iter 4, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.302 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.230 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.349 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.712 time per batch: 0.164\n",
      "ver 20, iter 5, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.102 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.201 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.285 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.890 time per batch: 0.164\n",
      "ver 20, iter 6, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.418 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.334 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.479 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.093 time per batch: 0.165\n",
      "ver 20, iter 7, fold 0, val ll: 0.0653, cor: 0.8367, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.383 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.579 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.703 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.245 time per batch: 0.166\n",
      "ver 20, iter 8, fold 0, val ll: 0.0653, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.637 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.959 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 25.966 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.442 time per batch: 0.167\n",
      "ver 20, iter 9, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.430 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.502 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.472 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.034 time per batch: 0.165\n",
      "ver 20, iter 10, fold 0, val ll: 0.0653, cor: 0.8371, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.338 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.695 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.765 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.408 time per batch: 0.167\n",
      "ver 20, iter 11, fold 0, val ll: 0.0652, cor: 0.8369, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.432 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.517 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.683 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.226 time per batch: 0.166\n",
      "ver 20, iter 12, fold 0, val ll: 0.0654, cor: 0.8366, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.586 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.818 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.856 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.451 time per batch: 0.167\n",
      "ver 20, iter 13, fold 0, val ll: 0.0653, cor: 0.8366, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.274 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.561 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.636 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.249 time per batch: 0.166\n",
      "ver 20, iter 14, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.238 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.549 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.718 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.236 time per batch: 0.166\n",
      "ver 20, iter 15, fold 0, val ll: 0.0651, cor: 0.8372, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.260 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.638 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.714 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.160 time per batch: 0.166\n",
      "ver 20, iter 16, fold 0, val ll: 0.0652, cor: 0.8372, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.193 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.419 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.493 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.010 time per batch: 0.165\n",
      "ver 20, iter 17, fold 0, val ll: 0.0654, cor: 0.8363, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.180 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.568 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.479 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.926 time per batch: 0.165\n",
      "ver 20, iter 18, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.240 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.413 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.334 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.913 time per batch: 0.165\n",
      "ver 20, iter 19, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.441 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.397 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.486 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.925 time per batch: 0.165\n",
      "ver 20, iter 20, fold 0, val ll: 0.0653, cor: 0.8370, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.684 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.005 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 25.952 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.417 time per batch: 0.167\n",
      "ver 20, iter 21, fold 0, val ll: 0.0653, cor: 0.8366, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.294 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.585 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.570 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.949 time per batch: 0.165\n",
      "ver 20, iter 22, fold 0, val ll: 0.0652, cor: 0.8368, auc: 0.9875\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 9.196 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.184 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.240 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.760 time per batch: 0.164\n",
      "ver 20, iter 23, fold 0, val ll: 0.0651, cor: 0.8373, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.508 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.648 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.758 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.134 time per batch: 0.166\n",
      "ver 20, iter 24, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.499 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.678 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.733 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.205 time per batch: 0.166\n",
      "ver 20, iter 25, fold 0, val ll: 0.0653, cor: 0.8370, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.526 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.573 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.499 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.782 time per batch: 0.164\n",
      "ver 20, iter 26, fold 0, val ll: 0.0653, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.409 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.376 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.526 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.891 time per batch: 0.164\n",
      "ver 20, iter 27, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.272 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.223 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.454 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.992 time per batch: 0.165\n",
      "ver 20, iter 28, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.541 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.596 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.655 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.114 time per batch: 0.166\n",
      "ver 20, iter 29, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.300 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.218 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.224 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.796 time per batch: 0.164\n",
      "ver 20, iter 30, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 8.999 time per batch: 0.180\n",
      "Batch 100 device: cuda time passed: 16.921 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 24.872 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.632 time per batch: 0.163\n",
      "ver 20, iter 31, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "total running time 1218.9592831134796\n",
      "total time 1219.3914034366608\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 12\n",
      "DataSet 6 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.472 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.586 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.829 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.627 time per batch: 0.168\n",
      "ver 20, iter 0, fold 1, val ll: 0.0630, cor: 0.8385, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.399 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.682 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.873 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.625 time per batch: 0.168\n",
      "ver 20, iter 1, fold 1, val ll: 0.0632, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.411 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.526 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.673 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.697 time per batch: 0.168\n",
      "ver 20, iter 2, fold 1, val ll: 0.0632, cor: 0.8385, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.652 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.778 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.979 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.770 time per batch: 0.169\n",
      "ver 20, iter 3, fold 1, val ll: 0.0630, cor: 0.8389, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.441 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.605 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.733 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.719 time per batch: 0.169\n",
      "ver 20, iter 4, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.710 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.774 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.998 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.721 time per batch: 0.169\n",
      "ver 20, iter 5, fold 1, val ll: 0.0631, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.782 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 17.953 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.219 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.719 time per batch: 0.169\n",
      "ver 20, iter 6, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.445 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.798 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.014 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.930 time per batch: 0.170\n",
      "ver 20, iter 7, fold 1, val ll: 0.0629, cor: 0.8391, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.564 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.843 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.013 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.915 time per batch: 0.170\n",
      "ver 20, iter 8, fold 1, val ll: 0.0631, cor: 0.8385, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.536 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.793 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.952 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.873 time per batch: 0.169\n",
      "ver 20, iter 9, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.592 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.804 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.982 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.637 time per batch: 0.168\n",
      "ver 20, iter 10, fold 1, val ll: 0.0631, cor: 0.8383, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.511 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.663 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.716 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.278 time per batch: 0.166\n",
      "ver 20, iter 11, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.348 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.330 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.205 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.558 time per batch: 0.163\n",
      "ver 20, iter 12, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.044 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 16.831 time per batch: 0.168\n",
      "Batch 150 device: cuda time passed: 24.853 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.686 time per batch: 0.163\n",
      "ver 20, iter 13, fold 1, val ll: 0.0629, cor: 0.8387, auc: 0.9880\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 9.573 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.772 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.785 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.333 time per batch: 0.167\n",
      "ver 20, iter 14, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.414 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.624 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.622 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.411 time per batch: 0.167\n",
      "ver 20, iter 15, fold 1, val ll: 0.0629, cor: 0.8387, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.614 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.852 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 25.977 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.525 time per batch: 0.168\n",
      "ver 20, iter 16, fold 1, val ll: 0.0630, cor: 0.8387, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.289 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.579 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.473 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.211 time per batch: 0.166\n",
      "ver 20, iter 17, fold 1, val ll: 0.0630, cor: 0.8385, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.233 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.399 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.367 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.006 time per batch: 0.165\n",
      "ver 20, iter 18, fold 1, val ll: 0.0629, cor: 0.8390, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.297 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.196 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.168 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 33.141 time per batch: 0.166\n",
      "ver 20, iter 19, fold 1, val ll: 0.0631, cor: 0.8384, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.354 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.256 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.306 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.014 time per batch: 0.165\n",
      "ver 20, iter 20, fold 1, val ll: 0.0631, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.511 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.620 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.739 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.378 time per batch: 0.167\n",
      "ver 20, iter 21, fold 1, val ll: 0.0629, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.331 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.721 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.804 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.593 time per batch: 0.168\n",
      "ver 20, iter 22, fold 1, val ll: 0.0630, cor: 0.8387, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.520 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.638 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.765 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.460 time per batch: 0.167\n",
      "ver 20, iter 23, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.283 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.253 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.434 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.171 time per batch: 0.166\n",
      "ver 20, iter 24, fold 1, val ll: 0.0631, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.432 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.466 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.479 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.261 time per batch: 0.166\n",
      "ver 20, iter 25, fold 1, val ll: 0.0631, cor: 0.8388, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.474 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.557 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.792 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.380 time per batch: 0.167\n",
      "ver 20, iter 26, fold 1, val ll: 0.0628, cor: 0.8390, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.441 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.634 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.656 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.294 time per batch: 0.166\n",
      "ver 20, iter 27, fold 1, val ll: 0.0631, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.126 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.402 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.423 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.005 time per batch: 0.165\n",
      "ver 20, iter 28, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.244 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.208 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.175 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.990 time per batch: 0.165\n",
      "ver 20, iter 29, fold 1, val ll: 0.0631, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.493 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.573 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.797 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.703 time per batch: 0.169\n",
      "ver 20, iter 30, fold 1, val ll: 0.0628, cor: 0.8389, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.231 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.492 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.469 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.097 time per batch: 0.165\n",
      "ver 20, iter 31, fold 1, val ll: 0.0629, cor: 0.8391, auc: 0.9880\n",
      "total running time 1227.9004607200623\n",
      "total time 2447.71595287323\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 2\n",
      "DataSet 6 valid size 6496 fold 2\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f2.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.034 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 16.871 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 25.266 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.781 time per batch: 0.164\n",
      "ver 20, iter 0, fold 2, val ll: 0.0617, cor: 0.8393, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.265 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.517 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.429 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.098 time per batch: 0.165\n",
      "ver 20, iter 1, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.439 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.625 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.803 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.287 time per batch: 0.166\n",
      "ver 20, iter 2, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.421 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.544 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.551 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.322 time per batch: 0.167\n",
      "ver 20, iter 3, fold 2, val ll: 0.0616, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.528 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.523 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.685 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.238 time per batch: 0.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver 20, iter 4, fold 2, val ll: 0.0615, cor: 0.8392, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.556 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.616 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.900 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.558 time per batch: 0.168\n",
      "ver 20, iter 5, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.495 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.533 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.709 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.233 time per batch: 0.166\n",
      "ver 20, iter 6, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.564 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.797 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.088 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.611 time per batch: 0.168\n",
      "ver 20, iter 7, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.310 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.583 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.731 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.132 time per batch: 0.166\n",
      "ver 20, iter 8, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.639 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.851 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.260 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.847 time per batch: 0.169\n",
      "ver 20, iter 9, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.658 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.953 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.318 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.023 time per batch: 0.170\n",
      "ver 20, iter 10, fold 2, val ll: 0.0617, cor: 0.8393, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.627 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.802 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.785 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.192 time per batch: 0.166\n",
      "ver 20, iter 11, fold 2, val ll: 0.0617, cor: 0.8390, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.528 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.731 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.932 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.206 time per batch: 0.166\n",
      "ver 20, iter 12, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.541 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.846 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.977 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.694 time per batch: 0.168\n",
      "ver 20, iter 13, fold 2, val ll: 0.0616, cor: 0.8394, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.692 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.922 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.089 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.662 time per batch: 0.168\n",
      "ver 20, iter 14, fold 2, val ll: 0.0618, cor: 0.8387, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.701 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.007 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.176 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.645 time per batch: 0.168\n",
      "ver 20, iter 15, fold 2, val ll: 0.0616, cor: 0.8395, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.311 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.462 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.605 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.285 time per batch: 0.166\n",
      "ver 20, iter 16, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.592 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.796 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.054 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.540 time per batch: 0.168\n",
      "ver 20, iter 17, fold 2, val ll: 0.0616, cor: 0.8394, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.762 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 17.975 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.201 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.661 time per batch: 0.168\n",
      "ver 20, iter 18, fold 2, val ll: 0.0618, cor: 0.8390, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.731 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 17.970 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.170 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.667 time per batch: 0.168\n",
      "ver 20, iter 19, fold 2, val ll: 0.0614, cor: 0.8397, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.424 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.738 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.917 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.730 time per batch: 0.169\n",
      "ver 20, iter 20, fold 2, val ll: 0.0616, cor: 0.8396, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.904 time per batch: 0.198\n",
      "Batch 100 device: cuda time passed: 18.114 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.117 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.686 time per batch: 0.168\n",
      "ver 20, iter 21, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.538 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.840 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.961 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.769 time per batch: 0.169\n",
      "ver 20, iter 22, fold 2, val ll: 0.0615, cor: 0.8394, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.576 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 18.019 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.307 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.011 time per batch: 0.170\n",
      "ver 20, iter 23, fold 2, val ll: 0.0618, cor: 0.8390, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.476 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.960 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.229 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.853 time per batch: 0.169\n",
      "ver 20, iter 24, fold 2, val ll: 0.0616, cor: 0.8396, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.509 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.863 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.212 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.073 time per batch: 0.170\n",
      "ver 20, iter 25, fold 2, val ll: 0.0616, cor: 0.8394, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.684 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.038 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.284 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.998 time per batch: 0.170\n",
      "ver 20, iter 26, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.736 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.179 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.444 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.115 time per batch: 0.171\n",
      "ver 20, iter 27, fold 2, val ll: 0.0616, cor: 0.8395, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.703 time per batch: 0.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 device: cuda time passed: 18.071 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.339 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.948 time per batch: 0.170\n",
      "ver 20, iter 28, fold 2, val ll: 0.0616, cor: 0.8395, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.508 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.596 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.773 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.248 time per batch: 0.166\n",
      "ver 20, iter 29, fold 2, val ll: 0.0615, cor: 0.8395, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.158 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.364 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.482 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.060 time per batch: 0.165\n",
      "ver 20, iter 30, fold 2, val ll: 0.0615, cor: 0.8396, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.074 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 17.194 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.425 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.180 time per batch: 0.166\n",
      "ver 20, iter 31, fold 2, val ll: 0.0617, cor: 0.8394, auc: 0.9889\n",
      "total running time 1230.425933599472\n",
      "total time 3678.56298661232\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 8\n",
      "DataSet 7 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.800 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 18.191 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.306 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.063 time per batch: 0.170\n",
      "ver 20, iter 0, fold 0, val ll: 0.0641, cor: 0.8415, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.975 time per batch: 0.199\n",
      "Batch 100 device: cuda time passed: 18.525 time per batch: 0.185\n",
      "Batch 150 device: cuda time passed: 26.775 time per batch: 0.179\n",
      "Batch 200 device: cuda time passed: 34.304 time per batch: 0.172\n",
      "ver 20, iter 1, fold 0, val ll: 0.0643, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.894 time per batch: 0.198\n",
      "Batch 100 device: cuda time passed: 18.210 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.467 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.336 time per batch: 0.172\n",
      "ver 20, iter 2, fold 0, val ll: 0.0642, cor: 0.8413, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.682 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.883 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.277 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.114 time per batch: 0.171\n",
      "ver 20, iter 3, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.680 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.014 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.248 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.090 time per batch: 0.170\n",
      "ver 20, iter 4, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.564 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.802 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.101 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 34.015 time per batch: 0.170\n",
      "ver 20, iter 5, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.622 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.821 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.109 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.918 time per batch: 0.170\n",
      "ver 20, iter 6, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.598 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.993 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.379 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.084 time per batch: 0.170\n",
      "ver 20, iter 7, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.732 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.102 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.585 time per batch: 0.177\n",
      "Batch 200 device: cuda time passed: 34.387 time per batch: 0.172\n",
      "ver 20, iter 8, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9877\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.689 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.015 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.254 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.118 time per batch: 0.171\n",
      "ver 20, iter 9, fold 0, val ll: 0.0643, cor: 0.8412, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.716 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.039 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.324 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.049 time per batch: 0.170\n",
      "ver 20, iter 10, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.718 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.196 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.347 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.970 time per batch: 0.170\n",
      "ver 20, iter 11, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.482 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.616 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.755 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.597 time per batch: 0.168\n",
      "ver 20, iter 12, fold 0, val ll: 0.0643, cor: 0.8408, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.575 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.747 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.956 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.840 time per batch: 0.169\n",
      "ver 20, iter 13, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.716 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.030 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.166 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.965 time per batch: 0.170\n",
      "ver 20, iter 14, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.563 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.794 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.982 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.846 time per batch: 0.169\n",
      "ver 20, iter 15, fold 0, val ll: 0.0642, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.454 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.607 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.773 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.512 time per batch: 0.168\n",
      "ver 20, iter 16, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.495 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.842 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.975 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.724 time per batch: 0.169\n",
      "ver 20, iter 17, fold 0, val ll: 0.0641, cor: 0.8417, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.628 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.903 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.128 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.688 time per batch: 0.168\n",
      "ver 20, iter 18, fold 0, val ll: 0.0643, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 9.682 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.865 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.045 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.835 time per batch: 0.169\n",
      "ver 20, iter 19, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.536 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.871 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.092 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.896 time per batch: 0.169\n",
      "ver 20, iter 20, fold 0, val ll: 0.0642, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 11.001 time per batch: 0.220\n",
      "Batch 100 device: cuda time passed: 21.225 time per batch: 0.212\n",
      "Batch 150 device: cuda time passed: 31.302 time per batch: 0.209\n",
      "Batch 200 device: cuda time passed: 39.301 time per batch: 0.197\n",
      "ver 20, iter 21, fold 0, val ll: 0.0642, cor: 0.8412, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.747 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.031 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.391 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.143 time per batch: 0.171\n",
      "ver 20, iter 22, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.588 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.957 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.221 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.979 time per batch: 0.170\n",
      "ver 20, iter 23, fold 0, val ll: 0.0642, cor: 0.8410, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.530 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.892 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.008 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.786 time per batch: 0.169\n",
      "ver 20, iter 24, fold 0, val ll: 0.0641, cor: 0.8413, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.809 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 18.105 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.392 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.946 time per batch: 0.170\n",
      "ver 20, iter 25, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.610 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.969 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.231 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.062 time per batch: 0.170\n",
      "ver 20, iter 26, fold 0, val ll: 0.0643, cor: 0.8412, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.603 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.993 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.352 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.977 time per batch: 0.170\n",
      "ver 20, iter 27, fold 0, val ll: 0.0642, cor: 0.8414, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.413 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.670 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.871 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.612 time per batch: 0.168\n",
      "ver 20, iter 28, fold 0, val ll: 0.0641, cor: 0.8414, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.545 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 18.044 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.073 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.876 time per batch: 0.169\n",
      "ver 20, iter 29, fold 0, val ll: 0.0642, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.537 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.802 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.952 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.729 time per batch: 0.169\n",
      "ver 20, iter 30, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.579 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.852 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.092 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.973 time per batch: 0.170\n",
      "ver 20, iter 31, fold 0, val ll: 0.0641, cor: 0.8413, auc: 0.9879\n",
      "total running time 1369.0706129074097\n",
      "total time 5048.076225280762\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 12\n",
      "DataSet 7 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.763 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.488 time per batch: 0.185\n",
      "Batch 150 device: cuda time passed: 27.071 time per batch: 0.180\n",
      "Batch 200 device: cuda time passed: 35.181 time per batch: 0.176\n",
      "ver 20, iter 0, fold 1, val ll: 0.0635, cor: 0.8379, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.705 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.102 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.400 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.394 time per batch: 0.172\n",
      "ver 20, iter 1, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.928 time per batch: 0.199\n",
      "Batch 100 device: cuda time passed: 18.463 time per batch: 0.185\n",
      "Batch 150 device: cuda time passed: 26.698 time per batch: 0.178\n",
      "Batch 200 device: cuda time passed: 34.803 time per batch: 0.174\n",
      "ver 20, iter 2, fold 1, val ll: 0.0634, cor: 0.8383, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.616 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 18.181 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.339 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.287 time per batch: 0.171\n",
      "ver 20, iter 3, fold 1, val ll: 0.0633, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.846 time per batch: 0.197\n",
      "Batch 100 device: cuda time passed: 18.220 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.636 time per batch: 0.178\n",
      "Batch 200 device: cuda time passed: 34.585 time per batch: 0.173\n",
      "ver 20, iter 4, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.754 time per batch: 0.195\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for ds in range(6,10):\n",
    "    for fold in range(3):\n",
    "        predictions = oof_one(num_iter=32, bs=32, fold=fold, dataset=ds)\n",
    "        pickle.dump(predictions, open(PATH_DISK/'ensemble/oof_d{}_f{}_v{}'.format(ds, fold, VERSION),'wb'))\n",
    "        print('total time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.231111111111111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total running time 1201.68962931633\n",
    "#total time 15020.348212480545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between models\n",
    "# scores per slice\n",
    "# what is the best way to agg oof, model\\run levels\n",
    "# best aggregation theoretically\n",
    "# distribution of oof preds\n",
    "# score - what uniform p will get\n",
    "# 0.5 + np.sign(x-0.5) *2*(x-0.5)**2 - makes it less aggressive, is it a good transform above mean?\n",
    "# does scaling help for single runs, or is it aggregation artifact.\n",
    "\n",
    "# s101 problem.\n",
    "    # maybe 8 and 32 behave differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting runs aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbd70c0e8d0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(101)/100\n",
    "plt.plot(scalePreds(x, center=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "mean    [0.06429 0.06347 0.06388 0.06304] [0.03816 0.03822 0.0384  0.03748]\n",
      "gmean   [0.06444 0.06361 0.06411 0.06326] [0.03824 0.03834 0.03854 0.03766]\n",
      "q50     [0.06454 0.06372 0.06428 0.06335] [0.03833 0.03843 0.03866 0.03772]\n",
      "q25     [0.06518 0.06432 0.06533 0.06426] [0.03866 0.0388  0.03924 0.0383 ]\n",
      "q75     [0.0646  0.06367 0.06456 0.06314] [0.03832 0.03838 0.03889 0.03755]\n",
      "psig    [0.06443 0.06362 0.06407 0.06324] [0.03823 0.03836 0.03853 0.03765]\n",
      "fold 1\n",
      "mean    [0.06225 0.06248 0.06258 0.06124] [0.03745 0.0385  0.03817 0.03723]\n",
      "gmean   [0.06232 0.06259 0.06286 0.06144] [0.03755 0.03864 0.0384  0.03744]\n",
      "q50     [0.06246 0.06274 0.06298 0.06153] [0.03764 0.03872 0.03849 0.03745]\n",
      "q25     [0.06279 0.06314 0.06421 0.06238] [0.03804 0.03919 0.03941 0.03828]\n",
      "q75     [0.0627  0.06297 0.06296 0.06155] [0.03752 0.03861 0.03817 0.03711]\n",
      "psig    [0.06237 0.06263 0.06278 0.06143] [0.03756 0.03865 0.03834 0.03742]\n",
      "fold 2\n",
      "mean    [0.06078 0.05956 0.06078 0.05974] [0.03823 0.03747 0.0383  0.03753]\n",
      "gmean   [0.06092 0.05969 0.06094 0.05986] [0.03832 0.03755 0.03841 0.03759]\n",
      "q50     [0.06105 0.05981 0.06111 0.05995] [0.03841 0.03765 0.03857 0.03767]\n",
      "q25     [0.06159 0.0603  0.06181 0.06045] [0.03876 0.03796 0.03896 0.03795]\n",
      "q75     [0.06104 0.05986 0.0618  0.06027] [0.03837 0.0377  0.03894 0.03785]\n",
      "psig    [0.06093 0.05971 0.06093 0.05987] [0.03833 0.03757 0.03842 0.0376 ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5)\n",
    "\n",
    "for fold in range(3):\n",
    "    print('fold', fold)\n",
    "    data_fold = train_md.loc[train_md.fold == fold]\n",
    "    ww = data_fold.weights.values\n",
    "    ww = ww/ww.mean()\n",
    "\n",
    "    preds = np.stack([pickle.load(open(PATH_WORK/'oof_d{}_f{}_v{}'.format(ds, fold, VERSION),'rb')) \\\n",
    "        for ds in range(6,10)])\n",
    "\n",
    "    assert len(data_fold) == preds.shape[2]\n",
    "    \n",
    "    preds = np.clip(preds, 1e-15, 1-1e-15)\n",
    "    for afunc in afuncs_names:\n",
    "        apreds = applyAggFunc(preds, afunc)\n",
    "        res = ((- data_fold[all_ich].values * np.log(apreds) - (1 - data_fold[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean((1,2))\n",
    "        resw = (((- data_fold[all_ich].values * np.log(apreds) - (1 - data_fold[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean(2)*ww).mean(1)\n",
    "        \n",
    "        #roc = [roc_auc_score(data_fold[all_ich].values.reshape(-1), apreds[i].reshape(-1)) for i in range(4)]\n",
    "        print('{:7s} {} {}'.format(afunc,res,resw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = getPredsOOF(aug=32,datasets=range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_y = [\n",
    "           'model_Densenet201_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl',\n",
    "           'model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl',\n",
    "           'model_Densenet169_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl',\n",
    "           'model_se_resnext101_32x4d_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding yuval_idx\n"
     ]
    }
   ],
   "source": [
    "preds_y = getYuvalOOF(train_md=train_md, names=names_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 674252, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14290754, 0.00339524, 0.0487164 , 0.03418155, 0.04797976,\n",
       "       0.0631835 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_y = preds_y[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = np.concatenate([preds_all, preds_y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32, 674252, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    [0.06233 0.06173 0.06221 0.06123 0.06155 0.06156 0.06217 0.06072]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (8, 1, 674252, 6) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b61b830f8a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mafunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mafuncs_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mapreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyAggFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n\u001b[1;32m      9\u001b[0m         * class_weights).mean((1,2))\n",
      "\u001b[0;32m<ipython-input-13-b12644745c16>\u001b[0m in \u001b[0;36mapplyAggFunc\u001b[0;34m(probs, func_name, axis, norm_axis)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gmean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q50'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (8, 1, 674252, 6) and data type float64"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5)\n",
    "\n",
    "ww = train_md.weights.values\n",
    "ww = ww/ww.mean()\n",
    "\n",
    "for afunc in afuncs_names:\n",
    "    apreds = applyAggFunc(preds_all, afunc)\n",
    "    res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean((1,2))\n",
    "    if False:\n",
    "        resw = (((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean(2)*ww).mean(1)\n",
    "\n",
    "        print('{:7s} {} {}'.format(afunc,res,resw))\n",
    "    else:\n",
    "        print('{:7s} {}'.format(afunc,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06332, 0.06269, 0.06419, 0.06245, 0.06213, 0.06225, 0.06376,\n",
       "       0.06184])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06244, 0.06184, 0.06241, 0.06134, 0.0616 , 0.06162, 0.06231,\n",
       "       0.06083])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all.mean(1)) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all.mean(1),1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_afunc = 'mean'\n",
    "preds2 = applyAggFunc(preds_all, runs_afunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 674252, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial score 0.058888036483987334\n",
      "any too low inconsistencies\n",
      "1 class: 0.011859664255723379\n",
      "2 class: 0.03324907290782971\n",
      "3 class: 0.01985389341633395\n",
      "4 class: 0.05154873242867652\n",
      "5 class: 0.11456576950272301\n",
      "total 0.16696667311517058\n",
      "any too low corrected score 0.05886780423978061\n",
      "any too high inconsistencies\n",
      "total 0.1935819596196971\n",
      "any too high corrected score 0.05886198530963556\n"
     ]
    }
   ],
   "source": [
    "preds_all = predBounding(preds_all, target=train_md[all_ich].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predBounding(pp, target=None):\n",
    "    if target is not None:\n",
    "        ll = ((- target * np.log(pp.mean((0,1))) - (1 - target) * np.log(np.clip(1 - pp.mean((0,1)),1e-15,1-1e-15)))\n",
    "            * class_weights).mean()\n",
    "        print('initial score', ll)\n",
    "    \n",
    "    print('any too low inconsistencies')\n",
    "    for i in range(1,6):\n",
    "        print(i, 'class:', (pp[...,0] < pp[...,i]).mean())\n",
    "    print('total', (pp[...,0] < pp[...,1:].max(-1)).mean())\n",
    "    \n",
    "    max_vals = pp[...,1:].max(-1)\n",
    "    mask = pp[...,0] < max_vals\n",
    "    pp[mask,0] = max_vals[mask]\n",
    "    #mask_vals = 0.5*(preds_all[:,:,:,0] + max_vals)[mask]\n",
    "    #preds_all[mask,0] = mask_vals\n",
    "    #preds_all[mask] = np.clip(preds_all[mask],0,np.expand_dims(mask_vals,1))\n",
    "\n",
    "    assert (pp[...,0] < pp[...,1:].max(-1)).sum() == 0\n",
    "\n",
    "    if target is not None:\n",
    "        ll = ((- target * np.log(pp.mean((0,1))) - (1 - target) * np.log(np.clip(1 - pp.mean((0,1)),1e-15,1-1e-15)))\n",
    "            * class_weights).mean()\n",
    "        print('any too low corrected score', ll)\n",
    "    \n",
    "    print('any too high inconsistencies')\n",
    "    mask = pp[...,0] > pp[...,1:].sum(-1)\n",
    "    print('total', mask.mean())\n",
    "\n",
    "    mask_val = 0.5*(pp[mask,0] + pp[...,1:].sum(-1)[mask])\n",
    "    scaler = mask_val / pp[...,1:].sum(-1)[mask]\n",
    "    pp[mask,1:] = pp[mask,1:] * np.expand_dims(scaler,1)\n",
    "    pp[mask,0] = mask_val\n",
    "\n",
    "    if target is not None:\n",
    "        ll = ((- target * np.log(pp.mean((0,1))) - (1 - target) * np.log(np.clip(1 - pp.mean((0,1)),1e-15,1-1e-15)))\n",
    "            * class_weights).mean()\n",
    "        print('any too high corrected score', ll)\n",
    "    \n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between serieses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = train_md[['SeriesInstanceUID','PatientID']].groupby('PatientID').agg(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.sort_values('SeriesInstanceUID',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PatientID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_fa949caf</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_9d7de224</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_9d7dc280</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_33a89c47</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_afefd364</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SeriesInstanceUID\n",
       "PatientID                     \n",
       "ID_fa949caf                  3\n",
       "ID_9d7de224                  3\n",
       "ID_9d7dc280                  3\n",
       "ID_33a89c47                  3\n",
       "ID_afefd364                  3"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.loc[tt.SeriesInstanceUID == 3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = preds_all.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_md = pd.concat([train_md, pd.DataFrame(pp,columns=[s+'2' for s in all_ich])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_md = train_md.sort_values(['SeriesInstanceUID','pos_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of serieses 11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(30, 10))\n",
    "serieses = train_md.loc[train_md.PatientID == 'ID_5e035492'].SeriesInstanceUID.unique()\n",
    "print('total number of serieses', len(serieses))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i >= len(serieses): continue\n",
    "    ser = serieses[i]\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any'].values)\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any2'].values)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>img_id</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>Modality</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>ImagePositionPatient</th>\n",
       "      <th>ImageOrientationPatient</th>\n",
       "      <th>SamplesPerPixel</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>BitsAllocated</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>HighBit</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <th>RescaleSlope</th>\n",
       "      <th>PxlMin</th>\n",
       "      <th>PxlMax</th>\n",
       "      <th>PxlStd</th>\n",
       "      <th>PxlMean</th>\n",
       "      <th>ImageOrientationPatient_0</th>\n",
       "      <th>ImageOrientationPatient_1</th>\n",
       "      <th>ImageOrientationPatient_2</th>\n",
       "      <th>ImageOrientationPatient_3</th>\n",
       "      <th>ImageOrientationPatient_4</th>\n",
       "      <th>ImageOrientationPatient_5</th>\n",
       "      <th>ImagePositionPatient_0</th>\n",
       "      <th>ImagePositionPatient_1</th>\n",
       "      <th>ImagePositionPatient_2</th>\n",
       "      <th>PixelSpacing_0</th>\n",
       "      <th>PixelSpacing_1</th>\n",
       "      <th>WindowCenter_0</th>\n",
       "      <th>WindowCenter_1</th>\n",
       "      <th>WindowCenter_1_NAN</th>\n",
       "      <th>WindowWidth_0</th>\n",
       "      <th>WindowWidth_1</th>\n",
       "      <th>WindowWidth_0_le</th>\n",
       "      <th>WindowWidth_1_le</th>\n",
       "      <th>WindowCenter_1_le</th>\n",
       "      <th>BitType_le</th>\n",
       "      <th>ImageOrientationPatient_4_f</th>\n",
       "      <th>ImageOrientationPatient_4_enc_0</th>\n",
       "      <th>ImageOrientationPatient_4_enc_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ImageOrientationPatient_5_enc_1</th>\n",
       "      <th>ImagePositionPatient_0_f</th>\n",
       "      <th>ImagePositionPatient_0_enc_0</th>\n",
       "      <th>ImagePositionPatient_0_enc_1</th>\n",
       "      <th>ImagePositionPatient_0_f_r1</th>\n",
       "      <th>ImagePositionPatient_0_f_r05</th>\n",
       "      <th>ImagePositionPatient_1_f</th>\n",
       "      <th>ImagePositionPatient_1_enc_0</th>\n",
       "      <th>ImagePositionPatient_2_f</th>\n",
       "      <th>ImagePositionPatient_2_f_r05</th>\n",
       "      <th>PixelSpacing_1_f</th>\n",
       "      <th>PixelSpacing_1_enc_0</th>\n",
       "      <th>PixelSpacing_1_enc_1</th>\n",
       "      <th>WindowCenter_0_le</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>pos_min</th>\n",
       "      <th>pos_size</th>\n",
       "      <th>pos_idx1</th>\n",
       "      <th>pos_idx</th>\n",
       "      <th>pos_idx2</th>\n",
       "      <th>pos_inc1</th>\n",
       "      <th>pos_inc2</th>\n",
       "      <th>pos_inc1_grp_le</th>\n",
       "      <th>pos_inc2_grp_le</th>\n",
       "      <th>pos_inc1_r1</th>\n",
       "      <th>pos_inc1_r0001</th>\n",
       "      <th>pos_inc1_enc_0</th>\n",
       "      <th>pos_inc2_enc_0</th>\n",
       "      <th>pos_inc1_enc_1</th>\n",
       "      <th>pos_inc2_enc_1</th>\n",
       "      <th>pos_size_le</th>\n",
       "      <th>pos_range</th>\n",
       "      <th>pos_rel</th>\n",
       "      <th>pos_zeros</th>\n",
       "      <th>pos_inc_rng</th>\n",
       "      <th>pos_zeros_le</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>PxlMin_grp_le</th>\n",
       "      <th>weights</th>\n",
       "      <th>any2</th>\n",
       "      <th>epidural2</th>\n",
       "      <th>intraparenchymal2</th>\n",
       "      <th>intraventricular2</th>\n",
       "      <th>subarachnoid2</th>\n",
       "      <th>subdural2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183829</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b867760e2</td>\n",
       "      <td>ID_b867760e2</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '63.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>0.841333</td>\n",
       "      <td>-0.961477</td>\n",
       "      <td>0.754339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>63.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.147708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.152542</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084746</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106245</th>\n",
       "      <td>2.0</td>\n",
       "      <td>bc4054157</td>\n",
       "      <td>ID_bc4054157</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '68.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.302667</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>-0.981734</td>\n",
       "      <td>0.762372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>68.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.140544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.084746</td>\n",
       "      <td>1</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362507</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5d62cc5c7</td>\n",
       "      <td>ID_5d62cc5c7</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '73.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.310667</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>-1.000766</td>\n",
       "      <td>0.779547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>73.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.133381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.016949</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.757576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55311</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3ce444e82</td>\n",
       "      <td>ID_3ce444e82</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '78.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>-0.991928</td>\n",
       "      <td>0.843982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>78.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.949153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420941</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18b2ba4c8</td>\n",
       "      <td>ID_18b2ba4c8</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '83.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.314667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>-0.962363</td>\n",
       "      <td>0.910149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>83.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.119054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>4</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.515151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300366</th>\n",
       "      <td>2.0</td>\n",
       "      <td>396e28829</td>\n",
       "      <td>ID_396e28829</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '88.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>-0.933907</td>\n",
       "      <td>0.936926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>88.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.111891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.813559</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153659</th>\n",
       "      <td>2.0</td>\n",
       "      <td>acf76cddc</td>\n",
       "      <td>ID_acf76cddc</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '93.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>-0.867829</td>\n",
       "      <td>0.978963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>93.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.104728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.745763</td>\n",
       "      <td>6</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643991</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ca0f1bd1f</td>\n",
       "      <td>ID_ca0f1bd1f</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '98.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.306667</td>\n",
       "      <td>0.145333</td>\n",
       "      <td>-0.807630</td>\n",
       "      <td>1.034565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>98.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.097564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.677966</td>\n",
       "      <td>7</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.007825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99751</th>\n",
       "      <td>2.0</td>\n",
       "      <td>601be48cc</td>\n",
       "      <td>ID_601be48cc</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '103.900024']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>-0.818013</td>\n",
       "      <td>1.061267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>103.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.090401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.610169</td>\n",
       "      <td>8</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.032839</td>\n",
       "      <td>0.037040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387211</th>\n",
       "      <td>2.0</td>\n",
       "      <td>aa19146ca</td>\n",
       "      <td>ID_aa19146ca</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '108.900024']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>0.281333</td>\n",
       "      <td>-0.838944</td>\n",
       "      <td>1.060826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>108.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.542373</td>\n",
       "      <td>9</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.543668</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.322572</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.135512</td>\n",
       "      <td>0.124260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459452</th>\n",
       "      <td>2.0</td>\n",
       "      <td>942078d6e</td>\n",
       "      <td>ID_942078d6e</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '113.900024']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>-0.899123</td>\n",
       "      <td>1.030091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>113.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.076074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.474576</td>\n",
       "      <td>10</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.499969</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.787878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.918656</td>\n",
       "      <td>0.024115</td>\n",
       "      <td>0.763064</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.315124</td>\n",
       "      <td>0.261145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451127</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1ecb66d35</td>\n",
       "      <td>ID_1ecb66d35</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '118.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.304000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>-0.978931</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>118.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.068911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.406780</td>\n",
       "      <td>11</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>1.499969</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.666668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.933054</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.762358</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.455088</td>\n",
       "      <td>0.252591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459214</th>\n",
       "      <td>2.0</td>\n",
       "      <td>874186cc5</td>\n",
       "      <td>ID_874186cc5</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '123.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>-0.041333</td>\n",
       "      <td>-0.988445</td>\n",
       "      <td>0.981606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>123.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.061748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.338983</td>\n",
       "      <td>12</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.920954</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.770226</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.563334</td>\n",
       "      <td>0.263610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118858</th>\n",
       "      <td>2.0</td>\n",
       "      <td>94ea99fbd</td>\n",
       "      <td>ID_94ea99fbd</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '128.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>-0.050667</td>\n",
       "      <td>-0.970255</td>\n",
       "      <td>0.993065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>128.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.054585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.271186</td>\n",
       "      <td>13</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.424243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.893019</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.717446</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.444525</td>\n",
       "      <td>0.180911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291418</th>\n",
       "      <td>2.0</td>\n",
       "      <td>656b6f494</td>\n",
       "      <td>ID_656b6f494</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '133.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.968606</td>\n",
       "      <td>1.002038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>133.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.047421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.203390</td>\n",
       "      <td>14</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.303031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.980438</td>\n",
       "      <td>0.009472</td>\n",
       "      <td>0.960037</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.337606</td>\n",
       "      <td>0.172147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473382</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ef16919b5</td>\n",
       "      <td>ID_ef16919b5</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '138.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.306667</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>-0.960171</td>\n",
       "      <td>1.014549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>138.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.040258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>15</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.181819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.988262</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.186669</td>\n",
       "      <td>0.121601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302721</th>\n",
       "      <td>2.0</td>\n",
       "      <td>f20709350</td>\n",
       "      <td>ID_f20709350</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '143.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.304000</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-0.940240</td>\n",
       "      <td>1.023711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>143.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.033095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.060607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.991860</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.135515</td>\n",
       "      <td>0.110268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401418</th>\n",
       "      <td>2.0</td>\n",
       "      <td>197a36d5d</td>\n",
       "      <td>ID_197a36d5d</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '148.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.936556</td>\n",
       "      <td>1.014516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>148.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.025931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.969767</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.967911</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.115135</td>\n",
       "      <td>0.092102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335737</th>\n",
       "      <td>2.0</td>\n",
       "      <td>fa093c6cb</td>\n",
       "      <td>ID_fa093c6cb</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '153.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>-0.022667</td>\n",
       "      <td>-0.954478</td>\n",
       "      <td>0.985129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>153.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.336236</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.302861</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.079112</td>\n",
       "      <td>0.059441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407299</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cdf49d705</td>\n",
       "      <td>ID_cdf49d705</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '158.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.313333</td>\n",
       "      <td>-0.065333</td>\n",
       "      <td>-0.973482</td>\n",
       "      <td>0.947405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>158.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.011605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.203390</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.281014</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.178869</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>0.101448</td>\n",
       "      <td>0.072873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463858</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ab11fbedf</td>\n",
       "      <td>ID_ab11fbedf</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '163.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-0.986472</td>\n",
       "      <td>0.906726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>163.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.004441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.271186</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.566976</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.428909</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.104829</td>\n",
       "      <td>0.094247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63088</th>\n",
       "      <td>2.0</td>\n",
       "      <td>acf54a89b</td>\n",
       "      <td>ID_acf54a89b</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '168.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-1.000733</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>168.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.338983</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.983561</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.975370</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.126935</td>\n",
       "      <td>0.121928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350252</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50dffd559</td>\n",
       "      <td>ID_50dffd559</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '173.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-1.017443</td>\n",
       "      <td>0.806401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>173.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.406780</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.985321</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.142108</td>\n",
       "      <td>0.139003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329738</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b13550aed</td>\n",
       "      <td>ID_b13550aed</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '178.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.314667</td>\n",
       "      <td>-0.274667</td>\n",
       "      <td>-1.039418</td>\n",
       "      <td>0.744862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>178.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.474576</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.787878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.986074</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.979739</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.142797</td>\n",
       "      <td>0.163557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212434</th>\n",
       "      <td>2.0</td>\n",
       "      <td>97048b0b5</td>\n",
       "      <td>ID_97048b0b5</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '183.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>-0.256000</td>\n",
       "      <td>-1.061740</td>\n",
       "      <td>0.673901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>183.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.542373</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.815646</td>\n",
       "      <td>0.013105</td>\n",
       "      <td>0.688247</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.161910</td>\n",
       "      <td>0.209642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210996</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b9799a238</td>\n",
       "      <td>ID_b9799a238</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '188.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>-0.349333</td>\n",
       "      <td>-1.082082</td>\n",
       "      <td>0.591044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>188.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.610169</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.405491</td>\n",
       "      <td>0.014217</td>\n",
       "      <td>0.102302</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.104954</td>\n",
       "      <td>0.227080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355909</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4f6986cea</td>\n",
       "      <td>ID_4f6986cea</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '193.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>-0.374667</td>\n",
       "      <td>-1.108516</td>\n",
       "      <td>0.498614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>193.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.677966</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.234505</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.061094</td>\n",
       "      <td>0.179025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517742</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64ea22498</td>\n",
       "      <td>ID_64ea22498</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '198.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>-0.540000</td>\n",
       "      <td>-1.147880</td>\n",
       "      <td>0.399292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>198.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.745763</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.140069</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>0.122967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595062</th>\n",
       "      <td>2.0</td>\n",
       "      <td>051798ab9</td>\n",
       "      <td>ID_051798ab9</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '203.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>-0.645333</td>\n",
       "      <td>-1.202330</td>\n",
       "      <td>0.287098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>203.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.813559</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.044199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122981</th>\n",
       "      <td>2.0</td>\n",
       "      <td>58226ab52</td>\n",
       "      <td>ID_58226ab52</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '208.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>-0.532000</td>\n",
       "      <td>-1.296195</td>\n",
       "      <td>0.141956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>208.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.515151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520134</th>\n",
       "      <td>2.0</td>\n",
       "      <td>327587846</td>\n",
       "      <td>ID_327587846</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '213.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>-0.649333</td>\n",
       "      <td>-1.494685</td>\n",
       "      <td>-0.061172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>213.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.949153</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208401</th>\n",
       "      <td>2.0</td>\n",
       "      <td>36108c996</td>\n",
       "      <td>ID_36108c996</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '218.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.306667</td>\n",
       "      <td>-1.052000</td>\n",
       "      <td>-1.962864</td>\n",
       "      <td>-0.331970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>218.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.016949</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.757576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85848</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5873a24d6</td>\n",
       "      <td>ID_5873a24d6</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '223.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>-1.556000</td>\n",
       "      <td>-2.590599</td>\n",
       "      <td>-0.575175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>223.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>32</td>\n",
       "      <td>-1.084746</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.878788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24414</th>\n",
       "      <td>2.0</td>\n",
       "      <td>a61bb8480</td>\n",
       "      <td>ID_a61bb8480</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '228.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>-1.546667</td>\n",
       "      <td>-2.807197</td>\n",
       "      <td>-0.682076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>228.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.084746</td>\n",
       "      <td>33</td>\n",
       "      <td>-1.152542</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold     img_id SOPInstanceUID Modality    PatientID StudyInstanceUID  \\\n",
       "183829   2.0  b867760e2   ID_b867760e2       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "106245   2.0  bc4054157   ID_bc4054157       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "362507   2.0  5d62cc5c7   ID_5d62cc5c7       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "55311    2.0  3ce444e82   ID_3ce444e82       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "420941   2.0  18b2ba4c8   ID_18b2ba4c8       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "300366   2.0  396e28829   ID_396e28829       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "153659   2.0  acf76cddc   ID_acf76cddc       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "643991   2.0  ca0f1bd1f   ID_ca0f1bd1f       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "99751    2.0  601be48cc   ID_601be48cc       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "387211   2.0  aa19146ca   ID_aa19146ca       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "459452   2.0  942078d6e   ID_942078d6e       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "451127   2.0  1ecb66d35   ID_1ecb66d35       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "459214   2.0  874186cc5   ID_874186cc5       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "118858   2.0  94ea99fbd   ID_94ea99fbd       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "291418   2.0  656b6f494   ID_656b6f494       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "473382   2.0  ef16919b5   ID_ef16919b5       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "302721   2.0  f20709350   ID_f20709350       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "401418   2.0  197a36d5d   ID_197a36d5d       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "335737   2.0  fa093c6cb   ID_fa093c6cb       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "407299   2.0  cdf49d705   ID_cdf49d705       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "463858   2.0  ab11fbedf   ID_ab11fbedf       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "63088    2.0  acf54a89b   ID_acf54a89b       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "350252   2.0  50dffd559   ID_50dffd559       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "329738   2.0  b13550aed   ID_b13550aed       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "212434   2.0  97048b0b5   ID_97048b0b5       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "210996   2.0  b9799a238   ID_b9799a238       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "355909   2.0  4f6986cea   ID_4f6986cea       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "517742   2.0  64ea22498   ID_64ea22498       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "595062   2.0  051798ab9   ID_051798ab9       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "122981   2.0  58226ab52   ID_58226ab52       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "520134   2.0  327587846   ID_327587846       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "208401   2.0  36108c996   ID_36108c996       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "85848    2.0  5873a24d6   ID_5873a24d6       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "24414    2.0  a61bb8480   ID_a61bb8480       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "\n",
       "       SeriesInstanceUID  StudyID                        ImagePositionPatient  \\\n",
       "183829     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '63.9000244']   \n",
       "106245     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '68.9000244']   \n",
       "362507     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '73.9000244']   \n",
       "55311      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '78.9000244']   \n",
       "420941     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '83.9000244']   \n",
       "300366     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '88.9000244']   \n",
       "153659     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '93.9000244']   \n",
       "643991     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '98.9000244']   \n",
       "99751      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '103.900024']   \n",
       "387211     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '108.900024']   \n",
       "459452     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '113.900024']   \n",
       "451127     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '118.899963']   \n",
       "459214     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '123.899963']   \n",
       "118858     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '128.899963']   \n",
       "291418     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '133.899963']   \n",
       "473382     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '138.899963']   \n",
       "302721     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '143.899963']   \n",
       "401418     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '148.899963']   \n",
       "335737     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '153.899963']   \n",
       "407299     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '158.899963']   \n",
       "463858     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '163.899963']   \n",
       "63088      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '168.899963']   \n",
       "350252     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '173.899963']   \n",
       "329738     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '178.899963']   \n",
       "212434     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '183.899963']   \n",
       "210996     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '188.899963']   \n",
       "355909     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '193.899963']   \n",
       "517742     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '198.899963']   \n",
       "595062     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '203.899963']   \n",
       "122981     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '208.899963']   \n",
       "520134     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '213.899963']   \n",
       "208401     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '218.899963']   \n",
       "85848      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '223.899963']   \n",
       "24414      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '228.899963']   \n",
       "\n",
       "               ImageOrientationPatient  SamplesPerPixel  \\\n",
       "183829  ['1', '0', '0', '0', '1', '0']                1   \n",
       "106245  ['1', '0', '0', '0', '1', '0']                1   \n",
       "362507  ['1', '0', '0', '0', '1', '0']                1   \n",
       "55311   ['1', '0', '0', '0', '1', '0']                1   \n",
       "420941  ['1', '0', '0', '0', '1', '0']                1   \n",
       "300366  ['1', '0', '0', '0', '1', '0']                1   \n",
       "153659  ['1', '0', '0', '0', '1', '0']                1   \n",
       "643991  ['1', '0', '0', '0', '1', '0']                1   \n",
       "99751   ['1', '0', '0', '0', '1', '0']                1   \n",
       "387211  ['1', '0', '0', '0', '1', '0']                1   \n",
       "459452  ['1', '0', '0', '0', '1', '0']                1   \n",
       "451127  ['1', '0', '0', '0', '1', '0']                1   \n",
       "459214  ['1', '0', '0', '0', '1', '0']                1   \n",
       "118858  ['1', '0', '0', '0', '1', '0']                1   \n",
       "291418  ['1', '0', '0', '0', '1', '0']                1   \n",
       "473382  ['1', '0', '0', '0', '1', '0']                1   \n",
       "302721  ['1', '0', '0', '0', '1', '0']                1   \n",
       "401418  ['1', '0', '0', '0', '1', '0']                1   \n",
       "335737  ['1', '0', '0', '0', '1', '0']                1   \n",
       "407299  ['1', '0', '0', '0', '1', '0']                1   \n",
       "463858  ['1', '0', '0', '0', '1', '0']                1   \n",
       "63088   ['1', '0', '0', '0', '1', '0']                1   \n",
       "350252  ['1', '0', '0', '0', '1', '0']                1   \n",
       "329738  ['1', '0', '0', '0', '1', '0']                1   \n",
       "212434  ['1', '0', '0', '0', '1', '0']                1   \n",
       "210996  ['1', '0', '0', '0', '1', '0']                1   \n",
       "355909  ['1', '0', '0', '0', '1', '0']                1   \n",
       "517742  ['1', '0', '0', '0', '1', '0']                1   \n",
       "595062  ['1', '0', '0', '0', '1', '0']                1   \n",
       "122981  ['1', '0', '0', '0', '1', '0']                1   \n",
       "520134  ['1', '0', '0', '0', '1', '0']                1   \n",
       "208401  ['1', '0', '0', '0', '1', '0']                1   \n",
       "85848   ['1', '0', '0', '0', '1', '0']                1   \n",
       "24414   ['1', '0', '0', '0', '1', '0']                1   \n",
       "\n",
       "       PhotometricInterpretation  Rows  Columns                  PixelSpacing  \\\n",
       "183829               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "106245               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "362507               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "55311                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "420941               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "300366               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "153659               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "643991               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "99751                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "387211               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "459452               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "451127               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "459214               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "118858               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "291418               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "473382               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "302721               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "401418               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "335737               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "407299               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "463858               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "63088                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "350252               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "329738               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "212434               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "210996               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "355909               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "517742               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "595062               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "122981               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "520134               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "208401               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "85848                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "24414                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "\n",
       "        BitsAllocated  BitsStored  HighBit  PixelRepresentation  \\\n",
       "183829             16          12       11                    0   \n",
       "106245             16          12       11                    0   \n",
       "362507             16          12       11                    0   \n",
       "55311              16          12       11                    0   \n",
       "420941             16          12       11                    0   \n",
       "300366             16          12       11                    0   \n",
       "153659             16          12       11                    0   \n",
       "643991             16          12       11                    0   \n",
       "99751              16          12       11                    0   \n",
       "387211             16          12       11                    0   \n",
       "459452             16          12       11                    0   \n",
       "451127             16          12       11                    0   \n",
       "459214             16          12       11                    0   \n",
       "118858             16          12       11                    0   \n",
       "291418             16          12       11                    0   \n",
       "473382             16          12       11                    0   \n",
       "302721             16          12       11                    0   \n",
       "401418             16          12       11                    0   \n",
       "335737             16          12       11                    0   \n",
       "407299             16          12       11                    0   \n",
       "463858             16          12       11                    0   \n",
       "63088              16          12       11                    0   \n",
       "350252             16          12       11                    0   \n",
       "329738             16          12       11                    0   \n",
       "212434             16          12       11                    0   \n",
       "210996             16          12       11                    0   \n",
       "355909             16          12       11                    0   \n",
       "517742             16          12       11                    0   \n",
       "595062             16          12       11                    0   \n",
       "122981             16          12       11                    0   \n",
       "520134             16          12       11                    0   \n",
       "208401             16          12       11                    0   \n",
       "85848              16          12       11                    0   \n",
       "24414              16          12       11                    0   \n",
       "\n",
       "              WindowCenter         WindowWidth  RescaleIntercept  \\\n",
       "183829  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "106245  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "362507  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "55311   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "420941  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "300366  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "153659  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "643991  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "99751   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "387211  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "459452  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "451127  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "459214  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "118858  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "291418  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "473382  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "302721  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "401418  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "335737  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "407299  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "463858  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "63088   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "350252  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "329738  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "212434  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "210996  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "355909  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "517742  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "595062  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "122981  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "520134  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "208401  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "85848   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "24414   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "\n",
       "        RescaleSlope    PxlMin    PxlMax    PxlStd   PxlMean  \\\n",
       "183829           1.0  1.301333  0.841333 -0.961477  0.754339   \n",
       "106245           1.0  1.302667  0.580000 -0.981734  0.762372   \n",
       "362507           1.0  1.310667  0.632000 -1.000766  0.779547   \n",
       "55311            1.0  1.316000  0.136000 -0.991928  0.843982   \n",
       "420941           1.0  1.314667  0.006667 -0.962363  0.910149   \n",
       "300366           1.0  1.312000 -0.048000 -0.933907  0.936926   \n",
       "153659           1.0  1.309333  0.018667 -0.867829  0.978963   \n",
       "643991           1.0  1.306667  0.145333 -0.807630  1.034565   \n",
       "99751            1.0  1.305333  0.060000 -0.818013  1.061267   \n",
       "387211           1.0  1.301333  0.281333 -0.838944  1.060826   \n",
       "459452           1.0  1.301333  0.028000 -0.899123  1.030091   \n",
       "451127           1.0  1.304000 -0.024000 -0.978931  0.988314   \n",
       "459214           1.0  1.308000 -0.041333 -0.988445  0.981606   \n",
       "118858           1.0  1.301333 -0.050667 -0.970255  0.993065   \n",
       "291418           1.0  1.301333 -0.066667 -0.968606  1.002038   \n",
       "473382           1.0  1.306667 -0.032000 -0.960171  1.014549   \n",
       "302721           1.0  1.304000 -0.012000 -0.940240  1.023711   \n",
       "401418           1.0  1.309333  0.000000 -0.936556  1.014516   \n",
       "335737           1.0  1.309333 -0.022667 -0.954478  0.985129   \n",
       "407299           1.0  1.313333 -0.065333 -0.973482  0.947405   \n",
       "463858           1.0  1.309333 -0.012000 -0.986472  0.906726   \n",
       "63088            1.0  1.308000 -0.133333 -1.000733  0.860140   \n",
       "350252           1.0  1.312000 -0.200000 -1.017443  0.806401   \n",
       "329738           1.0  1.314667 -0.274667 -1.039418  0.744862   \n",
       "212434           1.0  1.316000 -0.256000 -1.061740  0.673901   \n",
       "210996           1.0  1.309333 -0.349333 -1.082082  0.591044   \n",
       "355909           1.0  1.305333 -0.374667 -1.108516  0.498614   \n",
       "517742           1.0  1.301333 -0.540000 -1.147880  0.399292   \n",
       "595062           1.0  1.305333 -0.645333 -1.202330  0.287098   \n",
       "122981           1.0  1.316000 -0.532000 -1.296195  0.141956   \n",
       "520134           1.0  1.308000 -0.649333 -1.494685 -0.061172   \n",
       "208401           1.0  1.306667 -1.052000 -1.962864 -0.331970   \n",
       "85848            1.0  1.305333 -1.556000 -2.590599 -0.575175   \n",
       "24414            1.0  1.312000 -1.546667 -2.807197 -0.682076   \n",
       "\n",
       "        ImageOrientationPatient_0  ImageOrientationPatient_1  \\\n",
       "183829                        1.0                        0.0   \n",
       "106245                        1.0                        0.0   \n",
       "362507                        1.0                        0.0   \n",
       "55311                         1.0                        0.0   \n",
       "420941                        1.0                        0.0   \n",
       "300366                        1.0                        0.0   \n",
       "153659                        1.0                        0.0   \n",
       "643991                        1.0                        0.0   \n",
       "99751                         1.0                        0.0   \n",
       "387211                        1.0                        0.0   \n",
       "459452                        1.0                        0.0   \n",
       "451127                        1.0                        0.0   \n",
       "459214                        1.0                        0.0   \n",
       "118858                        1.0                        0.0   \n",
       "291418                        1.0                        0.0   \n",
       "473382                        1.0                        0.0   \n",
       "302721                        1.0                        0.0   \n",
       "401418                        1.0                        0.0   \n",
       "335737                        1.0                        0.0   \n",
       "407299                        1.0                        0.0   \n",
       "463858                        1.0                        0.0   \n",
       "63088                         1.0                        0.0   \n",
       "350252                        1.0                        0.0   \n",
       "329738                        1.0                        0.0   \n",
       "212434                        1.0                        0.0   \n",
       "210996                        1.0                        0.0   \n",
       "355909                        1.0                        0.0   \n",
       "517742                        1.0                        0.0   \n",
       "595062                        1.0                        0.0   \n",
       "122981                        1.0                        0.0   \n",
       "520134                        1.0                        0.0   \n",
       "208401                        1.0                        0.0   \n",
       "85848                         1.0                        0.0   \n",
       "24414                         1.0                        0.0   \n",
       "\n",
       "        ImageOrientationPatient_2  ImageOrientationPatient_3  \\\n",
       "183829                        0.0                        0.0   \n",
       "106245                        0.0                        0.0   \n",
       "362507                        0.0                        0.0   \n",
       "55311                         0.0                        0.0   \n",
       "420941                        0.0                        0.0   \n",
       "300366                        0.0                        0.0   \n",
       "153659                        0.0                        0.0   \n",
       "643991                        0.0                        0.0   \n",
       "99751                         0.0                        0.0   \n",
       "387211                        0.0                        0.0   \n",
       "459452                        0.0                        0.0   \n",
       "451127                        0.0                        0.0   \n",
       "459214                        0.0                        0.0   \n",
       "118858                        0.0                        0.0   \n",
       "291418                        0.0                        0.0   \n",
       "473382                        0.0                        0.0   \n",
       "302721                        0.0                        0.0   \n",
       "401418                        0.0                        0.0   \n",
       "335737                        0.0                        0.0   \n",
       "407299                        0.0                        0.0   \n",
       "463858                        0.0                        0.0   \n",
       "63088                         0.0                        0.0   \n",
       "350252                        0.0                        0.0   \n",
       "329738                        0.0                        0.0   \n",
       "212434                        0.0                        0.0   \n",
       "210996                        0.0                        0.0   \n",
       "355909                        0.0                        0.0   \n",
       "517742                        0.0                        0.0   \n",
       "595062                        0.0                        0.0   \n",
       "122981                        0.0                        0.0   \n",
       "520134                        0.0                        0.0   \n",
       "208401                        0.0                        0.0   \n",
       "85848                         0.0                        0.0   \n",
       "24414                         0.0                        0.0   \n",
       "\n",
       "        ImageOrientationPatient_4  ImageOrientationPatient_5  \\\n",
       "183829                        1.0                        0.0   \n",
       "106245                        1.0                        0.0   \n",
       "362507                        1.0                        0.0   \n",
       "55311                         1.0                        0.0   \n",
       "420941                        1.0                        0.0   \n",
       "300366                        1.0                        0.0   \n",
       "153659                        1.0                        0.0   \n",
       "643991                        1.0                        0.0   \n",
       "99751                         1.0                        0.0   \n",
       "387211                        1.0                        0.0   \n",
       "459452                        1.0                        0.0   \n",
       "451127                        1.0                        0.0   \n",
       "459214                        1.0                        0.0   \n",
       "118858                        1.0                        0.0   \n",
       "291418                        1.0                        0.0   \n",
       "473382                        1.0                        0.0   \n",
       "302721                        1.0                        0.0   \n",
       "401418                        1.0                        0.0   \n",
       "335737                        1.0                        0.0   \n",
       "407299                        1.0                        0.0   \n",
       "463858                        1.0                        0.0   \n",
       "63088                         1.0                        0.0   \n",
       "350252                        1.0                        0.0   \n",
       "329738                        1.0                        0.0   \n",
       "212434                        1.0                        0.0   \n",
       "210996                        1.0                        0.0   \n",
       "355909                        1.0                        0.0   \n",
       "517742                        1.0                        0.0   \n",
       "595062                        1.0                        0.0   \n",
       "122981                        1.0                        0.0   \n",
       "520134                        1.0                        0.0   \n",
       "208401                        1.0                        0.0   \n",
       "85848                         1.0                        0.0   \n",
       "24414                         1.0                        0.0   \n",
       "\n",
       "        ImagePositionPatient_0  ImagePositionPatient_1  \\\n",
       "183829              -122.73329                45.99968   \n",
       "106245              -122.73329                45.99968   \n",
       "362507              -122.73329                45.99968   \n",
       "55311               -122.73329                45.99968   \n",
       "420941              -122.73329                45.99968   \n",
       "300366              -122.73329                45.99968   \n",
       "153659              -122.73329                45.99968   \n",
       "643991              -122.73329                45.99968   \n",
       "99751               -122.73329                45.99968   \n",
       "387211              -122.73329                45.99968   \n",
       "459452              -122.73329                45.99968   \n",
       "451127              -122.73329                45.99968   \n",
       "459214              -122.73329                45.99968   \n",
       "118858              -122.73329                45.99968   \n",
       "291418              -122.73329                45.99968   \n",
       "473382              -122.73329                45.99968   \n",
       "302721              -122.73329                45.99968   \n",
       "401418              -122.73329                45.99968   \n",
       "335737              -122.73329                45.99968   \n",
       "407299              -122.73329                45.99968   \n",
       "463858              -122.73329                45.99968   \n",
       "63088               -122.73329                45.99968   \n",
       "350252              -122.73329                45.99968   \n",
       "329738              -122.73329                45.99968   \n",
       "212434              -122.73329                45.99968   \n",
       "210996              -122.73329                45.99968   \n",
       "355909              -122.73329                45.99968   \n",
       "517742              -122.73329                45.99968   \n",
       "595062              -122.73329                45.99968   \n",
       "122981              -122.73329                45.99968   \n",
       "520134              -122.73329                45.99968   \n",
       "208401              -122.73329                45.99968   \n",
       "85848               -122.73329                45.99968   \n",
       "24414               -122.73329                45.99968   \n",
       "\n",
       "        ImagePositionPatient_2  PixelSpacing_0  PixelSpacing_1  \\\n",
       "183829               63.900024        0.488281        0.488281   \n",
       "106245               68.900024        0.488281        0.488281   \n",
       "362507               73.900024        0.488281        0.488281   \n",
       "55311                78.900024        0.488281        0.488281   \n",
       "420941               83.900024        0.488281        0.488281   \n",
       "300366               88.900024        0.488281        0.488281   \n",
       "153659               93.900024        0.488281        0.488281   \n",
       "643991               98.900024        0.488281        0.488281   \n",
       "99751               103.900024        0.488281        0.488281   \n",
       "387211              108.900024        0.488281        0.488281   \n",
       "459452              113.900024        0.488281        0.488281   \n",
       "451127              118.899963        0.488281        0.488281   \n",
       "459214              123.899963        0.488281        0.488281   \n",
       "118858              128.899963        0.488281        0.488281   \n",
       "291418              133.899963        0.488281        0.488281   \n",
       "473382              138.899963        0.488281        0.488281   \n",
       "302721              143.899963        0.488281        0.488281   \n",
       "401418              148.899963        0.488281        0.488281   \n",
       "335737              153.899963        0.488281        0.488281   \n",
       "407299              158.899963        0.488281        0.488281   \n",
       "463858              163.899963        0.488281        0.488281   \n",
       "63088               168.899963        0.488281        0.488281   \n",
       "350252              173.899963        0.488281        0.488281   \n",
       "329738              178.899963        0.488281        0.488281   \n",
       "212434              183.899963        0.488281        0.488281   \n",
       "210996              188.899963        0.488281        0.488281   \n",
       "355909              193.899963        0.488281        0.488281   \n",
       "517742              198.899963        0.488281        0.488281   \n",
       "595062              203.899963        0.488281        0.488281   \n",
       "122981              208.899963        0.488281        0.488281   \n",
       "520134              213.899963        0.488281        0.488281   \n",
       "208401              218.899963        0.488281        0.488281   \n",
       "85848               223.899963        0.488281        0.488281   \n",
       "24414               228.899963        0.488281        0.488281   \n",
       "\n",
       "        WindowCenter_0  WindowCenter_1  WindowCenter_1_NAN  WindowWidth_0  \\\n",
       "183829            36.0            36.0               False           80.0   \n",
       "106245            36.0            36.0               False           80.0   \n",
       "362507            36.0            36.0               False           80.0   \n",
       "55311             36.0            36.0               False           80.0   \n",
       "420941            36.0            36.0               False           80.0   \n",
       "300366            36.0            36.0               False           80.0   \n",
       "153659            36.0            36.0               False           80.0   \n",
       "643991            36.0            36.0               False           80.0   \n",
       "99751             36.0            36.0               False           80.0   \n",
       "387211            36.0            36.0               False           80.0   \n",
       "459452            36.0            36.0               False           80.0   \n",
       "451127            36.0            36.0               False           80.0   \n",
       "459214            36.0            36.0               False           80.0   \n",
       "118858            36.0            36.0               False           80.0   \n",
       "291418            36.0            36.0               False           80.0   \n",
       "473382            36.0            36.0               False           80.0   \n",
       "302721            36.0            36.0               False           80.0   \n",
       "401418            36.0            36.0               False           80.0   \n",
       "335737            36.0            36.0               False           80.0   \n",
       "407299            36.0            36.0               False           80.0   \n",
       "463858            36.0            36.0               False           80.0   \n",
       "63088             36.0            36.0               False           80.0   \n",
       "350252            36.0            36.0               False           80.0   \n",
       "329738            36.0            36.0               False           80.0   \n",
       "212434            36.0            36.0               False           80.0   \n",
       "210996            36.0            36.0               False           80.0   \n",
       "355909            36.0            36.0               False           80.0   \n",
       "517742            36.0            36.0               False           80.0   \n",
       "595062            36.0            36.0               False           80.0   \n",
       "122981            36.0            36.0               False           80.0   \n",
       "520134            36.0            36.0               False           80.0   \n",
       "208401            36.0            36.0               False           80.0   \n",
       "85848             36.0            36.0               False           80.0   \n",
       "24414             36.0            36.0               False           80.0   \n",
       "\n",
       "        WindowWidth_1  WindowWidth_0_le  WindowWidth_1_le  WindowCenter_1_le  \\\n",
       "183829           80.0                 0                 0                  0   \n",
       "106245           80.0                 0                 0                  0   \n",
       "362507           80.0                 0                 0                  0   \n",
       "55311            80.0                 0                 0                  0   \n",
       "420941           80.0                 0                 0                  0   \n",
       "300366           80.0                 0                 0                  0   \n",
       "153659           80.0                 0                 0                  0   \n",
       "643991           80.0                 0                 0                  0   \n",
       "99751            80.0                 0                 0                  0   \n",
       "387211           80.0                 0                 0                  0   \n",
       "459452           80.0                 0                 0                  0   \n",
       "451127           80.0                 0                 0                  0   \n",
       "459214           80.0                 0                 0                  0   \n",
       "118858           80.0                 0                 0                  0   \n",
       "291418           80.0                 0                 0                  0   \n",
       "473382           80.0                 0                 0                  0   \n",
       "302721           80.0                 0                 0                  0   \n",
       "401418           80.0                 0                 0                  0   \n",
       "335737           80.0                 0                 0                  0   \n",
       "407299           80.0                 0                 0                  0   \n",
       "463858           80.0                 0                 0                  0   \n",
       "63088            80.0                 0                 0                  0   \n",
       "350252           80.0                 0                 0                  0   \n",
       "329738           80.0                 0                 0                  0   \n",
       "212434           80.0                 0                 0                  0   \n",
       "210996           80.0                 0                 0                  0   \n",
       "355909           80.0                 0                 0                  0   \n",
       "517742           80.0                 0                 0                  0   \n",
       "595062           80.0                 0                 0                  0   \n",
       "122981           80.0                 0                 0                  0   \n",
       "520134           80.0                 0                 0                  0   \n",
       "208401           80.0                 0                 0                  0   \n",
       "85848            80.0                 0                 0                  0   \n",
       "24414            80.0                 0                 0                  0   \n",
       "\n",
       "        BitType_le  ImageOrientationPatient_4_f  \\\n",
       "183829           1                    -1.333333   \n",
       "106245           1                    -1.333333   \n",
       "362507           1                    -1.333333   \n",
       "55311            1                    -1.333333   \n",
       "420941           1                    -1.333333   \n",
       "300366           1                    -1.333333   \n",
       "153659           1                    -1.333333   \n",
       "643991           1                    -1.333333   \n",
       "99751            1                    -1.333333   \n",
       "387211           1                    -1.333333   \n",
       "459452           1                    -1.333333   \n",
       "451127           1                    -1.333333   \n",
       "459214           1                    -1.333333   \n",
       "118858           1                    -1.333333   \n",
       "291418           1                    -1.333333   \n",
       "473382           1                    -1.333333   \n",
       "302721           1                    -1.333333   \n",
       "401418           1                    -1.333333   \n",
       "335737           1                    -1.333333   \n",
       "407299           1                    -1.333333   \n",
       "463858           1                    -1.333333   \n",
       "63088            1                    -1.333333   \n",
       "350252           1                    -1.333333   \n",
       "329738           1                    -1.333333   \n",
       "212434           1                    -1.333333   \n",
       "210996           1                    -1.333333   \n",
       "355909           1                    -1.333333   \n",
       "517742           1                    -1.333333   \n",
       "595062           1                    -1.333333   \n",
       "122981           1                    -1.333333   \n",
       "520134           1                    -1.333333   \n",
       "208401           1                    -1.333333   \n",
       "85848            1                    -1.333333   \n",
       "24414            1                    -1.333333   \n",
       "\n",
       "        ImageOrientationPatient_4_enc_0  ImageOrientationPatient_4_enc_1  ...  \\\n",
       "183829                              1.0                              0.0  ...   \n",
       "106245                              1.0                              0.0  ...   \n",
       "362507                              1.0                              0.0  ...   \n",
       "55311                               1.0                              0.0  ...   \n",
       "420941                              1.0                              0.0  ...   \n",
       "300366                              1.0                              0.0  ...   \n",
       "153659                              1.0                              0.0  ...   \n",
       "643991                              1.0                              0.0  ...   \n",
       "99751                               1.0                              0.0  ...   \n",
       "387211                              1.0                              0.0  ...   \n",
       "459452                              1.0                              0.0  ...   \n",
       "451127                              1.0                              0.0  ...   \n",
       "459214                              1.0                              0.0  ...   \n",
       "118858                              1.0                              0.0  ...   \n",
       "291418                              1.0                              0.0  ...   \n",
       "473382                              1.0                              0.0  ...   \n",
       "302721                              1.0                              0.0  ...   \n",
       "401418                              1.0                              0.0  ...   \n",
       "335737                              1.0                              0.0  ...   \n",
       "407299                              1.0                              0.0  ...   \n",
       "463858                              1.0                              0.0  ...   \n",
       "63088                               1.0                              0.0  ...   \n",
       "350252                              1.0                              0.0  ...   \n",
       "329738                              1.0                              0.0  ...   \n",
       "212434                              1.0                              0.0  ...   \n",
       "210996                              1.0                              0.0  ...   \n",
       "355909                              1.0                              0.0  ...   \n",
       "517742                              1.0                              0.0  ...   \n",
       "595062                              1.0                              0.0  ...   \n",
       "122981                              1.0                              0.0  ...   \n",
       "520134                              1.0                              0.0  ...   \n",
       "208401                              1.0                              0.0  ...   \n",
       "85848                               1.0                              0.0  ...   \n",
       "24414                               1.0                              0.0  ...   \n",
       "\n",
       "        ImageOrientationPatient_5_enc_1  ImagePositionPatient_0_f  \\\n",
       "183829                            False                  1.340446   \n",
       "106245                            False                  1.340446   \n",
       "362507                            False                  1.340446   \n",
       "55311                             False                  1.340446   \n",
       "420941                            False                  1.340446   \n",
       "300366                            False                  1.340446   \n",
       "153659                            False                  1.340446   \n",
       "643991                            False                  1.340446   \n",
       "99751                             False                  1.340446   \n",
       "387211                            False                  1.340446   \n",
       "459452                            False                  1.340446   \n",
       "451127                            False                  1.340446   \n",
       "459214                            False                  1.340446   \n",
       "118858                            False                  1.340446   \n",
       "291418                            False                  1.340446   \n",
       "473382                            False                  1.340446   \n",
       "302721                            False                  1.340446   \n",
       "401418                            False                  1.340446   \n",
       "335737                            False                  1.340446   \n",
       "407299                            False                  1.340446   \n",
       "463858                            False                  1.340446   \n",
       "63088                             False                  1.340446   \n",
       "350252                            False                  1.340446   \n",
       "329738                            False                  1.340446   \n",
       "212434                            False                  1.340446   \n",
       "210996                            False                  1.340446   \n",
       "355909                            False                  1.340446   \n",
       "517742                            False                  1.340446   \n",
       "595062                            False                  1.340446   \n",
       "122981                            False                  1.340446   \n",
       "520134                            False                  1.340446   \n",
       "208401                            False                  1.340446   \n",
       "85848                             False                  1.340446   \n",
       "24414                             False                  1.340446   \n",
       "\n",
       "        ImagePositionPatient_0_enc_0  ImagePositionPatient_0_enc_1  \\\n",
       "183829                           0.0                           0.0   \n",
       "106245                           0.0                           0.0   \n",
       "362507                           0.0                           0.0   \n",
       "55311                            0.0                           0.0   \n",
       "420941                           0.0                           0.0   \n",
       "300366                           0.0                           0.0   \n",
       "153659                           0.0                           0.0   \n",
       "643991                           0.0                           0.0   \n",
       "99751                            0.0                           0.0   \n",
       "387211                           0.0                           0.0   \n",
       "459452                           0.0                           0.0   \n",
       "451127                           0.0                           0.0   \n",
       "459214                           0.0                           0.0   \n",
       "118858                           0.0                           0.0   \n",
       "291418                           0.0                           0.0   \n",
       "473382                           0.0                           0.0   \n",
       "302721                           0.0                           0.0   \n",
       "401418                           0.0                           0.0   \n",
       "335737                           0.0                           0.0   \n",
       "407299                           0.0                           0.0   \n",
       "463858                           0.0                           0.0   \n",
       "63088                            0.0                           0.0   \n",
       "350252                           0.0                           0.0   \n",
       "329738                           0.0                           0.0   \n",
       "212434                           0.0                           0.0   \n",
       "210996                           0.0                           0.0   \n",
       "355909                           0.0                           0.0   \n",
       "517742                           0.0                           0.0   \n",
       "595062                           0.0                           0.0   \n",
       "122981                           0.0                           0.0   \n",
       "520134                           0.0                           0.0   \n",
       "208401                           0.0                           0.0   \n",
       "85848                            0.0                           0.0   \n",
       "24414                            0.0                           0.0   \n",
       "\n",
       "        ImagePositionPatient_0_f_r1  ImagePositionPatient_0_f_r05  \\\n",
       "183829                          0.0                           0.0   \n",
       "106245                          0.0                           0.0   \n",
       "362507                          0.0                           0.0   \n",
       "55311                           0.0                           0.0   \n",
       "420941                          0.0                           0.0   \n",
       "300366                          0.0                           0.0   \n",
       "153659                          0.0                           0.0   \n",
       "643991                          0.0                           0.0   \n",
       "99751                           0.0                           0.0   \n",
       "387211                          0.0                           0.0   \n",
       "459452                          0.0                           0.0   \n",
       "451127                          0.0                           0.0   \n",
       "459214                          0.0                           0.0   \n",
       "118858                          0.0                           0.0   \n",
       "291418                          0.0                           0.0   \n",
       "473382                          0.0                           0.0   \n",
       "302721                          0.0                           0.0   \n",
       "401418                          0.0                           0.0   \n",
       "335737                          0.0                           0.0   \n",
       "407299                          0.0                           0.0   \n",
       "463858                          0.0                           0.0   \n",
       "63088                           0.0                           0.0   \n",
       "350252                          0.0                           0.0   \n",
       "329738                          0.0                           0.0   \n",
       "212434                          0.0                           0.0   \n",
       "210996                          0.0                           0.0   \n",
       "355909                          0.0                           0.0   \n",
       "517742                          0.0                           0.0   \n",
       "595062                          0.0                           0.0   \n",
       "122981                          0.0                           0.0   \n",
       "520134                          0.0                           0.0   \n",
       "208401                          0.0                           0.0   \n",
       "85848                           0.0                           0.0   \n",
       "24414                           0.0                           0.0   \n",
       "\n",
       "        ImagePositionPatient_1_f  ImagePositionPatient_1_enc_0  \\\n",
       "183829                  1.479996                           1.0   \n",
       "106245                  1.479996                           1.0   \n",
       "362507                  1.479996                           1.0   \n",
       "55311                   1.479996                           1.0   \n",
       "420941                  1.479996                           1.0   \n",
       "300366                  1.479996                           1.0   \n",
       "153659                  1.479996                           1.0   \n",
       "643991                  1.479996                           1.0   \n",
       "99751                   1.479996                           1.0   \n",
       "387211                  1.479996                           1.0   \n",
       "459452                  1.479996                           1.0   \n",
       "451127                  1.479996                           1.0   \n",
       "459214                  1.479996                           1.0   \n",
       "118858                  1.479996                           1.0   \n",
       "291418                  1.479996                           1.0   \n",
       "473382                  1.479996                           1.0   \n",
       "302721                  1.479996                           1.0   \n",
       "401418                  1.479996                           1.0   \n",
       "335737                  1.479996                           1.0   \n",
       "407299                  1.479996                           1.0   \n",
       "463858                  1.479996                           1.0   \n",
       "63088                   1.479996                           1.0   \n",
       "350252                  1.479996                           1.0   \n",
       "329738                  1.479996                           1.0   \n",
       "212434                  1.479996                           1.0   \n",
       "210996                  1.479996                           1.0   \n",
       "355909                  1.479996                           1.0   \n",
       "517742                  1.479996                           1.0   \n",
       "595062                  1.479996                           1.0   \n",
       "122981                  1.479996                           1.0   \n",
       "520134                  1.479996                           1.0   \n",
       "208401                  1.479996                           1.0   \n",
       "85848                   1.479996                           1.0   \n",
       "24414                   1.479996                           1.0   \n",
       "\n",
       "        ImagePositionPatient_2_f  ImagePositionPatient_2_f_r05  \\\n",
       "183829                 -0.147708                           0.0   \n",
       "106245                 -0.140544                           0.0   \n",
       "362507                 -0.133381                           0.0   \n",
       "55311                  -0.126218                           0.0   \n",
       "420941                 -0.119054                           0.0   \n",
       "300366                 -0.111891                           0.0   \n",
       "153659                 -0.104728                           0.0   \n",
       "643991                 -0.097564                           0.0   \n",
       "99751                  -0.090401                           0.0   \n",
       "387211                 -0.083238                           0.0   \n",
       "459452                 -0.076074                           0.0   \n",
       "451127                 -0.068911                           0.0   \n",
       "459214                 -0.061748                           0.0   \n",
       "118858                 -0.054585                           0.0   \n",
       "291418                 -0.047421                           0.0   \n",
       "473382                 -0.040258                           0.0   \n",
       "302721                 -0.033095                           0.0   \n",
       "401418                 -0.025931                           0.0   \n",
       "335737                 -0.018768                           0.0   \n",
       "407299                 -0.011605                           0.0   \n",
       "463858                 -0.004441                           0.0   \n",
       "63088                   0.002722                           0.0   \n",
       "350252                  0.009885                           0.0   \n",
       "329738                  0.017049                           0.0   \n",
       "212434                  0.024212                           0.0   \n",
       "210996                  0.031375                           0.0   \n",
       "355909                  0.038539                           0.0   \n",
       "517742                  0.045702                           0.0   \n",
       "595062                  0.052865                           0.0   \n",
       "122981                  0.060029                           0.0   \n",
       "520134                  0.067192                           0.0   \n",
       "208401                  0.074355                           0.0   \n",
       "85848                   0.081519                           0.0   \n",
       "24414                   0.088682                           0.0   \n",
       "\n",
       "        PixelSpacing_1_f  PixelSpacing_1_enc_0  PixelSpacing_1_enc_1  \\\n",
       "183829             -0.48                   1.0                 False   \n",
       "106245             -0.48                   1.0                 False   \n",
       "362507             -0.48                   1.0                 False   \n",
       "55311              -0.48                   1.0                 False   \n",
       "420941             -0.48                   1.0                 False   \n",
       "300366             -0.48                   1.0                 False   \n",
       "153659             -0.48                   1.0                 False   \n",
       "643991             -0.48                   1.0                 False   \n",
       "99751              -0.48                   1.0                 False   \n",
       "387211             -0.48                   1.0                 False   \n",
       "459452             -0.48                   1.0                 False   \n",
       "451127             -0.48                   1.0                 False   \n",
       "459214             -0.48                   1.0                 False   \n",
       "118858             -0.48                   1.0                 False   \n",
       "291418             -0.48                   1.0                 False   \n",
       "473382             -0.48                   1.0                 False   \n",
       "302721             -0.48                   1.0                 False   \n",
       "401418             -0.48                   1.0                 False   \n",
       "335737             -0.48                   1.0                 False   \n",
       "407299             -0.48                   1.0                 False   \n",
       "463858             -0.48                   1.0                 False   \n",
       "63088              -0.48                   1.0                 False   \n",
       "350252             -0.48                   1.0                 False   \n",
       "329738             -0.48                   1.0                 False   \n",
       "212434             -0.48                   1.0                 False   \n",
       "210996             -0.48                   1.0                 False   \n",
       "355909             -0.48                   1.0                 False   \n",
       "517742             -0.48                   1.0                 False   \n",
       "595062             -0.48                   1.0                 False   \n",
       "122981             -0.48                   1.0                 False   \n",
       "520134             -0.48                   1.0                 False   \n",
       "208401             -0.48                   1.0                 False   \n",
       "85848              -0.48                   1.0                 False   \n",
       "24414              -0.48                   1.0                 False   \n",
       "\n",
       "        WindowCenter_0_le  pos_max  pos_min  pos_size  pos_idx1  pos_idx  \\\n",
       "183829                  1   0.9156   0.2556      -0.1 -1.152542        0   \n",
       "106245                  1   0.9156   0.2556      -0.1 -1.084746        1   \n",
       "362507                  1   0.9156   0.2556      -0.1 -1.016949        2   \n",
       "55311                   1   0.9156   0.2556      -0.1 -0.949153        3   \n",
       "420941                  1   0.9156   0.2556      -0.1 -0.881356        4   \n",
       "300366                  1   0.9156   0.2556      -0.1 -0.813559        5   \n",
       "153659                  1   0.9156   0.2556      -0.1 -0.745763        6   \n",
       "643991                  1   0.9156   0.2556      -0.1 -0.677966        7   \n",
       "99751                   1   0.9156   0.2556      -0.1 -0.610169        8   \n",
       "387211                  1   0.9156   0.2556      -0.1 -0.542373        9   \n",
       "459452                  1   0.9156   0.2556      -0.1 -0.474576       10   \n",
       "451127                  1   0.9156   0.2556      -0.1 -0.406780       11   \n",
       "459214                  1   0.9156   0.2556      -0.1 -0.338983       12   \n",
       "118858                  1   0.9156   0.2556      -0.1 -0.271186       13   \n",
       "291418                  1   0.9156   0.2556      -0.1 -0.203390       14   \n",
       "473382                  1   0.9156   0.2556      -0.1 -0.135593       15   \n",
       "302721                  1   0.9156   0.2556      -0.1 -0.067797       16   \n",
       "401418                  1   0.9156   0.2556      -0.1  0.000000       17   \n",
       "335737                  1   0.9156   0.2556      -0.1  0.067797       18   \n",
       "407299                  1   0.9156   0.2556      -0.1  0.135593       19   \n",
       "463858                  1   0.9156   0.2556      -0.1  0.203390       20   \n",
       "63088                   1   0.9156   0.2556      -0.1  0.271186       21   \n",
       "350252                  1   0.9156   0.2556      -0.1  0.338983       22   \n",
       "329738                  1   0.9156   0.2556      -0.1  0.406780       23   \n",
       "212434                  1   0.9156   0.2556      -0.1  0.474576       24   \n",
       "210996                  1   0.9156   0.2556      -0.1  0.542373       25   \n",
       "355909                  1   0.9156   0.2556      -0.1  0.610169       26   \n",
       "517742                  1   0.9156   0.2556      -0.1  0.677966       27   \n",
       "595062                  1   0.9156   0.2556      -0.1  0.745763       28   \n",
       "122981                  1   0.9156   0.2556      -0.1  0.813559       29   \n",
       "520134                  1   0.9156   0.2556      -0.1  0.881356       30   \n",
       "208401                  1   0.9156   0.2556      -0.1  0.949153       31   \n",
       "85848                   1   0.9156   0.2556      -0.1  1.016949       32   \n",
       "24414                   1   0.9156   0.2556      -0.1  1.084746       33   \n",
       "\n",
       "        pos_idx2  pos_inc1  pos_inc2  pos_inc1_grp_le  pos_inc2_grp_le  \\\n",
       "183829  1.084746 -1.500000  1.500000                0                3   \n",
       "106245  1.016949  1.500000 -1.500000                3                3   \n",
       "362507  0.949153 -1.500000 -1.500000                3                3   \n",
       "55311   0.881356 -1.500000 -1.500000                3                3   \n",
       "420941  0.813559 -1.500000 -1.500000                3                3   \n",
       "300366  0.745763 -1.500000 -1.500000                3                3   \n",
       "153659  0.677966 -1.500000 -1.500000                3                3   \n",
       "643991  0.610169 -1.500000  1.500000                3                3   \n",
       "99751   0.542373  1.500000 -1.500000                3                3   \n",
       "387211  0.474576 -1.500000 -1.500000                3                3   \n",
       "459452  0.406780 -1.500000  1.499969                3                3   \n",
       "451127  0.338983  1.499969 -1.500000                3                3   \n",
       "459214  0.271186 -1.500000  1.500000                3                3   \n",
       "118858  0.203390  1.500000 -1.500000                3                3   \n",
       "291418  0.135593 -1.500000 -1.500000                3                3   \n",
       "473382  0.067797 -1.500000 -1.500000                3                3   \n",
       "302721  0.000000 -1.500000 -1.500000                3                3   \n",
       "401418 -0.067797 -1.500000 -1.500000                3                3   \n",
       "335737 -0.135593 -1.500000 -1.500000                3                3   \n",
       "407299 -0.203390 -1.500000 -1.500000                3                3   \n",
       "463858 -0.271186 -1.500000 -1.500000                3                3   \n",
       "63088  -0.338983 -1.500000 -1.500000                3                3   \n",
       "350252 -0.406780 -1.500000 -1.500000                3                3   \n",
       "329738 -0.474576 -1.500000 -1.500000                3                3   \n",
       "212434 -0.542373 -1.500000 -1.500000                3                3   \n",
       "210996 -0.610169 -1.500000 -1.500000                3                3   \n",
       "355909 -0.677966 -1.500000 -1.500000                3                3   \n",
       "517742 -0.745763 -1.500000 -1.500000                3                3   \n",
       "595062 -0.813559 -1.500000 -1.500000                3                3   \n",
       "122981 -0.881356 -1.500000 -1.500000                3                3   \n",
       "520134 -0.949153 -1.500000 -1.500000                3                3   \n",
       "208401 -1.016949 -1.500000 -1.500000                3                3   \n",
       "85848  -1.084746 -1.500000 -1.500000                3                3   \n",
       "24414  -1.152542 -1.500000 -1.500000                3                0   \n",
       "\n",
       "        pos_inc1_r1  pos_inc1_r0001  pos_inc1_enc_0  pos_inc2_enc_0  \\\n",
       "183829          1.0             1.0             1.0             0.0   \n",
       "106245          1.0             1.0             0.0             0.0   \n",
       "362507          1.0             1.0             0.0             0.0   \n",
       "55311           1.0             1.0             0.0             0.0   \n",
       "420941          1.0             1.0             0.0             0.0   \n",
       "300366          1.0             1.0             0.0             0.0   \n",
       "153659          1.0             1.0             0.0             0.0   \n",
       "643991          1.0             1.0             0.0             0.0   \n",
       "99751           0.0             0.0             0.0             0.0   \n",
       "387211          1.0             1.0             0.0             0.0   \n",
       "459452          1.0             1.0             0.0             0.0   \n",
       "451127          0.0             0.0             0.0             0.0   \n",
       "459214          1.0             1.0             0.0             0.0   \n",
       "118858          1.0             1.0             0.0             0.0   \n",
       "291418          1.0             1.0             0.0             0.0   \n",
       "473382          1.0             1.0             0.0             0.0   \n",
       "302721          1.0             1.0             0.0             0.0   \n",
       "401418          1.0             1.0             0.0             0.0   \n",
       "335737          1.0             1.0             0.0             0.0   \n",
       "407299          1.0             1.0             0.0             0.0   \n",
       "463858          1.0             1.0             0.0             0.0   \n",
       "63088           1.0             1.0             0.0             0.0   \n",
       "350252          1.0             1.0             0.0             0.0   \n",
       "329738          1.0             1.0             0.0             0.0   \n",
       "212434          1.0             1.0             0.0             0.0   \n",
       "210996          1.0             1.0             0.0             0.0   \n",
       "355909          1.0             1.0             0.0             0.0   \n",
       "517742          1.0             1.0             0.0             0.0   \n",
       "595062          1.0             1.0             0.0             0.0   \n",
       "122981          1.0             1.0             0.0             0.0   \n",
       "520134          1.0             1.0             0.0             0.0   \n",
       "208401          1.0             1.0             0.0             0.0   \n",
       "85848           1.0             1.0             0.0             0.0   \n",
       "24414           1.0             1.0             0.0             1.0   \n",
       "\n",
       "        pos_inc1_enc_1  pos_inc2_enc_1  pos_size_le  pos_range   pos_rel  \\\n",
       "183829             0.0             0.0            4  -0.000002 -2.000000   \n",
       "106245             0.0             1.0            4  -0.000002 -1.878788   \n",
       "362507             1.0             1.0            4  -0.000002 -1.757576   \n",
       "55311              1.0             1.0            4  -0.000002 -1.636364   \n",
       "420941             1.0             1.0            4  -0.000002 -1.515151   \n",
       "300366             1.0             1.0            4  -0.000002 -1.393939   \n",
       "153659             1.0             1.0            4  -0.000002 -1.272727   \n",
       "643991             1.0             0.0            4  -0.000002 -1.151515   \n",
       "99751              0.0             1.0            4  -0.000002 -1.030303   \n",
       "387211             1.0             1.0            4  -0.000002 -0.909091   \n",
       "459452             1.0             0.0            4  -0.000002 -0.787878   \n",
       "451127             0.0             1.0            4  -0.000002 -0.666668   \n",
       "459214             1.0             0.0            4  -0.000002 -0.545455   \n",
       "118858             0.0             1.0            4  -0.000002 -0.424243   \n",
       "291418             1.0             1.0            4  -0.000002 -0.303031   \n",
       "473382             1.0             1.0            4  -0.000002 -0.181819   \n",
       "302721             1.0             1.0            4  -0.000002 -0.060607   \n",
       "401418             1.0             1.0            4  -0.000002  0.060605   \n",
       "335737             1.0             1.0            4  -0.000002  0.181818   \n",
       "407299             1.0             1.0            4  -0.000002  0.303030   \n",
       "463858             1.0             1.0            4  -0.000002  0.424242   \n",
       "63088              1.0             1.0            4  -0.000002  0.545454   \n",
       "350252             1.0             1.0            4  -0.000002  0.666666   \n",
       "329738             1.0             1.0            4  -0.000002  0.787878   \n",
       "212434             1.0             1.0            4  -0.000002  0.909091   \n",
       "210996             1.0             1.0            4  -0.000002  1.030303   \n",
       "355909             1.0             1.0            4  -0.000002  1.151515   \n",
       "517742             1.0             1.0            4  -0.000002  1.272727   \n",
       "595062             1.0             1.0            4  -0.000002  1.393939   \n",
       "122981             1.0             1.0            4  -0.000002  1.515151   \n",
       "520134             1.0             1.0            4  -0.000002  1.636364   \n",
       "208401             1.0             1.0            4  -0.000002  1.757576   \n",
       "85848              1.0             1.0            4  -0.000002  1.878788   \n",
       "24414              1.0             0.0            4  -0.000002  2.000000   \n",
       "\n",
       "        pos_zeros  pos_inc_rng  pos_zeros_le  any  epidural  intraparenchymal  \\\n",
       "183829        0.0    -0.599976             0    0         0                 0   \n",
       "106245        0.0    -0.599976             0    0         0                 0   \n",
       "362507        0.0    -0.599976             0    0         0                 0   \n",
       "55311         0.0    -0.599976             0    0         0                 0   \n",
       "420941        0.0    -0.599976             0    0         0                 0   \n",
       "300366        0.0    -0.599976             0    0         0                 0   \n",
       "153659        0.0    -0.599976             0    0         0                 0   \n",
       "643991        0.0    -0.599976             0    0         0                 0   \n",
       "99751         0.0    -0.599976             0    1         0                 0   \n",
       "387211        0.0    -0.599976             0    1         0                 1   \n",
       "459452        0.0    -0.599976             0    1         0                 1   \n",
       "451127        0.0    -0.599976             0    1         0                 1   \n",
       "459214        0.0    -0.599976             0    1         0                 1   \n",
       "118858        0.0    -0.599976             0    1         0                 1   \n",
       "291418        0.0    -0.599976             0    1         0                 1   \n",
       "473382        0.0    -0.599976             0    1         0                 1   \n",
       "302721        0.0    -0.599976             0    1         0                 1   \n",
       "401418        0.0    -0.599976             0    1         0                 1   \n",
       "335737        0.0    -0.599976             0    1         0                 0   \n",
       "407299        0.0    -0.599976             0    1         0                 1   \n",
       "463858        0.0    -0.599976             0    1         0                 1   \n",
       "63088         0.0    -0.599976             0    1         0                 1   \n",
       "350252        0.0    -0.599976             0    1         0                 1   \n",
       "329738        0.0    -0.599976             0    1         0                 1   \n",
       "212434        0.0    -0.599976             0    1         0                 1   \n",
       "210996        0.0    -0.599976             0    1         0                 1   \n",
       "355909        0.0    -0.599976             0    1         0                 0   \n",
       "517742        0.0    -0.599976             0    1         0                 0   \n",
       "595062        0.0    -0.599976             0    0         0                 0   \n",
       "122981        0.0    -0.599976             0    0         0                 0   \n",
       "520134        0.0    -0.599976             0    0         0                 0   \n",
       "208401        0.0    -0.599976             0    0         0                 0   \n",
       "85848         0.0    -0.599976             0    0         0                 0   \n",
       "24414         0.0    -0.599976             0    0         0                 0   \n",
       "\n",
       "        intraventricular  subarachnoid  subdural  PxlMin_grp_le   weights  \\\n",
       "183829                 0             0         0              2  0.034987   \n",
       "106245                 0             0         0              2  0.034987   \n",
       "362507                 0             0         0              2  0.034987   \n",
       "55311                  0             0         0              2  0.034987   \n",
       "420941                 0             0         0              2  0.034987   \n",
       "300366                 0             0         0              2  0.034987   \n",
       "153659                 0             0         0              2  0.034987   \n",
       "643991                 0             0         0              2  0.034987   \n",
       "99751                  0             1         0              2  0.034987   \n",
       "387211                 0             1         0              2  0.034987   \n",
       "459452                 0             1         0              2  0.034987   \n",
       "451127                 0             1         0              2  0.034987   \n",
       "459214                 0             1         0              2  0.034987   \n",
       "118858                 0             1         0              2  0.034987   \n",
       "291418                 0             1         0              2  0.034987   \n",
       "473382                 0             1         0              2  0.034987   \n",
       "302721                 0             1         0              2  0.034987   \n",
       "401418                 0             1         0              2  0.034987   \n",
       "335737                 0             1         0              2  0.034987   \n",
       "407299                 0             1         0              2  0.034987   \n",
       "463858                 0             1         0              2  0.034987   \n",
       "63088                  0             1         0              2  0.034987   \n",
       "350252                 0             1         0              2  0.034987   \n",
       "329738                 0             1         0              2  0.034987   \n",
       "212434                 0             1         0              2  0.034987   \n",
       "210996                 0             1         0              2  0.034987   \n",
       "355909                 0             1         0              2  0.034987   \n",
       "517742                 0             1         0              2  0.034987   \n",
       "595062                 0             0         0              2  0.034987   \n",
       "122981                 0             0         0              2  0.034987   \n",
       "520134                 0             0         0              2  0.034987   \n",
       "208401                 0             0         0              2  0.034987   \n",
       "85848                  0             0         0              2  0.034987   \n",
       "24414                  0             0         0              2  0.034987   \n",
       "\n",
       "            any2  epidural2  intraparenchymal2  intraventricular2  \\\n",
       "183829  0.000839   0.000099           0.000168           0.000138   \n",
       "106245  0.000584   0.000054           0.000185           0.000118   \n",
       "362507  0.001178   0.000100           0.000323           0.000155   \n",
       "55311   0.001729   0.000112           0.000339           0.000157   \n",
       "420941  0.001685   0.000111           0.000288           0.000189   \n",
       "300366  0.001612   0.000125           0.000305           0.000177   \n",
       "153659  0.003401   0.000254           0.000714           0.000404   \n",
       "643991  0.013303   0.000935           0.002368           0.001195   \n",
       "99751   0.099510   0.003812           0.032196           0.003922   \n",
       "387211  0.543668   0.009774           0.322572           0.005362   \n",
       "459452  0.918656   0.024115           0.763064           0.006704   \n",
       "451127  0.933054   0.019543           0.762358           0.005252   \n",
       "459214  0.920954   0.020513           0.770226           0.007980   \n",
       "118858  0.893019   0.011949           0.717446           0.006604   \n",
       "291418  0.980438   0.009472           0.960037           0.007377   \n",
       "473382  0.992883   0.005158           0.988262           0.006374   \n",
       "302721  0.991860   0.004986           0.989301           0.008418   \n",
       "401418  0.969767   0.005849           0.967911           0.014270   \n",
       "335737  0.336236   0.005383           0.302861           0.005350   \n",
       "407299  0.281014   0.007053           0.178869           0.006009   \n",
       "463858  0.566976   0.006558           0.428909           0.005297   \n",
       "63088   0.983561   0.005313           0.975370           0.006219   \n",
       "350252  0.991035   0.004644           0.985321           0.003356   \n",
       "329738  0.986074   0.005986           0.979739           0.004869   \n",
       "212434  0.815646   0.013105           0.688247           0.003345   \n",
       "210996  0.405491   0.014217           0.102302           0.001918   \n",
       "355909  0.234505   0.008246           0.016757           0.001161   \n",
       "517742  0.140069   0.004162           0.005150           0.000746   \n",
       "595062  0.061963   0.001527           0.002038           0.000626   \n",
       "122981  0.008272   0.000297           0.000405           0.000291   \n",
       "520134  0.000764   0.000073           0.000112           0.000127   \n",
       "208401  0.000222   0.000034           0.000052           0.000097   \n",
       "85848   0.000032   0.000015           0.000042           0.000029   \n",
       "24414   0.000074   0.000035           0.000052           0.000050   \n",
       "\n",
       "        subarachnoid2  subdural2  \n",
       "183829       0.000511   0.000372  \n",
       "106245       0.000284   0.000325  \n",
       "362507       0.000567   0.000675  \n",
       "55311        0.000622   0.001050  \n",
       "420941       0.000711   0.001004  \n",
       "300366       0.000802   0.001155  \n",
       "153659       0.001726   0.002313  \n",
       "643991       0.005325   0.007825  \n",
       "99751        0.032839   0.037040  \n",
       "387211       0.135512   0.124260  \n",
       "459452       0.315124   0.261145  \n",
       "451127       0.455088   0.252591  \n",
       "459214       0.563334   0.263610  \n",
       "118858       0.444525   0.180911  \n",
       "291418       0.337606   0.172147  \n",
       "473382       0.186669   0.121601  \n",
       "302721       0.135515   0.110268  \n",
       "401418       0.115135   0.092102  \n",
       "335737       0.079112   0.059441  \n",
       "407299       0.101448   0.072873  \n",
       "463858       0.104829   0.094247  \n",
       "63088        0.126935   0.121928  \n",
       "350252       0.142108   0.139003  \n",
       "329738       0.142797   0.163557  \n",
       "212434       0.161910   0.209642  \n",
       "210996       0.104954   0.227080  \n",
       "355909       0.061094   0.179025  \n",
       "517742       0.030422   0.122967  \n",
       "595062       0.012903   0.044199  \n",
       "122981       0.001939   0.005390  \n",
       "520134       0.000305   0.000570  \n",
       "208401       0.000101   0.000146  \n",
       "85848        0.000035   0.000051  \n",
       "24414        0.000076   0.000071  \n",
       "\n",
       "[34 rows x 102 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_md.loc[train_md.SeriesInstanceUID == 'ID_91616854b0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = train_md[['SeriesInstanceUID','PatientID']].groupby('PatientID').agg(lambda x: x.nunique())\n",
    "\n",
    "tt = tt.sort_values('SeriesInstanceUID',ascending=False)\n",
    "\n",
    "tt.loc[tt.SeriesInstanceUID == 6].head()\n",
    "\n",
    "pp = preds_all.mean((0,1))\n",
    "\n",
    "train_md = pd.concat([train_md, pd.DataFrame(pp,columns=[s+'2' for s in all_ich])],axis=1)\n",
    "\n",
    "train_md = train_md.sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(30, 10))\n",
    "serieses = train_md.loc[train_md.PatientID == 'ID_f41d724c'].SeriesInstanceUID.unique()\n",
    "print('total number of serieses', len(serieses))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i >= len(serieses): continue\n",
    "    ser = serieses[i]\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any'].values)\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any2'].values)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title(ser)\n",
    "\n",
    "train_md.loc[train_md.SeriesInstanceUID == 'ID_5752d1b055']\n",
    "\n",
    "\n",
    "\n",
    "sums1 = train_md[['SeriesInstanceUID'] + [s+'2' for s in all_ich]].groupby('SeriesInstanceUID').mean()\n",
    "\n",
    "sums2 = train_md[['PatientID'] + [s+'2' for s in all_ich]].groupby('PatientID').mean()\n",
    "\n",
    "train_md = train_md.join(sums1, on = 'SeriesInstanceUID',rsuffix='_s')\n",
    "\n",
    "train_md = train_md.join(sums2, on = 'PatientID',rsuffix='_p')\n",
    "\n",
    "train_md.head()\n",
    "\n",
    "lls = np.zeros(6)\n",
    "for i,col in enumerate(all_ich):\n",
    "    ll = log_loss(train_md[col], train_md[col+'2'])\n",
    "    lls[i] = ll\n",
    "    print('{:20s}{}'.format(col, ll))\n",
    "print('total',(lls*class_weights).mean())\n",
    "\n",
    "lls = np.zeros(6)\n",
    "for i,col in enumerate(all_ich):\n",
    "    ll = log_loss(train_md[col], train_md[col+'2']*(train_md[col+'2_p']/train_md[col+'2_s'])**0.01)\n",
    "    lls[i] = ll\n",
    "    print('{:20s}{}'.format(col, ll))\n",
    "print('total',(lls*class_weights).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting models aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    0.058905\n",
      "gmean   0.059180\n",
      "q50     0.059230\n",
      "q25     0.060806\n",
      "q75     0.059752\n",
      "psig    0.059120\n"
     ]
    }
   ],
   "source": [
    "for afunc in afuncs_names:\n",
    "    #print(afunc)\n",
    "    apreds = applyAggFunc(preds2, afunc, axis=0)\n",
    "    res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()\n",
    "    \n",
    "    if False:\n",
    "        best_score = res\n",
    "        best_k = 0\n",
    "        for k in range(1,50):\n",
    "            apreds2 = scalePreds(apreds, 1.0 + 0.01 * k)\n",
    "            apreds2 = np.clip(apreds2, 1e-15, 1-1e-15)\n",
    "\n",
    "            res2 = ((- train_md[all_ich].values * np.log(apreds2) - (1 - train_md[all_ich].values) * np.log(1 - apreds2))\\\n",
    "                    * class_weights).mean()\n",
    "\n",
    "            if res2 > best_score: break\n",
    "            best_score = res2\n",
    "            best_k = k\n",
    "\n",
    "        print('{:7s} {:5f}   {:2f} {:5f}'.format(afunc,res,1+0.01*best_k,best_score))\n",
    "    else:\n",
    "        print('{:7s} {:5f}'.format(afunc,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0589051240716035"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*(np.concatenate([np.ones(4)/8,np.ones(4)/8]))[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05925450523588664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*(np.concatenate([np.zeros(4),np.ones(4)/4]))[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058978989694675375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*(np.concatenate([np.ones(4)/16,3*np.ones(4)/16]))[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_afunc = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 674252, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06268, 0.06259, 0.06242, 0.06195])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    best_score = res\n",
    "    best_k = 0\n",
    "    for k in range(1,50):\n",
    "        apreds = scalePreds(preds_all, 1.0 + 0.01 * k)\n",
    "        apreds = np.clip(apreds, 1e-15, 1-1e-15)\n",
    "\n",
    "        res2 = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "                * class_weights).mean()\n",
    "\n",
    "        if res2 > best_score: break\n",
    "        best_score = res2\n",
    "        best_k = k\n",
    "\n",
    "    print('{{:5f}   {:2f} {:5f}'.format(res,1+0.01*best_k,best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models behavior per groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WindowCenter_1_le     0 248151   2157 [0.03754 0.03719 0.03679 0.03699 0.03656 0.03676 0.037   0.03685]\n",
      "WindowCenter_1_le     2  10377     34 [0.11828 0.11642 0.11726 0.11536 0.11701 0.11623 0.11605 0.11333]\n",
      "WindowCenter_1_le     3 341674  75369 [0.06474 0.06439 0.06526 0.06359 0.06427 0.06427 0.06513 0.06314]\n",
      "WindowCenter_1_le     1  70894    985 [0.12907 0.12632 0.12904 0.12675 0.12683 0.12644 0.12791 0.12472]\n",
      "WindowCenter_1_le     4   3156      0 [0.09075 0.09554 0.09205 0.08595 0.09443 0.09397 0.09533 0.0886 ]\n",
      "BitType_le            1 323550   3088 [0.05799 0.0573  0.05758 0.05716 0.05684 0.05697 0.05747 0.05667]\n",
      "BitType_le            0 338723  75369 [0.06411 0.06378 0.0646  0.06293 0.06364 0.06366 0.06451 0.06249]\n",
      "BitType_le            2   2252     60 [0.12818 0.12513 0.12613 0.12392 0.13314 0.12856 0.12732 0.12169]\n",
      "BitType_le            4   6776     28 [0.13693 0.12889 0.12844 0.12693 0.1308  0.12802 0.1291  0.12263]\n",
      "BitType_le            3   2951      0 [0.13769 0.13434 0.14018 0.13928 0.13676 0.1339  0.13665 0.13799]\n",
      "WindowCenter_0_le     1 248151   2157 [0.03754 0.03719 0.03679 0.03699 0.03656 0.03676 0.037   0.03685]\n",
      "WindowCenter_0_le     4  10343     34 [0.11838 0.11662 0.1173  0.11543 0.11717 0.1164  0.11612 0.11339]\n",
      "WindowCenter_0_le     2 151196   2148 [0.1232  0.12122 0.12367 0.12085 0.12164 0.1212  0.12283 0.1196 ]\n",
      "WindowCenter_0_le     0 213404  69272 [0.0356  0.03576 0.03592 0.03505 0.03564 0.03574 0.03624 0.03493]\n",
      "WindowCenter_0_le     3  43648   4934 [0.10603 0.10517 0.10645 0.10424 0.10382 0.10419 0.10524 0.10254]\n",
      "WindowCenter_0_le     6   3553      0 [0.0863  0.0899  0.08581 0.08013 0.09024 0.08986 0.08956 0.08275]\n",
      "WindowCenter_0_le     5   3957      0 [0.10166 0.09817 0.1068  0.10114 0.10183 0.10133 0.10354 0.09903]\n",
      "pos_inc1_grp_le       3 589641  59576 [0.06549 0.0647  0.06535 0.06444 0.06446 0.06446 0.0652  0.06381]\n",
      "pos_inc1_grp_le       0  25148   3724 [0.03066 0.0299  0.03029 0.02929 0.0314  0.03124 0.0302  0.03054]\n",
      "pos_inc1_grp_le       1  51896  14995 [0.03733 0.0386  0.03823 0.0359  0.03773 0.03778 0.03873 0.03615]\n",
      "pos_inc1_grp_le       2   7567    250 [0.10276 0.1043  0.10583 0.1005  0.10306 0.10447 0.10491 0.09895]\n",
      "pos_inc2_grp_le       3 589642  59576 [0.06603 0.06522 0.06589 0.06498 0.065   0.06497 0.06574 0.06432]\n",
      "pos_inc2_grp_le       0  25147   3724 [0.02662 0.02652 0.02648 0.0254  0.02713 0.02825 0.02621 0.02695]\n",
      "pos_inc2_grp_le       1  51896  14995 [0.03446 0.03574 0.03538 0.0331  0.03514 0.03503 0.03596 0.0334 ]\n",
      "pos_inc2_grp_le       2   7567    250 [0.09397 0.09426 0.09629 0.09117 0.09305 0.09377 0.09503 0.08997]\n",
      "pos_size_le          10 113357   7349 [0.05377 0.05336 0.05314 0.05246 0.05343 0.05339 0.05352 0.05258]\n",
      "pos_size_le           2  78912   9072 [0.05846 0.05841 0.05939 0.05796 0.05839 0.05835 0.05889 0.05762]\n",
      "pos_size_le           3  52218   9884 [0.07602 0.07416 0.07576 0.07413 0.07514 0.07404 0.07571 0.07283]\n",
      "pos_size_le           0 156544  21824 [0.07402 0.07334 0.07436 0.07271 0.07319 0.07324 0.07407 0.07191]\n",
      "pos_size_le           7  30393    231 [0.03408 0.03338 0.03309 0.03375 0.0328  0.0327  0.03287 0.03406]\n",
      "pos_size_le           8  25270   1596 [0.05737 0.05755 0.05649 0.05675 0.05463 0.05686 0.05649 0.05595]\n",
      "pos_size_le           4  51508    884 [0.07359 0.07292 0.07389 0.07346 0.07286 0.07248 0.07423 0.07224]\n",
      "pos_size_le           5  33180    930 [0.10807 0.10402 0.1057  0.10399 0.10576 0.10473 0.10443 0.10306]\n",
      "pos_size_le           1  79040  21840 [0.04457 0.04484 0.04527 0.04399 0.04376 0.04414 0.04515 0.04386]\n",
      "pos_size_le           6  32270    315 [0.04138 0.04146 0.04155 0.0416  0.04014 0.04106 0.04192 0.04143]\n",
      "pos_size_le           9  21560   4620 [0.05172 0.05214 0.0515  0.04966 0.0509  0.0513  0.05153 0.04895]\n",
      "pos_zeros_le          0 669377  77188 [0.06225 0.06165 0.0622  0.06117 0.06139 0.06138 0.06208 0.06062]\n",
      "pos_zeros_le          3   2665    917 [0.10061 0.09651 0.10214 0.09344 0.10265 0.10859 0.10435 0.09879]\n",
      "pos_zeros_le          2   1132    332 [0.08937 0.08674 0.08746 0.08854 0.08971 0.09384 0.09184 0.09408]\n",
      "pos_zeros_le          1   1078    108 [0.05822 0.0633  0.06831 0.06056 0.06124 0.0629  0.07016 0.06182]\n",
      "WindowWidth_0_le      0 541489  72448 [0.05015 0.04967 0.04991 0.04935 0.04941 0.04948 0.04997 0.04893]\n",
      "WindowWidth_0_le      1  63927    921 [0.1146  0.11291 0.11504 0.11176 0.11392 0.11343 0.11464 0.11147]\n",
      "WindowWidth_0_le      2  30067   4308 [0.09336 0.0928  0.09517 0.09161 0.093   0.09253 0.09452 0.0912 ]\n",
      "WindowWidth_0_le      3  31237    762 [0.13246 0.13112 0.13263 0.13015 0.12933 0.12951 0.13091 0.12774]\n",
      "WindowWidth_0_le      5   5389     90 [0.08139 0.08339 0.08448 0.08302 0.07962 0.08062 0.08526 0.0805 ]\n",
      "WindowWidth_0_le      4   2143     16 [0.1088  0.11343 0.11194 0.1049  0.10881 0.11158 0.10959 0.10588]\n",
      "WindowWidth_1_le      0 329597   3176 [0.05977 0.05886 0.05917 0.05877 0.05852 0.05856 0.05905 0.05817]\n",
      "WindowWidth_1_le      1 341674  75369 [0.06474 0.06439 0.06526 0.06359 0.06427 0.06427 0.06513 0.06314]\n",
      "WindowWidth_1_le      2   2981      0 [0.09309 0.09853 0.09519 0.08769 0.0968  0.09617 0.09789 0.08997]\n",
      "PxlMin_grp_le         2 363504   3934 [0.06615 0.06525 0.06563 0.065   0.06477 0.06482 0.0654  0.06427]\n",
      "PxlMin_grp_le         1  83433   1095 [0.11636 0.11505 0.11728 0.11371 0.11551 0.11513 0.11678 0.11312]\n",
      "PxlMin_grp_le         0 227315  73516 [0.03671 0.03685 0.03712 0.03627 0.03676 0.03687 0.03737 0.03614]\n"
     ]
    }
   ],
   "source": [
    "for col in cols_le:\n",
    "    for i in train_md[col].unique():\n",
    "        res = ((- train_md[all_ich].values * np.log(preds_all.mean(1)) - (1 - train_md[all_ich].values) \\\n",
    "                * np.log(1 - preds_all.mean(1))) * class_weights)[:,(train_md[col] == i)].mean((1,2))\n",
    "        sz = (train_md[col] == i).sum()\n",
    "        sz_test = (test_md[col] == i).sum()\n",
    "        print('{:20s} {:2d} {:6d} {:6d} {}'.format(col,i,sz,sz_test,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PxlMin_grp_le         2 any                  363504   3934 [0.10395 0.10279 0.10281 0.10252 0.10261 0.103   0.10377 0.10255]\n",
      "PxlMin_grp_le         1 any                   83433   1095 [0.18196 0.17981 0.1821  0.17766 0.18249 0.18235 0.1828  0.17839]\n",
      "PxlMin_grp_le         0 any                  227315  73516 [0.06435 0.06464 0.06487 0.06336 0.06476 0.06512 0.06577 0.06412]\n",
      "PxlMin_grp_le         2 epidural             363504   3934 [0.01702 0.01776 0.01722 0.01757 0.01783 0.01777 0.01732 0.01544]\n",
      "PxlMin_grp_le         1 epidural              83433   1095 [0.02218 0.02326 0.02527 0.0242  0.02376 0.02341 0.0243  0.02053]\n",
      "PxlMin_grp_le         0 epidural             227315  73516 [0.01231 0.01366 0.01299 0.01279 0.01327 0.01387 0.01382 0.01163]\n",
      "PxlMin_grp_le         2 intraparenchymal     363504   3934 [0.04702 0.04555 0.04753 0.04491 0.04441 0.04455 0.04546 0.04434]\n",
      "PxlMin_grp_le         1 intraparenchymal      83433   1095 [0.0879  0.08405 0.08973 0.0842  0.08421 0.08298 0.08739 0.08412]\n",
      "PxlMin_grp_le         0 intraparenchymal     227315  73516 [0.02321 0.02288 0.02356 0.02277 0.0228  0.02267 0.02333 0.02231]\n",
      "PxlMin_grp_le         2 intraventricular     363504   3934 [0.02567 0.02499 0.02586 0.02512 0.02466 0.02434 0.02522 0.02479]\n",
      "PxlMin_grp_le         1 intraventricular      83433   1095 [0.06925 0.06802 0.07146 0.06848 0.06773 0.06774 0.0709  0.06827]\n",
      "PxlMin_grp_le         0 intraventricular     227315  73516 [0.01181 0.01142 0.01221 0.01157 0.01126 0.01112 0.01189 0.01133]\n",
      "PxlMin_grp_le         2 subarachnoid         363504   3934 [0.07405 0.07273 0.07322 0.07215 0.07155 0.07154 0.07247 0.07117]\n",
      "PxlMin_grp_le         1 subarachnoid          83433   1095 [0.12831 0.12705 0.12803 0.12445 0.1257  0.12666 0.12691 0.12493]\n",
      "PxlMin_grp_le         0 subarachnoid         227315  73516 [0.03469 0.03427 0.03478 0.03424 0.03469 0.03403 0.03445 0.03414]\n",
      "PxlMin_grp_le         2 subdural             363504   3934 [0.09141 0.09011 0.08999 0.09023 0.0897  0.08951 0.08976 0.08907]\n",
      "PxlMin_grp_le         1 subdural              83433   1095 [0.14299 0.14334 0.1423  0.13929 0.14222 0.14041 0.1424  0.13723]\n",
      "PxlMin_grp_le         0 subdural             227315  73516 [0.04624 0.04648 0.04659 0.04578 0.04577 0.04613 0.04656 0.04529]\n"
     ]
    }
   ],
   "source": [
    "col = 'PxlMin_grp_le'\n",
    "for k in range(6):\n",
    "    for i in train_md[col].unique():\n",
    "        res = (- train_md[all_ich[k]].values * np.log(preds_all.mean(1)[:,:,k]) - (1 - train_md[all_ich[k]].values) \\\n",
    "                * np.log(1 - preds_all.mean(1)[:,:,k]))[:,(train_md[col] == i)].mean(1)\n",
    "        sz = (train_md[col] == i).sum()\n",
    "        sz_test = (test_md[col] == i).sum()\n",
    "        print('{:20s} {:2d} {:20s} {:6d} {:6d} {}'.format(col,i,all_ich[k],sz,sz_test,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>any</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PxlMin_grp_le</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>212492</td>\n",
       "      <td>14823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>56254</td>\n",
       "      <td>27179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>308403</td>\n",
       "      <td>55101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "any                 0      1\n",
       "PxlMin_grp_le               \n",
       "0              212492  14823\n",
       "1               56254  27179\n",
       "2              308403  55101"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab([train_md['PxlMin_grp_le']], [train_md[all_ich[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (8, 32, 674252, 6) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6c3b567b7cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m--> 217\u001b[0;31m                keepdims=keepdims)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (8, 32, 674252, 6) and data type float64"
     ]
    }
   ],
   "source": [
    "stds = preds_all.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00663, 0.00082, 0.00371, 0.00237, 0.00463, 0.00465],\n",
       "       [0.00653, 0.00076, 0.00331, 0.00226, 0.00419, 0.00432],\n",
       "       [0.01035, 0.00107, 0.00553, 0.00373, 0.00675, 0.00676],\n",
       "       [0.00783, 0.00065, 0.00383, 0.00267, 0.00484, 0.00487],\n",
       "       [0.00585, 0.00061, 0.00281, 0.00171, 0.00363, 0.0036 ],\n",
       "       [0.00608, 0.00067, 0.00278, 0.00178, 0.00325, 0.00362],\n",
       "       [0.01031, 0.00072, 0.00515, 0.00293, 0.00594, 0.00608],\n",
       "       [0.0078 , 0.00073, 0.00368, 0.00236, 0.00467, 0.00449]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds.mean((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 674252, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0721  0.69844 0.04717 0.87074 0.90913 0.38538 0.47888 0.49287]\n",
      "[0.65942 0.14143 0.80356 0.20604 0.03734 0.7852  0.74105 0.29836]\n",
      "[0.93923 0.87878 0.88173 0.10275 0.9006  0.17714 0.87711 0.22097]\n",
      "[0.92357 0.05838 0.82988 0.1811  0.91063 0.91305 0.1835  0.28412]\n",
      "[0.23838 0.77077 0.26534 0.11955 0.63966 0.28781 0.76715 0.17522]\n",
      "[0.75192 0.22898 0.87654 0.65612 0.38861 0.84263 0.21847 0.60288]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    idx = stds[0,:,i].argmax()\n",
    "    print(preds_all[0,:,idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89607 0.12613 0.89643 0.10395 0.8919  0.10412 0.12296 0.10019]\n",
      "[0.29146 0.09448 0.08381 0.29124 0.25786 0.27932 0.26    0.17203]\n",
      "[0.9805  0.96471 0.96605 0.97915 0.96169 0.12889 0.20027 0.15312]\n",
      "[0.88048 0.84696 0.0523  0.05313 0.06338 0.23104 0.20848 0.92539]\n",
      "[0.79051 0.40486 0.24571 0.92017 0.90041 0.22817 0.2481  0.90389]\n",
      "[0.14481 0.74231 0.74153 0.14874 0.15549 0.66152 0.74362 0.17278]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    idx = stds[3,:,i].argmax()\n",
    "    print(preds_all[3,:,idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14491, 0.00945, 0.03508, 0.02361, 0.05398, 0.06132],\n",
       "       [0.14669, 0.01034, 0.03552, 0.02403, 0.05463, 0.06025],\n",
       "       [0.14752, 0.00944, 0.03492, 0.02384, 0.05311, 0.06174],\n",
       "       [0.14552, 0.01318, 0.03636, 0.02443, 0.05468, 0.06079]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean(1, keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean(1, keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05472, 0.05524, 0.05509, 0.05582])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean(1, keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean(1, keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6043 , 0.60165, 0.59441, 0.6038 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean((1,2), keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean((1,2), keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 2.207 time per batch: 0.221\n",
      "B20 -> time passed: 2.576 time per batch: 0.129\n",
      "B30 -> time passed: 3.367 time per batch: 0.112\n",
      "B40 -> time passed: 4.128 time per batch: 0.103\n",
      "B50 -> time passed: 5.453 time per batch: 0.109\n",
      "B60 -> time passed: 6.224 time per batch: 0.104\n",
      "B70 -> time passed: 6.764 time per batch: 0.097\n",
      "test processing time: 11.842602968215942\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.500 time per batch: 0.150\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.039 time per batch: 0.101\n",
      "B40 -> time passed: 3.826 time per batch: 0.096\n",
      "B50 -> time passed: 5.234 time per batch: 0.105\n",
      "B60 -> time passed: 5.998 time per batch: 0.100\n",
      "B70 -> time passed: 6.430 time per batch: 0.092\n",
      "test processing time: 9.026065111160278\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.502 time per batch: 0.150\n",
      "B20 -> time passed: 2.342 time per batch: 0.117\n",
      "B30 -> time passed: 3.141 time per batch: 0.105\n",
      "B40 -> time passed: 3.964 time per batch: 0.099\n",
      "B50 -> time passed: 5.137 time per batch: 0.103\n",
      "B60 -> time passed: 6.059 time per batch: 0.101\n",
      "B70 -> time passed: 6.544 time per batch: 0.093\n",
      "test processing time: 9.137217044830322\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.446 time per batch: 0.145\n",
      "B20 -> time passed: 2.224 time per batch: 0.111\n",
      "B30 -> time passed: 3.028 time per batch: 0.101\n",
      "B40 -> time passed: 3.803 time per batch: 0.095\n",
      "B50 -> time passed: 5.153 time per batch: 0.103\n",
      "B60 -> time passed: 5.946 time per batch: 0.099\n",
      "B70 -> time passed: 6.463 time per batch: 0.092\n",
      "test processing time: 9.121670246124268\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.585 time per batch: 0.158\n",
      "B20 -> time passed: 2.412 time per batch: 0.121\n",
      "B30 -> time passed: 3.255 time per batch: 0.108\n",
      "B40 -> time passed: 4.095 time per batch: 0.102\n",
      "B50 -> time passed: 5.547 time per batch: 0.111\n",
      "B60 -> time passed: 6.297 time per batch: 0.105\n",
      "B70 -> time passed: 6.736 time per batch: 0.096\n",
      "test processing time: 9.341562747955322\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.495 time per batch: 0.149\n",
      "B20 -> time passed: 2.274 time per batch: 0.114\n",
      "B30 -> time passed: 3.072 time per batch: 0.102\n",
      "B40 -> time passed: 3.881 time per batch: 0.097\n",
      "B50 -> time passed: 5.357 time per batch: 0.107\n",
      "B60 -> time passed: 6.088 time per batch: 0.101\n",
      "B70 -> time passed: 6.528 time per batch: 0.093\n",
      "test processing time: 9.081677198410034\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.362 time per batch: 0.118\n",
      "B30 -> time passed: 3.192 time per batch: 0.106\n",
      "B40 -> time passed: 3.999 time per batch: 0.100\n",
      "B50 -> time passed: 5.368 time per batch: 0.107\n",
      "B60 -> time passed: 6.054 time per batch: 0.101\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 9.062324523925781\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.251 time per batch: 0.113\n",
      "B30 -> time passed: 3.042 time per batch: 0.101\n",
      "B40 -> time passed: 3.802 time per batch: 0.095\n",
      "B50 -> time passed: 5.089 time per batch: 0.102\n",
      "B60 -> time passed: 5.843 time per batch: 0.097\n",
      "B70 -> time passed: 6.435 time per batch: 0.092\n",
      "test processing time: 9.001469850540161\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.532 time per batch: 0.153\n",
      "B20 -> time passed: 2.316 time per batch: 0.116\n",
      "B30 -> time passed: 3.116 time per batch: 0.104\n",
      "B40 -> time passed: 3.860 time per batch: 0.097\n",
      "B50 -> time passed: 5.336 time per batch: 0.107\n",
      "B60 -> time passed: 6.049 time per batch: 0.101\n",
      "B70 -> time passed: 6.554 time per batch: 0.094\n",
      "test processing time: 9.124186038970947\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.117 time per batch: 0.104\n",
      "B40 -> time passed: 3.868 time per batch: 0.097\n",
      "B50 -> time passed: 5.326 time per batch: 0.107\n",
      "B60 -> time passed: 6.071 time per batch: 0.101\n",
      "B70 -> time passed: 6.549 time per batch: 0.094\n",
      "test processing time: 9.185373067855835\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.546 time per batch: 0.155\n",
      "B20 -> time passed: 2.395 time per batch: 0.120\n",
      "B30 -> time passed: 3.194 time per batch: 0.106\n",
      "B40 -> time passed: 4.010 time per batch: 0.100\n",
      "B50 -> time passed: 5.269 time per batch: 0.105\n",
      "B60 -> time passed: 6.245 time per batch: 0.104\n",
      "B70 -> time passed: 6.691 time per batch: 0.096\n",
      "test processing time: 9.293678283691406\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.578 time per batch: 0.158\n",
      "B20 -> time passed: 2.350 time per batch: 0.117\n",
      "B30 -> time passed: 3.180 time per batch: 0.106\n",
      "B40 -> time passed: 4.010 time per batch: 0.100\n",
      "B50 -> time passed: 5.388 time per batch: 0.108\n",
      "B60 -> time passed: 6.121 time per batch: 0.102\n",
      "B70 -> time passed: 6.616 time per batch: 0.095\n",
      "test processing time: 9.242607355117798\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.481 time per batch: 0.148\n",
      "B20 -> time passed: 2.238 time per batch: 0.112\n",
      "B30 -> time passed: 3.008 time per batch: 0.100\n",
      "B40 -> time passed: 3.790 time per batch: 0.095\n",
      "B50 -> time passed: 5.109 time per batch: 0.102\n",
      "B60 -> time passed: 5.894 time per batch: 0.098\n",
      "B70 -> time passed: 6.429 time per batch: 0.092\n",
      "test processing time: 8.957036972045898\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.088 time per batch: 0.103\n",
      "B40 -> time passed: 3.832 time per batch: 0.096\n",
      "B50 -> time passed: 5.142 time per batch: 0.103\n",
      "B60 -> time passed: 5.973 time per batch: 0.100\n",
      "B70 -> time passed: 6.457 time per batch: 0.092\n",
      "test processing time: 9.016406059265137\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.286 time per batch: 0.114\n",
      "B30 -> time passed: 3.082 time per batch: 0.103\n",
      "B40 -> time passed: 3.843 time per batch: 0.096\n",
      "B50 -> time passed: 5.195 time per batch: 0.104\n",
      "B60 -> time passed: 5.967 time per batch: 0.099\n",
      "B70 -> time passed: 6.430 time per batch: 0.092\n",
      "test processing time: 8.976611614227295\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.509 time per batch: 0.151\n",
      "B20 -> time passed: 2.315 time per batch: 0.116\n",
      "B30 -> time passed: 3.112 time per batch: 0.104\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.271 time per batch: 0.105\n",
      "B60 -> time passed: 6.064 time per batch: 0.101\n",
      "B70 -> time passed: 6.573 time per batch: 0.094\n",
      "test processing time: 9.121875762939453\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.331 time per batch: 0.117\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.921 time per batch: 0.098\n",
      "B50 -> time passed: 5.157 time per batch: 0.103\n",
      "B60 -> time passed: 6.044 time per batch: 0.101\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 9.03476858139038\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.573 time per batch: 0.157\n",
      "B20 -> time passed: 2.345 time per batch: 0.117\n",
      "B30 -> time passed: 3.163 time per batch: 0.105\n",
      "B40 -> time passed: 3.982 time per batch: 0.100\n",
      "B50 -> time passed: 5.379 time per batch: 0.108\n",
      "B60 -> time passed: 6.108 time per batch: 0.102\n",
      "B70 -> time passed: 6.531 time per batch: 0.093\n",
      "test processing time: 9.108634233474731\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.503 time per batch: 0.150\n",
      "B20 -> time passed: 2.329 time per batch: 0.116\n",
      "B30 -> time passed: 3.125 time per batch: 0.104\n",
      "B40 -> time passed: 3.932 time per batch: 0.098\n",
      "B50 -> time passed: 5.121 time per batch: 0.102\n",
      "B60 -> time passed: 6.050 time per batch: 0.101\n",
      "B70 -> time passed: 6.527 time per batch: 0.093\n",
      "test processing time: 9.045315265655518\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.482 time per batch: 0.148\n",
      "B20 -> time passed: 2.314 time per batch: 0.116\n",
      "B30 -> time passed: 3.127 time per batch: 0.104\n",
      "B40 -> time passed: 3.861 time per batch: 0.097\n",
      "B50 -> time passed: 5.085 time per batch: 0.102\n",
      "B60 -> time passed: 6.023 time per batch: 0.100\n",
      "B70 -> time passed: 6.525 time per batch: 0.093\n",
      "test processing time: 9.081825971603394\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.514 time per batch: 0.151\n",
      "B20 -> time passed: 2.308 time per batch: 0.115\n",
      "B30 -> time passed: 3.116 time per batch: 0.104\n",
      "B40 -> time passed: 3.917 time per batch: 0.098\n",
      "B50 -> time passed: 5.162 time per batch: 0.103\n",
      "B60 -> time passed: 6.042 time per batch: 0.101\n",
      "B70 -> time passed: 6.511 time per batch: 0.093\n",
      "test processing time: 9.023768424987793\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.524 time per batch: 0.152\n",
      "B20 -> time passed: 2.371 time per batch: 0.119\n",
      "B30 -> time passed: 3.159 time per batch: 0.105\n",
      "B40 -> time passed: 3.988 time per batch: 0.100\n",
      "B50 -> time passed: 5.392 time per batch: 0.108\n",
      "B60 -> time passed: 6.121 time per batch: 0.102\n",
      "B70 -> time passed: 6.565 time per batch: 0.094\n",
      "test processing time: 9.08661937713623\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.287 time per batch: 0.114\n",
      "B30 -> time passed: 3.093 time per batch: 0.103\n",
      "B40 -> time passed: 3.918 time per batch: 0.098\n",
      "B50 -> time passed: 5.290 time per batch: 0.106\n",
      "B60 -> time passed: 5.982 time per batch: 0.100\n",
      "B70 -> time passed: 6.531 time per batch: 0.093\n",
      "test processing time: 9.05089020729065\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.537 time per batch: 0.154\n",
      "B20 -> time passed: 2.316 time per batch: 0.116\n",
      "B30 -> time passed: 3.074 time per batch: 0.102\n",
      "B40 -> time passed: 3.872 time per batch: 0.097\n",
      "B50 -> time passed: 5.195 time per batch: 0.104\n",
      "B60 -> time passed: 6.059 time per batch: 0.101\n",
      "B70 -> time passed: 6.613 time per batch: 0.094\n",
      "test processing time: 9.163508176803589\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.303 time per batch: 0.115\n",
      "B30 -> time passed: 3.097 time per batch: 0.103\n",
      "B40 -> time passed: 3.888 time per batch: 0.097\n",
      "B50 -> time passed: 5.301 time per batch: 0.106\n",
      "B60 -> time passed: 6.038 time per batch: 0.101\n",
      "B70 -> time passed: 6.518 time per batch: 0.093\n",
      "test processing time: 9.065711498260498\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.450 time per batch: 0.145\n",
      "B20 -> time passed: 2.203 time per batch: 0.110\n",
      "B30 -> time passed: 2.972 time per batch: 0.099\n",
      "B40 -> time passed: 3.680 time per batch: 0.092\n",
      "B50 -> time passed: 5.090 time per batch: 0.102\n",
      "B60 -> time passed: 5.871 time per batch: 0.098\n",
      "B70 -> time passed: 6.408 time per batch: 0.092\n",
      "test processing time: 8.991652965545654\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.544 time per batch: 0.154\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.045 time per batch: 0.102\n",
      "B40 -> time passed: 3.854 time per batch: 0.096\n",
      "B50 -> time passed: 5.180 time per batch: 0.104\n",
      "B60 -> time passed: 5.980 time per batch: 0.100\n",
      "B70 -> time passed: 6.465 time per batch: 0.092\n",
      "test processing time: 9.009056329727173\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.256 time per batch: 0.113\n",
      "B30 -> time passed: 3.083 time per batch: 0.103\n",
      "B40 -> time passed: 3.847 time per batch: 0.096\n",
      "B50 -> time passed: 5.264 time per batch: 0.105\n",
      "B60 -> time passed: 6.083 time per batch: 0.101\n",
      "B70 -> time passed: 6.499 time per batch: 0.093\n",
      "test processing time: 9.07373046875\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.274 time per batch: 0.114\n",
      "B30 -> time passed: 3.117 time per batch: 0.104\n",
      "B40 -> time passed: 3.941 time per batch: 0.099\n",
      "B50 -> time passed: 5.256 time per batch: 0.105\n",
      "B60 -> time passed: 6.033 time per batch: 0.101\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 9.053974866867065\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.542 time per batch: 0.154\n",
      "B20 -> time passed: 2.346 time per batch: 0.117\n",
      "B30 -> time passed: 3.116 time per batch: 0.104\n",
      "B40 -> time passed: 3.915 time per batch: 0.098\n",
      "B50 -> time passed: 5.301 time per batch: 0.106\n",
      "B60 -> time passed: 6.011 time per batch: 0.100\n",
      "B70 -> time passed: 6.498 time per batch: 0.093\n",
      "test processing time: 9.001604080200195\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.273 time per batch: 0.114\n",
      "B30 -> time passed: 2.985 time per batch: 0.099\n",
      "B40 -> time passed: 3.792 time per batch: 0.095\n",
      "B50 -> time passed: 5.189 time per batch: 0.104\n",
      "B60 -> time passed: 5.943 time per batch: 0.099\n",
      "B70 -> time passed: 6.475 time per batch: 0.093\n",
      "test processing time: 9.016136407852173\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.478 time per batch: 0.148\n",
      "B20 -> time passed: 2.246 time per batch: 0.112\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.807 time per batch: 0.095\n",
      "B50 -> time passed: 5.187 time per batch: 0.104\n",
      "B60 -> time passed: 6.031 time per batch: 0.101\n",
      "B70 -> time passed: 6.452 time per batch: 0.092\n",
      "test processing time: 8.993726253509521\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.613 time per batch: 0.161\n",
      "B20 -> time passed: 2.449 time per batch: 0.122\n",
      "B30 -> time passed: 3.282 time per batch: 0.109\n",
      "B40 -> time passed: 4.126 time per batch: 0.103\n",
      "B50 -> time passed: 5.610 time per batch: 0.112\n",
      "B60 -> time passed: 6.320 time per batch: 0.105\n",
      "B70 -> time passed: 6.768 time per batch: 0.097\n",
      "test processing time: 13.933590650558472\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.502 time per batch: 0.150\n",
      "B20 -> time passed: 2.328 time per batch: 0.116\n",
      "B30 -> time passed: 3.095 time per batch: 0.103\n",
      "B40 -> time passed: 3.898 time per batch: 0.097\n",
      "B50 -> time passed: 5.093 time per batch: 0.102\n",
      "B60 -> time passed: 6.047 time per batch: 0.101\n",
      "B70 -> time passed: 6.545 time per batch: 0.094\n",
      "test processing time: 9.108900785446167\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.492 time per batch: 0.149\n",
      "B20 -> time passed: 2.261 time per batch: 0.113\n",
      "B30 -> time passed: 3.029 time per batch: 0.101\n",
      "B40 -> time passed: 3.793 time per batch: 0.095\n",
      "B50 -> time passed: 5.119 time per batch: 0.102\n",
      "B60 -> time passed: 5.928 time per batch: 0.099\n",
      "B70 -> time passed: 6.445 time per batch: 0.092\n",
      "test processing time: 8.96512484550476\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.547 time per batch: 0.155\n",
      "B20 -> time passed: 2.343 time per batch: 0.117\n",
      "B30 -> time passed: 3.096 time per batch: 0.103\n",
      "B40 -> time passed: 3.939 time per batch: 0.098\n",
      "B50 -> time passed: 5.384 time per batch: 0.108\n",
      "B60 -> time passed: 6.130 time per batch: 0.102\n",
      "B70 -> time passed: 6.603 time per batch: 0.094\n",
      "test processing time: 9.140665531158447\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.573 time per batch: 0.157\n",
      "B20 -> time passed: 2.403 time per batch: 0.120\n",
      "B30 -> time passed: 3.200 time per batch: 0.107\n",
      "B40 -> time passed: 3.982 time per batch: 0.100\n",
      "B50 -> time passed: 5.267 time per batch: 0.105\n",
      "B60 -> time passed: 6.105 time per batch: 0.102\n",
      "B70 -> time passed: 6.571 time per batch: 0.094\n",
      "test processing time: 9.108694553375244\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.524 time per batch: 0.152\n",
      "B20 -> time passed: 2.333 time per batch: 0.117\n",
      "B30 -> time passed: 3.174 time per batch: 0.106\n",
      "B40 -> time passed: 3.897 time per batch: 0.097\n",
      "B50 -> time passed: 5.390 time per batch: 0.108\n",
      "B60 -> time passed: 6.116 time per batch: 0.102\n",
      "B70 -> time passed: 6.564 time per batch: 0.094\n",
      "test processing time: 9.141327142715454\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.246 time per batch: 0.112\n",
      "B30 -> time passed: 3.033 time per batch: 0.101\n",
      "B40 -> time passed: 3.767 time per batch: 0.094\n",
      "B50 -> time passed: 5.098 time per batch: 0.102\n",
      "B60 -> time passed: 5.844 time per batch: 0.097\n",
      "B70 -> time passed: 6.375 time per batch: 0.091\n",
      "test processing time: 8.972059965133667\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.500 time per batch: 0.150\n",
      "B20 -> time passed: 2.256 time per batch: 0.113\n",
      "B30 -> time passed: 3.049 time per batch: 0.102\n",
      "B40 -> time passed: 3.815 time per batch: 0.095\n",
      "B50 -> time passed: 5.143 time per batch: 0.103\n",
      "B60 -> time passed: 5.890 time per batch: 0.098\n",
      "B70 -> time passed: 6.466 time per batch: 0.092\n",
      "test processing time: 9.034222602844238\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.504 time per batch: 0.150\n",
      "B20 -> time passed: 2.227 time per batch: 0.111\n",
      "B30 -> time passed: 3.029 time per batch: 0.101\n",
      "B40 -> time passed: 3.830 time per batch: 0.096\n",
      "B50 -> time passed: 5.184 time per batch: 0.104\n",
      "B60 -> time passed: 5.913 time per batch: 0.099\n",
      "B70 -> time passed: 6.406 time per batch: 0.092\n",
      "test processing time: 8.98062515258789\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.277 time per batch: 0.114\n",
      "B30 -> time passed: 3.082 time per batch: 0.103\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.245 time per batch: 0.105\n",
      "B60 -> time passed: 5.965 time per batch: 0.099\n",
      "B70 -> time passed: 6.414 time per batch: 0.092\n",
      "test processing time: 8.939317464828491\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.449 time per batch: 0.145\n",
      "B20 -> time passed: 2.220 time per batch: 0.111\n",
      "B30 -> time passed: 3.015 time per batch: 0.101\n",
      "B40 -> time passed: 3.722 time per batch: 0.093\n",
      "B50 -> time passed: 5.064 time per batch: 0.101\n",
      "B60 -> time passed: 5.806 time per batch: 0.097\n",
      "B70 -> time passed: 6.311 time per batch: 0.090\n",
      "test processing time: 8.882152080535889\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.570 time per batch: 0.157\n",
      "B20 -> time passed: 2.327 time per batch: 0.116\n",
      "B30 -> time passed: 3.119 time per batch: 0.104\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.256 time per batch: 0.105\n",
      "B60 -> time passed: 5.974 time per batch: 0.100\n",
      "B70 -> time passed: 6.431 time per batch: 0.092\n",
      "test processing time: 8.964987516403198\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.447 time per batch: 0.145\n",
      "B20 -> time passed: 2.235 time per batch: 0.112\n",
      "B30 -> time passed: 3.034 time per batch: 0.101\n",
      "B40 -> time passed: 3.812 time per batch: 0.095\n",
      "B50 -> time passed: 5.069 time per batch: 0.101\n",
      "B60 -> time passed: 5.875 time per batch: 0.098\n",
      "B70 -> time passed: 6.404 time per batch: 0.091\n",
      "test processing time: 8.949799299240112\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.489 time per batch: 0.149\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.093 time per batch: 0.103\n",
      "B40 -> time passed: 3.856 time per batch: 0.096\n",
      "B50 -> time passed: 5.163 time per batch: 0.103\n",
      "B60 -> time passed: 5.996 time per batch: 0.100\n",
      "B70 -> time passed: 6.465 time per batch: 0.092\n",
      "test processing time: 9.007906675338745\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.135 time per batch: 0.104\n",
      "B40 -> time passed: 3.920 time per batch: 0.098\n",
      "B50 -> time passed: 5.282 time per batch: 0.106\n",
      "B60 -> time passed: 5.986 time per batch: 0.100\n",
      "B70 -> time passed: 6.413 time per batch: 0.092\n",
      "test processing time: 8.94338059425354\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.484 time per batch: 0.148\n",
      "B20 -> time passed: 2.251 time per batch: 0.113\n",
      "B30 -> time passed: 2.979 time per batch: 0.099\n",
      "B40 -> time passed: 3.758 time per batch: 0.094\n",
      "B50 -> time passed: 5.060 time per batch: 0.101\n",
      "B60 -> time passed: 5.803 time per batch: 0.097\n",
      "B70 -> time passed: 6.282 time per batch: 0.090\n",
      "test processing time: 8.815083742141724\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.226 time per batch: 0.111\n",
      "B30 -> time passed: 2.949 time per batch: 0.098\n",
      "B40 -> time passed: 3.682 time per batch: 0.092\n",
      "B50 -> time passed: 4.951 time per batch: 0.099\n",
      "B60 -> time passed: 5.790 time per batch: 0.096\n",
      "B70 -> time passed: 6.298 time per batch: 0.090\n",
      "test processing time: 8.843396186828613\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.464 time per batch: 0.146\n",
      "B20 -> time passed: 2.232 time per batch: 0.112\n",
      "B30 -> time passed: 2.991 time per batch: 0.100\n",
      "B40 -> time passed: 3.730 time per batch: 0.093\n",
      "B50 -> time passed: 5.011 time per batch: 0.100\n",
      "B60 -> time passed: 5.937 time per batch: 0.099\n",
      "B70 -> time passed: 6.375 time per batch: 0.091\n",
      "test processing time: 8.89706039428711\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.482 time per batch: 0.148\n",
      "B20 -> time passed: 2.259 time per batch: 0.113\n",
      "B30 -> time passed: 3.023 time per batch: 0.101\n",
      "B40 -> time passed: 3.812 time per batch: 0.095\n",
      "B50 -> time passed: 5.169 time per batch: 0.103\n",
      "B60 -> time passed: 5.909 time per batch: 0.098\n",
      "B70 -> time passed: 6.389 time per batch: 0.091\n",
      "test processing time: 8.925796031951904\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.486 time per batch: 0.149\n",
      "B20 -> time passed: 2.240 time per batch: 0.112\n",
      "B30 -> time passed: 2.973 time per batch: 0.099\n",
      "B40 -> time passed: 3.716 time per batch: 0.093\n",
      "B50 -> time passed: 5.016 time per batch: 0.100\n",
      "B60 -> time passed: 5.815 time per batch: 0.097\n",
      "B70 -> time passed: 6.325 time per batch: 0.090\n",
      "test processing time: 8.864880561828613\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.458 time per batch: 0.146\n",
      "B20 -> time passed: 2.227 time per batch: 0.111\n",
      "B30 -> time passed: 2.992 time per batch: 0.100\n",
      "B40 -> time passed: 3.786 time per batch: 0.095\n",
      "B50 -> time passed: 5.070 time per batch: 0.101\n",
      "B60 -> time passed: 5.874 time per batch: 0.098\n",
      "B70 -> time passed: 6.332 time per batch: 0.090\n",
      "test processing time: 8.866707801818848\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.141 time per batch: 0.105\n",
      "B40 -> time passed: 3.936 time per batch: 0.098\n",
      "B50 -> time passed: 5.332 time per batch: 0.107\n",
      "B60 -> time passed: 6.051 time per batch: 0.101\n",
      "B70 -> time passed: 6.456 time per batch: 0.092\n",
      "test processing time: 8.986533641815186\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.306 time per batch: 0.115\n",
      "B30 -> time passed: 3.078 time per batch: 0.103\n",
      "B40 -> time passed: 3.878 time per batch: 0.097\n",
      "B50 -> time passed: 5.315 time per batch: 0.106\n",
      "B60 -> time passed: 6.053 time per batch: 0.101\n",
      "B70 -> time passed: 6.461 time per batch: 0.092\n",
      "test processing time: 8.984882116317749\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.247 time per batch: 0.112\n",
      "B30 -> time passed: 3.011 time per batch: 0.100\n",
      "B40 -> time passed: 3.773 time per batch: 0.094\n",
      "B50 -> time passed: 5.042 time per batch: 0.101\n",
      "B60 -> time passed: 5.827 time per batch: 0.097\n",
      "B70 -> time passed: 6.323 time per batch: 0.090\n",
      "test processing time: 8.843563795089722\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.446 time per batch: 0.145\n",
      "B20 -> time passed: 2.228 time per batch: 0.111\n",
      "B30 -> time passed: 3.044 time per batch: 0.101\n",
      "B40 -> time passed: 3.826 time per batch: 0.096\n",
      "B50 -> time passed: 5.244 time per batch: 0.105\n",
      "B60 -> time passed: 5.991 time per batch: 0.100\n",
      "B70 -> time passed: 6.429 time per batch: 0.092\n",
      "test processing time: 8.998311996459961\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.496 time per batch: 0.150\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.113 time per batch: 0.104\n",
      "B40 -> time passed: 3.933 time per batch: 0.098\n",
      "B50 -> time passed: 5.255 time per batch: 0.105\n",
      "B60 -> time passed: 6.018 time per batch: 0.100\n",
      "B70 -> time passed: 6.451 time per batch: 0.092\n",
      "test processing time: 9.012238025665283\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.536 time per batch: 0.154\n",
      "B20 -> time passed: 2.327 time per batch: 0.116\n",
      "B30 -> time passed: 3.154 time per batch: 0.105\n",
      "B40 -> time passed: 3.971 time per batch: 0.099\n",
      "B50 -> time passed: 5.376 time per batch: 0.108\n",
      "B60 -> time passed: 6.148 time per batch: 0.102\n",
      "B70 -> time passed: 6.536 time per batch: 0.093\n",
      "test processing time: 9.054214715957642\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.265 time per batch: 0.113\n",
      "B30 -> time passed: 3.053 time per batch: 0.102\n",
      "B40 -> time passed: 3.860 time per batch: 0.096\n",
      "B50 -> time passed: 5.206 time per batch: 0.104\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.456 time per batch: 0.092\n",
      "test processing time: 9.055185317993164\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.558 time per batch: 0.156\n",
      "B20 -> time passed: 2.317 time per batch: 0.116\n",
      "B30 -> time passed: 3.150 time per batch: 0.105\n",
      "B40 -> time passed: 3.875 time per batch: 0.097\n",
      "B50 -> time passed: 5.195 time per batch: 0.104\n",
      "B60 -> time passed: 5.914 time per batch: 0.099\n",
      "B70 -> time passed: 6.363 time per batch: 0.091\n",
      "test processing time: 8.903928279876709\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.151\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.053 time per batch: 0.102\n",
      "B40 -> time passed: 3.861 time per batch: 0.097\n",
      "B50 -> time passed: 5.105 time per batch: 0.102\n",
      "B60 -> time passed: 5.960 time per batch: 0.099\n",
      "B70 -> time passed: 6.447 time per batch: 0.092\n",
      "test processing time: 9.007552146911621\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.457 time per batch: 0.146\n",
      "B20 -> time passed: 2.268 time per batch: 0.113\n",
      "B30 -> time passed: 3.106 time per batch: 0.104\n",
      "B40 -> time passed: 3.846 time per batch: 0.096\n",
      "B50 -> time passed: 5.086 time per batch: 0.102\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.421 time per batch: 0.092\n",
      "test processing time: 8.944348812103271\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.467 time per batch: 0.147\n",
      "B20 -> time passed: 2.266 time per batch: 0.113\n",
      "B30 -> time passed: 3.036 time per batch: 0.101\n",
      "B40 -> time passed: 3.848 time per batch: 0.096\n",
      "B50 -> time passed: 5.082 time per batch: 0.102\n",
      "B60 -> time passed: 5.979 time per batch: 0.100\n",
      "B70 -> time passed: 6.441 time per batch: 0.092\n",
      "test processing time: 9.002416610717773\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.152\n",
      "B20 -> time passed: 2.332 time per batch: 0.117\n",
      "B30 -> time passed: 3.174 time per batch: 0.106\n",
      "B40 -> time passed: 3.918 time per batch: 0.098\n",
      "B50 -> time passed: 5.195 time per batch: 0.104\n",
      "B60 -> time passed: 6.129 time per batch: 0.102\n",
      "B70 -> time passed: 6.640 time per batch: 0.095\n",
      "test processing time: 13.63286018371582\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.508 time per batch: 0.151\n",
      "B20 -> time passed: 2.321 time per batch: 0.116\n",
      "B30 -> time passed: 3.133 time per batch: 0.104\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.077 time per batch: 0.102\n",
      "B60 -> time passed: 6.036 time per batch: 0.101\n",
      "B70 -> time passed: 6.556 time per batch: 0.094\n",
      "test processing time: 9.009151697158813\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.348 time per batch: 0.107\n",
      "B60 -> time passed: 6.171 time per batch: 0.103\n",
      "B70 -> time passed: 6.610 time per batch: 0.094\n",
      "test processing time: 9.06514573097229\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.271 time per batch: 0.114\n",
      "B30 -> time passed: 3.037 time per batch: 0.101\n",
      "B40 -> time passed: 3.835 time per batch: 0.096\n",
      "B50 -> time passed: 5.197 time per batch: 0.104\n",
      "B60 -> time passed: 5.952 time per batch: 0.099\n",
      "B70 -> time passed: 6.466 time per batch: 0.092\n",
      "test processing time: 8.996935606002808\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.613 time per batch: 0.161\n",
      "B20 -> time passed: 2.408 time per batch: 0.120\n",
      "B30 -> time passed: 3.228 time per batch: 0.108\n",
      "B40 -> time passed: 4.053 time per batch: 0.101\n",
      "B50 -> time passed: 5.472 time per batch: 0.109\n",
      "B60 -> time passed: 6.161 time per batch: 0.103\n",
      "B70 -> time passed: 6.590 time per batch: 0.094\n",
      "test processing time: 9.079035758972168\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.532 time per batch: 0.153\n",
      "B20 -> time passed: 2.307 time per batch: 0.115\n",
      "B30 -> time passed: 3.082 time per batch: 0.103\n",
      "B40 -> time passed: 3.829 time per batch: 0.096\n",
      "B50 -> time passed: 5.164 time per batch: 0.103\n",
      "B60 -> time passed: 5.947 time per batch: 0.099\n",
      "B70 -> time passed: 6.438 time per batch: 0.092\n",
      "test processing time: 8.86711573600769\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.605 time per batch: 0.161\n",
      "B20 -> time passed: 2.458 time per batch: 0.123\n",
      "B30 -> time passed: 3.337 time per batch: 0.111\n",
      "B40 -> time passed: 4.171 time per batch: 0.104\n",
      "B50 -> time passed: 5.607 time per batch: 0.112\n",
      "B60 -> time passed: 6.285 time per batch: 0.105\n",
      "B70 -> time passed: 6.703 time per batch: 0.096\n",
      "test processing time: 9.151318788528442\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.150\n",
      "B20 -> time passed: 2.280 time per batch: 0.114\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.897 time per batch: 0.097\n",
      "B50 -> time passed: 5.270 time per batch: 0.105\n",
      "B60 -> time passed: 6.028 time per batch: 0.100\n",
      "B70 -> time passed: 6.552 time per batch: 0.094\n",
      "test processing time: 9.011696100234985\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.270 time per batch: 0.114\n",
      "B30 -> time passed: 3.087 time per batch: 0.103\n",
      "B40 -> time passed: 3.913 time per batch: 0.098\n",
      "B50 -> time passed: 5.167 time per batch: 0.103\n",
      "B60 -> time passed: 6.055 time per batch: 0.101\n",
      "B70 -> time passed: 6.505 time per batch: 0.093\n",
      "test processing time: 9.001709461212158\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.441 time per batch: 0.144\n",
      "B20 -> time passed: 2.214 time per batch: 0.111\n",
      "B30 -> time passed: 2.997 time per batch: 0.100\n",
      "B40 -> time passed: 3.782 time per batch: 0.095\n",
      "B50 -> time passed: 5.127 time per batch: 0.103\n",
      "B60 -> time passed: 5.868 time per batch: 0.098\n",
      "B70 -> time passed: 6.514 time per batch: 0.093\n",
      "test processing time: 9.054370641708374\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.587 time per batch: 0.159\n",
      "B20 -> time passed: 2.429 time per batch: 0.121\n",
      "B30 -> time passed: 3.257 time per batch: 0.109\n",
      "B40 -> time passed: 4.039 time per batch: 0.101\n",
      "B50 -> time passed: 5.414 time per batch: 0.108\n",
      "B60 -> time passed: 6.145 time per batch: 0.102\n",
      "B70 -> time passed: 6.623 time per batch: 0.095\n",
      "test processing time: 9.108015298843384\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.539 time per batch: 0.154\n",
      "B20 -> time passed: 2.335 time per batch: 0.117\n",
      "B30 -> time passed: 3.151 time per batch: 0.105\n",
      "B40 -> time passed: 3.848 time per batch: 0.096\n",
      "B50 -> time passed: 5.289 time per batch: 0.106\n",
      "B60 -> time passed: 6.086 time per batch: 0.101\n",
      "B70 -> time passed: 6.623 time per batch: 0.095\n",
      "test processing time: 9.132219552993774\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.539 time per batch: 0.154\n",
      "B20 -> time passed: 2.321 time per batch: 0.116\n",
      "B30 -> time passed: 3.120 time per batch: 0.104\n",
      "B40 -> time passed: 3.908 time per batch: 0.098\n",
      "B50 -> time passed: 5.321 time per batch: 0.106\n",
      "B60 -> time passed: 6.083 time per batch: 0.101\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 9.082178354263306\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.580 time per batch: 0.158\n",
      "B20 -> time passed: 2.397 time per batch: 0.120\n",
      "B30 -> time passed: 3.223 time per batch: 0.107\n",
      "B40 -> time passed: 4.039 time per batch: 0.101\n",
      "B50 -> time passed: 5.443 time per batch: 0.109\n",
      "B60 -> time passed: 6.162 time per batch: 0.103\n",
      "B70 -> time passed: 6.612 time per batch: 0.094\n",
      "test processing time: 9.121468782424927\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.583 time per batch: 0.158\n",
      "B20 -> time passed: 2.445 time per batch: 0.122\n",
      "B30 -> time passed: 3.222 time per batch: 0.107\n",
      "B40 -> time passed: 4.040 time per batch: 0.101\n",
      "B50 -> time passed: 5.437 time per batch: 0.109\n",
      "B60 -> time passed: 6.150 time per batch: 0.102\n",
      "B70 -> time passed: 6.618 time per batch: 0.095\n",
      "test processing time: 9.156781435012817\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.326 time per batch: 0.116\n",
      "B30 -> time passed: 3.168 time per batch: 0.106\n",
      "B40 -> time passed: 3.997 time per batch: 0.100\n",
      "B50 -> time passed: 5.455 time per batch: 0.109\n",
      "B60 -> time passed: 6.221 time per batch: 0.104\n",
      "B70 -> time passed: 6.675 time per batch: 0.095\n",
      "test processing time: 9.21147608757019\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.527 time per batch: 0.153\n",
      "B20 -> time passed: 2.359 time per batch: 0.118\n",
      "B30 -> time passed: 3.173 time per batch: 0.106\n",
      "B40 -> time passed: 4.023 time per batch: 0.101\n",
      "B50 -> time passed: 5.489 time per batch: 0.110\n",
      "B60 -> time passed: 6.193 time per batch: 0.103\n",
      "B70 -> time passed: 6.648 time per batch: 0.095\n",
      "test processing time: 9.202656984329224\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.500 time per batch: 0.150\n",
      "B20 -> time passed: 2.290 time per batch: 0.114\n",
      "B30 -> time passed: 3.085 time per batch: 0.103\n",
      "B40 -> time passed: 3.861 time per batch: 0.097\n",
      "B50 -> time passed: 5.319 time per batch: 0.106\n",
      "B60 -> time passed: 6.053 time per batch: 0.101\n",
      "B70 -> time passed: 6.509 time per batch: 0.093\n",
      "test processing time: 9.089410305023193\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.583 time per batch: 0.158\n",
      "B20 -> time passed: 2.383 time per batch: 0.119\n",
      "B30 -> time passed: 3.210 time per batch: 0.107\n",
      "B40 -> time passed: 4.008 time per batch: 0.100\n",
      "B50 -> time passed: 5.457 time per batch: 0.109\n",
      "B60 -> time passed: 6.184 time per batch: 0.103\n",
      "B70 -> time passed: 6.596 time per batch: 0.094\n",
      "test processing time: 9.136579036712646\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.532 time per batch: 0.153\n",
      "B20 -> time passed: 2.294 time per batch: 0.115\n",
      "B30 -> time passed: 3.047 time per batch: 0.102\n",
      "B40 -> time passed: 3.887 time per batch: 0.097\n",
      "B50 -> time passed: 5.375 time per batch: 0.108\n",
      "B60 -> time passed: 6.084 time per batch: 0.101\n",
      "B70 -> time passed: 6.499 time per batch: 0.093\n",
      "test processing time: 8.933676958084106\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.253 time per batch: 0.113\n",
      "B30 -> time passed: 3.035 time per batch: 0.101\n",
      "B40 -> time passed: 3.758 time per batch: 0.094\n",
      "B50 -> time passed: 5.140 time per batch: 0.103\n",
      "B60 -> time passed: 5.909 time per batch: 0.098\n",
      "B70 -> time passed: 6.408 time per batch: 0.092\n",
      "test processing time: 8.87703013420105\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.529 time per batch: 0.153\n",
      "B20 -> time passed: 2.382 time per batch: 0.119\n",
      "B30 -> time passed: 3.254 time per batch: 0.108\n",
      "B40 -> time passed: 4.047 time per batch: 0.101\n",
      "B50 -> time passed: 5.470 time per batch: 0.109\n",
      "B60 -> time passed: 6.233 time per batch: 0.104\n",
      "B70 -> time passed: 6.689 time per batch: 0.096\n",
      "test processing time: 9.226715087890625\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.309 time per batch: 0.115\n",
      "B30 -> time passed: 3.137 time per batch: 0.105\n",
      "B40 -> time passed: 3.946 time per batch: 0.099\n",
      "B50 -> time passed: 5.305 time per batch: 0.106\n",
      "B60 -> time passed: 6.048 time per batch: 0.101\n",
      "B70 -> time passed: 6.630 time per batch: 0.095\n",
      "test processing time: 9.198661088943481\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.508 time per batch: 0.151\n",
      "B20 -> time passed: 2.289 time per batch: 0.114\n",
      "B30 -> time passed: 3.091 time per batch: 0.103\n",
      "B40 -> time passed: 3.947 time per batch: 0.099\n",
      "B50 -> time passed: 5.389 time per batch: 0.108\n",
      "B60 -> time passed: 6.202 time per batch: 0.103\n",
      "B70 -> time passed: 6.653 time per batch: 0.095\n",
      "test processing time: 9.221333265304565\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.584 time per batch: 0.158\n",
      "B20 -> time passed: 2.452 time per batch: 0.123\n",
      "B30 -> time passed: 3.286 time per batch: 0.110\n",
      "B40 -> time passed: 4.106 time per batch: 0.103\n",
      "B50 -> time passed: 5.568 time per batch: 0.111\n",
      "B60 -> time passed: 6.256 time per batch: 0.104\n",
      "B70 -> time passed: 6.727 time per batch: 0.096\n",
      "test processing time: 9.295363903045654\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.507 time per batch: 0.151\n",
      "B20 -> time passed: 2.311 time per batch: 0.116\n",
      "B30 -> time passed: 3.118 time per batch: 0.104\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.275 time per batch: 0.106\n",
      "B60 -> time passed: 6.144 time per batch: 0.102\n",
      "B70 -> time passed: 6.625 time per batch: 0.095\n",
      "test processing time: 9.152119398117065\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.498 time per batch: 0.150\n",
      "B20 -> time passed: 2.298 time per batch: 0.115\n",
      "B30 -> time passed: 3.119 time per batch: 0.104\n",
      "B40 -> time passed: 3.926 time per batch: 0.098\n",
      "B50 -> time passed: 5.375 time per batch: 0.108\n",
      "B60 -> time passed: 6.123 time per batch: 0.102\n",
      "B70 -> time passed: 6.607 time per batch: 0.094\n",
      "test processing time: 9.207146167755127\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.528 time per batch: 0.153\n",
      "B20 -> time passed: 2.387 time per batch: 0.119\n",
      "B30 -> time passed: 3.246 time per batch: 0.108\n",
      "B40 -> time passed: 4.075 time per batch: 0.102\n",
      "B50 -> time passed: 5.204 time per batch: 0.104\n",
      "B60 -> time passed: 6.317 time per batch: 0.105\n",
      "B70 -> time passed: 6.737 time per batch: 0.096\n",
      "test processing time: 9.19992733001709\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.572 time per batch: 0.157\n",
      "B20 -> time passed: 2.366 time per batch: 0.118\n",
      "B30 -> time passed: 3.187 time per batch: 0.106\n",
      "B40 -> time passed: 3.975 time per batch: 0.099\n",
      "B50 -> time passed: 5.348 time per batch: 0.107\n",
      "B60 -> time passed: 6.098 time per batch: 0.102\n",
      "B70 -> time passed: 6.581 time per batch: 0.094\n",
      "test processing time: 9.10925579071045\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.585 time per batch: 0.159\n",
      "B20 -> time passed: 2.435 time per batch: 0.122\n",
      "B30 -> time passed: 3.283 time per batch: 0.109\n",
      "B40 -> time passed: 4.138 time per batch: 0.103\n",
      "B50 -> time passed: 5.538 time per batch: 0.111\n",
      "B60 -> time passed: 6.241 time per batch: 0.104\n",
      "B70 -> time passed: 6.677 time per batch: 0.095\n",
      "test processing time: 9.216744661331177\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.573 time per batch: 0.157\n",
      "B20 -> time passed: 2.354 time per batch: 0.118\n",
      "B30 -> time passed: 3.169 time per batch: 0.106\n",
      "B40 -> time passed: 4.030 time per batch: 0.101\n",
      "B50 -> time passed: 5.453 time per batch: 0.109\n",
      "B60 -> time passed: 6.220 time per batch: 0.104\n",
      "B70 -> time passed: 6.668 time per batch: 0.095\n",
      "test processing time: 9.27119493484497\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d6.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 6 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.497 time per batch: 0.150\n",
      "B20 -> time passed: 2.268 time per batch: 0.113\n",
      "B30 -> time passed: 3.057 time per batch: 0.102\n",
      "B40 -> time passed: 3.834 time per batch: 0.096\n",
      "B50 -> time passed: 5.164 time per batch: 0.103\n",
      "B60 -> time passed: 5.912 time per batch: 0.099\n",
      "B70 -> time passed: 6.388 time per batch: 0.091\n",
      "test processing time: 8.983206510543823\n",
      "total time 883.3684198856354\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.496 time per batch: 0.150\n",
      "B20 -> time passed: 2.302 time per batch: 0.115\n",
      "B30 -> time passed: 3.096 time per batch: 0.103\n",
      "B40 -> time passed: 3.888 time per batch: 0.097\n",
      "B50 -> time passed: 5.227 time per batch: 0.105\n",
      "B60 -> time passed: 5.952 time per batch: 0.099\n",
      "B70 -> time passed: 6.449 time per batch: 0.092\n",
      "test processing time: 22.322985649108887\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.544 time per batch: 0.154\n",
      "B20 -> time passed: 2.340 time per batch: 0.117\n",
      "B30 -> time passed: 3.104 time per batch: 0.103\n",
      "B40 -> time passed: 3.852 time per batch: 0.096\n",
      "B50 -> time passed: 5.256 time per batch: 0.105\n",
      "B60 -> time passed: 6.006 time per batch: 0.100\n",
      "B70 -> time passed: 6.478 time per batch: 0.093\n",
      "test processing time: 11.416289567947388\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.636 time per batch: 0.164\n",
      "B20 -> time passed: 2.499 time per batch: 0.125\n",
      "B30 -> time passed: 3.378 time per batch: 0.113\n",
      "B40 -> time passed: 4.188 time per batch: 0.105\n",
      "B50 -> time passed: 5.654 time per batch: 0.113\n",
      "B60 -> time passed: 6.391 time per batch: 0.107\n",
      "B70 -> time passed: 6.845 time per batch: 0.098\n",
      "test processing time: 11.79332423210144\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.567 time per batch: 0.157\n",
      "B20 -> time passed: 2.416 time per batch: 0.121\n",
      "B30 -> time passed: 3.226 time per batch: 0.108\n",
      "B40 -> time passed: 4.086 time per batch: 0.102\n",
      "B50 -> time passed: 5.582 time per batch: 0.112\n",
      "B60 -> time passed: 6.346 time per batch: 0.106\n",
      "B70 -> time passed: 6.798 time per batch: 0.097\n",
      "test processing time: 11.766889333724976\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.356 time per batch: 0.118\n",
      "B30 -> time passed: 3.115 time per batch: 0.104\n",
      "B40 -> time passed: 3.879 time per batch: 0.097\n",
      "B50 -> time passed: 5.142 time per batch: 0.103\n",
      "B60 -> time passed: 6.048 time per batch: 0.101\n",
      "B70 -> time passed: 6.538 time per batch: 0.093\n",
      "test processing time: 11.467153787612915\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.595 time per batch: 0.160\n",
      "B20 -> time passed: 2.444 time per batch: 0.122\n",
      "B30 -> time passed: 3.249 time per batch: 0.108\n",
      "B40 -> time passed: 4.046 time per batch: 0.101\n",
      "B50 -> time passed: 5.405 time per batch: 0.108\n",
      "B60 -> time passed: 6.199 time per batch: 0.103\n",
      "B70 -> time passed: 6.700 time per batch: 0.096\n",
      "test processing time: 11.637989521026611\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.620 time per batch: 0.162\n",
      "B20 -> time passed: 2.427 time per batch: 0.121\n",
      "B30 -> time passed: 3.285 time per batch: 0.110\n",
      "B40 -> time passed: 4.153 time per batch: 0.104\n",
      "B50 -> time passed: 5.658 time per batch: 0.113\n",
      "B60 -> time passed: 6.366 time per batch: 0.106\n",
      "B70 -> time passed: 6.812 time per batch: 0.097\n",
      "test processing time: 11.779109716415405\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.596 time per batch: 0.160\n",
      "B20 -> time passed: 2.400 time per batch: 0.120\n",
      "B30 -> time passed: 3.221 time per batch: 0.107\n",
      "B40 -> time passed: 4.008 time per batch: 0.100\n",
      "B50 -> time passed: 5.338 time per batch: 0.107\n",
      "B60 -> time passed: 6.248 time per batch: 0.104\n",
      "B70 -> time passed: 6.718 time per batch: 0.096\n",
      "test processing time: 11.737497091293335\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.331 time per batch: 0.117\n",
      "B30 -> time passed: 3.146 time per batch: 0.105\n",
      "B40 -> time passed: 3.917 time per batch: 0.098\n",
      "B50 -> time passed: 5.356 time per batch: 0.107\n",
      "B60 -> time passed: 6.142 time per batch: 0.102\n",
      "B70 -> time passed: 6.609 time per batch: 0.094\n",
      "test processing time: 11.543105840682983\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.153\n",
      "B20 -> time passed: 2.364 time per batch: 0.118\n",
      "B30 -> time passed: 3.134 time per batch: 0.104\n",
      "B40 -> time passed: 3.889 time per batch: 0.097\n",
      "B50 -> time passed: 5.254 time per batch: 0.105\n",
      "B60 -> time passed: 6.137 time per batch: 0.102\n",
      "B70 -> time passed: 6.596 time per batch: 0.094\n",
      "test processing time: 11.587713479995728\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.515 time per batch: 0.152\n",
      "B20 -> time passed: 2.346 time per batch: 0.117\n",
      "B30 -> time passed: 3.098 time per batch: 0.103\n",
      "B40 -> time passed: 3.907 time per batch: 0.098\n",
      "B50 -> time passed: 5.293 time per batch: 0.106\n",
      "B60 -> time passed: 6.067 time per batch: 0.101\n",
      "B70 -> time passed: 6.509 time per batch: 0.093\n",
      "test processing time: 11.46996784210205\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.586 time per batch: 0.159\n",
      "B20 -> time passed: 2.462 time per batch: 0.123\n",
      "B30 -> time passed: 3.251 time per batch: 0.108\n",
      "B40 -> time passed: 4.127 time per batch: 0.103\n",
      "B50 -> time passed: 5.567 time per batch: 0.111\n",
      "B60 -> time passed: 6.336 time per batch: 0.106\n",
      "B70 -> time passed: 6.769 time per batch: 0.097\n",
      "test processing time: 11.748424291610718\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.601 time per batch: 0.160\n",
      "B20 -> time passed: 2.407 time per batch: 0.120\n",
      "B30 -> time passed: 3.197 time per batch: 0.107\n",
      "B40 -> time passed: 4.040 time per batch: 0.101\n",
      "B50 -> time passed: 5.496 time per batch: 0.110\n",
      "B60 -> time passed: 6.276 time per batch: 0.105\n",
      "B70 -> time passed: 6.745 time per batch: 0.096\n",
      "test processing time: 11.704918146133423\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.546 time per batch: 0.155\n",
      "B20 -> time passed: 2.359 time per batch: 0.118\n",
      "B30 -> time passed: 3.170 time per batch: 0.106\n",
      "B40 -> time passed: 3.994 time per batch: 0.100\n",
      "B50 -> time passed: 5.236 time per batch: 0.105\n",
      "B60 -> time passed: 6.204 time per batch: 0.103\n",
      "B70 -> time passed: 6.713 time per batch: 0.096\n",
      "test processing time: 11.745988368988037\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.607 time per batch: 0.161\n",
      "B20 -> time passed: 2.471 time per batch: 0.124\n",
      "B30 -> time passed: 3.348 time per batch: 0.112\n",
      "B40 -> time passed: 4.152 time per batch: 0.104\n",
      "B50 -> time passed: 5.545 time per batch: 0.111\n",
      "B60 -> time passed: 6.358 time per batch: 0.106\n",
      "B70 -> time passed: 6.875 time per batch: 0.098\n",
      "test processing time: 11.870309352874756\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.592 time per batch: 0.159\n",
      "B20 -> time passed: 2.402 time per batch: 0.120\n",
      "B30 -> time passed: 3.269 time per batch: 0.109\n",
      "B40 -> time passed: 4.102 time per batch: 0.103\n",
      "B50 -> time passed: 5.545 time per batch: 0.111\n",
      "B60 -> time passed: 6.305 time per batch: 0.105\n",
      "B70 -> time passed: 6.798 time per batch: 0.097\n",
      "test processing time: 11.76028847694397\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.627 time per batch: 0.163\n",
      "B20 -> time passed: 2.443 time per batch: 0.122\n",
      "B30 -> time passed: 3.298 time per batch: 0.110\n",
      "B40 -> time passed: 4.101 time per batch: 0.103\n",
      "B50 -> time passed: 5.453 time per batch: 0.109\n",
      "B60 -> time passed: 6.234 time per batch: 0.104\n",
      "B70 -> time passed: 6.725 time per batch: 0.096\n",
      "test processing time: 11.692259073257446\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.580 time per batch: 0.158\n",
      "B20 -> time passed: 2.401 time per batch: 0.120\n",
      "B30 -> time passed: 3.196 time per batch: 0.107\n",
      "B40 -> time passed: 4.089 time per batch: 0.102\n",
      "B50 -> time passed: 5.463 time per batch: 0.109\n",
      "B60 -> time passed: 6.244 time per batch: 0.104\n",
      "B70 -> time passed: 6.690 time per batch: 0.096\n",
      "test processing time: 11.680050134658813\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.597 time per batch: 0.160\n",
      "B20 -> time passed: 2.398 time per batch: 0.120\n",
      "B30 -> time passed: 3.237 time per batch: 0.108\n",
      "B40 -> time passed: 4.064 time per batch: 0.102\n",
      "B50 -> time passed: 5.483 time per batch: 0.110\n",
      "B60 -> time passed: 6.251 time per batch: 0.104\n",
      "B70 -> time passed: 6.789 time per batch: 0.097\n",
      "test processing time: 11.78839635848999\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.588 time per batch: 0.159\n",
      "B20 -> time passed: 2.449 time per batch: 0.122\n",
      "B30 -> time passed: 3.254 time per batch: 0.108\n",
      "B40 -> time passed: 4.042 time per batch: 0.101\n",
      "B50 -> time passed: 5.517 time per batch: 0.110\n",
      "B60 -> time passed: 6.299 time per batch: 0.105\n",
      "B70 -> time passed: 6.801 time per batch: 0.097\n",
      "test processing time: 11.84031343460083\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.574 time per batch: 0.157\n",
      "B20 -> time passed: 2.366 time per batch: 0.118\n",
      "B30 -> time passed: 3.219 time per batch: 0.107\n",
      "B40 -> time passed: 3.976 time per batch: 0.099\n",
      "B50 -> time passed: 5.275 time per batch: 0.106\n",
      "B60 -> time passed: 6.122 time per batch: 0.102\n",
      "B70 -> time passed: 6.689 time per batch: 0.096\n",
      "test processing time: 11.680577039718628\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.561 time per batch: 0.156\n",
      "B20 -> time passed: 2.359 time per batch: 0.118\n",
      "B30 -> time passed: 3.153 time per batch: 0.105\n",
      "B40 -> time passed: 3.967 time per batch: 0.099\n",
      "B50 -> time passed: 5.313 time per batch: 0.106\n",
      "B60 -> time passed: 6.131 time per batch: 0.102\n",
      "B70 -> time passed: 6.689 time per batch: 0.096\n",
      "test processing time: 11.66965365409851\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.583 time per batch: 0.158\n",
      "B20 -> time passed: 2.413 time per batch: 0.121\n",
      "B30 -> time passed: 3.278 time per batch: 0.109\n",
      "B40 -> time passed: 4.080 time per batch: 0.102\n",
      "B50 -> time passed: 5.490 time per batch: 0.110\n",
      "B60 -> time passed: 6.272 time per batch: 0.105\n",
      "B70 -> time passed: 6.764 time per batch: 0.097\n",
      "test processing time: 11.752203702926636\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.539 time per batch: 0.154\n",
      "B20 -> time passed: 2.320 time per batch: 0.116\n",
      "B30 -> time passed: 3.127 time per batch: 0.104\n",
      "B40 -> time passed: 3.944 time per batch: 0.099\n",
      "B50 -> time passed: 5.324 time per batch: 0.106\n",
      "B60 -> time passed: 6.134 time per batch: 0.102\n",
      "B70 -> time passed: 6.630 time per batch: 0.095\n",
      "test processing time: 11.542455434799194\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.499 time per batch: 0.150\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.917 time per batch: 0.098\n",
      "B50 -> time passed: 5.287 time per batch: 0.106\n",
      "B60 -> time passed: 6.150 time per batch: 0.102\n",
      "B70 -> time passed: 6.552 time per batch: 0.094\n",
      "test processing time: 11.54919695854187\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.577 time per batch: 0.158\n",
      "B20 -> time passed: 2.397 time per batch: 0.120\n",
      "B30 -> time passed: 3.222 time per batch: 0.107\n",
      "B40 -> time passed: 4.005 time per batch: 0.100\n",
      "B50 -> time passed: 5.495 time per batch: 0.110\n",
      "B60 -> time passed: 6.267 time per batch: 0.104\n",
      "B70 -> time passed: 6.737 time per batch: 0.096\n",
      "test processing time: 11.699341058731079\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.367 time per batch: 0.118\n",
      "B30 -> time passed: 3.226 time per batch: 0.108\n",
      "B40 -> time passed: 4.043 time per batch: 0.101\n",
      "B50 -> time passed: 5.377 time per batch: 0.108\n",
      "B60 -> time passed: 6.062 time per batch: 0.101\n",
      "B70 -> time passed: 6.541 time per batch: 0.093\n",
      "test processing time: 11.595119714736938\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.543 time per batch: 0.154\n",
      "B20 -> time passed: 2.422 time per batch: 0.121\n",
      "B30 -> time passed: 3.232 time per batch: 0.108\n",
      "B40 -> time passed: 3.994 time per batch: 0.100\n",
      "B50 -> time passed: 5.409 time per batch: 0.108\n",
      "B60 -> time passed: 6.272 time per batch: 0.105\n",
      "B70 -> time passed: 6.697 time per batch: 0.096\n",
      "test processing time: 11.688419342041016\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.546 time per batch: 0.155\n",
      "B20 -> time passed: 2.395 time per batch: 0.120\n",
      "B30 -> time passed: 3.276 time per batch: 0.109\n",
      "B40 -> time passed: 4.088 time per batch: 0.102\n",
      "B50 -> time passed: 5.446 time per batch: 0.109\n",
      "B60 -> time passed: 6.186 time per batch: 0.103\n",
      "B70 -> time passed: 6.702 time per batch: 0.096\n",
      "test processing time: 11.649563550949097\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.334 time per batch: 0.117\n",
      "B30 -> time passed: 3.123 time per batch: 0.104\n",
      "B40 -> time passed: 3.902 time per batch: 0.098\n",
      "B50 -> time passed: 5.209 time per batch: 0.104\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.489 time per batch: 0.093\n",
      "test processing time: 11.384141445159912\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.550 time per batch: 0.155\n",
      "B20 -> time passed: 2.360 time per batch: 0.118\n",
      "B30 -> time passed: 3.200 time per batch: 0.107\n",
      "B40 -> time passed: 4.034 time per batch: 0.101\n",
      "B50 -> time passed: 5.264 time per batch: 0.105\n",
      "B60 -> time passed: 6.170 time per batch: 0.103\n",
      "B70 -> time passed: 6.659 time per batch: 0.095\n",
      "test processing time: 11.632181882858276\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.509 time per batch: 0.151\n",
      "B20 -> time passed: 2.318 time per batch: 0.116\n",
      "B30 -> time passed: 3.117 time per batch: 0.104\n",
      "B40 -> time passed: 3.906 time per batch: 0.098\n",
      "B50 -> time passed: 5.276 time per batch: 0.106\n",
      "B60 -> time passed: 6.054 time per batch: 0.101\n",
      "B70 -> time passed: 6.524 time per batch: 0.093\n",
      "test processing time: 11.503279685974121\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.529 time per batch: 0.153\n",
      "B20 -> time passed: 2.376 time per batch: 0.119\n",
      "B30 -> time passed: 3.223 time per batch: 0.107\n",
      "B40 -> time passed: 4.067 time per batch: 0.102\n",
      "B50 -> time passed: 5.482 time per batch: 0.110\n",
      "B60 -> time passed: 6.265 time per batch: 0.104\n",
      "B70 -> time passed: 6.695 time per batch: 0.096\n",
      "test processing time: 22.64159870147705\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.153\n",
      "B20 -> time passed: 2.432 time per batch: 0.122\n",
      "B30 -> time passed: 3.221 time per batch: 0.107\n",
      "B40 -> time passed: 4.060 time per batch: 0.101\n",
      "B50 -> time passed: 5.351 time per batch: 0.107\n",
      "B60 -> time passed: 6.160 time per batch: 0.103\n",
      "B70 -> time passed: 6.636 time per batch: 0.095\n",
      "test processing time: 11.627165079116821\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.551 time per batch: 0.155\n",
      "B20 -> time passed: 2.401 time per batch: 0.120\n",
      "B30 -> time passed: 3.263 time per batch: 0.109\n",
      "B40 -> time passed: 4.148 time per batch: 0.104\n",
      "B50 -> time passed: 5.545 time per batch: 0.111\n",
      "B60 -> time passed: 6.277 time per batch: 0.105\n",
      "B70 -> time passed: 6.708 time per batch: 0.096\n",
      "test processing time: 11.720735788345337\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.579 time per batch: 0.158\n",
      "B20 -> time passed: 2.323 time per batch: 0.116\n",
      "B30 -> time passed: 3.198 time per batch: 0.107\n",
      "B40 -> time passed: 3.955 time per batch: 0.099\n",
      "B50 -> time passed: 5.351 time per batch: 0.107\n",
      "B60 -> time passed: 6.134 time per batch: 0.102\n",
      "B70 -> time passed: 6.627 time per batch: 0.095\n",
      "test processing time: 11.61001706123352\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.541 time per batch: 0.154\n",
      "B20 -> time passed: 2.335 time per batch: 0.117\n",
      "B30 -> time passed: 3.128 time per batch: 0.104\n",
      "B40 -> time passed: 3.904 time per batch: 0.098\n",
      "B50 -> time passed: 5.215 time per batch: 0.104\n",
      "B60 -> time passed: 6.049 time per batch: 0.101\n",
      "B70 -> time passed: 6.582 time per batch: 0.094\n",
      "test processing time: 11.542827844619751\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.579 time per batch: 0.158\n",
      "B20 -> time passed: 2.394 time per batch: 0.120\n",
      "B30 -> time passed: 3.175 time per batch: 0.106\n",
      "B40 -> time passed: 3.979 time per batch: 0.099\n",
      "B50 -> time passed: 5.393 time per batch: 0.108\n",
      "B60 -> time passed: 6.168 time per batch: 0.103\n",
      "B70 -> time passed: 6.602 time per batch: 0.094\n",
      "test processing time: 11.618227005004883\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.499 time per batch: 0.150\n",
      "B20 -> time passed: 2.327 time per batch: 0.116\n",
      "B30 -> time passed: 3.101 time per batch: 0.103\n",
      "B40 -> time passed: 3.872 time per batch: 0.097\n",
      "B50 -> time passed: 5.195 time per batch: 0.104\n",
      "B60 -> time passed: 6.087 time per batch: 0.101\n",
      "B70 -> time passed: 6.614 time per batch: 0.094\n",
      "test processing time: 11.577794790267944\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.570 time per batch: 0.157\n",
      "B20 -> time passed: 2.330 time per batch: 0.116\n",
      "B30 -> time passed: 3.116 time per batch: 0.104\n",
      "B40 -> time passed: 3.918 time per batch: 0.098\n",
      "B50 -> time passed: 5.230 time per batch: 0.105\n",
      "B60 -> time passed: 6.019 time per batch: 0.100\n",
      "B70 -> time passed: 6.605 time per batch: 0.094\n",
      "test processing time: 11.57157850265503\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.503 time per batch: 0.150\n",
      "B20 -> time passed: 2.330 time per batch: 0.117\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.879 time per batch: 0.097\n",
      "B50 -> time passed: 5.107 time per batch: 0.102\n",
      "B60 -> time passed: 5.989 time per batch: 0.100\n",
      "B70 -> time passed: 6.512 time per batch: 0.093\n",
      "test processing time: 11.442933559417725\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.509 time per batch: 0.151\n",
      "B20 -> time passed: 2.301 time per batch: 0.115\n",
      "B30 -> time passed: 3.113 time per batch: 0.104\n",
      "B40 -> time passed: 3.910 time per batch: 0.098\n",
      "B50 -> time passed: 5.214 time per batch: 0.104\n",
      "B60 -> time passed: 6.048 time per batch: 0.101\n",
      "B70 -> time passed: 6.530 time per batch: 0.093\n",
      "test processing time: 11.483132123947144\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.473 time per batch: 0.147\n",
      "B20 -> time passed: 2.259 time per batch: 0.113\n",
      "B30 -> time passed: 3.079 time per batch: 0.103\n",
      "B40 -> time passed: 3.837 time per batch: 0.096\n",
      "B50 -> time passed: 5.143 time per batch: 0.103\n",
      "B60 -> time passed: 5.965 time per batch: 0.099\n",
      "B70 -> time passed: 6.487 time per batch: 0.093\n",
      "test processing time: 11.509948015213013\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.600 time per batch: 0.160\n",
      "B20 -> time passed: 2.376 time per batch: 0.119\n",
      "B30 -> time passed: 3.212 time per batch: 0.107\n",
      "B40 -> time passed: 4.036 time per batch: 0.101\n",
      "B50 -> time passed: 5.518 time per batch: 0.110\n",
      "B60 -> time passed: 6.251 time per batch: 0.104\n",
      "B70 -> time passed: 6.693 time per batch: 0.096\n",
      "test processing time: 11.63502812385559\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.500 time per batch: 0.150\n",
      "B20 -> time passed: 2.332 time per batch: 0.117\n",
      "B30 -> time passed: 3.172 time per batch: 0.106\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.196 time per batch: 0.104\n",
      "B60 -> time passed: 6.069 time per batch: 0.101\n",
      "B70 -> time passed: 6.521 time per batch: 0.093\n",
      "test processing time: 11.46792721748352\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.569 time per batch: 0.157\n",
      "B20 -> time passed: 2.331 time per batch: 0.117\n",
      "B30 -> time passed: 3.131 time per batch: 0.104\n",
      "B40 -> time passed: 3.906 time per batch: 0.098\n",
      "B50 -> time passed: 5.436 time per batch: 0.109\n",
      "B60 -> time passed: 6.181 time per batch: 0.103\n",
      "B70 -> time passed: 6.613 time per batch: 0.094\n",
      "test processing time: 11.545190334320068\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.336 time per batch: 0.117\n",
      "B30 -> time passed: 3.161 time per batch: 0.105\n",
      "B40 -> time passed: 3.938 time per batch: 0.098\n",
      "B50 -> time passed: 5.249 time per batch: 0.105\n",
      "B60 -> time passed: 6.149 time per batch: 0.102\n",
      "B70 -> time passed: 6.567 time per batch: 0.094\n",
      "test processing time: 11.55138874053955\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.475 time per batch: 0.148\n",
      "B20 -> time passed: 2.289 time per batch: 0.114\n",
      "B30 -> time passed: 3.115 time per batch: 0.104\n",
      "B40 -> time passed: 3.902 time per batch: 0.098\n",
      "B50 -> time passed: 5.374 time per batch: 0.107\n",
      "B60 -> time passed: 6.120 time per batch: 0.102\n",
      "B70 -> time passed: 6.590 time per batch: 0.094\n",
      "test processing time: 11.552595138549805\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.514 time per batch: 0.151\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.116 time per batch: 0.104\n",
      "B40 -> time passed: 3.953 time per batch: 0.099\n",
      "B50 -> time passed: 5.176 time per batch: 0.104\n",
      "B60 -> time passed: 5.996 time per batch: 0.100\n",
      "B70 -> time passed: 6.641 time per batch: 0.095\n",
      "test processing time: 11.570778369903564\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.562 time per batch: 0.156\n",
      "B20 -> time passed: 2.337 time per batch: 0.117\n",
      "B30 -> time passed: 3.181 time per batch: 0.106\n",
      "B40 -> time passed: 3.984 time per batch: 0.100\n",
      "B50 -> time passed: 5.468 time per batch: 0.109\n",
      "B60 -> time passed: 6.235 time per batch: 0.104\n",
      "B70 -> time passed: 6.666 time per batch: 0.095\n",
      "test processing time: 11.60957932472229\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.601 time per batch: 0.160\n",
      "B20 -> time passed: 2.465 time per batch: 0.123\n",
      "B30 -> time passed: 3.270 time per batch: 0.109\n",
      "B40 -> time passed: 4.048 time per batch: 0.101\n",
      "B50 -> time passed: 5.435 time per batch: 0.109\n",
      "B60 -> time passed: 6.172 time per batch: 0.103\n",
      "B70 -> time passed: 6.630 time per batch: 0.095\n",
      "test processing time: 11.619052171707153\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.519 time per batch: 0.152\n",
      "B20 -> time passed: 2.296 time per batch: 0.115\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.953 time per batch: 0.099\n",
      "B50 -> time passed: 5.281 time per batch: 0.106\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.556 time per batch: 0.094\n",
      "test processing time: 11.51915979385376\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.481 time per batch: 0.148\n",
      "B20 -> time passed: 2.287 time per batch: 0.114\n",
      "B30 -> time passed: 3.065 time per batch: 0.102\n",
      "B40 -> time passed: 3.846 time per batch: 0.096\n",
      "B50 -> time passed: 5.201 time per batch: 0.104\n",
      "B60 -> time passed: 6.003 time per batch: 0.100\n",
      "B70 -> time passed: 6.495 time per batch: 0.093\n",
      "test processing time: 11.480162620544434\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.495 time per batch: 0.149\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.977 time per batch: 0.099\n",
      "B50 -> time passed: 5.388 time per batch: 0.108\n",
      "B60 -> time passed: 6.144 time per batch: 0.102\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 11.56082034111023\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.341 time per batch: 0.117\n",
      "B30 -> time passed: 3.156 time per batch: 0.105\n",
      "B40 -> time passed: 3.941 time per batch: 0.099\n",
      "B50 -> time passed: 5.211 time per batch: 0.104\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 11.576170444488525\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.579 time per batch: 0.158\n",
      "B20 -> time passed: 2.419 time per batch: 0.121\n",
      "B30 -> time passed: 3.257 time per batch: 0.109\n",
      "B40 -> time passed: 4.043 time per batch: 0.101\n",
      "B50 -> time passed: 5.435 time per batch: 0.109\n",
      "B60 -> time passed: 6.168 time per batch: 0.103\n",
      "B70 -> time passed: 6.643 time per batch: 0.095\n",
      "test processing time: 11.614633321762085\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.312 time per batch: 0.116\n",
      "B30 -> time passed: 3.089 time per batch: 0.103\n",
      "B40 -> time passed: 3.934 time per batch: 0.098\n",
      "B50 -> time passed: 5.139 time per batch: 0.103\n",
      "B60 -> time passed: 6.076 time per batch: 0.101\n",
      "B70 -> time passed: 6.563 time per batch: 0.094\n",
      "test processing time: 11.558240175247192\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.595 time per batch: 0.159\n",
      "B20 -> time passed: 2.446 time per batch: 0.122\n",
      "B30 -> time passed: 3.268 time per batch: 0.109\n",
      "B40 -> time passed: 4.043 time per batch: 0.101\n",
      "B50 -> time passed: 5.433 time per batch: 0.109\n",
      "B60 -> time passed: 6.305 time per batch: 0.105\n",
      "B70 -> time passed: 6.757 time per batch: 0.097\n",
      "test processing time: 11.804036617279053\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.554 time per batch: 0.155\n",
      "B20 -> time passed: 2.372 time per batch: 0.119\n",
      "B30 -> time passed: 3.200 time per batch: 0.107\n",
      "B40 -> time passed: 4.037 time per batch: 0.101\n",
      "B50 -> time passed: 5.415 time per batch: 0.108\n",
      "B60 -> time passed: 6.235 time per batch: 0.104\n",
      "B70 -> time passed: 6.678 time per batch: 0.095\n",
      "test processing time: 11.644407033920288\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.548 time per batch: 0.155\n",
      "B20 -> time passed: 2.418 time per batch: 0.121\n",
      "B30 -> time passed: 3.228 time per batch: 0.108\n",
      "B40 -> time passed: 3.992 time per batch: 0.100\n",
      "B50 -> time passed: 5.469 time per batch: 0.109\n",
      "B60 -> time passed: 6.276 time per batch: 0.105\n",
      "B70 -> time passed: 6.718 time per batch: 0.096\n",
      "test processing time: 11.742904901504517\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.564 time per batch: 0.156\n",
      "B20 -> time passed: 2.368 time per batch: 0.118\n",
      "B30 -> time passed: 3.181 time per batch: 0.106\n",
      "B40 -> time passed: 3.959 time per batch: 0.099\n",
      "B50 -> time passed: 5.315 time per batch: 0.106\n",
      "B60 -> time passed: 6.144 time per batch: 0.102\n",
      "B70 -> time passed: 6.679 time per batch: 0.095\n",
      "test processing time: 11.70627737045288\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.582 time per batch: 0.158\n",
      "B20 -> time passed: 2.394 time per batch: 0.120\n",
      "B30 -> time passed: 3.262 time per batch: 0.109\n",
      "B40 -> time passed: 4.062 time per batch: 0.102\n",
      "B50 -> time passed: 5.488 time per batch: 0.110\n",
      "B60 -> time passed: 6.227 time per batch: 0.104\n",
      "B70 -> time passed: 6.696 time per batch: 0.096\n",
      "test processing time: 11.656155109405518\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.492 time per batch: 0.149\n",
      "B20 -> time passed: 2.295 time per batch: 0.115\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.951 time per batch: 0.099\n",
      "B50 -> time passed: 5.387 time per batch: 0.108\n",
      "B60 -> time passed: 6.138 time per batch: 0.102\n",
      "B70 -> time passed: 6.667 time per batch: 0.095\n",
      "test processing time: 11.679659366607666\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.558 time per batch: 0.156\n",
      "B20 -> time passed: 2.363 time per batch: 0.118\n",
      "B30 -> time passed: 3.174 time per batch: 0.106\n",
      "B40 -> time passed: 3.940 time per batch: 0.099\n",
      "B50 -> time passed: 5.288 time per batch: 0.106\n",
      "B60 -> time passed: 6.104 time per batch: 0.102\n",
      "B70 -> time passed: 6.610 time per batch: 0.094\n",
      "test processing time: 11.630499124526978\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.560 time per batch: 0.156\n",
      "B20 -> time passed: 2.393 time per batch: 0.120\n",
      "B30 -> time passed: 3.226 time per batch: 0.108\n",
      "B40 -> time passed: 4.098 time per batch: 0.102\n",
      "B50 -> time passed: 5.541 time per batch: 0.111\n",
      "B60 -> time passed: 6.285 time per batch: 0.105\n",
      "B70 -> time passed: 6.805 time per batch: 0.097\n",
      "test processing time: 22.619751453399658\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.651 time per batch: 0.165\n",
      "B20 -> time passed: 2.549 time per batch: 0.127\n",
      "B30 -> time passed: 3.380 time per batch: 0.113\n",
      "B40 -> time passed: 4.262 time per batch: 0.107\n",
      "B50 -> time passed: 5.722 time per batch: 0.114\n",
      "B60 -> time passed: 6.379 time per batch: 0.106\n",
      "B70 -> time passed: 6.851 time per batch: 0.098\n",
      "test processing time: 11.907772541046143\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.553 time per batch: 0.155\n",
      "B20 -> time passed: 2.370 time per batch: 0.118\n",
      "B30 -> time passed: 3.171 time per batch: 0.106\n",
      "B40 -> time passed: 4.026 time per batch: 0.101\n",
      "B50 -> time passed: 5.397 time per batch: 0.108\n",
      "B60 -> time passed: 6.175 time per batch: 0.103\n",
      "B70 -> time passed: 6.679 time per batch: 0.095\n",
      "test processing time: 11.690492868423462\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.593 time per batch: 0.159\n",
      "B20 -> time passed: 2.464 time per batch: 0.123\n",
      "B30 -> time passed: 3.241 time per batch: 0.108\n",
      "B40 -> time passed: 4.072 time per batch: 0.102\n",
      "B50 -> time passed: 5.500 time per batch: 0.110\n",
      "B60 -> time passed: 6.304 time per batch: 0.105\n",
      "B70 -> time passed: 6.820 time per batch: 0.097\n",
      "test processing time: 11.754159212112427\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.614 time per batch: 0.161\n",
      "B20 -> time passed: 2.438 time per batch: 0.122\n",
      "B30 -> time passed: 3.247 time per batch: 0.108\n",
      "B40 -> time passed: 4.082 time per batch: 0.102\n",
      "B50 -> time passed: 5.467 time per batch: 0.109\n",
      "B60 -> time passed: 6.245 time per batch: 0.104\n",
      "B70 -> time passed: 6.714 time per batch: 0.096\n",
      "test processing time: 11.670424461364746\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.586 time per batch: 0.159\n",
      "B20 -> time passed: 2.377 time per batch: 0.119\n",
      "B30 -> time passed: 3.212 time per batch: 0.107\n",
      "B40 -> time passed: 4.005 time per batch: 0.100\n",
      "B50 -> time passed: 5.341 time per batch: 0.107\n",
      "B60 -> time passed: 6.148 time per batch: 0.102\n",
      "B70 -> time passed: 6.654 time per batch: 0.095\n",
      "test processing time: 11.61866545677185\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.153\n",
      "B20 -> time passed: 2.363 time per batch: 0.118\n",
      "B30 -> time passed: 3.211 time per batch: 0.107\n",
      "B40 -> time passed: 4.007 time per batch: 0.100\n",
      "B50 -> time passed: 5.387 time per batch: 0.108\n",
      "B60 -> time passed: 6.207 time per batch: 0.103\n",
      "B70 -> time passed: 6.654 time per batch: 0.095\n",
      "test processing time: 11.622314453125\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.343 time per batch: 0.117\n",
      "B30 -> time passed: 3.157 time per batch: 0.105\n",
      "B40 -> time passed: 3.916 time per batch: 0.098\n",
      "B50 -> time passed: 5.251 time per batch: 0.105\n",
      "B60 -> time passed: 6.082 time per batch: 0.101\n",
      "B70 -> time passed: 6.575 time per batch: 0.094\n",
      "test processing time: 11.569512367248535\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.542 time per batch: 0.154\n",
      "B20 -> time passed: 2.357 time per batch: 0.118\n",
      "B30 -> time passed: 3.142 time per batch: 0.105\n",
      "B40 -> time passed: 3.986 time per batch: 0.100\n",
      "B50 -> time passed: 5.423 time per batch: 0.108\n",
      "B60 -> time passed: 6.249 time per batch: 0.104\n",
      "B70 -> time passed: 6.740 time per batch: 0.096\n",
      "test processing time: 11.774159908294678\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.342 time per batch: 0.117\n",
      "B30 -> time passed: 3.207 time per batch: 0.107\n",
      "B40 -> time passed: 4.019 time per batch: 0.100\n",
      "B50 -> time passed: 5.228 time per batch: 0.105\n",
      "B60 -> time passed: 6.357 time per batch: 0.106\n",
      "B70 -> time passed: 6.817 time per batch: 0.097\n",
      "test processing time: 11.869484186172485\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.534 time per batch: 0.153\n",
      "B20 -> time passed: 2.370 time per batch: 0.118\n",
      "B30 -> time passed: 3.166 time per batch: 0.106\n",
      "B40 -> time passed: 3.971 time per batch: 0.099\n",
      "B50 -> time passed: 5.236 time per batch: 0.105\n",
      "B60 -> time passed: 6.080 time per batch: 0.101\n",
      "B70 -> time passed: 6.636 time per batch: 0.095\n",
      "test processing time: 11.611292839050293\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.571 time per batch: 0.157\n",
      "B20 -> time passed: 2.386 time per batch: 0.119\n",
      "B30 -> time passed: 3.202 time per batch: 0.107\n",
      "B40 -> time passed: 4.001 time per batch: 0.100\n",
      "B50 -> time passed: 5.367 time per batch: 0.107\n",
      "B60 -> time passed: 6.154 time per batch: 0.103\n",
      "B70 -> time passed: 6.663 time per batch: 0.095\n",
      "test processing time: 11.657577753067017\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.553 time per batch: 0.155\n",
      "B20 -> time passed: 2.342 time per batch: 0.117\n",
      "B30 -> time passed: 3.151 time per batch: 0.105\n",
      "B40 -> time passed: 3.919 time per batch: 0.098\n",
      "B50 -> time passed: 5.223 time per batch: 0.104\n",
      "B60 -> time passed: 6.133 time per batch: 0.102\n",
      "B70 -> time passed: 6.615 time per batch: 0.094\n",
      "test processing time: 11.600436925888062\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.501 time per batch: 0.150\n",
      "B20 -> time passed: 2.283 time per batch: 0.114\n",
      "B30 -> time passed: 3.107 time per batch: 0.104\n",
      "B40 -> time passed: 3.904 time per batch: 0.098\n",
      "B50 -> time passed: 5.255 time per batch: 0.105\n",
      "B60 -> time passed: 6.074 time per batch: 0.101\n",
      "B70 -> time passed: 6.576 time per batch: 0.094\n",
      "test processing time: 11.56071424484253\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.494 time per batch: 0.149\n",
      "B20 -> time passed: 2.286 time per batch: 0.114\n",
      "B30 -> time passed: 3.094 time per batch: 0.103\n",
      "B40 -> time passed: 3.860 time per batch: 0.096\n",
      "B50 -> time passed: 5.287 time per batch: 0.106\n",
      "B60 -> time passed: 6.107 time per batch: 0.102\n",
      "B70 -> time passed: 6.599 time per batch: 0.094\n",
      "test processing time: 11.585032224655151\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.582 time per batch: 0.158\n",
      "B20 -> time passed: 2.422 time per batch: 0.121\n",
      "B30 -> time passed: 3.291 time per batch: 0.110\n",
      "B40 -> time passed: 4.149 time per batch: 0.104\n",
      "B50 -> time passed: 5.575 time per batch: 0.111\n",
      "B60 -> time passed: 6.320 time per batch: 0.105\n",
      "B70 -> time passed: 6.762 time per batch: 0.097\n",
      "test processing time: 11.735456705093384\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.310 time per batch: 0.116\n",
      "B30 -> time passed: 3.128 time per batch: 0.104\n",
      "B40 -> time passed: 3.924 time per batch: 0.098\n",
      "B50 -> time passed: 5.264 time per batch: 0.105\n",
      "B60 -> time passed: 6.070 time per batch: 0.101\n",
      "B70 -> time passed: 6.571 time per batch: 0.094\n",
      "test processing time: 11.570740222930908\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.550 time per batch: 0.155\n",
      "B20 -> time passed: 2.353 time per batch: 0.118\n",
      "B30 -> time passed: 3.138 time per batch: 0.105\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.280 time per batch: 0.106\n",
      "B60 -> time passed: 6.012 time per batch: 0.100\n",
      "B70 -> time passed: 6.689 time per batch: 0.096\n",
      "test processing time: 11.651012182235718\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.537 time per batch: 0.154\n",
      "B20 -> time passed: 2.422 time per batch: 0.121\n",
      "B30 -> time passed: 3.259 time per batch: 0.109\n",
      "B40 -> time passed: 4.055 time per batch: 0.101\n",
      "B50 -> time passed: 5.250 time per batch: 0.105\n",
      "B60 -> time passed: 6.231 time per batch: 0.104\n",
      "B70 -> time passed: 6.695 time per batch: 0.096\n",
      "test processing time: 11.689144611358643\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.530 time per batch: 0.153\n",
      "B20 -> time passed: 2.346 time per batch: 0.117\n",
      "B30 -> time passed: 3.166 time per batch: 0.106\n",
      "B40 -> time passed: 3.961 time per batch: 0.099\n",
      "B50 -> time passed: 5.352 time per batch: 0.107\n",
      "B60 -> time passed: 6.078 time per batch: 0.101\n",
      "B70 -> time passed: 6.582 time per batch: 0.094\n",
      "test processing time: 11.56137490272522\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.153\n",
      "B20 -> time passed: 2.337 time per batch: 0.117\n",
      "B30 -> time passed: 3.126 time per batch: 0.104\n",
      "B40 -> time passed: 3.946 time per batch: 0.099\n",
      "B50 -> time passed: 5.342 time per batch: 0.107\n",
      "B60 -> time passed: 6.161 time per batch: 0.103\n",
      "B70 -> time passed: 6.642 time per batch: 0.095\n",
      "test processing time: 11.587265729904175\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.391 time per batch: 0.120\n",
      "B30 -> time passed: 3.183 time per batch: 0.106\n",
      "B40 -> time passed: 3.994 time per batch: 0.100\n",
      "B50 -> time passed: 5.206 time per batch: 0.104\n",
      "B60 -> time passed: 6.146 time per batch: 0.102\n",
      "B70 -> time passed: 6.622 time per batch: 0.095\n",
      "test processing time: 11.611432790756226\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.552 time per batch: 0.155\n",
      "B20 -> time passed: 2.368 time per batch: 0.118\n",
      "B30 -> time passed: 3.172 time per batch: 0.106\n",
      "B40 -> time passed: 4.022 time per batch: 0.101\n",
      "B50 -> time passed: 5.257 time per batch: 0.105\n",
      "B60 -> time passed: 6.167 time per batch: 0.103\n",
      "B70 -> time passed: 6.615 time per batch: 0.095\n",
      "test processing time: 11.58305811882019\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.568 time per batch: 0.157\n",
      "B20 -> time passed: 2.427 time per batch: 0.121\n",
      "B30 -> time passed: 3.210 time per batch: 0.107\n",
      "B40 -> time passed: 3.989 time per batch: 0.100\n",
      "B50 -> time passed: 5.503 time per batch: 0.110\n",
      "B60 -> time passed: 6.238 time per batch: 0.104\n",
      "B70 -> time passed: 6.695 time per batch: 0.096\n",
      "test processing time: 11.663631916046143\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.533 time per batch: 0.153\n",
      "B20 -> time passed: 2.332 time per batch: 0.117\n",
      "B30 -> time passed: 3.210 time per batch: 0.107\n",
      "B40 -> time passed: 4.062 time per batch: 0.102\n",
      "B50 -> time passed: 5.218 time per batch: 0.104\n",
      "B60 -> time passed: 6.306 time per batch: 0.105\n",
      "B70 -> time passed: 6.734 time per batch: 0.096\n",
      "test processing time: 11.72162938117981\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.585 time per batch: 0.158\n",
      "B20 -> time passed: 2.386 time per batch: 0.119\n",
      "B30 -> time passed: 3.178 time per batch: 0.106\n",
      "B40 -> time passed: 4.006 time per batch: 0.100\n",
      "B50 -> time passed: 5.387 time per batch: 0.108\n",
      "B60 -> time passed: 6.222 time per batch: 0.104\n",
      "B70 -> time passed: 6.703 time per batch: 0.096\n",
      "test processing time: 11.79380488395691\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.539 time per batch: 0.154\n",
      "B20 -> time passed: 2.397 time per batch: 0.120\n",
      "B30 -> time passed: 3.208 time per batch: 0.107\n",
      "B40 -> time passed: 4.068 time per batch: 0.102\n",
      "B50 -> time passed: 5.481 time per batch: 0.110\n",
      "B60 -> time passed: 6.242 time per batch: 0.104\n",
      "B70 -> time passed: 6.693 time per batch: 0.096\n",
      "test processing time: 11.728047609329224\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.330 time per batch: 0.116\n",
      "B30 -> time passed: 3.172 time per batch: 0.106\n",
      "B40 -> time passed: 3.990 time per batch: 0.100\n",
      "B50 -> time passed: 5.212 time per batch: 0.104\n",
      "B60 -> time passed: 6.179 time per batch: 0.103\n",
      "B70 -> time passed: 6.644 time per batch: 0.095\n",
      "test processing time: 11.660760402679443\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.568 time per batch: 0.157\n",
      "B20 -> time passed: 2.375 time per batch: 0.119\n",
      "B30 -> time passed: 3.227 time per batch: 0.108\n",
      "B40 -> time passed: 3.970 time per batch: 0.099\n",
      "B50 -> time passed: 5.373 time per batch: 0.107\n",
      "B60 -> time passed: 6.128 time per batch: 0.102\n",
      "B70 -> time passed: 6.653 time per batch: 0.095\n",
      "test processing time: 11.678520441055298\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.541 time per batch: 0.154\n",
      "B20 -> time passed: 2.326 time per batch: 0.116\n",
      "B30 -> time passed: 3.119 time per batch: 0.104\n",
      "B40 -> time passed: 3.919 time per batch: 0.098\n",
      "B50 -> time passed: 5.219 time per batch: 0.104\n",
      "B60 -> time passed: 6.114 time per batch: 0.102\n",
      "B70 -> time passed: 6.616 time per batch: 0.095\n",
      "test processing time: 11.614607572555542\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.726 time per batch: 0.173\n",
      "B20 -> time passed: 2.482 time per batch: 0.124\n",
      "B30 -> time passed: 3.287 time per batch: 0.110\n",
      "B40 -> time passed: 4.071 time per batch: 0.102\n",
      "B50 -> time passed: 5.391 time per batch: 0.108\n",
      "B60 -> time passed: 6.170 time per batch: 0.103\n",
      "B70 -> time passed: 6.699 time per batch: 0.096\n",
      "test processing time: 11.699623823165894\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.530 time per batch: 0.153\n",
      "B20 -> time passed: 2.309 time per batch: 0.115\n",
      "B30 -> time passed: 3.110 time per batch: 0.104\n",
      "B40 -> time passed: 3.922 time per batch: 0.098\n",
      "B50 -> time passed: 5.223 time per batch: 0.104\n",
      "B60 -> time passed: 6.185 time per batch: 0.103\n",
      "B70 -> time passed: 6.675 time per batch: 0.095\n",
      "test processing time: 11.66807746887207\n",
      "total time 2037.5209605693817\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.278 time per batch: 0.114\n",
      "B30 -> time passed: 3.059 time per batch: 0.102\n",
      "B40 -> time passed: 3.876 time per batch: 0.097\n",
      "B50 -> time passed: 5.235 time per batch: 0.105\n",
      "B60 -> time passed: 6.045 time per batch: 0.101\n",
      "B70 -> time passed: 6.509 time per batch: 0.093\n",
      "test processing time: 12.604173183441162\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.528 time per batch: 0.153\n",
      "B20 -> time passed: 2.307 time per batch: 0.115\n",
      "B30 -> time passed: 3.092 time per batch: 0.103\n",
      "B40 -> time passed: 3.913 time per batch: 0.098\n",
      "B50 -> time passed: 5.236 time per batch: 0.105\n",
      "B60 -> time passed: 6.060 time per batch: 0.101\n",
      "B70 -> time passed: 6.518 time per batch: 0.093\n",
      "test processing time: 8.851070165634155\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.536 time per batch: 0.154\n",
      "B20 -> time passed: 2.330 time per batch: 0.116\n",
      "B30 -> time passed: 3.156 time per batch: 0.105\n",
      "B40 -> time passed: 3.960 time per batch: 0.099\n",
      "B50 -> time passed: 5.377 time per batch: 0.108\n",
      "B60 -> time passed: 6.156 time per batch: 0.103\n",
      "B70 -> time passed: 6.614 time per batch: 0.094\n",
      "test processing time: 8.906870126724243\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.419 time per batch: 0.142\n",
      "B20 -> time passed: 2.184 time per batch: 0.109\n",
      "B30 -> time passed: 2.902 time per batch: 0.097\n",
      "B40 -> time passed: 3.651 time per batch: 0.091\n",
      "B50 -> time passed: 4.886 time per batch: 0.098\n",
      "B60 -> time passed: 5.778 time per batch: 0.096\n",
      "B70 -> time passed: 6.249 time per batch: 0.089\n",
      "test processing time: 8.60757303237915\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.483 time per batch: 0.148\n",
      "B20 -> time passed: 2.330 time per batch: 0.116\n",
      "B30 -> time passed: 3.131 time per batch: 0.104\n",
      "B40 -> time passed: 3.930 time per batch: 0.098\n",
      "B50 -> time passed: 5.061 time per batch: 0.101\n",
      "B60 -> time passed: 5.906 time per batch: 0.098\n",
      "B70 -> time passed: 6.382 time per batch: 0.091\n",
      "test processing time: 8.631661415100098\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.484 time per batch: 0.148\n",
      "B20 -> time passed: 2.247 time per batch: 0.112\n",
      "B30 -> time passed: 3.077 time per batch: 0.103\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.237 time per batch: 0.105\n",
      "B60 -> time passed: 5.988 time per batch: 0.100\n",
      "B70 -> time passed: 6.528 time per batch: 0.093\n",
      "test processing time: 8.775143146514893\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.351 time per batch: 0.118\n",
      "B30 -> time passed: 3.082 time per batch: 0.103\n",
      "B40 -> time passed: 3.905 time per batch: 0.098\n",
      "B50 -> time passed: 5.363 time per batch: 0.107\n",
      "B60 -> time passed: 6.146 time per batch: 0.102\n",
      "B70 -> time passed: 6.590 time per batch: 0.094\n",
      "test processing time: 8.899165630340576\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.472 time per batch: 0.147\n",
      "B20 -> time passed: 2.239 time per batch: 0.112\n",
      "B30 -> time passed: 3.013 time per batch: 0.100\n",
      "B40 -> time passed: 3.809 time per batch: 0.095\n",
      "B50 -> time passed: 5.160 time per batch: 0.103\n",
      "B60 -> time passed: 5.993 time per batch: 0.100\n",
      "B70 -> time passed: 6.508 time per batch: 0.093\n",
      "test processing time: 8.842163324356079\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.555 time per batch: 0.155\n",
      "B20 -> time passed: 2.372 time per batch: 0.119\n",
      "B30 -> time passed: 3.163 time per batch: 0.105\n",
      "B40 -> time passed: 4.014 time per batch: 0.100\n",
      "B50 -> time passed: 5.410 time per batch: 0.108\n",
      "B60 -> time passed: 6.117 time per batch: 0.102\n",
      "B70 -> time passed: 6.576 time per batch: 0.094\n",
      "test processing time: 8.948529720306396\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.498 time per batch: 0.150\n",
      "B20 -> time passed: 2.332 time per batch: 0.117\n",
      "B30 -> time passed: 3.154 time per batch: 0.105\n",
      "B40 -> time passed: 3.965 time per batch: 0.099\n",
      "B50 -> time passed: 5.108 time per batch: 0.102\n",
      "B60 -> time passed: 6.078 time per batch: 0.101\n",
      "B70 -> time passed: 6.503 time per batch: 0.093\n",
      "test processing time: 8.835140705108643\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.528 time per batch: 0.153\n",
      "B20 -> time passed: 2.361 time per batch: 0.118\n",
      "B30 -> time passed: 3.181 time per batch: 0.106\n",
      "B40 -> time passed: 4.012 time per batch: 0.100\n",
      "B50 -> time passed: 5.452 time per batch: 0.109\n",
      "B60 -> time passed: 6.202 time per batch: 0.103\n",
      "B70 -> time passed: 6.716 time per batch: 0.096\n",
      "test processing time: 9.079910278320312\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.546 time per batch: 0.155\n",
      "B20 -> time passed: 2.334 time per batch: 0.117\n",
      "B30 -> time passed: 3.095 time per batch: 0.103\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.240 time per batch: 0.105\n",
      "B60 -> time passed: 6.052 time per batch: 0.101\n",
      "B70 -> time passed: 6.526 time per batch: 0.093\n",
      "test processing time: 8.878143787384033\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.566 time per batch: 0.157\n",
      "B20 -> time passed: 2.347 time per batch: 0.117\n",
      "B30 -> time passed: 3.207 time per batch: 0.107\n",
      "B40 -> time passed: 3.981 time per batch: 0.100\n",
      "B50 -> time passed: 5.297 time per batch: 0.106\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.568 time per batch: 0.094\n",
      "test processing time: 8.902189016342163\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.150\n",
      "B20 -> time passed: 2.248 time per batch: 0.112\n",
      "B30 -> time passed: 3.032 time per batch: 0.101\n",
      "B40 -> time passed: 3.830 time per batch: 0.096\n",
      "B50 -> time passed: 5.174 time per batch: 0.103\n",
      "B60 -> time passed: 5.918 time per batch: 0.099\n",
      "B70 -> time passed: 6.436 time per batch: 0.092\n",
      "test processing time: 8.751132249832153\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.536 time per batch: 0.154\n",
      "B20 -> time passed: 2.335 time per batch: 0.117\n",
      "B30 -> time passed: 3.153 time per batch: 0.105\n",
      "B40 -> time passed: 3.973 time per batch: 0.099\n",
      "B50 -> time passed: 5.331 time per batch: 0.107\n",
      "B60 -> time passed: 6.055 time per batch: 0.101\n",
      "B70 -> time passed: 6.497 time per batch: 0.093\n",
      "test processing time: 8.808717489242554\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.523 time per batch: 0.152\n",
      "B20 -> time passed: 2.316 time per batch: 0.116\n",
      "B30 -> time passed: 3.074 time per batch: 0.102\n",
      "B40 -> time passed: 3.896 time per batch: 0.097\n",
      "B50 -> time passed: 5.337 time per batch: 0.107\n",
      "B60 -> time passed: 5.969 time per batch: 0.099\n",
      "B70 -> time passed: 6.430 time per batch: 0.092\n",
      "test processing time: 8.752521991729736\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.552 time per batch: 0.155\n",
      "B20 -> time passed: 2.280 time per batch: 0.114\n",
      "B30 -> time passed: 3.049 time per batch: 0.102\n",
      "B40 -> time passed: 3.811 time per batch: 0.095\n",
      "B50 -> time passed: 5.160 time per batch: 0.103\n",
      "B60 -> time passed: 6.010 time per batch: 0.100\n",
      "B70 -> time passed: 6.477 time per batch: 0.093\n",
      "test processing time: 8.7849280834198\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.458 time per batch: 0.146\n",
      "B20 -> time passed: 2.245 time per batch: 0.112\n",
      "B30 -> time passed: 2.997 time per batch: 0.100\n",
      "B40 -> time passed: 3.785 time per batch: 0.095\n",
      "B50 -> time passed: 5.089 time per batch: 0.102\n",
      "B60 -> time passed: 5.953 time per batch: 0.099\n",
      "B70 -> time passed: 6.469 time per batch: 0.092\n",
      "test processing time: 8.816241979598999\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.486 time per batch: 0.149\n",
      "B20 -> time passed: 2.282 time per batch: 0.114\n",
      "B30 -> time passed: 3.036 time per batch: 0.101\n",
      "B40 -> time passed: 3.831 time per batch: 0.096\n",
      "B50 -> time passed: 5.192 time per batch: 0.104\n",
      "B60 -> time passed: 5.938 time per batch: 0.099\n",
      "B70 -> time passed: 6.482 time per batch: 0.093\n",
      "test processing time: 8.774255990982056\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.538 time per batch: 0.154\n",
      "B20 -> time passed: 2.292 time per batch: 0.115\n",
      "B30 -> time passed: 3.085 time per batch: 0.103\n",
      "B40 -> time passed: 3.868 time per batch: 0.097\n",
      "B50 -> time passed: 5.284 time per batch: 0.106\n",
      "B60 -> time passed: 6.061 time per batch: 0.101\n",
      "B70 -> time passed: 6.552 time per batch: 0.094\n",
      "test processing time: 8.847543478012085\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.292 time per batch: 0.115\n",
      "B30 -> time passed: 3.044 time per batch: 0.101\n",
      "B40 -> time passed: 3.829 time per batch: 0.096\n",
      "B50 -> time passed: 5.121 time per batch: 0.102\n",
      "B60 -> time passed: 5.907 time per batch: 0.098\n",
      "B70 -> time passed: 6.450 time per batch: 0.092\n",
      "test processing time: 8.75608491897583\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.530 time per batch: 0.153\n",
      "B20 -> time passed: 2.309 time per batch: 0.115\n",
      "B30 -> time passed: 3.088 time per batch: 0.103\n",
      "B40 -> time passed: 3.870 time per batch: 0.097\n",
      "B50 -> time passed: 5.254 time per batch: 0.105\n",
      "B60 -> time passed: 6.037 time per batch: 0.101\n",
      "B70 -> time passed: 6.553 time per batch: 0.094\n",
      "test processing time: 8.868181467056274\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.456 time per batch: 0.146\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.823 time per batch: 0.096\n",
      "B50 -> time passed: 5.135 time per batch: 0.103\n",
      "B60 -> time passed: 5.987 time per batch: 0.100\n",
      "B70 -> time passed: 6.447 time per batch: 0.092\n",
      "test processing time: 8.827534198760986\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.558 time per batch: 0.156\n",
      "B20 -> time passed: 2.348 time per batch: 0.117\n",
      "B30 -> time passed: 3.182 time per batch: 0.106\n",
      "B40 -> time passed: 3.999 time per batch: 0.100\n",
      "B50 -> time passed: 5.434 time per batch: 0.109\n",
      "B60 -> time passed: 6.216 time per batch: 0.104\n",
      "B70 -> time passed: 6.651 time per batch: 0.095\n",
      "test processing time: 8.953395128250122\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.495 time per batch: 0.149\n",
      "B20 -> time passed: 2.267 time per batch: 0.113\n",
      "B30 -> time passed: 3.068 time per batch: 0.102\n",
      "B40 -> time passed: 3.836 time per batch: 0.096\n",
      "B50 -> time passed: 5.068 time per batch: 0.101\n",
      "B60 -> time passed: 5.998 time per batch: 0.100\n",
      "B70 -> time passed: 6.485 time per batch: 0.093\n",
      "test processing time: 8.793564558029175\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.507 time per batch: 0.151\n",
      "B20 -> time passed: 2.315 time per batch: 0.116\n",
      "B30 -> time passed: 3.092 time per batch: 0.103\n",
      "B40 -> time passed: 3.892 time per batch: 0.097\n",
      "B50 -> time passed: 5.059 time per batch: 0.101\n",
      "B60 -> time passed: 5.994 time per batch: 0.100\n",
      "B70 -> time passed: 6.468 time per batch: 0.092\n",
      "test processing time: 8.770667791366577\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.524 time per batch: 0.152\n",
      "B20 -> time passed: 2.333 time per batch: 0.117\n",
      "B30 -> time passed: 3.169 time per batch: 0.106\n",
      "B40 -> time passed: 3.977 time per batch: 0.099\n",
      "B50 -> time passed: 5.443 time per batch: 0.109\n",
      "B60 -> time passed: 6.116 time per batch: 0.102\n",
      "B70 -> time passed: 6.573 time per batch: 0.094\n",
      "test processing time: 8.851788520812988\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.492 time per batch: 0.149\n",
      "B20 -> time passed: 2.297 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.887 time per batch: 0.097\n",
      "B50 -> time passed: 5.058 time per batch: 0.101\n",
      "B60 -> time passed: 6.050 time per batch: 0.101\n",
      "B70 -> time passed: 6.514 time per batch: 0.093\n",
      "test processing time: 8.82554578781128\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.307 time per batch: 0.115\n",
      "B30 -> time passed: 3.119 time per batch: 0.104\n",
      "B40 -> time passed: 3.929 time per batch: 0.098\n",
      "B50 -> time passed: 5.299 time per batch: 0.106\n",
      "B60 -> time passed: 6.131 time per batch: 0.102\n",
      "B70 -> time passed: 6.539 time per batch: 0.093\n",
      "test processing time: 8.87134599685669\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.576 time per batch: 0.158\n",
      "B20 -> time passed: 2.360 time per batch: 0.118\n",
      "B30 -> time passed: 3.149 time per batch: 0.105\n",
      "B40 -> time passed: 3.943 time per batch: 0.099\n",
      "B50 -> time passed: 5.360 time per batch: 0.107\n",
      "B60 -> time passed: 6.122 time per batch: 0.102\n",
      "B70 -> time passed: 6.575 time per batch: 0.094\n",
      "test processing time: 8.866196393966675\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.556 time per batch: 0.156\n",
      "B20 -> time passed: 2.336 time per batch: 0.117\n",
      "B30 -> time passed: 3.147 time per batch: 0.105\n",
      "B40 -> time passed: 3.927 time per batch: 0.098\n",
      "B50 -> time passed: 5.349 time per batch: 0.107\n",
      "B60 -> time passed: 6.074 time per batch: 0.101\n",
      "B70 -> time passed: 6.529 time per batch: 0.093\n",
      "test processing time: 8.81784725189209\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.475 time per batch: 0.147\n",
      "B20 -> time passed: 2.286 time per batch: 0.114\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.855 time per batch: 0.096\n",
      "B50 -> time passed: 5.163 time per batch: 0.103\n",
      "B60 -> time passed: 6.001 time per batch: 0.100\n",
      "B70 -> time passed: 6.461 time per batch: 0.092\n",
      "test processing time: 8.728048324584961\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.572 time per batch: 0.157\n",
      "B20 -> time passed: 2.407 time per batch: 0.120\n",
      "B30 -> time passed: 3.188 time per batch: 0.106\n",
      "B40 -> time passed: 3.997 time per batch: 0.100\n",
      "B50 -> time passed: 5.337 time per batch: 0.107\n",
      "B60 -> time passed: 6.206 time per batch: 0.103\n",
      "B70 -> time passed: 6.688 time per batch: 0.096\n",
      "test processing time: 12.539693832397461\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.318 time per batch: 0.116\n",
      "B30 -> time passed: 3.102 time per batch: 0.103\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.308 time per batch: 0.106\n",
      "B60 -> time passed: 6.061 time per batch: 0.101\n",
      "B70 -> time passed: 6.529 time per batch: 0.093\n",
      "test processing time: 8.840806007385254\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.545 time per batch: 0.154\n",
      "B20 -> time passed: 2.311 time per batch: 0.116\n",
      "B30 -> time passed: 3.136 time per batch: 0.105\n",
      "B40 -> time passed: 3.892 time per batch: 0.097\n",
      "B50 -> time passed: 5.283 time per batch: 0.106\n",
      "B60 -> time passed: 6.139 time per batch: 0.102\n",
      "B70 -> time passed: 6.579 time per batch: 0.094\n",
      "test processing time: 8.84884762763977\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.153\n",
      "B20 -> time passed: 2.298 time per batch: 0.115\n",
      "B30 -> time passed: 3.087 time per batch: 0.103\n",
      "B40 -> time passed: 3.917 time per batch: 0.098\n",
      "B50 -> time passed: 5.343 time per batch: 0.107\n",
      "B60 -> time passed: 6.095 time per batch: 0.102\n",
      "B70 -> time passed: 6.557 time per batch: 0.094\n",
      "test processing time: 8.853194236755371\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.504 time per batch: 0.150\n",
      "B20 -> time passed: 2.264 time per batch: 0.113\n",
      "B30 -> time passed: 3.081 time per batch: 0.103\n",
      "B40 -> time passed: 3.803 time per batch: 0.095\n",
      "B50 -> time passed: 5.199 time per batch: 0.104\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.504 time per batch: 0.093\n",
      "test processing time: 8.783921241760254\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.515 time per batch: 0.151\n",
      "B20 -> time passed: 2.306 time per batch: 0.115\n",
      "B30 -> time passed: 3.080 time per batch: 0.103\n",
      "B40 -> time passed: 3.894 time per batch: 0.097\n",
      "B50 -> time passed: 5.158 time per batch: 0.103\n",
      "B60 -> time passed: 6.072 time per batch: 0.101\n",
      "B70 -> time passed: 6.636 time per batch: 0.095\n",
      "test processing time: 8.920394897460938\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.278 time per batch: 0.114\n",
      "B30 -> time passed: 3.080 time per batch: 0.103\n",
      "B40 -> time passed: 3.864 time per batch: 0.097\n",
      "B50 -> time passed: 5.224 time per batch: 0.104\n",
      "B60 -> time passed: 5.979 time per batch: 0.100\n",
      "B70 -> time passed: 6.517 time per batch: 0.093\n",
      "test processing time: 8.843246698379517\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.523 time per batch: 0.152\n",
      "B20 -> time passed: 2.282 time per batch: 0.114\n",
      "B30 -> time passed: 3.073 time per batch: 0.102\n",
      "B40 -> time passed: 3.851 time per batch: 0.096\n",
      "B50 -> time passed: 5.212 time per batch: 0.104\n",
      "B60 -> time passed: 6.007 time per batch: 0.100\n",
      "B70 -> time passed: 6.470 time per batch: 0.092\n",
      "test processing time: 8.733114957809448\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.296 time per batch: 0.115\n",
      "B30 -> time passed: 3.131 time per batch: 0.104\n",
      "B40 -> time passed: 3.886 time per batch: 0.097\n",
      "B50 -> time passed: 5.309 time per batch: 0.106\n",
      "B60 -> time passed: 6.159 time per batch: 0.103\n",
      "B70 -> time passed: 6.586 time per batch: 0.094\n",
      "test processing time: 8.851855993270874\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.530 time per batch: 0.153\n",
      "B20 -> time passed: 2.323 time per batch: 0.116\n",
      "B30 -> time passed: 3.084 time per batch: 0.103\n",
      "B40 -> time passed: 3.889 time per batch: 0.097\n",
      "B50 -> time passed: 5.295 time per batch: 0.106\n",
      "B60 -> time passed: 6.029 time per batch: 0.100\n",
      "B70 -> time passed: 6.538 time per batch: 0.093\n",
      "test processing time: 8.831599950790405\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.493 time per batch: 0.149\n",
      "B20 -> time passed: 2.334 time per batch: 0.117\n",
      "B30 -> time passed: 3.143 time per batch: 0.105\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.221 time per batch: 0.104\n",
      "B60 -> time passed: 6.133 time per batch: 0.102\n",
      "B70 -> time passed: 6.614 time per batch: 0.094\n",
      "test processing time: 8.908931732177734\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.538 time per batch: 0.154\n",
      "B20 -> time passed: 2.322 time per batch: 0.116\n",
      "B30 -> time passed: 3.135 time per batch: 0.104\n",
      "B40 -> time passed: 3.947 time per batch: 0.099\n",
      "B50 -> time passed: 5.257 time per batch: 0.105\n",
      "B60 -> time passed: 6.120 time per batch: 0.102\n",
      "B70 -> time passed: 6.639 time per batch: 0.095\n",
      "test processing time: 8.926486492156982\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.573 time per batch: 0.157\n",
      "B20 -> time passed: 2.354 time per batch: 0.118\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.953 time per batch: 0.099\n",
      "B50 -> time passed: 5.331 time per batch: 0.107\n",
      "B60 -> time passed: 6.132 time per batch: 0.102\n",
      "B70 -> time passed: 6.610 time per batch: 0.094\n",
      "test processing time: 8.888048648834229\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.558 time per batch: 0.156\n",
      "B20 -> time passed: 2.336 time per batch: 0.117\n",
      "B30 -> time passed: 3.169 time per batch: 0.106\n",
      "B40 -> time passed: 3.922 time per batch: 0.098\n",
      "B50 -> time passed: 5.340 time per batch: 0.107\n",
      "B60 -> time passed: 6.057 time per batch: 0.101\n",
      "B70 -> time passed: 6.538 time per batch: 0.093\n",
      "test processing time: 8.846452474594116\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.518 time per batch: 0.152\n",
      "B20 -> time passed: 2.270 time per batch: 0.114\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.905 time per batch: 0.098\n",
      "B50 -> time passed: 5.361 time per batch: 0.107\n",
      "B60 -> time passed: 6.167 time per batch: 0.103\n",
      "B70 -> time passed: 6.625 time per batch: 0.095\n",
      "test processing time: 8.901999950408936\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.496 time per batch: 0.150\n",
      "B20 -> time passed: 2.242 time per batch: 0.112\n",
      "B30 -> time passed: 3.044 time per batch: 0.101\n",
      "B40 -> time passed: 3.891 time per batch: 0.097\n",
      "B50 -> time passed: 5.292 time per batch: 0.106\n",
      "B60 -> time passed: 6.047 time per batch: 0.101\n",
      "B70 -> time passed: 6.525 time per batch: 0.093\n",
      "test processing time: 8.847315073013306\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.519 time per batch: 0.152\n",
      "B20 -> time passed: 2.330 time per batch: 0.117\n",
      "B30 -> time passed: 3.116 time per batch: 0.104\n",
      "B40 -> time passed: 3.942 time per batch: 0.099\n",
      "B50 -> time passed: 5.151 time per batch: 0.103\n",
      "B60 -> time passed: 6.103 time per batch: 0.102\n",
      "B70 -> time passed: 6.562 time per batch: 0.094\n",
      "test processing time: 8.849372386932373\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.524 time per batch: 0.152\n",
      "B20 -> time passed: 2.328 time per batch: 0.116\n",
      "B30 -> time passed: 3.159 time per batch: 0.105\n",
      "B40 -> time passed: 3.939 time per batch: 0.098\n",
      "B50 -> time passed: 5.206 time per batch: 0.104\n",
      "B60 -> time passed: 6.126 time per batch: 0.102\n",
      "B70 -> time passed: 6.601 time per batch: 0.094\n",
      "test processing time: 8.874018669128418\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.302 time per batch: 0.115\n",
      "B30 -> time passed: 3.128 time per batch: 0.104\n",
      "B40 -> time passed: 3.881 time per batch: 0.097\n",
      "B50 -> time passed: 5.254 time per batch: 0.105\n",
      "B60 -> time passed: 6.071 time per batch: 0.101\n",
      "B70 -> time passed: 6.523 time per batch: 0.093\n",
      "test processing time: 8.777599334716797\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.564 time per batch: 0.156\n",
      "B20 -> time passed: 2.353 time per batch: 0.118\n",
      "B30 -> time passed: 3.164 time per batch: 0.105\n",
      "B40 -> time passed: 3.948 time per batch: 0.099\n",
      "B50 -> time passed: 5.237 time per batch: 0.105\n",
      "B60 -> time passed: 6.124 time per batch: 0.102\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 8.867504596710205\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.554 time per batch: 0.155\n",
      "B20 -> time passed: 2.298 time per batch: 0.115\n",
      "B30 -> time passed: 3.090 time per batch: 0.103\n",
      "B40 -> time passed: 3.874 time per batch: 0.097\n",
      "B50 -> time passed: 5.253 time per batch: 0.105\n",
      "B60 -> time passed: 6.022 time per batch: 0.100\n",
      "B70 -> time passed: 6.539 time per batch: 0.093\n",
      "test processing time: 8.808531999588013\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.309 time per batch: 0.115\n",
      "B30 -> time passed: 3.132 time per batch: 0.104\n",
      "B40 -> time passed: 4.005 time per batch: 0.100\n",
      "B50 -> time passed: 5.479 time per batch: 0.110\n",
      "B60 -> time passed: 6.183 time per batch: 0.103\n",
      "B70 -> time passed: 6.650 time per batch: 0.095\n",
      "test processing time: 8.956343173980713\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.482 time per batch: 0.148\n",
      "B20 -> time passed: 2.275 time per batch: 0.114\n",
      "B30 -> time passed: 3.040 time per batch: 0.101\n",
      "B40 -> time passed: 3.835 time per batch: 0.096\n",
      "B50 -> time passed: 5.122 time per batch: 0.102\n",
      "B60 -> time passed: 6.030 time per batch: 0.100\n",
      "B70 -> time passed: 6.591 time per batch: 0.094\n",
      "test processing time: 8.873743295669556\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.152\n",
      "B20 -> time passed: 2.359 time per batch: 0.118\n",
      "B30 -> time passed: 3.184 time per batch: 0.106\n",
      "B40 -> time passed: 3.994 time per batch: 0.100\n",
      "B50 -> time passed: 5.211 time per batch: 0.104\n",
      "B60 -> time passed: 6.154 time per batch: 0.103\n",
      "B70 -> time passed: 6.639 time per batch: 0.095\n",
      "test processing time: 8.95044493675232\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.529 time per batch: 0.153\n",
      "B20 -> time passed: 2.315 time per batch: 0.116\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.263 time per batch: 0.105\n",
      "B60 -> time passed: 6.081 time per batch: 0.101\n",
      "B70 -> time passed: 6.581 time per batch: 0.094\n",
      "test processing time: 8.898542881011963\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.549 time per batch: 0.155\n",
      "B20 -> time passed: 2.380 time per batch: 0.119\n",
      "B30 -> time passed: 3.202 time per batch: 0.107\n",
      "B40 -> time passed: 4.030 time per batch: 0.101\n",
      "B50 -> time passed: 5.274 time per batch: 0.105\n",
      "B60 -> time passed: 6.187 time per batch: 0.103\n",
      "B70 -> time passed: 6.668 time per batch: 0.095\n",
      "test processing time: 8.94844651222229\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.152\n",
      "B20 -> time passed: 2.341 time per batch: 0.117\n",
      "B30 -> time passed: 3.147 time per batch: 0.105\n",
      "B40 -> time passed: 3.930 time per batch: 0.098\n",
      "B50 -> time passed: 5.321 time per batch: 0.106\n",
      "B60 -> time passed: 6.113 time per batch: 0.102\n",
      "B70 -> time passed: 6.612 time per batch: 0.094\n",
      "test processing time: 8.900826454162598\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.519 time per batch: 0.152\n",
      "B20 -> time passed: 2.292 time per batch: 0.115\n",
      "B30 -> time passed: 3.110 time per batch: 0.104\n",
      "B40 -> time passed: 3.915 time per batch: 0.098\n",
      "B50 -> time passed: 5.137 time per batch: 0.103\n",
      "B60 -> time passed: 6.063 time per batch: 0.101\n",
      "B70 -> time passed: 6.575 time per batch: 0.094\n",
      "test processing time: 8.849917888641357\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.576 time per batch: 0.158\n",
      "B20 -> time passed: 2.370 time per batch: 0.119\n",
      "B30 -> time passed: 3.221 time per batch: 0.107\n",
      "B40 -> time passed: 4.027 time per batch: 0.101\n",
      "B50 -> time passed: 5.539 time per batch: 0.111\n",
      "B60 -> time passed: 6.244 time per batch: 0.104\n",
      "B70 -> time passed: 6.697 time per batch: 0.096\n",
      "test processing time: 8.94111156463623\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.484 time per batch: 0.148\n",
      "B20 -> time passed: 2.296 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.893 time per batch: 0.097\n",
      "B50 -> time passed: 5.257 time per batch: 0.105\n",
      "B60 -> time passed: 6.059 time per batch: 0.101\n",
      "B70 -> time passed: 6.512 time per batch: 0.093\n",
      "test processing time: 8.791300773620605\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.568 time per batch: 0.157\n",
      "B20 -> time passed: 2.378 time per batch: 0.119\n",
      "B30 -> time passed: 3.155 time per batch: 0.105\n",
      "B40 -> time passed: 3.939 time per batch: 0.098\n",
      "B50 -> time passed: 5.296 time per batch: 0.106\n",
      "B60 -> time passed: 6.084 time per batch: 0.101\n",
      "B70 -> time passed: 6.533 time per batch: 0.093\n",
      "test processing time: 8.807520627975464\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.549 time per batch: 0.155\n",
      "B20 -> time passed: 2.403 time per batch: 0.120\n",
      "B30 -> time passed: 3.191 time per batch: 0.106\n",
      "B40 -> time passed: 4.022 time per batch: 0.101\n",
      "B50 -> time passed: 5.449 time per batch: 0.109\n",
      "B60 -> time passed: 6.220 time per batch: 0.104\n",
      "B70 -> time passed: 6.656 time per batch: 0.095\n",
      "test processing time: 8.914926528930664\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.482 time per batch: 0.148\n",
      "B20 -> time passed: 2.539 time per batch: 0.127\n",
      "B30 -> time passed: 3.292 time per batch: 0.110\n",
      "B40 -> time passed: 4.083 time per batch: 0.102\n",
      "B50 -> time passed: 5.048 time per batch: 0.101\n",
      "B60 -> time passed: 6.143 time per batch: 0.102\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 12.525097846984863\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.469 time per batch: 0.147\n",
      "B20 -> time passed: 2.235 time per batch: 0.112\n",
      "B30 -> time passed: 3.027 time per batch: 0.101\n",
      "B40 -> time passed: 3.829 time per batch: 0.096\n",
      "B50 -> time passed: 5.202 time per batch: 0.104\n",
      "B60 -> time passed: 5.961 time per batch: 0.099\n",
      "B70 -> time passed: 6.485 time per batch: 0.093\n",
      "test processing time: 8.76728892326355\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.539 time per batch: 0.154\n",
      "B20 -> time passed: 2.337 time per batch: 0.117\n",
      "B30 -> time passed: 3.114 time per batch: 0.104\n",
      "B40 -> time passed: 3.913 time per batch: 0.098\n",
      "B50 -> time passed: 5.426 time per batch: 0.109\n",
      "B60 -> time passed: 6.159 time per batch: 0.103\n",
      "B70 -> time passed: 6.570 time per batch: 0.094\n",
      "test processing time: 8.872875928878784\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.504 time per batch: 0.150\n",
      "B20 -> time passed: 2.280 time per batch: 0.114\n",
      "B30 -> time passed: 3.053 time per batch: 0.102\n",
      "B40 -> time passed: 3.840 time per batch: 0.096\n",
      "B50 -> time passed: 5.211 time per batch: 0.104\n",
      "B60 -> time passed: 5.984 time per batch: 0.100\n",
      "B70 -> time passed: 6.512 time per batch: 0.093\n",
      "test processing time: 8.772040605545044\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.485 time per batch: 0.149\n",
      "B20 -> time passed: 2.224 time per batch: 0.111\n",
      "B30 -> time passed: 3.016 time per batch: 0.101\n",
      "B40 -> time passed: 3.828 time per batch: 0.096\n",
      "B50 -> time passed: 5.216 time per batch: 0.104\n",
      "B60 -> time passed: 5.993 time per batch: 0.100\n",
      "B70 -> time passed: 6.426 time per batch: 0.092\n",
      "test processing time: 8.690860509872437\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.515 time per batch: 0.151\n",
      "B20 -> time passed: 2.272 time per batch: 0.114\n",
      "B30 -> time passed: 3.066 time per batch: 0.102\n",
      "B40 -> time passed: 3.832 time per batch: 0.096\n",
      "B50 -> time passed: 5.149 time per batch: 0.103\n",
      "B60 -> time passed: 5.926 time per batch: 0.099\n",
      "B70 -> time passed: 6.425 time per batch: 0.092\n",
      "test processing time: 8.711238145828247\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.536 time per batch: 0.154\n",
      "B20 -> time passed: 2.330 time per batch: 0.116\n",
      "B30 -> time passed: 3.120 time per batch: 0.104\n",
      "B40 -> time passed: 3.918 time per batch: 0.098\n",
      "B50 -> time passed: 5.183 time per batch: 0.104\n",
      "B60 -> time passed: 6.010 time per batch: 0.100\n",
      "B70 -> time passed: 6.460 time per batch: 0.092\n",
      "test processing time: 8.718761444091797\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.433 time per batch: 0.143\n",
      "B20 -> time passed: 2.231 time per batch: 0.112\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.761 time per batch: 0.094\n",
      "B50 -> time passed: 5.001 time per batch: 0.100\n",
      "B60 -> time passed: 5.896 time per batch: 0.098\n",
      "B70 -> time passed: 6.366 time per batch: 0.091\n",
      "test processing time: 8.734464168548584\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.233 time per batch: 0.112\n",
      "B30 -> time passed: 3.035 time per batch: 0.101\n",
      "B40 -> time passed: 3.823 time per batch: 0.096\n",
      "B50 -> time passed: 5.191 time per batch: 0.104\n",
      "B60 -> time passed: 5.986 time per batch: 0.100\n",
      "B70 -> time passed: 6.481 time per batch: 0.093\n",
      "test processing time: 8.735866069793701\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.256 time per batch: 0.113\n",
      "B30 -> time passed: 3.036 time per batch: 0.101\n",
      "B40 -> time passed: 3.809 time per batch: 0.095\n",
      "B50 -> time passed: 5.243 time per batch: 0.105\n",
      "B60 -> time passed: 6.001 time per batch: 0.100\n",
      "B70 -> time passed: 6.467 time per batch: 0.092\n",
      "test processing time: 8.742335081100464\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.264 time per batch: 0.113\n",
      "B30 -> time passed: 3.004 time per batch: 0.100\n",
      "B40 -> time passed: 3.781 time per batch: 0.095\n",
      "B50 -> time passed: 5.085 time per batch: 0.102\n",
      "B60 -> time passed: 5.911 time per batch: 0.099\n",
      "B70 -> time passed: 6.383 time per batch: 0.091\n",
      "test processing time: 8.634852170944214\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.475 time per batch: 0.148\n",
      "B20 -> time passed: 2.237 time per batch: 0.112\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.788 time per batch: 0.095\n",
      "B50 -> time passed: 5.172 time per batch: 0.103\n",
      "B60 -> time passed: 5.981 time per batch: 0.100\n",
      "B70 -> time passed: 6.484 time per batch: 0.093\n",
      "test processing time: 8.737295627593994\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.509 time per batch: 0.151\n",
      "B20 -> time passed: 2.271 time per batch: 0.114\n",
      "B30 -> time passed: 3.050 time per batch: 0.102\n",
      "B40 -> time passed: 3.856 time per batch: 0.096\n",
      "B50 -> time passed: 5.198 time per batch: 0.104\n",
      "B60 -> time passed: 5.949 time per batch: 0.099\n",
      "B70 -> time passed: 6.429 time per batch: 0.092\n",
      "test processing time: 8.687102794647217\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.519 time per batch: 0.152\n",
      "B20 -> time passed: 2.345 time per batch: 0.117\n",
      "B30 -> time passed: 3.165 time per batch: 0.105\n",
      "B40 -> time passed: 4.006 time per batch: 0.100\n",
      "B50 -> time passed: 5.152 time per batch: 0.103\n",
      "B60 -> time passed: 6.138 time per batch: 0.102\n",
      "B70 -> time passed: 6.612 time per batch: 0.094\n",
      "test processing time: 8.898064136505127\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.509 time per batch: 0.151\n",
      "B20 -> time passed: 2.277 time per batch: 0.114\n",
      "B30 -> time passed: 3.034 time per batch: 0.101\n",
      "B40 -> time passed: 3.817 time per batch: 0.095\n",
      "B50 -> time passed: 5.091 time per batch: 0.102\n",
      "B60 -> time passed: 5.980 time per batch: 0.100\n",
      "B70 -> time passed: 6.496 time per batch: 0.093\n",
      "test processing time: 8.784264087677002\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.288 time per batch: 0.114\n",
      "B30 -> time passed: 3.074 time per batch: 0.102\n",
      "B40 -> time passed: 3.828 time per batch: 0.096\n",
      "B50 -> time passed: 5.106 time per batch: 0.102\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.501 time per batch: 0.093\n",
      "test processing time: 8.727630853652954\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.351 time per batch: 0.118\n",
      "B30 -> time passed: 3.132 time per batch: 0.104\n",
      "B40 -> time passed: 3.922 time per batch: 0.098\n",
      "B50 -> time passed: 5.297 time per batch: 0.106\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.524 time per batch: 0.093\n",
      "test processing time: 8.759544849395752\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.238 time per batch: 0.112\n",
      "B30 -> time passed: 3.023 time per batch: 0.101\n",
      "B40 -> time passed: 3.836 time per batch: 0.096\n",
      "B50 -> time passed: 5.060 time per batch: 0.101\n",
      "B60 -> time passed: 5.955 time per batch: 0.099\n",
      "B70 -> time passed: 6.393 time per batch: 0.091\n",
      "test processing time: 8.661581754684448\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.238 time per batch: 0.112\n",
      "B30 -> time passed: 3.027 time per batch: 0.101\n",
      "B40 -> time passed: 3.809 time per batch: 0.095\n",
      "B50 -> time passed: 5.164 time per batch: 0.103\n",
      "B60 -> time passed: 5.958 time per batch: 0.099\n",
      "B70 -> time passed: 6.449 time per batch: 0.092\n",
      "test processing time: 8.701346397399902\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.538 time per batch: 0.154\n",
      "B20 -> time passed: 2.336 time per batch: 0.117\n",
      "B30 -> time passed: 3.196 time per batch: 0.107\n",
      "B40 -> time passed: 3.918 time per batch: 0.098\n",
      "B50 -> time passed: 5.377 time per batch: 0.108\n",
      "B60 -> time passed: 6.073 time per batch: 0.101\n",
      "B70 -> time passed: 6.497 time per batch: 0.093\n",
      "test processing time: 8.757129907608032\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.418 time per batch: 0.142\n",
      "B20 -> time passed: 2.202 time per batch: 0.110\n",
      "B30 -> time passed: 3.000 time per batch: 0.100\n",
      "B40 -> time passed: 3.779 time per batch: 0.094\n",
      "B50 -> time passed: 5.076 time per batch: 0.102\n",
      "B60 -> time passed: 5.857 time per batch: 0.098\n",
      "B70 -> time passed: 6.402 time per batch: 0.091\n",
      "test processing time: 8.697086334228516\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.265 time per batch: 0.113\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.831 time per batch: 0.096\n",
      "B50 -> time passed: 5.053 time per batch: 0.101\n",
      "B60 -> time passed: 5.974 time per batch: 0.100\n",
      "B70 -> time passed: 6.476 time per batch: 0.093\n",
      "test processing time: 8.705680847167969\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.280 time per batch: 0.114\n",
      "B30 -> time passed: 3.046 time per batch: 0.102\n",
      "B40 -> time passed: 3.822 time per batch: 0.096\n",
      "B50 -> time passed: 5.177 time per batch: 0.104\n",
      "B60 -> time passed: 5.950 time per batch: 0.099\n",
      "B70 -> time passed: 6.424 time per batch: 0.092\n",
      "test processing time: 8.652487754821777\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.470 time per batch: 0.147\n",
      "B20 -> time passed: 2.271 time per batch: 0.114\n",
      "B30 -> time passed: 3.067 time per batch: 0.102\n",
      "B40 -> time passed: 3.893 time per batch: 0.097\n",
      "B50 -> time passed: 5.125 time per batch: 0.103\n",
      "B60 -> time passed: 5.985 time per batch: 0.100\n",
      "B70 -> time passed: 6.484 time per batch: 0.093\n",
      "test processing time: 8.728729009628296\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.476 time per batch: 0.148\n",
      "B20 -> time passed: 2.251 time per batch: 0.113\n",
      "B30 -> time passed: 3.060 time per batch: 0.102\n",
      "B40 -> time passed: 3.848 time per batch: 0.096\n",
      "B50 -> time passed: 5.256 time per batch: 0.105\n",
      "B60 -> time passed: 6.013 time per batch: 0.100\n",
      "B70 -> time passed: 6.474 time per batch: 0.092\n",
      "test processing time: 8.773179292678833\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.487 time per batch: 0.149\n",
      "B20 -> time passed: 2.255 time per batch: 0.113\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.816 time per batch: 0.095\n",
      "B50 -> time passed: 5.060 time per batch: 0.101\n",
      "B60 -> time passed: 5.911 time per batch: 0.099\n",
      "B70 -> time passed: 6.383 time per batch: 0.091\n",
      "test processing time: 8.61937952041626\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.238 time per batch: 0.112\n",
      "B30 -> time passed: 3.005 time per batch: 0.100\n",
      "B40 -> time passed: 3.802 time per batch: 0.095\n",
      "B50 -> time passed: 5.115 time per batch: 0.102\n",
      "B60 -> time passed: 5.904 time per batch: 0.098\n",
      "B70 -> time passed: 6.425 time per batch: 0.092\n",
      "test processing time: 8.69349718093872\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.509 time per batch: 0.151\n",
      "B20 -> time passed: 2.277 time per batch: 0.114\n",
      "B30 -> time passed: 3.139 time per batch: 0.105\n",
      "B40 -> time passed: 3.966 time per batch: 0.099\n",
      "B50 -> time passed: 5.414 time per batch: 0.108\n",
      "B60 -> time passed: 6.228 time per batch: 0.104\n",
      "B70 -> time passed: 6.638 time per batch: 0.095\n",
      "test processing time: 8.88866639137268\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.497 time per batch: 0.150\n",
      "B20 -> time passed: 2.288 time per batch: 0.114\n",
      "B30 -> time passed: 3.072 time per batch: 0.102\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.259 time per batch: 0.105\n",
      "B60 -> time passed: 6.100 time per batch: 0.102\n",
      "B70 -> time passed: 6.548 time per batch: 0.094\n",
      "test processing time: 8.799955368041992\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.448 time per batch: 0.145\n",
      "B20 -> time passed: 2.234 time per batch: 0.112\n",
      "B30 -> time passed: 2.999 time per batch: 0.100\n",
      "B40 -> time passed: 3.790 time per batch: 0.095\n",
      "B50 -> time passed: 4.987 time per batch: 0.100\n",
      "B60 -> time passed: 5.898 time per batch: 0.098\n",
      "B70 -> time passed: 6.401 time per batch: 0.091\n",
      "test processing time: 8.63645076751709\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.497 time per batch: 0.150\n",
      "B20 -> time passed: 2.255 time per batch: 0.113\n",
      "B30 -> time passed: 3.002 time per batch: 0.100\n",
      "B40 -> time passed: 3.770 time per batch: 0.094\n",
      "B50 -> time passed: 5.074 time per batch: 0.101\n",
      "B60 -> time passed: 5.860 time per batch: 0.098\n",
      "B70 -> time passed: 6.415 time per batch: 0.092\n",
      "test processing time: 8.663035154342651\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.085 time per batch: 0.103\n",
      "B40 -> time passed: 3.863 time per batch: 0.097\n",
      "B50 -> time passed: 5.197 time per batch: 0.104\n",
      "B60 -> time passed: 5.946 time per batch: 0.099\n",
      "B70 -> time passed: 6.423 time per batch: 0.092\n",
      "test processing time: 8.663372278213501\n",
      "total time 2897.7119121551514\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.225 time per batch: 0.111\n",
      "B30 -> time passed: 3.039 time per batch: 0.101\n",
      "B40 -> time passed: 3.845 time per batch: 0.096\n",
      "B50 -> time passed: 5.192 time per batch: 0.104\n",
      "B60 -> time passed: 5.937 time per batch: 0.099\n",
      "B70 -> time passed: 6.392 time per batch: 0.091\n",
      "test processing time: 13.906512260437012\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.493 time per batch: 0.149\n",
      "B20 -> time passed: 2.279 time per batch: 0.114\n",
      "B30 -> time passed: 3.038 time per batch: 0.101\n",
      "B40 -> time passed: 3.793 time per batch: 0.095\n",
      "B50 -> time passed: 5.185 time per batch: 0.104\n",
      "B60 -> time passed: 5.983 time per batch: 0.100\n",
      "B70 -> time passed: 6.483 time per batch: 0.093\n",
      "test processing time: 9.122605085372925\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.152\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.047 time per batch: 0.102\n",
      "B40 -> time passed: 3.872 time per batch: 0.097\n",
      "B50 -> time passed: 5.336 time per batch: 0.107\n",
      "B60 -> time passed: 6.067 time per batch: 0.101\n",
      "B70 -> time passed: 6.537 time per batch: 0.093\n",
      "test processing time: 9.140328645706177\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.251 time per batch: 0.113\n",
      "B30 -> time passed: 3.070 time per batch: 0.102\n",
      "B40 -> time passed: 3.818 time per batch: 0.095\n",
      "B50 -> time passed: 5.112 time per batch: 0.102\n",
      "B60 -> time passed: 5.918 time per batch: 0.099\n",
      "B70 -> time passed: 6.434 time per batch: 0.092\n",
      "test processing time: 9.079049825668335\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.495 time per batch: 0.150\n",
      "B20 -> time passed: 2.232 time per batch: 0.112\n",
      "B30 -> time passed: 3.025 time per batch: 0.101\n",
      "B40 -> time passed: 3.803 time per batch: 0.095\n",
      "B50 -> time passed: 5.162 time per batch: 0.103\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.438 time per batch: 0.092\n",
      "test processing time: 9.066450834274292\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.331 time per batch: 0.117\n",
      "B30 -> time passed: 3.080 time per batch: 0.103\n",
      "B40 -> time passed: 3.865 time per batch: 0.097\n",
      "B50 -> time passed: 5.161 time per batch: 0.103\n",
      "B60 -> time passed: 6.128 time per batch: 0.102\n",
      "B70 -> time passed: 6.554 time per batch: 0.094\n",
      "test processing time: 9.181644678115845\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.150\n",
      "B20 -> time passed: 2.271 time per batch: 0.114\n",
      "B30 -> time passed: 3.066 time per batch: 0.102\n",
      "B40 -> time passed: 3.862 time per batch: 0.097\n",
      "B50 -> time passed: 5.313 time per batch: 0.106\n",
      "B60 -> time passed: 6.044 time per batch: 0.101\n",
      "B70 -> time passed: 6.487 time per batch: 0.093\n",
      "test processing time: 9.103289604187012\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.538 time per batch: 0.154\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.104 time per batch: 0.103\n",
      "B40 -> time passed: 3.945 time per batch: 0.099\n",
      "B50 -> time passed: 5.322 time per batch: 0.106\n",
      "B60 -> time passed: 5.961 time per batch: 0.099\n",
      "B70 -> time passed: 6.399 time per batch: 0.091\n",
      "test processing time: 9.046622276306152\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.690 time per batch: 0.169\n",
      "B20 -> time passed: 2.413 time per batch: 0.121\n",
      "B30 -> time passed: 3.165 time per batch: 0.106\n",
      "B40 -> time passed: 3.944 time per batch: 0.099\n",
      "B50 -> time passed: 5.339 time per batch: 0.107\n",
      "B60 -> time passed: 6.147 time per batch: 0.102\n",
      "B70 -> time passed: 6.551 time per batch: 0.094\n",
      "test processing time: 9.173457622528076\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.479 time per batch: 0.148\n",
      "B20 -> time passed: 2.243 time per batch: 0.112\n",
      "B30 -> time passed: 3.044 time per batch: 0.101\n",
      "B40 -> time passed: 3.779 time per batch: 0.094\n",
      "B50 -> time passed: 5.112 time per batch: 0.102\n",
      "B60 -> time passed: 5.926 time per batch: 0.099\n",
      "B70 -> time passed: 6.430 time per batch: 0.092\n",
      "test processing time: 9.020910739898682\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.310 time per batch: 0.116\n",
      "B30 -> time passed: 3.088 time per batch: 0.103\n",
      "B40 -> time passed: 3.852 time per batch: 0.096\n",
      "B50 -> time passed: 5.227 time per batch: 0.105\n",
      "B60 -> time passed: 6.031 time per batch: 0.101\n",
      "B70 -> time passed: 6.493 time per batch: 0.093\n",
      "test processing time: 9.09158444404602\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.456 time per batch: 0.146\n",
      "B20 -> time passed: 2.304 time per batch: 0.115\n",
      "B30 -> time passed: 3.096 time per batch: 0.103\n",
      "B40 -> time passed: 3.843 time per batch: 0.096\n",
      "B50 -> time passed: 5.069 time per batch: 0.101\n",
      "B60 -> time passed: 5.980 time per batch: 0.100\n",
      "B70 -> time passed: 6.450 time per batch: 0.092\n",
      "test processing time: 9.09056568145752\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.497 time per batch: 0.150\n",
      "B20 -> time passed: 2.267 time per batch: 0.113\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.868 time per batch: 0.097\n",
      "B50 -> time passed: 5.328 time per batch: 0.107\n",
      "B60 -> time passed: 6.044 time per batch: 0.101\n",
      "B70 -> time passed: 6.473 time per batch: 0.092\n",
      "test processing time: 9.068909406661987\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.549 time per batch: 0.155\n",
      "B20 -> time passed: 2.395 time per batch: 0.120\n",
      "B30 -> time passed: 3.237 time per batch: 0.108\n",
      "B40 -> time passed: 4.055 time per batch: 0.101\n",
      "B50 -> time passed: 5.499 time per batch: 0.110\n",
      "B60 -> time passed: 6.183 time per batch: 0.103\n",
      "B70 -> time passed: 6.591 time per batch: 0.094\n",
      "test processing time: 9.221390962600708\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.497 time per batch: 0.150\n",
      "B20 -> time passed: 2.256 time per batch: 0.113\n",
      "B30 -> time passed: 3.061 time per batch: 0.102\n",
      "B40 -> time passed: 3.865 time per batch: 0.097\n",
      "B50 -> time passed: 5.058 time per batch: 0.101\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.421 time per batch: 0.092\n",
      "test processing time: 9.03263235092163\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.278 time per batch: 0.114\n",
      "B30 -> time passed: 3.105 time per batch: 0.103\n",
      "B40 -> time passed: 3.873 time per batch: 0.097\n",
      "B50 -> time passed: 5.078 time per batch: 0.102\n",
      "B60 -> time passed: 6.069 time per batch: 0.101\n",
      "B70 -> time passed: 6.510 time per batch: 0.093\n",
      "test processing time: 9.138378858566284\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.469 time per batch: 0.147\n",
      "B20 -> time passed: 2.317 time per batch: 0.116\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.060 time per batch: 0.101\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.486 time per batch: 0.093\n",
      "test processing time: 9.147410154342651\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.523 time per batch: 0.152\n",
      "B20 -> time passed: 2.282 time per batch: 0.114\n",
      "B30 -> time passed: 3.071 time per batch: 0.102\n",
      "B40 -> time passed: 3.851 time per batch: 0.096\n",
      "B50 -> time passed: 5.189 time per batch: 0.104\n",
      "B60 -> time passed: 5.984 time per batch: 0.100\n",
      "B70 -> time passed: 6.461 time per batch: 0.092\n",
      "test processing time: 9.081314325332642\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.277 time per batch: 0.114\n",
      "B30 -> time passed: 3.047 time per batch: 0.102\n",
      "B40 -> time passed: 3.824 time per batch: 0.096\n",
      "B50 -> time passed: 5.230 time per batch: 0.105\n",
      "B60 -> time passed: 6.043 time per batch: 0.101\n",
      "B70 -> time passed: 6.519 time per batch: 0.093\n",
      "test processing time: 9.16724419593811\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.291 time per batch: 0.115\n",
      "B30 -> time passed: 3.076 time per batch: 0.103\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.303 time per batch: 0.106\n",
      "B60 -> time passed: 6.059 time per batch: 0.101\n",
      "B70 -> time passed: 6.465 time per batch: 0.092\n",
      "test processing time: 9.089624881744385\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.335 time per batch: 0.117\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.301 time per batch: 0.106\n",
      "B60 -> time passed: 6.143 time per batch: 0.102\n",
      "B70 -> time passed: 6.564 time per batch: 0.094\n",
      "test processing time: 9.167369365692139\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.502 time per batch: 0.150\n",
      "B20 -> time passed: 2.437 time per batch: 0.122\n",
      "B30 -> time passed: 3.272 time per batch: 0.109\n",
      "B40 -> time passed: 4.020 time per batch: 0.101\n",
      "B50 -> time passed: 5.101 time per batch: 0.102\n",
      "B60 -> time passed: 6.123 time per batch: 0.102\n",
      "B70 -> time passed: 6.564 time per batch: 0.094\n",
      "test processing time: 9.169780492782593\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.578 time per batch: 0.158\n",
      "B20 -> time passed: 2.359 time per batch: 0.118\n",
      "B30 -> time passed: 3.185 time per batch: 0.106\n",
      "B40 -> time passed: 3.937 time per batch: 0.098\n",
      "B50 -> time passed: 5.357 time per batch: 0.107\n",
      "B60 -> time passed: 6.068 time per batch: 0.101\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 9.121215581893921\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.465 time per batch: 0.146\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.812 time per batch: 0.095\n",
      "B50 -> time passed: 5.087 time per batch: 0.102\n",
      "B60 -> time passed: 5.959 time per batch: 0.099\n",
      "B70 -> time passed: 6.408 time per batch: 0.092\n",
      "test processing time: 9.055383443832397\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.538 time per batch: 0.154\n",
      "B20 -> time passed: 2.343 time per batch: 0.117\n",
      "B30 -> time passed: 3.169 time per batch: 0.106\n",
      "B40 -> time passed: 3.990 time per batch: 0.100\n",
      "B50 -> time passed: 5.381 time per batch: 0.108\n",
      "B60 -> time passed: 6.197 time per batch: 0.103\n",
      "B70 -> time passed: 6.611 time per batch: 0.094\n",
      "test processing time: 9.263262271881104\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.496 time per batch: 0.150\n",
      "B20 -> time passed: 2.261 time per batch: 0.113\n",
      "B30 -> time passed: 3.050 time per batch: 0.102\n",
      "B40 -> time passed: 3.832 time per batch: 0.096\n",
      "B50 -> time passed: 5.178 time per batch: 0.104\n",
      "B60 -> time passed: 5.969 time per batch: 0.099\n",
      "B70 -> time passed: 6.430 time per batch: 0.092\n",
      "test processing time: 9.089058876037598\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.492 time per batch: 0.149\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.051 time per batch: 0.102\n",
      "B40 -> time passed: 3.886 time per batch: 0.097\n",
      "B50 -> time passed: 5.234 time per batch: 0.105\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.467 time per batch: 0.092\n",
      "test processing time: 9.110769510269165\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.531 time per batch: 0.153\n",
      "B20 -> time passed: 2.311 time per batch: 0.116\n",
      "B30 -> time passed: 3.080 time per batch: 0.103\n",
      "B40 -> time passed: 3.863 time per batch: 0.097\n",
      "B50 -> time passed: 5.264 time per batch: 0.105\n",
      "B60 -> time passed: 6.004 time per batch: 0.100\n",
      "B70 -> time passed: 6.454 time per batch: 0.092\n",
      "test processing time: 9.078367710113525\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.493 time per batch: 0.149\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.099 time per batch: 0.103\n",
      "B40 -> time passed: 3.936 time per batch: 0.098\n",
      "B50 -> time passed: 5.282 time per batch: 0.106\n",
      "B60 -> time passed: 6.001 time per batch: 0.100\n",
      "B70 -> time passed: 6.457 time per batch: 0.092\n",
      "test processing time: 9.132854461669922\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.289 time per batch: 0.114\n",
      "B30 -> time passed: 3.070 time per batch: 0.102\n",
      "B40 -> time passed: 3.833 time per batch: 0.096\n",
      "B50 -> time passed: 5.238 time per batch: 0.105\n",
      "B60 -> time passed: 5.986 time per batch: 0.100\n",
      "B70 -> time passed: 6.516 time per batch: 0.093\n",
      "test processing time: 9.144128561019897\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.474 time per batch: 0.147\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.015 time per batch: 0.100\n",
      "B40 -> time passed: 3.797 time per batch: 0.095\n",
      "B50 -> time passed: 5.059 time per batch: 0.101\n",
      "B60 -> time passed: 5.960 time per batch: 0.099\n",
      "B70 -> time passed: 6.447 time per batch: 0.092\n",
      "test processing time: 9.074146032333374\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.482 time per batch: 0.148\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.113 time per batch: 0.104\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.362 time per batch: 0.107\n",
      "B60 -> time passed: 6.148 time per batch: 0.102\n",
      "B70 -> time passed: 6.577 time per batch: 0.094\n",
      "test processing time: 9.212087631225586\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.508 time per batch: 0.151\n",
      "B20 -> time passed: 2.314 time per batch: 0.116\n",
      "B30 -> time passed: 3.072 time per batch: 0.102\n",
      "B40 -> time passed: 3.840 time per batch: 0.096\n",
      "B50 -> time passed: 5.086 time per batch: 0.102\n",
      "B60 -> time passed: 5.962 time per batch: 0.099\n",
      "B70 -> time passed: 6.408 time per batch: 0.092\n",
      "test processing time: 13.914192914962769\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.475 time per batch: 0.147\n",
      "B20 -> time passed: 2.259 time per batch: 0.113\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.847 time per batch: 0.096\n",
      "B50 -> time passed: 5.160 time per batch: 0.103\n",
      "B60 -> time passed: 5.977 time per batch: 0.100\n",
      "B70 -> time passed: 6.478 time per batch: 0.093\n",
      "test processing time: 9.171845197677612\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.564 time per batch: 0.156\n",
      "B20 -> time passed: 2.376 time per batch: 0.119\n",
      "B30 -> time passed: 3.252 time per batch: 0.108\n",
      "B40 -> time passed: 4.026 time per batch: 0.101\n",
      "B50 -> time passed: 5.415 time per batch: 0.108\n",
      "B60 -> time passed: 6.165 time per batch: 0.103\n",
      "B70 -> time passed: 6.585 time per batch: 0.094\n",
      "test processing time: 9.271293640136719\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.267 time per batch: 0.113\n",
      "B30 -> time passed: 3.064 time per batch: 0.102\n",
      "B40 -> time passed: 3.883 time per batch: 0.097\n",
      "B50 -> time passed: 5.299 time per batch: 0.106\n",
      "B60 -> time passed: 6.105 time per batch: 0.102\n",
      "B70 -> time passed: 6.543 time per batch: 0.093\n",
      "test processing time: 9.202924728393555\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.322 time per batch: 0.116\n",
      "B30 -> time passed: 3.063 time per batch: 0.102\n",
      "B40 -> time passed: 3.872 time per batch: 0.097\n",
      "B50 -> time passed: 5.210 time per batch: 0.104\n",
      "B60 -> time passed: 5.989 time per batch: 0.100\n",
      "B70 -> time passed: 6.448 time per batch: 0.092\n",
      "test processing time: 9.141406297683716\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.238 time per batch: 0.112\n",
      "B30 -> time passed: 3.020 time per batch: 0.101\n",
      "B40 -> time passed: 3.827 time per batch: 0.096\n",
      "B50 -> time passed: 5.142 time per batch: 0.103\n",
      "B60 -> time passed: 5.952 time per batch: 0.099\n",
      "B70 -> time passed: 6.406 time per batch: 0.092\n",
      "test processing time: 9.107638597488403\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.537 time per batch: 0.154\n",
      "B20 -> time passed: 2.337 time per batch: 0.117\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.816 time per batch: 0.095\n",
      "B50 -> time passed: 5.168 time per batch: 0.103\n",
      "B60 -> time passed: 5.923 time per batch: 0.099\n",
      "B70 -> time passed: 6.409 time per batch: 0.092\n",
      "test processing time: 9.092346429824829\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.278 time per batch: 0.114\n",
      "B30 -> time passed: 3.055 time per batch: 0.102\n",
      "B40 -> time passed: 3.836 time per batch: 0.096\n",
      "B50 -> time passed: 5.171 time per batch: 0.103\n",
      "B60 -> time passed: 6.060 time per batch: 0.101\n",
      "B70 -> time passed: 6.493 time per batch: 0.093\n",
      "test processing time: 9.157291650772095\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.546 time per batch: 0.155\n",
      "B20 -> time passed: 2.328 time per batch: 0.116\n",
      "B30 -> time passed: 3.105 time per batch: 0.103\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.299 time per batch: 0.106\n",
      "B60 -> time passed: 6.050 time per batch: 0.101\n",
      "B70 -> time passed: 6.491 time per batch: 0.093\n",
      "test processing time: 9.169968366622925\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.501 time per batch: 0.150\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.047 time per batch: 0.102\n",
      "B40 -> time passed: 3.844 time per batch: 0.096\n",
      "B50 -> time passed: 5.127 time per batch: 0.103\n",
      "B60 -> time passed: 5.978 time per batch: 0.100\n",
      "B70 -> time passed: 6.433 time per batch: 0.092\n",
      "test processing time: 9.121339082717896\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.519 time per batch: 0.152\n",
      "B20 -> time passed: 2.324 time per batch: 0.116\n",
      "B30 -> time passed: 3.115 time per batch: 0.104\n",
      "B40 -> time passed: 3.868 time per batch: 0.097\n",
      "B50 -> time passed: 5.281 time per batch: 0.106\n",
      "B60 -> time passed: 6.043 time per batch: 0.101\n",
      "B70 -> time passed: 6.488 time per batch: 0.093\n",
      "test processing time: 9.152013301849365\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.255 time per batch: 0.113\n",
      "B30 -> time passed: 3.046 time per batch: 0.102\n",
      "B40 -> time passed: 3.787 time per batch: 0.095\n",
      "B50 -> time passed: 5.094 time per batch: 0.102\n",
      "B60 -> time passed: 5.962 time per batch: 0.099\n",
      "B70 -> time passed: 6.411 time per batch: 0.092\n",
      "test processing time: 9.20889163017273\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.367 time per batch: 0.118\n",
      "B30 -> time passed: 3.142 time per batch: 0.105\n",
      "B40 -> time passed: 3.915 time per batch: 0.098\n",
      "B50 -> time passed: 5.265 time per batch: 0.105\n",
      "B60 -> time passed: 5.984 time per batch: 0.100\n",
      "B70 -> time passed: 6.453 time per batch: 0.092\n",
      "test processing time: 9.182975769042969\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.561 time per batch: 0.156\n",
      "B20 -> time passed: 2.337 time per batch: 0.117\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.922 time per batch: 0.098\n",
      "B50 -> time passed: 5.303 time per batch: 0.106\n",
      "B60 -> time passed: 6.089 time per batch: 0.101\n",
      "B70 -> time passed: 6.566 time per batch: 0.094\n",
      "test processing time: 9.242571830749512\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.492 time per batch: 0.149\n",
      "B20 -> time passed: 2.281 time per batch: 0.114\n",
      "B30 -> time passed: 3.099 time per batch: 0.103\n",
      "B40 -> time passed: 3.858 time per batch: 0.096\n",
      "B50 -> time passed: 5.227 time per batch: 0.105\n",
      "B60 -> time passed: 6.002 time per batch: 0.100\n",
      "B70 -> time passed: 6.532 time per batch: 0.093\n",
      "test processing time: 9.211443424224854\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.477 time per batch: 0.148\n",
      "B20 -> time passed: 2.261 time per batch: 0.113\n",
      "B30 -> time passed: 3.055 time per batch: 0.102\n",
      "B40 -> time passed: 3.823 time per batch: 0.096\n",
      "B50 -> time passed: 5.090 time per batch: 0.102\n",
      "B60 -> time passed: 6.010 time per batch: 0.100\n",
      "B70 -> time passed: 6.516 time per batch: 0.093\n",
      "test processing time: 9.199496269226074\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.523 time per batch: 0.152\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.041 time per batch: 0.101\n",
      "B40 -> time passed: 3.814 time per batch: 0.095\n",
      "B50 -> time passed: 5.239 time per batch: 0.105\n",
      "B60 -> time passed: 6.070 time per batch: 0.101\n",
      "B70 -> time passed: 6.549 time per batch: 0.094\n",
      "test processing time: 9.236202239990234\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.491 time per batch: 0.149\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.841 time per batch: 0.096\n",
      "B50 -> time passed: 5.198 time per batch: 0.104\n",
      "B60 -> time passed: 6.044 time per batch: 0.101\n",
      "B70 -> time passed: 6.523 time per batch: 0.093\n",
      "test processing time: 9.191378831863403\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.506 time per batch: 0.151\n",
      "B20 -> time passed: 2.300 time per batch: 0.115\n",
      "B30 -> time passed: 3.084 time per batch: 0.103\n",
      "B40 -> time passed: 3.856 time per batch: 0.096\n",
      "B50 -> time passed: 5.224 time per batch: 0.104\n",
      "B60 -> time passed: 6.003 time per batch: 0.100\n",
      "B70 -> time passed: 6.479 time per batch: 0.093\n",
      "test processing time: 9.14732027053833\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.537 time per batch: 0.154\n",
      "B20 -> time passed: 2.346 time per batch: 0.117\n",
      "B30 -> time passed: 3.162 time per batch: 0.105\n",
      "B40 -> time passed: 4.020 time per batch: 0.101\n",
      "B50 -> time passed: 5.442 time per batch: 0.109\n",
      "B60 -> time passed: 6.248 time per batch: 0.104\n",
      "B70 -> time passed: 6.661 time per batch: 0.095\n",
      "test processing time: 9.312276840209961\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.344 time per batch: 0.117\n",
      "B30 -> time passed: 3.179 time per batch: 0.106\n",
      "B40 -> time passed: 3.984 time per batch: 0.100\n",
      "B50 -> time passed: 5.371 time per batch: 0.107\n",
      "B60 -> time passed: 6.199 time per batch: 0.103\n",
      "B70 -> time passed: 6.620 time per batch: 0.095\n",
      "test processing time: 9.301661491394043\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.564 time per batch: 0.156\n",
      "B20 -> time passed: 2.394 time per batch: 0.120\n",
      "B30 -> time passed: 3.171 time per batch: 0.106\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.334 time per batch: 0.107\n",
      "B60 -> time passed: 6.079 time per batch: 0.101\n",
      "B70 -> time passed: 6.553 time per batch: 0.094\n",
      "test processing time: 9.221004962921143\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.274 time per batch: 0.114\n",
      "B30 -> time passed: 3.076 time per batch: 0.103\n",
      "B40 -> time passed: 3.851 time per batch: 0.096\n",
      "B50 -> time passed: 5.300 time per batch: 0.106\n",
      "B60 -> time passed: 6.015 time per batch: 0.100\n",
      "B70 -> time passed: 6.519 time per batch: 0.093\n",
      "test processing time: 9.214202642440796\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.328 time per batch: 0.116\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.884 time per batch: 0.097\n",
      "B50 -> time passed: 5.178 time per batch: 0.104\n",
      "B60 -> time passed: 6.068 time per batch: 0.101\n",
      "B70 -> time passed: 6.527 time per batch: 0.093\n",
      "test processing time: 9.21480131149292\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.514 time per batch: 0.151\n",
      "B20 -> time passed: 2.257 time per batch: 0.113\n",
      "B30 -> time passed: 3.039 time per batch: 0.101\n",
      "B40 -> time passed: 3.822 time per batch: 0.096\n",
      "B50 -> time passed: 5.278 time per batch: 0.106\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.499 time per batch: 0.093\n",
      "test processing time: 9.19713544845581\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.493 time per batch: 0.149\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.046 time per batch: 0.102\n",
      "B40 -> time passed: 3.848 time per batch: 0.096\n",
      "B50 -> time passed: 5.041 time per batch: 0.101\n",
      "B60 -> time passed: 6.006 time per batch: 0.100\n",
      "B70 -> time passed: 6.523 time per batch: 0.093\n",
      "test processing time: 9.18347954750061\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.472 time per batch: 0.147\n",
      "B20 -> time passed: 2.288 time per batch: 0.114\n",
      "B30 -> time passed: 3.071 time per batch: 0.102\n",
      "B40 -> time passed: 3.835 time per batch: 0.096\n",
      "B50 -> time passed: 5.073 time per batch: 0.101\n",
      "B60 -> time passed: 5.965 time per batch: 0.099\n",
      "B70 -> time passed: 6.446 time per batch: 0.092\n",
      "test processing time: 9.162488222122192\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.558 time per batch: 0.156\n",
      "B20 -> time passed: 2.345 time per batch: 0.117\n",
      "B30 -> time passed: 3.117 time per batch: 0.104\n",
      "B40 -> time passed: 3.961 time per batch: 0.099\n",
      "B50 -> time passed: 5.381 time per batch: 0.108\n",
      "B60 -> time passed: 6.138 time per batch: 0.102\n",
      "B70 -> time passed: 6.574 time per batch: 0.094\n",
      "test processing time: 9.256039381027222\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.153 time per batch: 0.105\n",
      "B40 -> time passed: 3.887 time per batch: 0.097\n",
      "B50 -> time passed: 5.289 time per batch: 0.106\n",
      "B60 -> time passed: 6.042 time per batch: 0.101\n",
      "B70 -> time passed: 6.497 time per batch: 0.093\n",
      "test processing time: 9.18193244934082\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.500 time per batch: 0.150\n",
      "B20 -> time passed: 2.281 time per batch: 0.114\n",
      "B30 -> time passed: 3.090 time per batch: 0.103\n",
      "B40 -> time passed: 3.891 time per batch: 0.097\n",
      "B50 -> time passed: 5.291 time per batch: 0.106\n",
      "B60 -> time passed: 6.038 time per batch: 0.101\n",
      "B70 -> time passed: 6.525 time per batch: 0.093\n",
      "test processing time: 9.261452198028564\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.261 time per batch: 0.113\n",
      "B30 -> time passed: 3.068 time per batch: 0.102\n",
      "B40 -> time passed: 3.886 time per batch: 0.097\n",
      "B50 -> time passed: 5.274 time per batch: 0.105\n",
      "B60 -> time passed: 5.986 time per batch: 0.100\n",
      "B70 -> time passed: 6.456 time per batch: 0.092\n",
      "test processing time: 9.137340068817139\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.347 time per batch: 0.117\n",
      "B30 -> time passed: 3.178 time per batch: 0.106\n",
      "B40 -> time passed: 4.014 time per batch: 0.100\n",
      "B50 -> time passed: 5.338 time per batch: 0.107\n",
      "B60 -> time passed: 6.049 time per batch: 0.101\n",
      "B70 -> time passed: 6.492 time per batch: 0.093\n",
      "test processing time: 9.186838865280151\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.514 time per batch: 0.151\n",
      "B20 -> time passed: 2.307 time per batch: 0.115\n",
      "B30 -> time passed: 3.156 time per batch: 0.105\n",
      "B40 -> time passed: 3.983 time per batch: 0.100\n",
      "B50 -> time passed: 5.367 time per batch: 0.107\n",
      "B60 -> time passed: 6.081 time per batch: 0.101\n",
      "B70 -> time passed: 6.519 time per batch: 0.093\n",
      "test processing time: 13.606040477752686\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.495 time per batch: 0.149\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.029 time per batch: 0.101\n",
      "B40 -> time passed: 3.811 time per batch: 0.095\n",
      "B50 -> time passed: 5.037 time per batch: 0.101\n",
      "B60 -> time passed: 5.985 time per batch: 0.100\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 9.227406978607178\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.530 time per batch: 0.153\n",
      "B20 -> time passed: 2.321 time per batch: 0.116\n",
      "B30 -> time passed: 3.084 time per batch: 0.103\n",
      "B40 -> time passed: 3.904 time per batch: 0.098\n",
      "B50 -> time passed: 5.334 time per batch: 0.107\n",
      "B60 -> time passed: 6.166 time per batch: 0.103\n",
      "B70 -> time passed: 6.602 time per batch: 0.094\n",
      "test processing time: 9.291182279586792\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.876 time per batch: 0.097\n",
      "B50 -> time passed: 5.267 time per batch: 0.105\n",
      "B60 -> time passed: 6.054 time per batch: 0.101\n",
      "B70 -> time passed: 6.507 time per batch: 0.093\n",
      "test processing time: 9.177020072937012\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.458 time per batch: 0.146\n",
      "B20 -> time passed: 2.242 time per batch: 0.112\n",
      "B30 -> time passed: 3.056 time per batch: 0.102\n",
      "B40 -> time passed: 3.816 time per batch: 0.095\n",
      "B50 -> time passed: 5.030 time per batch: 0.101\n",
      "B60 -> time passed: 5.949 time per batch: 0.099\n",
      "B70 -> time passed: 6.449 time per batch: 0.092\n",
      "test processing time: 9.147778511047363\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.060 time per batch: 0.102\n",
      "B40 -> time passed: 3.817 time per batch: 0.095\n",
      "B50 -> time passed: 5.146 time per batch: 0.103\n",
      "B60 -> time passed: 5.943 time per batch: 0.099\n",
      "B70 -> time passed: 6.471 time per batch: 0.092\n",
      "test processing time: 9.163790225982666\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.541 time per batch: 0.154\n",
      "B20 -> time passed: 2.334 time per batch: 0.117\n",
      "B30 -> time passed: 3.141 time per batch: 0.105\n",
      "B40 -> time passed: 3.925 time per batch: 0.098\n",
      "B50 -> time passed: 5.289 time per batch: 0.106\n",
      "B60 -> time passed: 6.121 time per batch: 0.102\n",
      "B70 -> time passed: 6.565 time per batch: 0.094\n",
      "test processing time: 9.231491565704346\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.500 time per batch: 0.150\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.073 time per batch: 0.102\n",
      "B40 -> time passed: 3.876 time per batch: 0.097\n",
      "B50 -> time passed: 5.132 time per batch: 0.103\n",
      "B60 -> time passed: 6.025 time per batch: 0.100\n",
      "B70 -> time passed: 6.521 time per batch: 0.093\n",
      "test processing time: 9.221038103103638\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.272 time per batch: 0.114\n",
      "B30 -> time passed: 3.081 time per batch: 0.103\n",
      "B40 -> time passed: 3.992 time per batch: 0.100\n",
      "B50 -> time passed: 5.322 time per batch: 0.106\n",
      "B60 -> time passed: 6.104 time per batch: 0.102\n",
      "B70 -> time passed: 6.532 time per batch: 0.093\n",
      "test processing time: 9.247914552688599\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.523 time per batch: 0.152\n",
      "B20 -> time passed: 2.321 time per batch: 0.116\n",
      "B30 -> time passed: 3.152 time per batch: 0.105\n",
      "B40 -> time passed: 3.967 time per batch: 0.099\n",
      "B50 -> time passed: 5.388 time per batch: 0.108\n",
      "B60 -> time passed: 6.082 time per batch: 0.101\n",
      "B70 -> time passed: 6.522 time per batch: 0.093\n",
      "test processing time: 9.224900245666504\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.362 time per batch: 0.118\n",
      "B30 -> time passed: 3.180 time per batch: 0.106\n",
      "B40 -> time passed: 3.994 time per batch: 0.100\n",
      "B50 -> time passed: 5.491 time per batch: 0.110\n",
      "B60 -> time passed: 6.160 time per batch: 0.103\n",
      "B70 -> time passed: 6.554 time per batch: 0.094\n",
      "test processing time: 9.21959400177002\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.267 time per batch: 0.113\n",
      "B30 -> time passed: 3.036 time per batch: 0.101\n",
      "B40 -> time passed: 3.816 time per batch: 0.095\n",
      "B50 -> time passed: 5.142 time per batch: 0.103\n",
      "B60 -> time passed: 5.975 time per batch: 0.100\n",
      "B70 -> time passed: 6.444 time per batch: 0.092\n",
      "test processing time: 9.121769905090332\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.486 time per batch: 0.149\n",
      "B20 -> time passed: 2.261 time per batch: 0.113\n",
      "B30 -> time passed: 3.046 time per batch: 0.102\n",
      "B40 -> time passed: 3.834 time per batch: 0.096\n",
      "B50 -> time passed: 5.164 time per batch: 0.103\n",
      "B60 -> time passed: 5.955 time per batch: 0.099\n",
      "B70 -> time passed: 6.427 time per batch: 0.092\n",
      "test processing time: 9.1212477684021\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.506 time per batch: 0.151\n",
      "B20 -> time passed: 2.352 time per batch: 0.118\n",
      "B30 -> time passed: 3.125 time per batch: 0.104\n",
      "B40 -> time passed: 3.852 time per batch: 0.096\n",
      "B50 -> time passed: 5.167 time per batch: 0.103\n",
      "B60 -> time passed: 6.021 time per batch: 0.100\n",
      "B70 -> time passed: 6.551 time per batch: 0.094\n",
      "test processing time: 9.182101011276245\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.465 time per batch: 0.147\n",
      "B20 -> time passed: 2.265 time per batch: 0.113\n",
      "B30 -> time passed: 3.082 time per batch: 0.103\n",
      "B40 -> time passed: 3.860 time per batch: 0.097\n",
      "B50 -> time passed: 5.232 time per batch: 0.105\n",
      "B60 -> time passed: 6.003 time per batch: 0.100\n",
      "B70 -> time passed: 6.457 time per batch: 0.092\n",
      "test processing time: 9.11985158920288\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.519 time per batch: 0.152\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.071 time per batch: 0.102\n",
      "B40 -> time passed: 3.858 time per batch: 0.096\n",
      "B50 -> time passed: 5.327 time per batch: 0.107\n",
      "B60 -> time passed: 6.042 time per batch: 0.101\n",
      "B70 -> time passed: 6.469 time per batch: 0.092\n",
      "test processing time: 9.140344858169556\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.323 time per batch: 0.116\n",
      "B30 -> time passed: 3.106 time per batch: 0.104\n",
      "B40 -> time passed: 3.927 time per batch: 0.098\n",
      "B50 -> time passed: 5.198 time per batch: 0.104\n",
      "B60 -> time passed: 6.060 time per batch: 0.101\n",
      "B70 -> time passed: 6.540 time per batch: 0.093\n",
      "test processing time: 9.220311164855957\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.297 time per batch: 0.115\n",
      "B30 -> time passed: 3.120 time per batch: 0.104\n",
      "B40 -> time passed: 3.904 time per batch: 0.098\n",
      "B50 -> time passed: 5.335 time per batch: 0.107\n",
      "B60 -> time passed: 6.096 time per batch: 0.102\n",
      "B70 -> time passed: 6.540 time per batch: 0.093\n",
      "test processing time: 9.192695140838623\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.297 time per batch: 0.115\n",
      "B30 -> time passed: 3.134 time per batch: 0.104\n",
      "B40 -> time passed: 3.906 time per batch: 0.098\n",
      "B50 -> time passed: 5.229 time per batch: 0.105\n",
      "B60 -> time passed: 6.029 time per batch: 0.100\n",
      "B70 -> time passed: 6.480 time per batch: 0.093\n",
      "test processing time: 9.18045973777771\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.274 time per batch: 0.114\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.853 time per batch: 0.096\n",
      "B50 -> time passed: 5.113 time per batch: 0.102\n",
      "B60 -> time passed: 6.023 time per batch: 0.100\n",
      "B70 -> time passed: 6.518 time per batch: 0.093\n",
      "test processing time: 9.163259983062744\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.476 time per batch: 0.148\n",
      "B20 -> time passed: 2.234 time per batch: 0.112\n",
      "B30 -> time passed: 3.027 time per batch: 0.101\n",
      "B40 -> time passed: 3.821 time per batch: 0.096\n",
      "B50 -> time passed: 5.155 time per batch: 0.103\n",
      "B60 -> time passed: 5.963 time per batch: 0.099\n",
      "B70 -> time passed: 6.477 time per batch: 0.093\n",
      "test processing time: 9.157998323440552\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.548 time per batch: 0.155\n",
      "B20 -> time passed: 2.349 time per batch: 0.117\n",
      "B30 -> time passed: 3.132 time per batch: 0.104\n",
      "B40 -> time passed: 3.919 time per batch: 0.098\n",
      "B50 -> time passed: 5.224 time per batch: 0.104\n",
      "B60 -> time passed: 6.139 time per batch: 0.102\n",
      "B70 -> time passed: 6.595 time per batch: 0.094\n",
      "test processing time: 9.242784023284912\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.061 time per batch: 0.102\n",
      "B40 -> time passed: 3.839 time per batch: 0.096\n",
      "B50 -> time passed: 5.251 time per batch: 0.105\n",
      "B60 -> time passed: 5.971 time per batch: 0.100\n",
      "B70 -> time passed: 6.481 time per batch: 0.093\n",
      "test processing time: 9.150382041931152\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.498 time per batch: 0.150\n",
      "B20 -> time passed: 2.304 time per batch: 0.115\n",
      "B30 -> time passed: 3.079 time per batch: 0.103\n",
      "B40 -> time passed: 3.862 time per batch: 0.097\n",
      "B50 -> time passed: 5.143 time per batch: 0.103\n",
      "B60 -> time passed: 6.022 time per batch: 0.100\n",
      "B70 -> time passed: 6.511 time per batch: 0.093\n",
      "test processing time: 9.148072481155396\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.489 time per batch: 0.149\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.088 time per batch: 0.103\n",
      "B40 -> time passed: 3.819 time per batch: 0.095\n",
      "B50 -> time passed: 5.163 time per batch: 0.103\n",
      "B60 -> time passed: 5.939 time per batch: 0.099\n",
      "B70 -> time passed: 6.408 time per batch: 0.092\n",
      "test processing time: 9.0783109664917\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.490 time per batch: 0.149\n",
      "B20 -> time passed: 2.276 time per batch: 0.114\n",
      "B30 -> time passed: 3.047 time per batch: 0.102\n",
      "B40 -> time passed: 3.852 time per batch: 0.096\n",
      "B50 -> time passed: 5.244 time per batch: 0.105\n",
      "B60 -> time passed: 6.048 time per batch: 0.101\n",
      "B70 -> time passed: 6.519 time per batch: 0.093\n",
      "test processing time: 9.19321322441101\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.477 time per batch: 0.148\n",
      "B20 -> time passed: 2.273 time per batch: 0.114\n",
      "B30 -> time passed: 3.043 time per batch: 0.101\n",
      "B40 -> time passed: 3.823 time per batch: 0.096\n",
      "B50 -> time passed: 5.210 time per batch: 0.104\n",
      "B60 -> time passed: 5.985 time per batch: 0.100\n",
      "B70 -> time passed: 6.458 time per batch: 0.092\n",
      "test processing time: 9.120096445083618\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.541 time per batch: 0.154\n",
      "B20 -> time passed: 2.317 time per batch: 0.116\n",
      "B30 -> time passed: 3.105 time per batch: 0.104\n",
      "B40 -> time passed: 3.944 time per batch: 0.099\n",
      "B50 -> time passed: 5.373 time per batch: 0.107\n",
      "B60 -> time passed: 6.172 time per batch: 0.103\n",
      "B70 -> time passed: 6.603 time per batch: 0.094\n",
      "test processing time: 9.257035970687866\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.496 time per batch: 0.150\n",
      "B20 -> time passed: 2.257 time per batch: 0.113\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.834 time per batch: 0.096\n",
      "B50 -> time passed: 5.222 time per batch: 0.104\n",
      "B60 -> time passed: 5.960 time per batch: 0.099\n",
      "B70 -> time passed: 6.426 time per batch: 0.092\n",
      "test processing time: 9.113739728927612\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.530 time per batch: 0.153\n",
      "B20 -> time passed: 2.351 time per batch: 0.118\n",
      "B30 -> time passed: 3.175 time per batch: 0.106\n",
      "B40 -> time passed: 3.977 time per batch: 0.099\n",
      "B50 -> time passed: 5.415 time per batch: 0.108\n",
      "B60 -> time passed: 6.227 time per batch: 0.104\n",
      "B70 -> time passed: 6.614 time per batch: 0.094\n",
      "test processing time: 9.302011728286743\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.502 time per batch: 0.150\n",
      "B20 -> time passed: 2.281 time per batch: 0.114\n",
      "B30 -> time passed: 3.060 time per batch: 0.102\n",
      "B40 -> time passed: 3.840 time per batch: 0.096\n",
      "B50 -> time passed: 5.168 time per batch: 0.103\n",
      "B60 -> time passed: 5.947 time per batch: 0.099\n",
      "B70 -> time passed: 6.386 time per batch: 0.091\n",
      "test processing time: 9.038770198822021\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.489 time per batch: 0.149\n",
      "B20 -> time passed: 2.262 time per batch: 0.113\n",
      "B30 -> time passed: 3.010 time per batch: 0.100\n",
      "B40 -> time passed: 3.797 time per batch: 0.095\n",
      "B50 -> time passed: 5.150 time per batch: 0.103\n",
      "B60 -> time passed: 5.895 time per batch: 0.098\n",
      "B70 -> time passed: 6.424 time per batch: 0.092\n",
      "test processing time: 9.119261264801025\n",
      "total time 3794.8006286621094\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "\n",
    "for ds in range(6,10):\n",
    "    preds = []\n",
    "    for fold in range(3):\n",
    "        preds2 = []\n",
    "        for anum in range(32):\n",
    "            predictions = inference_one(fold = fold, anum = anum, bs=bs, dataset=ds)\n",
    "            preds2.append(predictions)\n",
    "        preds.append(np.stack(preds2))\n",
    "    preds = np.stack(preds)\n",
    "    print('total time', time.time() - stg)\n",
    "    \n",
    "    pickle.dump(preds, open(PATH_WORK/'preds_d{}_v{}'.format(ds, VERSION),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total time 883.3684198856354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "243*4*4/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 78545, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13104, 0.00452, 0.04275, 0.03004, 0.0462 , 0.05505],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/zahar_chikishev/running/oof_d6_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d6_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d6_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f0_v20 [Content-Type=application/octet-stream]...\n",
      "- [4 files][164.5 MiB/164.5 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f2_v20 [Content-Type=application/octet-stream]...\n",
      "| [12 files][493.8 MiB/493.8 MiB]   35.9 MiB/s                                  \n",
      "Operation completed over 12 objects/493.8 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/zahar_chikishev/running/oof* gs://rsna-hemorrhage/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/zahar_chikishev/running/preds_d6_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d7_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d8_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d9_v20 [Content-Type=application/octet-stream]...\n",
      "\\ [4 files][172.6 MiB/172.6 MiB]                                                \n",
      "Operation completed over 4 objects/172.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/zahar_chikishev/running/preds* gs://rsna-hemorrhage/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/results/* C:\\StudioProjects\\Hemorrhage\\running\\ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/yuvals/model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/yuvals/model_*_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/yuvals/model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://rsna-hemorrhage/yuvals/OOF_validation_image_ids.pkl .\n",
    "!gsutil cp gs://rsna-hemorrhage/yuvals/ensemble_test_image_ids.pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /home/zahar_chikishev/running/*v53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/preds_se_resnext101_32x4d_v53\r\n",
      "/home/zahar_chikishev/running/stats.f0.v53\r\n",
      "/home/zahar_chikishev/running/stats.f1.v53\r\n",
      "/home/zahar_chikishev/running/stats.f2.v53\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/*v53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/oof_Densenet161_f0_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet161_f1_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet161_f2_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f0_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f1_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f2_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f0_v74\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f1_v74\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f2_v74\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f0_v75\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f1_v75\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f2_v75\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/oof*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/preds_Densenet161_v72\r\n",
      "/home/zahar_chikishev/running/preds_Densenet169_v73\r\n",
      "/home/zahar_chikishev/running/preds_Densenet201_v74\r\n",
      "/home/zahar_chikishev/running/preds_se_resnext101_32x4d_v75\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/preds*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = getPredsOOF(aug=8,datasets=range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 674252, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model 0 fold 0 target 0\n",
      "obj  0.09963246200739749\n",
      "obj  0.09944626015243509\n",
      "obj  0.09922579717545336\n",
      "obj  0.09959406002618562\n",
      "obj  0.09914780112894109\n",
      "obj  0.09927343760444553\n",
      "obj  0.09921529914176029\n",
      "obj  0.09923348052784052\n",
      "obj  0.09901851667872234\n",
      "obj  0.09892307277505202\n",
      "obj  0.09889239879419555\n",
      "obj  0.09887923261027613\n",
      "obj  0.09887614953657274\n",
      "obj  0.09887481947749617\n",
      "obj  0.09887456036056812\n",
      "obj  0.09887448990695526\n",
      "obj  0.09887448987401994\n",
      "obj  0.09887447383218922\n",
      "v20 d0 f0 t0: original ll 0.1011 auc 0.9859, ensemble ll 0.1006 auc 0.9859\n",
      "running time 4.219389200210571\n",
      "starting model 0 fold 0 target 1\n",
      "obj  0.015584478597402246\n",
      "obj  0.015490994344686372\n",
      "obj  0.015285626523234026\n",
      "obj  0.014793111591036785\n",
      "obj  0.014719859730592316\n",
      "obj  0.01481745942272261\n",
      "obj  0.014787601118543709\n",
      "obj  0.014606331108436682\n",
      "obj  0.014446043715261838\n",
      "obj  0.01419255642894775\n",
      "obj  0.014107198200344685\n",
      "obj  0.014079550399998557\n",
      "obj  0.014071771732908047\n",
      "obj  0.014070875061271939\n",
      "obj  0.014070393185298315\n",
      "obj  0.014070280090453156\n",
      "obj  0.014070268868487484\n",
      "obj  0.014070258006766423\n",
      "obj  0.01407025591049732\n",
      "obj  0.014070255248255144\n",
      "v20 d0 f0 t1: original ll 0.0168 auc 0.9718, ensemble ll 0.0167 auc 0.9718\n",
      "running time 4.092484474182129\n",
      "starting model 0 fold 0 target 2\n",
      "obj  0.042057977976099\n",
      "obj  0.042036326801644104\n",
      "obj  0.04203698979922003\n",
      "obj  0.042031954162446004\n",
      "obj  0.042029159337582875\n",
      "obj  0.042019734980116505\n",
      "obj  0.04201993525313531\n",
      "obj  0.0420194366427101\n",
      "obj  0.042012208750672166\n",
      "obj  0.04200934996405427\n",
      "obj  0.042006072202433326\n",
      "obj  0.04200607039973174\n",
      "obj  0.042005292329376324\n",
      "obj  0.04200521710930271\n",
      "obj  0.042005212001326994\n",
      "obj  0.04200520376078814\n",
      "obj  0.042005201521928714\n",
      "obj  0.04200520152088215\n",
      "obj  0.04200520112376289\n",
      "v20 d0 f0 t2: original ll 0.0477 auc 0.9904, ensemble ll 0.0476 auc 0.9904\n",
      "running time 4.130813837051392\n",
      "starting model 0 fold 0 target 3\n",
      "obj  0.025482161119457534\n",
      "obj  0.02548816605654806\n",
      "obj  0.025503845445101696\n",
      "obj  0.025436448409031906\n",
      "obj  0.02548325589649946\n",
      "obj  0.025459006584741074\n",
      "obj  0.025463010112669875\n",
      "obj  0.025460706338136373\n",
      "obj  0.025446439832616456\n",
      "obj  0.025404291271963038\n",
      "obj  0.02539784301516\n",
      "obj  0.025396480946576067\n",
      "obj  0.025394926191092057\n",
      "obj  0.025394921709978806\n",
      "obj  0.02539459003693542\n",
      "obj  0.025394513315981967\n",
      "obj  0.02539449347320852\n",
      "obj  0.025394488131945107\n",
      "obj  0.025394487057617193\n",
      "obj  0.02539448685512969\n",
      "v20 d0 f0 t3: original ll 0.0279 auc 0.9956, ensemble ll 0.0279 auc 0.9956\n",
      "running time 4.162871599197388\n",
      "starting model 0 fold 0 target 4\n",
      "obj  0.06624944417898733\n",
      "obj  0.06620944041633925\n",
      "obj  0.06615521747133318\n",
      "obj  0.06633757864931346\n",
      "obj  0.06615443505058141\n",
      "obj  0.06616442792149792\n",
      "obj  0.06616490497307635\n",
      "obj  0.06615052581321325\n",
      "obj  0.06611989367078808\n",
      "obj  0.06610302958286732\n",
      "obj  0.06609028668371728\n",
      "obj  0.0660826751795906\n",
      "obj  0.06608255724589118\n",
      "obj  0.06607937161283527\n",
      "obj  0.06607896458178769\n",
      "obj  0.06607891407502728\n",
      "obj  0.0660788952185063\n",
      "obj  0.06607889395110868\n",
      "obj  0.06607889371043389\n",
      "v20 d0 f0 t4: original ll 0.0696 auc 0.9785, ensemble ll 0.0695 auc 0.9785\n",
      "running time 4.065750360488892\n",
      "starting model 0 fold 0 target 5\n",
      "obj  0.08106124190484539\n",
      "obj  0.08088861870191835\n",
      "obj  0.08076579573655204\n",
      "obj  0.08088804429333664\n",
      "obj  0.08069211710936902\n",
      "obj  0.08069031105856773\n",
      "obj  0.0806904089815897\n",
      "obj  0.080690968936358\n",
      "obj  0.08063407483629939\n",
      "obj  0.08058589376326288\n",
      "obj  0.08057392041666651\n",
      "obj  0.08057085335105853\n",
      "obj  0.08057082633057605\n",
      "obj  0.080569705474419\n",
      "obj  0.08056970528662205\n",
      "obj  0.08056967635074713\n",
      "obj  0.0805696690292198\n",
      "obj  0.0805696674721582\n",
      "v20 d0 f0 t5: original ll 0.0852 auc 0.9769, ensemble ll 0.0849 auc 0.9769\n",
      "running time 3.8451809883117676\n",
      "starting model 1 fold 0 target 0\n",
      "obj  0.09857273211637907\n",
      "obj  0.09844291566867648\n",
      "obj  0.09820452314986501\n",
      "obj  0.09860242949822186\n",
      "obj  0.09810575471014005\n",
      "obj  0.09824832694747071\n",
      "obj  0.09817813422869084\n",
      "obj  0.09819898445529228\n",
      "obj  0.0979270582547318\n",
      "obj  0.09780299337372166\n",
      "obj  0.09776076297071838\n",
      "obj  0.09774521002294793\n",
      "obj  0.09773996076403245\n",
      "obj  0.09773910932555822\n",
      "obj  0.09773910902254379\n",
      "obj  0.09773892722971231\n",
      "obj  0.09773890954738364\n",
      "obj  0.09773890558172052\n",
      "obj  0.09773890466905116\n",
      "obj  0.09773890445384305\n",
      "v20 d1 f0 t0: original ll 0.1007 auc 0.9859, ensemble ll 0.0999 auc 0.9859\n",
      "running time 4.171807050704956\n",
      "starting model 1 fold 0 target 1\n",
      "obj  0.016650082707297828\n",
      "obj  0.01658032816628951\n",
      "obj  0.016422113694642596\n",
      "obj  0.016186144444266103\n",
      "obj  0.01583715974905203\n",
      "obj  0.015768536848992307\n",
      "obj  0.015848231087512012\n",
      "obj  0.01565390665455033\n",
      "obj  0.015457438376020592\n",
      "obj  0.01520340695063229\n",
      "obj  0.0151197655896222\n",
      "obj  0.015094354956470398\n",
      "obj  0.015087900919557645\n",
      "obj  0.015087205625160688\n",
      "obj  0.015086922818160048\n",
      "obj  0.015086832765435116\n",
      "obj  0.015086819265519818\n",
      "obj  0.015086816239042445\n",
      "v20 d1 f0 t1: original ll 0.0176 auc 0.9706, ensemble ll 0.0172 auc 0.9705\n",
      "running time 3.7711055278778076\n",
      "starting model 1 fold 0 target 2\n",
      "obj  0.04160890375036497\n",
      "obj  0.041598430921024276\n",
      "obj  0.041592896196616394\n",
      "obj  0.04161764153912414\n",
      "obj  0.04158570292411893\n",
      "obj  0.041583095300675825\n",
      "obj  0.04158265018331587\n",
      "obj  0.041583779710179784\n",
      "obj  0.04153887686769316\n",
      "obj  0.04153878595015795\n",
      "obj  0.04153642092575482\n",
      "obj  0.04153550346233399\n",
      "obj  0.04153180328034569\n",
      "obj  0.041531803208940066\n",
      "obj  0.0415306317767667\n",
      "obj  0.04153052824569068\n",
      "obj  0.04153052824462312\n",
      "obj  0.041530526077012145\n",
      "obj  0.04153051229716621\n",
      "obj  0.04153051229134847\n",
      "obj  0.04153051012001047\n",
      "v20 d1 f0 t2: original ll 0.0443 auc 0.9916, ensemble ll 0.0443 auc 0.9916\n",
      "running time 4.2322869300842285\n",
      "starting model 1 fold 0 target 3\n",
      "obj  0.025005247959712987\n",
      "obj  0.025004499888729437\n",
      "obj  0.02504075802880035\n",
      "obj  0.024920806868237787\n",
      "obj  0.025025514413948742\n",
      "obj  0.024994495637403358\n",
      "obj  0.025000087694056292\n",
      "obj  0.024996313008458164\n",
      "obj  0.02496216072071981\n",
      "obj  0.024911090257427448\n",
      "obj  0.024892929439038654\n",
      "obj  0.024891884021120397\n",
      "obj  0.024891068322661282\n",
      "obj  0.024890924453831606\n",
      "obj  0.024890893393218323\n",
      "obj  0.024890889687443962\n",
      "v20 d1 f0 t3: original ll 0.0270 auc 0.9959, ensemble ll 0.0270 auc 0.9959\n",
      "running time 3.5639779567718506\n",
      "starting model 1 fold 0 target 4\n",
      "obj  0.065485902204167\n",
      "obj  0.06543416417727313\n",
      "obj  0.06538151478204317\n",
      "obj  0.06561215408790523\n",
      "obj  0.06534551643087562\n",
      "obj  0.06533892589936025\n",
      "obj  0.06533614718250914\n",
      "obj  0.06534031597479668\n",
      "obj  0.06533055040569435\n",
      "obj  0.0652946212164045\n",
      "obj  0.06527990410791645\n",
      "obj  0.06527462916368214\n",
      "obj  0.06527272532890295\n",
      "obj  0.06527238150936711\n",
      "obj  0.06527231277012116\n",
      "obj  0.06527229316931403\n",
      "v20 d1 f0 t4: original ll 0.0681 auc 0.9796, ensemble ll 0.0681 auc 0.9796\n",
      "running time 3.6099319458007812\n",
      "starting model 1 fold 0 target 5\n",
      "obj  0.08036672665829073\n",
      "obj  0.0802000800229656\n",
      "obj  0.08008779348166344\n",
      "obj  0.08022060637746796\n",
      "obj  0.08001722936910916\n",
      "obj  0.08001683380684932\n",
      "obj  0.08001669912351334\n",
      "obj  0.08001732435598921\n",
      "obj  0.07995706397097757\n",
      "obj  0.0799082926084003\n",
      "obj  0.07989397537094962\n",
      "obj  0.0798905760028611\n",
      "obj  0.07989039528801464\n",
      "obj  0.07988938877089255\n",
      "obj  0.07988927981858815\n",
      "obj  0.07988926583606926\n",
      "obj  0.07988926109016493\n",
      "v20 d1 f0 t5: original ll 0.0849 auc 0.9768, ensemble ll 0.0844 auc 0.9768\n",
      "running time 3.7441232204437256\n",
      "starting model 2 fold 0 target 0\n",
      "obj  0.09913895795838201\n",
      "obj  0.09906262118006245\n",
      "obj  0.09899562524727995\n",
      "obj  0.09914222052763774\n",
      "obj  0.09896545305471109\n",
      "obj  0.09899703353798875\n",
      "obj  0.09897941912965112\n",
      "obj  0.09898494301965981\n",
      "obj  0.09895507918898933\n",
      "obj  0.09894916454030434\n",
      "obj  0.09894220370894098\n",
      "obj  0.09893843587971775\n",
      "obj  0.09893804420223692\n",
      "obj  0.09893692517018003\n",
      "obj  0.09893687616480351\n",
      "obj  0.09893673687350145\n",
      "obj  0.09893671250493236\n",
      "obj  0.09893671250329174\n",
      "obj  0.0989367048484891\n",
      "obj  0.09893670376743906\n",
      "obj  0.09893670365657475\n",
      "obj  0.09893670365657466\n",
      "v20 d2 f0 t0: original ll 0.1002 auc 0.9860, ensemble ll 0.1000 auc 0.9860\n",
      "running time 4.474426031112671\n",
      "starting model 2 fold 0 target 1\n",
      "obj  0.01571408604679892\n",
      "obj  0.015711106536838087\n",
      "obj  0.015683635644064324\n",
      "obj  0.01564785620424894\n",
      "obj  0.015641910454106015\n",
      "obj  0.01567534146162221\n",
      "obj  0.01567656357497551\n",
      "obj  0.01563256923406647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.015592418992449607\n",
      "obj  0.015576796615881922\n",
      "obj  0.015565142009164808\n",
      "obj  0.015564373256231535\n",
      "obj  0.01556391686418517\n",
      "obj  0.015563772702795473\n",
      "obj  0.015563723259090043\n",
      "obj  0.015563711530514968\n",
      "obj  0.015563709850268349\n",
      "obj  0.015563709849700133\n",
      "obj  0.015563709520499843\n",
      "v20 d2 f0 t1: original ll 0.0188 auc 0.9622, ensemble ll 0.0187 auc 0.9620\n",
      "running time 3.9534380435943604\n",
      "starting model 2 fold 0 target 2\n",
      "obj  0.04358294945467838\n",
      "obj  0.04359289383909989\n",
      "obj  0.043605516614172835\n",
      "obj  0.0436250189702021\n",
      "obj  0.043602041371494885\n",
      "obj  0.04359671840562607\n",
      "obj  0.0435991791593165\n",
      "obj  0.04359754681427303\n",
      "obj  0.04359724466842668\n",
      "obj  0.043596810191510495\n",
      "obj  0.04359492141146251\n",
      "obj  0.04359293008552962\n",
      "obj  0.04359128356229148\n",
      "obj  0.043590635598515455\n",
      "obj  0.04359057639256845\n",
      "obj  0.04357822770032844\n",
      "obj  0.0435741143650453\n",
      "obj  0.043574113753709176\n",
      "obj  0.043571578933168785\n",
      "obj  0.0435714498008556\n",
      "obj  0.043571448496809835\n",
      "obj  0.04357136701765237\n",
      "obj  0.04357136701474176\n",
      "obj  0.04357132838469637\n",
      "obj  0.043571324995117074\n",
      "v20 d2 f0 t2: original ll 0.0461 auc 0.9911, ensemble ll 0.0462 auc 0.9911\n",
      "running time 4.7694830894470215\n",
      "starting model 2 fold 0 target 3\n",
      "obj  0.026094845929329123\n",
      "obj  0.02611301353382255\n",
      "obj  0.026153680338754162\n",
      "obj  0.02600348731106048\n",
      "obj  0.026144018493787974\n",
      "obj  0.026113442857827424\n",
      "obj  0.026119841647183693\n",
      "obj  0.02611504176148181\n",
      "obj  0.02606146139733455\n",
      "obj  0.026002753788764637\n",
      "obj  0.025975404199389186\n",
      "obj  0.02597151772705833\n",
      "obj  0.025970184372148607\n",
      "obj  0.02596984857846149\n",
      "obj  0.025969819047544758\n",
      "obj  0.02596981677714848\n",
      "obj  0.025969816483389006\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.025969816483444097\n",
      "obj  0.02596981648342128\n",
      "obj  0.025969816483421275\n",
      "obj  0.025969816483405107\n",
      "obj  0.02596981648343743\n",
      "obj  0.025969816483437425\n",
      "obj  0.025969816483408327\n",
      "obj  0.025969816483408327\n",
      "v20 d2 f0 t3: original ll 0.0280 auc 0.9954, ensemble ll 0.0280 auc 0.9954\n",
      "running time 4.251877069473267\n",
      "starting model 2 fold 0 target 4\n",
      "obj  0.06605731465761758\n",
      "obj  0.06605408750845033\n",
      "obj  0.06605225707860549\n",
      "obj  0.06612333608107293\n",
      "obj  0.06603513351211034\n",
      "obj  0.06602597099928893\n",
      "obj  0.06602556634073727\n",
      "obj  0.06602558070279314\n",
      "obj  0.06602255158748815\n",
      "obj  0.06601320301008601\n",
      "obj  0.06600853559243278\n",
      "obj  0.06600799091593028\n",
      "obj  0.06600761479248768\n",
      "obj  0.06600755185304114\n",
      "obj  0.06600753711142256\n",
      "obj  0.06600753458557346\n",
      "v20 d2 f0 t4: original ll 0.0684 auc 0.9793, ensemble ll 0.0685 auc 0.9793\n",
      "running time 3.595405101776123\n",
      "starting model 2 fold 0 target 5\n",
      "obj  0.0805479980469592\n",
      "obj  0.080453532442521\n",
      "obj  0.08040515231711166\n",
      "obj  0.08039203665530034\n",
      "obj  0.08035748962779632\n",
      "obj  0.08032620012537549\n",
      "obj  0.08032854163561445\n",
      "obj  0.08032836613997195\n",
      "obj  0.08032511518703753\n",
      "obj  0.08029758949628465\n",
      "obj  0.08029321317410419\n",
      "obj  0.08029160825573392\n",
      "obj  0.08029072803910073\n",
      "obj  0.08029062355066614\n",
      "obj  0.08029062347016837\n",
      "obj  0.08029059158294742\n",
      "obj  0.0802905788926614\n",
      "v20 d2 f0 t5: original ll 0.0840 auc 0.9774, ensemble ll 0.0838 auc 0.9774\n",
      "running time 3.7210679054260254\n",
      "starting model 3 fold 0 target 0\n",
      "obj  0.09750536341177803\n",
      "obj  0.09737950220579832\n",
      "obj  0.09719782252608627\n",
      "obj  0.09745774277414293\n",
      "obj  0.09710243017373665\n",
      "obj  0.09719228902525426\n",
      "obj  0.09713431201797706\n",
      "obj  0.09714794686095723\n",
      "obj  0.09699436220744245\n",
      "obj  0.0969324277502062\n",
      "obj  0.09690710143765627\n",
      "obj  0.09690096016524562\n",
      "obj  0.09689867377699525\n",
      "obj  0.09689865194234941\n",
      "obj  0.0968982744437169\n",
      "obj  0.09689827305149606\n",
      "obj  0.09689821693482364\n",
      "obj  0.0968982064333114\n",
      "obj  0.0968982049899539\n",
      "v20 d3 f0 t0: original ll 0.1000 auc 0.9862, ensemble ll 0.0993 auc 0.9862\n",
      "running time 4.021082639694214\n",
      "starting model 3 fold 0 target 1\n",
      "obj  0.01617091765618266\n",
      "obj  0.016164915269849728\n",
      "obj  0.016171669704040447\n",
      "obj  0.016138936799796725\n",
      "obj  0.016169593114211445\n",
      "obj  0.016171618655483062\n",
      "obj  0.016173633647952372\n",
      "obj  0.016151354723792526\n",
      "obj  0.016131075777777833\n",
      "obj  0.016122271423592682\n",
      "obj  0.01611790205547692\n",
      "obj  0.016117339101417487\n",
      "obj  0.01611664911014966\n",
      "obj  0.016116627490919147\n",
      "obj  0.01611660304466969\n",
      "obj  0.016116600643766188\n",
      "obj  0.016116600276030266\n",
      "obj  0.016116600211045547\n",
      "v20 d3 f0 t1: original ll 0.0179 auc 0.9661, ensemble ll 0.0180 auc 0.9661\n",
      "running time 3.850060224533081\n",
      "starting model 3 fold 0 target 2\n",
      "obj  0.04105433306705723\n",
      "obj  0.04105066247962921\n",
      "obj  0.041039334466770994\n",
      "obj  0.04107734208254331\n",
      "obj  0.04103042062179747\n",
      "obj  0.041039397251266735\n",
      "obj  0.04103703377278455\n",
      "obj  0.04103848105159199\n",
      "obj  0.041038483904087326\n",
      "obj  0.041035924178569036\n",
      "obj  0.04103592402296669\n",
      "obj  0.0410327866037443\n",
      "obj  0.04103198307422356\n",
      "obj  0.041030543673260395\n",
      "obj  0.041030147857446214\n",
      "obj  0.04103012780747486\n",
      "obj  0.04103012690775676\n",
      "obj  0.041030106513142116\n",
      "obj  0.041030106511115605\n",
      "obj  0.04103010268526942\n",
      "v20 d3 f0 t2: original ll 0.0443 auc 0.9918, ensemble ll 0.0443 auc 0.9918\n",
      "running time 4.104358911514282\n",
      "starting model 3 fold 0 target 3\n",
      "obj  0.024994310133694277\n",
      "obj  0.025002682124606528\n",
      "obj  0.02504488581690273\n",
      "obj  0.02489269223138988\n",
      "obj  0.02502380799012008\n",
      "obj  0.024986065574082658\n",
      "obj  0.02499358789152052\n",
      "obj  0.024989096205532992\n",
      "obj  0.0249131639956094\n",
      "obj  0.024850754727870187\n",
      "obj  0.02484859466523546\n",
      "obj  0.024826980653918213\n",
      "obj  0.024825410789265943\n",
      "obj  0.024824612969242914\n",
      "obj  0.024824433135180447\n",
      "obj  0.024824391487139053\n",
      "obj  0.024824382921085263\n",
      "v20 d3 f0 t3: original ll 0.0275 auc 0.9957, ensemble ll 0.0274 auc 0.9957\n",
      "running time 3.6483395099639893\n",
      "starting model 3 fold 0 target 4\n",
      "obj  0.06526835387287733\n",
      "obj  0.06524333127950475\n",
      "obj  0.0652068198476736\n",
      "obj  0.06529921199382946\n",
      "obj  0.0651798796261647\n",
      "obj  0.06516929160050292\n",
      "obj  0.06517069722881755\n",
      "obj  0.06517207254052053\n",
      "obj  0.06515001219594525\n",
      "obj  0.06512890874996036\n",
      "obj  0.06511831004082777\n",
      "obj  0.06511295082812964\n",
      "obj  0.06510983313133566\n",
      "obj  0.0651091513233513\n",
      "obj  0.06510893380168052\n",
      "obj  0.06510890965687469\n",
      "obj  0.06510890634926958\n",
      "v20 d3 f0 t4: original ll 0.0666 auc 0.9805, ensemble ll 0.0667 auc 0.9805\n",
      "running time 3.6579108238220215\n",
      "starting model 3 fold 0 target 5\n",
      "obj  0.07971829967232143\n",
      "obj  0.07959331581662293\n",
      "obj  0.07951017296299237\n",
      "obj  0.07957215655935801\n",
      "obj  0.07943714861279702\n",
      "obj  0.07941620364198829\n",
      "obj  0.07941802936132719\n",
      "obj  0.07941652635321965\n",
      "obj  0.07937635061542495\n",
      "obj  0.07934055301812852\n",
      "obj  0.07933050245005878\n",
      "obj  0.07932696484747094\n",
      "obj  0.0793262693138908\n",
      "obj  0.07932626731669315\n",
      "obj  0.07932618563519461\n",
      "obj  0.07932617307934392\n",
      "obj  0.07932616928624961\n",
      "v20 d3 f0 t5: original ll 0.0842 auc 0.9771, ensemble ll 0.0839 auc 0.9771\n",
      "running time 3.7007386684417725\n",
      "starting model 4 fold 0 target 0\n",
      "obj  0.09949909790852982\n",
      "obj  0.09945842279691035\n",
      "obj  0.09937730456955628\n",
      "obj  0.0994293961826334\n",
      "obj  0.09926931849772057\n",
      "obj  0.09927676104155841\n",
      "obj  0.09926437499069414\n",
      "obj  0.09926824473794194\n",
      "obj  0.09920655873789222\n",
      "obj  0.09920276753050844\n",
      "obj  0.09916825048781105\n",
      "obj  0.09915935772349593\n",
      "obj  0.09915872866928899\n",
      "obj  0.09915851005812287\n",
      "obj  0.09915846835089615\n",
      "obj  0.0991584624902504\n",
      "v20 d4 f0 t0: original ll 0.0993 auc 0.9863, ensemble ll 0.0995 auc 0.9863\n",
      "running time 3.6115264892578125\n",
      "starting model 4 fold 0 target 1\n",
      "obj  0.01686009398136815\n",
      "obj  0.01681241848528617\n",
      "obj  0.016680685207570375\n",
      "obj  0.01661362279952207\n",
      "obj  0.01637621978139977\n",
      "obj  0.016173871098010606\n",
      "obj  0.016028190333984376\n",
      "obj  0.015805892219387087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.015578729040898262\n",
      "obj  0.015234245401583388\n",
      "obj  0.01507732148112426\n",
      "obj  0.015007840936609769\n",
      "obj  0.015006871785323703\n",
      "obj  0.014990116746903556\n",
      "obj  0.014990061236806159\n",
      "obj  0.014988204281777587\n",
      "obj  0.014988201879822081\n",
      "obj  0.014987681082494122\n",
      "obj  0.01498749904232582\n",
      "obj  0.014987476105597137\n",
      "obj  0.014987467643490467\n",
      "obj  0.014987464174000776\n",
      "obj  0.014987463925368826\n",
      "v20 d4 f0 t1: original ll 0.0172 auc 0.9658, ensemble ll 0.0169 auc 0.9653\n",
      "running time 4.617523908615112\n",
      "starting model 4 fold 0 target 2\n",
      "obj  0.040555354978724596\n",
      "obj  0.04055340186869342\n",
      "obj  0.040550816901568476\n",
      "obj  0.04057701491839121\n",
      "obj  0.040550548616058675\n",
      "obj  0.04055288071988089\n",
      "obj  0.040552493960334855\n",
      "obj  0.04055335244419241\n",
      "obj  0.04051062876167279\n",
      "obj  0.040510569660703946\n",
      "obj  0.040507496637030106\n",
      "obj  0.04050749551655163\n",
      "obj  0.040499271259394024\n",
      "obj  0.0404992691713637\n",
      "obj  0.04049536153295458\n",
      "obj  0.04049392787401944\n",
      "obj  0.04049383687599511\n",
      "obj  0.04049381450327697\n",
      "obj  0.0404937965883568\n",
      "obj  0.04049379383814861\n",
      "v20 d4 f0 t2: original ll 0.0449 auc 0.9919, ensemble ll 0.0450 auc 0.9919\n",
      "running time 4.172311067581177\n",
      "starting model 4 fold 0 target 3\n",
      "obj  0.024627376418255274\n",
      "obj  0.02462704655278272\n",
      "obj  0.024632876463715703\n",
      "obj  0.024639632676126767\n",
      "obj  0.024633070357388067\n",
      "obj  0.02462955025702856\n",
      "obj  0.024630081039325527\n",
      "obj  0.02462976554562147\n",
      "obj  0.02457973409142841\n",
      "obj  0.024573482457154537\n",
      "obj  0.024565120333728728\n",
      "obj  0.02456001772941566\n",
      "obj  0.02455868914482946\n",
      "obj  0.024557855251038145\n",
      "obj  0.024557765680809637\n",
      "obj  0.02455774807638245\n",
      "obj  0.024557744580301757\n",
      "v20 d4 f0 t3: original ll 0.0271 auc 0.9959, ensemble ll 0.0269 auc 0.9959\n",
      "running time 3.641925096511841\n",
      "starting model 4 fold 0 target 4\n",
      "obj  0.0649444970792232\n",
      "obj  0.06492691651847222\n",
      "obj  0.06497301829119063\n",
      "obj  0.06483253718108743\n",
      "obj  0.0649663843481612\n",
      "obj  0.06490554946858129\n",
      "obj  0.06491229383387376\n",
      "obj  0.06490464594941164\n",
      "obj  0.06481066088305257\n",
      "obj  0.06476605847504582\n",
      "obj  0.0647598536475573\n",
      "obj  0.06475360501448033\n",
      "obj  0.06475344339458955\n",
      "obj  0.06475342775237698\n",
      "obj  0.06475342273075647\n",
      "obj  0.06475342089130577\n",
      "v20 d4 f0 t4: original ll 0.0674 auc 0.9803, ensemble ll 0.0675 auc 0.9803\n",
      "running time 3.657266616821289\n",
      "starting model 4 fold 0 target 5\n",
      "obj  0.08037684349503632\n",
      "obj  0.0802517677669313\n",
      "obj  0.08018872615178438\n",
      "obj  0.08002263955736381\n",
      "obj  0.08011027695323428\n",
      "obj  0.08003172348156987\n",
      "obj  0.08004180240486831\n",
      "obj  0.08002742586066532\n",
      "obj  0.0799715100110834\n",
      "obj  0.07994626671559242\n",
      "obj  0.07993453247785443\n",
      "obj  0.0799322593707283\n",
      "obj  0.07993144047270308\n",
      "obj  0.07993134705753678\n",
      "obj  0.07993132624342014\n",
      "obj  0.07993132175861727\n",
      "v20 d4 f0 t5: original ll 0.0830 auc 0.9779, ensemble ll 0.0836 auc 0.9779\n",
      "running time 3.6404595375061035\n",
      "starting model 5 fold 0 target 0\n",
      "obj  0.09907450638188527\n",
      "obj  0.09900995815173762\n",
      "obj  0.09882300804858628\n",
      "obj  0.09912468578481748\n",
      "obj  0.09866149382527734\n",
      "obj  0.098771741205312\n",
      "obj  0.09872643993948915\n",
      "obj  0.0987439447230431\n",
      "obj  0.09857088320735119\n",
      "obj  0.09850383336036245\n",
      "obj  0.09848012862612109\n",
      "obj  0.09847188558209352\n",
      "obj  0.09846948587879616\n",
      "obj  0.09846947042278506\n",
      "obj  0.09846843785415668\n",
      "obj  0.0984683595680668\n",
      "obj  0.09846834734112658\n",
      "obj  0.09846834734112636\n",
      "obj  0.09846834289750857\n",
      "v20 d5 f0 t0: original ll 0.1013 auc 0.9861, ensemble ll 0.1010 auc 0.9861\n",
      "running time 4.000441074371338\n",
      "starting model 5 fold 0 target 1\n",
      "obj  0.01726917254404488\n",
      "obj  0.017164152018745528\n",
      "obj  0.016939116615303597\n",
      "obj  0.01675232203571775\n",
      "obj  0.016231379438044844\n",
      "obj  0.016214195930039057\n",
      "obj  0.016298133054026585\n",
      "obj  0.01607716276522665\n",
      "obj  0.015826498628678323\n",
      "obj  0.01544086591858893\n",
      "obj  0.015261575558776821\n",
      "obj  0.01523964328514296\n",
      "obj  0.015229445548518556\n",
      "obj  0.015227384981312004\n",
      "obj  0.015226965699714361\n",
      "obj  0.015226868814728138\n",
      "obj  0.01522684478164177\n",
      "obj  0.015226838268526213\n",
      "obj  0.01522683700948502\n",
      "obj  0.015226837009484056\n",
      "obj  0.015226836577738935\n",
      "obj  0.015226836514046495\n",
      "v20 d5 f0 t1: original ll 0.0168 auc 0.9741, ensemble ll 0.0163 auc 0.9738\n",
      "running time 4.357545852661133\n",
      "starting model 5 fold 0 target 2\n",
      "obj  0.04053273414197143\n",
      "obj  0.04052256476094817\n",
      "obj  0.04048961543691778\n",
      "obj  0.04058939131935001\n",
      "obj  0.04048025254670685\n",
      "obj  0.04051686520886271\n",
      "obj  0.04050478289360146\n",
      "obj  0.04050859826677889\n",
      "obj  0.04047130762420081\n",
      "obj  0.04044535914118085\n",
      "obj  0.040441444543579806\n",
      "obj  0.04044047154587191\n",
      "obj  0.040439541120689655\n",
      "obj  0.04043928399926803\n",
      "obj  0.040439265966096476\n",
      "obj  0.040439265680660384\n",
      "obj  0.04043926082374306\n",
      "v20 d5 f0 t2: original ll 0.0444 auc 0.9917, ensemble ll 0.0444 auc 0.9917\n",
      "running time 3.6251533031463623\n",
      "starting model 5 fold 0 target 3\n",
      "obj  0.024349617017502104\n",
      "obj  0.02434237096207515\n",
      "obj  0.02434604970373575\n",
      "obj  0.02433027015632165\n",
      "obj  0.02434094912315378\n",
      "obj  0.024331827513341803\n",
      "obj  0.02433269173684806\n",
      "obj  0.024331960812308387\n",
      "obj  0.0243045633911904\n",
      "obj  0.02430101741397955\n",
      "obj  0.02429447893747403\n",
      "obj  0.024293429360821163\n",
      "obj  0.024292452910225686\n",
      "obj  0.024292353048186194\n",
      "obj  0.02429232946351844\n",
      "obj  0.02429230518715087\n",
      "obj  0.02429230266454813\n",
      "v20 d5 f0 t3: original ll 0.0269 auc 0.9962, ensemble ll 0.0269 auc 0.9962\n",
      "running time 3.5989229679107666\n",
      "starting model 5 fold 0 target 4\n",
      "obj  0.06491321500350482\n",
      "obj  0.06486466100492025\n",
      "obj  0.06478717419891583\n",
      "obj  0.06490503470548366\n",
      "obj  0.06473109930436803\n",
      "obj  0.06473888454954571\n",
      "obj  0.06473305033445628\n",
      "obj  0.06471987797933482\n",
      "obj  0.06465051175339241\n",
      "obj  0.06461608147640778\n",
      "obj  0.06460488560833877\n",
      "obj  0.0646007879953087\n",
      "obj  0.0645989920743908\n",
      "obj  0.06459880491521106\n",
      "obj  0.06459878810054963\n",
      "obj  0.06459878459360711\n",
      "v20 d5 f0 t4: original ll 0.0670 auc 0.9804, ensemble ll 0.0670 auc 0.9804\n",
      "running time 3.540196418762207\n",
      "starting model 5 fold 0 target 5\n",
      "obj  0.08022319121978835\n",
      "obj  0.08009069905687752\n",
      "obj  0.07997040655449184\n",
      "obj  0.07995377005544704\n",
      "obj  0.0798577989361953\n",
      "obj  0.07981266499701534\n",
      "obj  0.07981875070161529\n",
      "obj  0.07982034191837988\n",
      "obj  0.07978771428425951\n",
      "obj  0.07974439335415381\n",
      "obj  0.0797386834199384\n",
      "obj  0.07973716388282241\n",
      "obj  0.07973698469382282\n",
      "obj  0.07973692007806174\n",
      "obj  0.0797369025154848\n",
      "obj  0.07973689728505363\n",
      "v20 d5 f0 t5: original ll 0.0830 auc 0.9778, ensemble ll 0.0829 auc 0.9778\n",
      "running time 3.5471606254577637\n",
      "starting model 6 fold 0 target 0\n",
      "obj  0.10032240812567156\n",
      "obj  0.10031723268945299\n",
      "obj  0.10038831416036932\n",
      "obj  0.10033186972189033\n",
      "obj  0.10043108361449647\n",
      "obj  0.1003655943923925\n",
      "obj  0.10037839735403889\n",
      "obj  0.10037490155095088\n",
      "obj  0.10019252214189482\n",
      "obj  0.10019231638099793\n",
      "obj  0.10012546864149421\n",
      "obj  0.10011691984836095\n",
      "obj  0.10009283812021764\n",
      "obj  0.10009283802836337\n",
      "obj  0.10009042371131584\n",
      "obj  0.10009017617178398\n",
      "obj  0.10009013056225596\n",
      "obj  0.10009013042478972\n",
      "obj  0.10009011761756219\n",
      "obj  0.10009011552594473\n",
      "v20 d6 f0 t0: original ll 0.1003 auc 0.9862, ensemble ll 0.1001 auc 0.9862\n",
      "running time 3.9701712131500244\n",
      "starting model 6 fold 0 target 1\n",
      "obj  0.016076414279242942\n",
      "obj  0.016044351602666033\n",
      "obj  0.015933107301257358\n",
      "obj  0.01583319456453273\n",
      "obj  0.01551222431017553\n",
      "obj  0.01557451314787694\n",
      "obj  0.015557932746465077\n",
      "obj  0.0154756667758478\n",
      "obj  0.015196471194045222\n",
      "obj  0.014999993202664234\n",
      "obj  0.014901704244313736\n",
      "obj  0.014881827014206782\n",
      "obj  0.014873925585000787\n",
      "obj  0.014872544089166778\n",
      "obj  0.014872307227486978\n",
      "obj  0.014872225714325069\n",
      "obj  0.014872211047358736\n",
      "obj  0.014872206270772891\n",
      "v20 d6 f0 t1: original ll 0.0188 auc 0.9699, ensemble ll 0.0177 auc 0.9697\n",
      "running time 3.6174697875976562\n",
      "starting model 6 fold 0 target 2\n",
      "obj  0.042203340810120005\n",
      "obj  0.04221491830288568\n",
      "obj  0.04228484709735017\n",
      "obj  0.042159952604004104\n",
      "obj  0.04230011874801733\n",
      "obj  0.042276918048416275\n",
      "obj  0.042289507997564646\n",
      "obj  0.042282938675376795\n",
      "obj  0.04220292517978461\n",
      "obj  0.042169029201253025\n",
      "obj  0.04209278455287459\n",
      "obj  0.04208543290079616\n",
      "obj  0.042051901412903915\n",
      "obj  0.042051898044781856\n",
      "obj  0.04205014810169716\n",
      "obj  0.042049889520566264\n",
      "obj  0.04204970462675517\n",
      "obj  0.042049661134806474\n",
      "obj  0.042049660706425365\n",
      "obj  0.04204964948079197\n",
      "obj  0.04204964745395585\n",
      "v20 d6 f0 t2: original ll 0.0449 auc 0.9920, ensemble ll 0.0446 auc 0.9920\n",
      "running time 4.034621477127075\n",
      "starting model 6 fold 0 target 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.025532902780174487\n",
      "obj  0.025582430418628403\n",
      "obj  0.025592169230686995\n",
      "obj  0.025605006391653196\n",
      "obj  0.02559711401173484\n",
      "obj  0.025593322011651157\n",
      "obj  0.025595183340863494\n",
      "obj  0.02559494000898686\n",
      "obj  0.025594236099279372\n",
      "obj  0.025592806611693657\n",
      "obj  0.02559112098041277\n",
      "obj  0.025589253698680023\n",
      "obj  0.025587360466134516\n",
      "obj  0.025585129851563297\n",
      "obj  0.02558356757788485\n",
      "obj  0.02558237327400449\n",
      "obj  0.025579912517200484\n",
      "obj  0.025578215070265527\n",
      "obj  0.0255769259292384\n",
      "obj  0.025575895047142205\n",
      "obj  0.025575049064725443\n",
      "obj  0.025574345139334004\n",
      "obj  0.025573013928655165\n",
      "obj  0.025571319318381663\n",
      "obj  0.025569279813279302\n",
      "obj  0.025567200277490845\n",
      "obj  0.02556570722803542\n",
      "obj  0.02556454607173261\n",
      "obj  0.02556360819553789\n",
      "obj  0.025562834891345084\n",
      "obj  0.025562190832595554\n",
      "obj  0.025561651981248056\n",
      "obj  0.025560393479248114\n",
      "obj  0.02555884878475966\n",
      "obj  0.025557779769230866\n",
      "obj  0.02555696907425039\n",
      "obj  0.02555632982063598\n",
      "obj  0.02555581700764853\n",
      "obj  0.02555540335632064\n",
      "obj  0.02555507141689643\n",
      "obj  0.025554809980032313\n",
      "obj  0.025554609156338347\n",
      "obj  0.025554462195613144\n",
      "obj  0.025554365841557458\n",
      "obj  0.0255543151520614\n",
      "obj  0.025554304704916472\n",
      "obj  0.025554331512263925\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543942797641\n",
      "obj  0.0255543863073656\n",
      "obj  0.025554386307365597\n",
      "obj  0.025554355514765422\n",
      "obj  0.025554386307394532\n",
      "obj  0.025554386307394535\n",
      "obj  0.025554370075234124\n",
      "obj  0.02555437007523413\n",
      "obj  0.025554362592115305\n",
      "obj  0.025554362592115302\n",
      "obj  0.025554359000340476\n",
      "obj  0.025554359000340476\n",
      "obj  0.025554357245304384\n",
      "obj  0.025554357245304377\n",
      "obj  0.025554356376969737\n",
      "obj  0.025554356376969733\n",
      "obj  0.025554355945100922\n",
      "obj  0.025554355945100922\n",
      "obj  0.02555435572974146\n",
      "obj  0.02555435572974146\n",
      "obj  0.025554355622205507\n",
      "obj  0.025554355622205507\n",
      "obj  0.02555435556847348\n",
      "obj  0.02555435556847348\n",
      "obj  0.02555435554161645\n",
      "obj  0.02555435554161645\n",
      "obj  0.025554355528190194\n",
      "obj  0.025554355528190197\n",
      "obj  0.025554355521477622\n",
      "obj  0.025554355521477622\n",
      "obj  0.025554355518121474\n",
      "obj  0.025554355518121477\n",
      "obj  0.025554355514765422\n",
      "obj  0.025554433033930138\n",
      "obj  0.025554433033930138\n",
      "obj  0.025554433033930138\n",
      "obj  0.025554433033930138\n",
      "obj  0.025554433033930138\n",
      "obj  0.025554433033930138\n",
      "obj  0.025554432804783346\n",
      "obj  0.02555439010781264\n",
      "obj  0.025554390107812644\n",
      "obj  0.025554371781555958\n",
      "obj  0.025554371781555958\n",
      "obj  0.025554363399182514\n",
      "obj  0.025554363399182514\n",
      "obj  0.02555435939111356\n",
      "obj  0.02555435939111356\n",
      "obj  0.025554357437831215\n",
      "obj  0.025554357437831215\n",
      "obj  0.025554356472517116\n",
      "obj  0.025554356472517116\n",
      "obj  0.025554355992695458\n",
      "obj  0.025554355992695458\n",
      "obj  0.025554355753493928\n",
      "obj  0.02555435575349392\n",
      "obj  0.025554355634070533\n",
      "obj  0.025554355634070533\n",
      "obj  0.025554355574403192\n",
      "obj  0.0255543555744032\n",
      "obj  0.02555435554458062\n",
      "obj  0.02555435554458062\n",
      "obj  0.025554355529672088\n",
      "obj  0.025554355529672088\n",
      "obj  0.025554355522218526\n",
      "obj  0.025554355522218526\n",
      "obj  0.02555435551849193\n",
      "obj  0.025554355518491927\n",
      "obj  0.025554355514765422\n",
      "obj  0.02555443301550923\n",
      "obj  0.02555443301550923\n",
      "obj  0.02555443301550923\n",
      "obj  0.02555443301550923\n",
      "obj  0.02555443301550923\n",
      "obj  0.02555443301550923\n",
      "obj  0.02555443275779307\n",
      "obj  0.02555443275779307\n",
      "obj  0.025554390088019824\n",
      "obj  0.025554390088019824\n",
      "obj  0.02555437177255656\n",
      "obj  0.025554371772556556\n",
      "obj  0.025554363394928732\n",
      "obj  0.025554363394928732\n",
      "obj  0.025554359389048497\n",
      "obj  0.0255543593890485\n",
      "obj  0.025554357436812614\n",
      "obj  0.025554357436812614\n",
      "obj  0.025554356472011312\n",
      "obj  0.025554356472011316\n",
      "obj  0.025554355992443427\n",
      "obj  0.025554355992443427\n",
      "obj  0.025554355753368126\n",
      "obj  0.025554355753368126\n",
      "obj  0.025554355634007684\n",
      "obj  0.025554355634007684\n",
      "obj  0.025554355574371794\n",
      "obj  0.025554355574371797\n",
      "obj  0.02555435554456491\n",
      "obj  0.02555435554456491\n",
      "obj  0.025554355529664247\n",
      "obj  0.025554355529664247\n",
      "obj  0.0255543555222146\n",
      "obj  0.0255543555222146\n",
      "obj  0.025554355518489964\n",
      "obj  0.025554355518489964\n",
      "obj  0.025554355514765422\n",
      "obj  0.0255544330118573\n",
      "obj  0.02555443301185731\n",
      "obj  0.0255544330118573\n",
      "obj  0.02555443301185731\n",
      "obj  0.0255544330118573\n",
      "obj  0.02555443301185731\n",
      "obj  0.02555443274849424\n",
      "obj  0.02555443274849424\n",
      "obj  0.025554390084102253\n",
      "obj  0.02555439008410225\n",
      "obj  0.025554371770775068\n",
      "obj  0.025554371770775068\n",
      "obj  0.025554363394086597\n",
      "obj  0.025554363394086597\n",
      "obj  0.025554359388639654\n",
      "obj  0.025554357436610945\n",
      "obj  0.025554357436610945\n",
      "obj  0.025554356471911167\n",
      "obj  0.025554356471911167\n",
      "obj  0.02555435599239353\n",
      "obj  0.02555435599239353\n",
      "obj  0.025554355753343215\n",
      "obj  0.02555435575334322\n",
      "obj  0.02555435563399525\n",
      "obj  0.02555435563399525\n",
      "obj  0.025554355574365573\n",
      "obj  0.025554355574365573\n",
      "obj  0.025554355544561803\n",
      "obj  0.025554355544561803\n",
      "obj  0.0255543555296627\n",
      "obj  0.0255543555296627\n",
      "obj  0.02555435552221383\n",
      "obj  0.02555435552221383\n",
      "obj  0.02555435551848958\n",
      "obj  0.02555435551848958\n",
      "obj  0.025554355514765422\n",
      "obj  0.02555443301112822\n",
      "obj  0.02555443301112822\n",
      "obj  0.02555443301112822\n",
      "obj  0.02555443301112822\n",
      "obj  0.02555443301112822\n",
      "obj  0.02555443301112822\n",
      "obj  0.025554432746638437\n",
      "obj  0.025554432746638437\n",
      "obj  0.025554390083320375\n",
      "obj  0.02555439008332037\n",
      "obj  0.02555437177041951\n",
      "obj  0.025554363393918512\n",
      "obj  0.025554363393918512\n",
      "obj  0.025554359388558053\n",
      "obj  0.025554359388558053\n",
      "obj  0.025554357436570696\n",
      "obj  0.025554357436570696\n",
      "obj  0.025554356471891186\n",
      "obj  0.025554356471891186\n",
      "obj  0.02555435599238356\n",
      "obj  0.02555435599238356\n",
      "obj  0.02555435575333825\n",
      "obj  0.02555435575333825\n",
      "obj  0.025554355633992776\n",
      "obj  0.025554355633992776\n",
      "obj  0.02555435557436433\n",
      "obj  0.02555435557436433\n",
      "obj  0.025554355544561185\n",
      "obj  0.025554355544561185\n",
      "obj  0.025554355529662384\n",
      "obj  0.025554355522213683\n",
      "obj  0.025554355522213683\n",
      "obj  0.025554355518489502\n",
      "obj  0.025554355518489502\n",
      "obj  0.025554355514765422\n",
      "obj  0.025554433010982446\n",
      "obj  0.025554433010982446\n",
      "obj  0.025554433010982446\n",
      "obj  0.025554433010982446\n",
      "obj  0.025554433010982446\n",
      "obj  0.025554433010982446\n",
      "obj  0.025554432746267446\n",
      "obj  0.025554432746267446\n",
      "obj  0.025554390083164062\n",
      "obj  0.025554390083164062\n",
      "obj  0.025554371770348423\n",
      "obj  0.025554371770348423\n",
      "obj  0.025554363393884904\n",
      "obj  0.025554363393884904\n",
      "obj  0.025554359388541732\n",
      "obj  0.02555435938854173\n",
      "obj  0.025554357436562647\n",
      "obj  0.025554357436562643\n",
      "obj  0.02555435647188719\n",
      "obj  0.02555435647188719\n",
      "obj  0.025554355992381567\n",
      "obj  0.025554355992381577\n",
      "obj  0.02555435575333726\n",
      "obj  0.02555435575333726\n",
      "obj  0.025554355633992273\n",
      "obj  0.02555435563399227\n",
      "obj  0.025554355574364074\n",
      "obj  0.025554355574364074\n",
      "obj  0.02555435554456106\n",
      "obj  0.02555435554456106\n",
      "obj  0.025554355529662322\n",
      "obj  0.02555435552966232\n",
      "obj  0.025554355522213648\n",
      "obj  0.025554355522213648\n",
      "obj  0.02555435551848948\n",
      "obj  0.02555435551848948\n",
      "obj  0.025554355514765422\n",
      "obj  0.025554433010953302\n",
      "obj  0.025554433010953302\n",
      "obj  0.025554433010953302\n",
      "obj  0.025554433010953302\n",
      "obj  0.025554433010953302\n",
      "obj  0.025554433010953302\n",
      "obj  0.025554432746193245\n",
      "obj  0.025554432746193245\n",
      "obj  0.025554390083132806\n",
      "obj  0.025554390083132806\n",
      "obj  0.025554371770334216\n",
      "obj  0.025554371770334205\n",
      "obj  0.02555436339387818\n",
      "obj  0.025554359388538474\n",
      "obj  0.02555435938853847\n",
      "obj  0.025554357436561037\n",
      "obj  0.025554356471886384\n",
      "obj  0.025554356471886384\n",
      "obj  0.025554355992381175\n",
      "obj  0.025554355992381175\n",
      "obj  0.02555435575333706\n",
      "obj  0.02555435575333706\n",
      "obj  0.025554355633992172\n",
      "obj  0.025554355633992172\n",
      "obj  0.02555435557436403\n",
      "obj  0.02555435557436403\n",
      "obj  0.025554355544561036\n",
      "obj  0.025554355544561036\n",
      "obj  0.025554355529662315\n",
      "obj  0.025554355529662315\n",
      "obj  0.025554355522213645\n",
      "obj  0.025554355522213645\n",
      "obj  0.025554355518489478\n",
      "obj  0.025554355518489478\n",
      "obj  0.025554355514765422\n",
      "obj  0.02555443301094746\n",
      "obj  0.02555443301094746\n",
      "obj  0.02555443301094746\n",
      "obj  0.02555443301094746\n",
      "obj  0.02555443301094746\n",
      "obj  0.02555443301094746\n",
      "obj  0.025554432746178402\n",
      "obj  0.025554432746178406\n",
      "obj  0.025554390083126547\n",
      "obj  0.025554390083126547\n",
      "obj  0.025554371770331374\n",
      "obj  0.02555437177033138\n",
      "obj  0.025554363393876837\n",
      "obj  0.025554363393876837\n",
      "obj  0.025554359388537826\n",
      "obj  0.025554359388537822\n",
      "obj  0.025554357436560718\n",
      "obj  0.025554357436560718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.025554356471886225\n",
      "obj  0.02555435647188623\n",
      "obj  0.0255543559923811\n",
      "obj  0.0255543559923811\n",
      "obj  0.02555435575333701\n",
      "obj  0.02555435575333701\n",
      "obj  0.025554355633992148\n",
      "obj  0.02555435563399215\n",
      "obj  0.025554355574364026\n",
      "obj  0.025554355574364026\n",
      "obj  0.02555435554456105\n",
      "obj  0.02555435554456105\n",
      "obj  0.025554355529662308\n",
      "obj  0.025554355529662308\n",
      "obj  0.02555435552221363\n",
      "obj  0.025554355522213627\n",
      "obj  0.02555435551848947\n",
      "obj  0.025554355518489464\n",
      "obj  0.025554355514765422\n",
      "obj  0.025554433010946304\n",
      "obj  0.025554433010946304\n",
      "obj  0.025554433010946304\n",
      "obj  0.025554433010946304\n",
      "obj  0.025554433010946304\n",
      "obj  0.025554433010946304\n",
      "obj  0.025554432746175443\n",
      "obj  0.025554432746175436\n",
      "obj  0.02555439008312531\n",
      "obj  0.02555439008312531\n",
      "obj  0.025554371770330802\n",
      "obj  0.025554371770330812\n",
      "obj  0.025554363393876584\n",
      "obj  0.025554363393876584\n",
      "obj  0.025554359388537694\n",
      "obj  0.02555435938853769\n",
      "obj  0.025554357436560652\n",
      "obj  0.02555435743656066\n",
      "obj  0.025554356471886204\n",
      "obj  0.025554356471886204\n",
      "obj  0.02555435599238109\n",
      "obj  0.02555435599238109\n",
      "obj  0.025554355753337008\n",
      "obj  0.025554355753337008\n",
      "obj  0.025554355633992144\n",
      "obj  0.025554355633992144\n",
      "obj  0.025554355574364022\n",
      "obj  0.025554355574364026\n",
      "obj  0.02555435554456104\n",
      "obj  0.02555435554456104\n",
      "obj  0.02555435552966231\n",
      "obj  0.02555435552966231\n",
      "obj  0.025554355522213627\n",
      "obj  0.025554355522213627\n",
      "obj  0.025554355518489474\n",
      "obj  0.02555435551848947\n",
      "v20 d6 f0 t3: original ll 0.0278 auc 0.9960, ensemble ll 0.0296 auc 0.9960\n",
      "running time 12.262839794158936\n",
      "starting model 6 fold 0 target 4\n",
      "obj  0.06578966829775819\n",
      "obj  0.0658102459238369\n",
      "obj  0.06585352139389451\n",
      "obj  0.0658529530312968\n",
      "obj  0.06586120089454947\n",
      "obj  0.06585374624896297\n",
      "obj  0.06585214627891237\n",
      "obj  0.06584970337545734\n",
      "obj  0.06582853046157566\n",
      "obj  0.0657936276506992\n",
      "obj  0.06577692602237417\n",
      "obj  0.06577059122801757\n",
      "obj  0.06576771819968759\n",
      "obj  0.06576762127487235\n",
      "obj  0.0657671321662875\n",
      "obj  0.06576702319017781\n",
      "obj  0.06576699462200024\n",
      "obj  0.06576699267710456\n",
      "obj  0.06576699238467715\n",
      "v20 d6 f0 t4: original ll 0.0672 auc 0.9802, ensemble ll 0.0672 auc 0.9802\n",
      "running time 3.9319496154785156\n",
      "starting model 6 fold 0 target 5\n",
      "obj  0.08049947955122051\n",
      "obj  0.08045419178414627\n",
      "obj  0.08055629270669065\n",
      "obj  0.08020701894142017\n",
      "obj  0.08054801786537022\n",
      "obj  0.080398785498123\n",
      "obj  0.08042370417102741\n",
      "obj  0.08040448736493966\n",
      "obj  0.08010109996374526\n",
      "obj  0.07998783563802059\n",
      "obj  0.07997335425219361\n",
      "obj  0.07997264360581698\n",
      "obj  0.07997185553759772\n",
      "obj  0.07997178971839715\n",
      "obj  0.07997177237268455\n",
      "v20 d6 f0 t5: original ll 0.0836 auc 0.9781, ensemble ll 0.0846 auc 0.9781\n",
      "running time 3.4264118671417236\n",
      "starting model 7 fold 0 target 0\n",
      "obj  0.09805289839334803\n",
      "obj  0.09795960428808216\n",
      "obj  0.09786111011719752\n",
      "obj  0.09807594326798463\n",
      "obj  0.09781468689013487\n",
      "obj  0.09787432719357345\n",
      "obj  0.0978421004093377\n",
      "obj  0.09785128589058001\n",
      "obj  0.09778755062680371\n",
      "obj  0.09777027646451823\n",
      "obj  0.09775297445995887\n",
      "obj  0.09774883099504696\n",
      "obj  0.09774717536909384\n",
      "obj  0.09774691902080541\n",
      "obj  0.09774687981035456\n",
      "obj  0.09774686963842578\n",
      "obj  0.09774686963842534\n",
      "obj  0.09774686861691319\n",
      "v20 d7 f0 t0: original ll 0.0997 auc 0.9863, ensemble ll 0.0991 auc 0.9863\n",
      "running time 3.92590069770813\n",
      "starting model 7 fold 0 target 1\n",
      "obj  0.014289758280828464\n",
      "obj  0.014214218676337438\n",
      "obj  0.014018686346754558\n",
      "obj  0.013880229330940606\n",
      "obj  0.01397021075100481\n",
      "obj  0.014056447501352933\n",
      "obj  0.01406233685177864\n",
      "obj  0.013987439101350745\n",
      "obj  0.013910115521822088\n",
      "obj  0.013835852165360044\n",
      "obj  0.013819036445901791\n",
      "obj  0.013810857627000255\n",
      "obj  0.013809242196229176\n",
      "obj  0.01380851919019946\n",
      "obj  0.013808237092462722\n",
      "obj  0.013808201293799454\n",
      "obj  0.013808186999081344\n",
      "obj  0.01380818370312821\n",
      "obj  0.013808182478252278\n",
      "v20 d7 f0 t1: original ll 0.0157 auc 0.9763, ensemble ll 0.0157 auc 0.9763\n",
      "running time 3.9417805671691895\n",
      "starting model 7 fold 0 target 2\n",
      "obj  0.04075378626178986\n",
      "obj  0.040753728025780554\n",
      "obj  0.04076567852749391\n",
      "obj  0.040763512991085535\n",
      "obj  0.04077416517532965\n",
      "obj  0.0407720870214412\n",
      "obj  0.040769917472216304\n",
      "obj  0.04076642905416379\n",
      "obj  0.04076510113922266\n",
      "obj  0.040745362508798635\n",
      "obj  0.04073872869285622\n",
      "obj  0.040735012588085255\n",
      "obj  0.040735012451658295\n",
      "obj  0.04073296823115743\n",
      "obj  0.04073296752785332\n",
      "obj  0.04073289360504841\n",
      "obj  0.04073284938168278\n",
      "obj  0.040732848705068346\n",
      "obj  0.04073284335425881\n",
      "v20 d7 f0 t2: original ll 0.0438 auc 0.9922, ensemble ll 0.0438 auc 0.9922\n",
      "running time 3.994109869003296\n",
      "starting model 7 fold 0 target 3\n",
      "obj  0.024943319355202973\n",
      "obj  0.02494315958070874\n",
      "obj  0.024961109014477078\n",
      "obj  0.024917880389573575\n",
      "obj  0.024954388131430916\n",
      "obj  0.024938364112822225\n",
      "obj  0.024941345719057238\n",
      "obj  0.024939760809573656\n",
      "obj  0.02487680686085294\n",
      "obj  0.02483827162112651\n",
      "obj  0.024838262097358937\n",
      "obj  0.02483252416130581\n",
      "obj  0.024831088266814842\n",
      "obj  0.024829842943705077\n",
      "obj  0.024829823703645185\n",
      "obj  0.0248294237409491\n",
      "obj  0.024829393640396165\n",
      "obj  0.024829374878490396\n",
      "obj  0.024829369009478776\n",
      "obj  0.02482936855115611\n",
      "v20 d7 f0 t3: original ll 0.0267 auc 0.9961, ensemble ll 0.0267 auc 0.9961\n",
      "running time 4.104206323623657\n",
      "starting model 7 fold 0 target 4\n",
      "obj  0.06488887884006345\n",
      "obj  0.0648625567211479\n",
      "obj  0.06489294825031425\n",
      "obj  0.06480787431563499\n",
      "obj  0.06490460077912\n",
      "obj  0.06485018453167762\n",
      "obj  0.06485644953197453\n",
      "obj  0.06480815421236873\n",
      "obj  0.06473347544139019\n",
      "obj  0.06473304876631596\n",
      "obj  0.0646801980921578\n",
      "obj  0.06467606398615304\n",
      "obj  0.06467575620370973\n",
      "obj  0.06467416354378615\n",
      "obj  0.06467408242812356\n",
      "obj  0.0646740799317312\n",
      "obj  0.06467404454711834\n",
      "obj  0.0646740445467228\n",
      "obj  0.06467403990178365\n",
      "v20 d7 f0 t4: original ll 0.0658 auc 0.9812, ensemble ll 0.0658 auc 0.9812\n",
      "running time 3.981308698654175\n",
      "starting model 7 fold 0 target 5\n",
      "obj  0.07879210740298354\n",
      "obj  0.07874012144853079\n",
      "obj  0.07868650622362167\n",
      "obj  0.07872835227563402\n",
      "obj  0.07861179381297521\n",
      "obj  0.07858816943140105\n",
      "obj  0.07858464665754354\n",
      "obj  0.0785890261113873\n",
      "obj  0.07856155514173767\n",
      "obj  0.07852100374017891\n",
      "obj  0.078521002893433\n",
      "obj  0.0785185866258906\n",
      "obj  0.07851769401850903\n",
      "obj  0.07851769030735724\n",
      "obj  0.07851758147329065\n",
      "obj  0.07851756796059454\n",
      "obj  0.07851756371144689\n",
      "v20 d7 f0 t5: original ll 0.0827 auc 0.9781, ensemble ll 0.0824 auc 0.9781\n",
      "running time 3.6900572776794434\n",
      "starting model 0 fold 1 target 0\n",
      "obj  0.09947387554979885\n",
      "obj  0.0993292746168154\n",
      "obj  0.0991540818668584\n",
      "obj  0.09952569568325031\n",
      "obj  0.09908737547152852\n",
      "obj  0.09921047344383833\n",
      "obj  0.09915028241570005\n",
      "obj  0.09916818259670405\n",
      "obj  0.09893991114733325\n",
      "obj  0.09884350724600169\n",
      "obj  0.09881405252046786\n",
      "obj  0.09879945433164068\n",
      "obj  0.0987964426762549\n",
      "obj  0.09879503027429976\n",
      "obj  0.09879475809066873\n",
      "obj  0.09879466998844585\n",
      "obj  0.09879466994350031\n",
      "obj  0.09879465479025316\n",
      "obj  0.09879465123695955\n",
      "v20 d0 f1 t0: original ll 0.1014 auc 0.9854, ensemble ll 0.1007 auc 0.9854\n",
      "running time 4.016505718231201\n",
      "starting model 0 fold 1 target 1\n",
      "obj  0.01655978383617616\n",
      "obj  0.016501424307884073\n",
      "obj  0.01626183527743367\n",
      "obj  0.016048303834941522\n",
      "obj  0.016101106979810063\n",
      "obj  0.016151449157326046\n",
      "obj  0.016151065983849095\n",
      "obj  0.016106240511431013\n",
      "obj  0.015937055665660175\n",
      "obj  0.015847098467733568\n",
      "obj  0.015816113966687643\n",
      "obj  0.01580342310473417\n",
      "obj  0.015798680501612188\n",
      "obj  0.015796967702338363\n",
      "obj  0.015796964565695685\n",
      "obj  0.015796593126751832\n",
      "obj  0.01579653434558507\n",
      "obj  0.015796534026057088\n",
      "obj  0.015796528253976667\n",
      "obj  0.015796526832930046\n",
      "v20 d0 f1 t1: original ll 0.0149 auc 0.9629, ensemble ll 0.0135 auc 0.9628\n",
      "running time 4.090397357940674\n",
      "starting model 0 fold 1 target 2\n",
      "obj  0.0443924136637074\n",
      "obj  0.0443669302098721\n",
      "obj  0.044355990603277766\n",
      "obj  0.0443843108387553\n",
      "obj  0.044342843148715484\n",
      "obj  0.044339769132543554\n",
      "obj  0.04433950531092321\n",
      "obj  0.04434097519832987\n",
      "obj  0.044306787545007206\n",
      "obj  0.04430412788467565\n",
      "obj  0.04429838862126371\n",
      "obj  0.044295434469790576\n",
      "obj  0.04429529443314484\n",
      "obj  0.0442952587929464\n",
      "obj  0.0442952233211014\n",
      "obj  0.044295218014471206\n",
      "obj  0.044295218014377684\n",
      "obj  0.044295217958012514\n",
      "v20 d0 f1 t2: original ll 0.0430 auc 0.9915, ensemble ll 0.0431 auc 0.9915\n",
      "running time 3.8550636768341064\n",
      "starting model 0 fold 1 target 3\n",
      "obj  0.02703463450035575\n",
      "obj  0.02703581539329055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.027050462124247762\n",
      "obj  0.027004405161027006\n",
      "obj  0.027034038917703958\n",
      "obj  0.027013557638497138\n",
      "obj  0.027016571816483755\n",
      "obj  0.02701472710543605\n",
      "obj  0.027009997728863804\n",
      "obj  0.026981539638794644\n",
      "obj  0.026979572625671865\n",
      "obj  0.02697754092733439\n",
      "obj  0.026977493822346973\n",
      "obj  0.02697735484813708\n",
      "obj  0.026977339724979458\n",
      "obj  0.02697729924311548\n",
      "obj  0.02697729923385495\n",
      "obj  0.026977293993940686\n",
      "v20 d0 f1 t3: original ll 0.0248 auc 0.9965, ensemble ll 0.0247 auc 0.9965\n",
      "running time 3.8107142448425293\n",
      "starting model 0 fold 1 target 4\n",
      "obj  0.06808368666176444\n",
      "obj  0.06807109211212008\n",
      "obj  0.06800691957417579\n",
      "obj  0.06819121203344841\n",
      "obj  0.06799375758717446\n",
      "obj  0.06800223738244798\n",
      "obj  0.06800262680055161\n",
      "obj  0.06800599892830772\n",
      "obj  0.06798340385480107\n",
      "obj  0.06795816356756605\n",
      "obj  0.06794743334135772\n",
      "obj  0.06794253793597738\n",
      "obj  0.06794052970089279\n",
      "obj  0.06794007924205486\n",
      "obj  0.06793995544254929\n",
      "obj  0.06793995444430388\n",
      "obj  0.06793992613850275\n",
      "obj  0.06793992149371626\n",
      "v20 d0 f1 t4: original ll 0.0659 auc 0.9787, ensemble ll 0.0658 auc 0.9787\n",
      "running time 3.8413548469543457\n",
      "starting model 0 fold 1 target 5\n",
      "obj  0.08195519761088857\n",
      "obj  0.08181338847532314\n",
      "obj  0.08171148262160319\n",
      "obj  0.08187138043621235\n",
      "obj  0.08165815431201695\n",
      "obj  0.08166887872133906\n",
      "obj  0.08166705653413833\n",
      "obj  0.08166607741118971\n",
      "obj  0.08159433978388515\n",
      "obj  0.0815503064249093\n",
      "obj  0.08153623571795017\n",
      "obj  0.08153179748087788\n",
      "obj  0.081531076336614\n",
      "obj  0.08153105916842579\n",
      "obj  0.08153092637522143\n",
      "obj  0.08153091219190912\n",
      "obj  0.08153090767939916\n",
      "v20 d0 f1 t5: original ll 0.0834 auc 0.9769, ensemble ll 0.0829 auc 0.9769\n",
      "running time 3.7413604259490967\n",
      "starting model 1 fold 1 target 0\n",
      "obj  0.0982693323632899\n",
      "obj  0.09818531727461503\n",
      "obj  0.09800451688742452\n",
      "obj  0.09847299073527851\n",
      "obj  0.09793040708848018\n",
      "obj  0.09809178383601867\n",
      "obj  0.0980126551525989\n",
      "obj  0.098036385574487\n",
      "obj  0.09769616967542495\n",
      "obj  0.09757110787613928\n",
      "obj  0.09750320900011407\n",
      "obj  0.09747925879114912\n",
      "obj  0.09747241208490762\n",
      "obj  0.09747166191774939\n",
      "obj  0.09747166159195958\n",
      "obj  0.09747143146204387\n",
      "obj  0.097471380726626\n",
      "obj  0.0974713732855191\n",
      "obj  0.09747137146082224\n",
      "obj  0.09747137104343055\n",
      "v20 d1 f1 t0: original ll 0.1013 auc 0.9857, ensemble ll 0.1004 auc 0.9857\n",
      "running time 4.183948993682861\n",
      "starting model 1 fold 1 target 1\n",
      "obj  0.017390610439832425\n",
      "obj  0.017309539819552452\n",
      "obj  0.017071410035169765\n",
      "obj  0.016809046442978787\n",
      "obj  0.016885349759155312\n",
      "obj  0.01693434008776116\n",
      "obj  0.016937784077589085\n",
      "obj  0.016883040467096554\n",
      "obj  0.016704591269962477\n",
      "obj  0.01660965341459964\n",
      "obj  0.016576552846001378\n",
      "obj  0.016561312236731733\n",
      "obj  0.016555399406729107\n",
      "obj  0.016552851274415088\n",
      "obj  0.016552251906615294\n",
      "obj  0.01655218240777638\n",
      "obj  0.01655216950594049\n",
      "obj  0.016552164935262945\n",
      "v20 d1 f1 t1: original ll 0.0161 auc 0.9582, ensemble ll 0.0144 auc 0.9581\n",
      "running time 3.8390161991119385\n",
      "starting model 1 fold 1 target 2\n",
      "obj  0.0418406527829545\n",
      "obj  0.04182532245161475\n",
      "obj  0.04182696070428502\n",
      "obj  0.04186344620806192\n",
      "obj  0.041801911996950554\n",
      "obj  0.04178658604018523\n",
      "obj  0.04178798589793085\n",
      "obj  0.041787664761761\n",
      "obj  0.04178391523987252\n",
      "obj  0.04177239550818025\n",
      "obj  0.041768670501985655\n",
      "obj  0.0417682848568365\n",
      "obj  0.04176717361843938\n",
      "obj  0.04176716555104589\n",
      "obj  0.041766987562336516\n",
      "obj  0.04176698708835052\n",
      "obj  0.041766968457399016\n",
      "obj  0.04176696637623772\n",
      "v20 d1 f1 t2: original ll 0.0439 auc 0.9911, ensemble ll 0.0438 auc 0.9911\n",
      "running time 3.8189847469329834\n",
      "starting model 1 fold 1 target 3\n",
      "obj  0.0259170657452045\n",
      "obj  0.025901197869974073\n",
      "obj  0.025910822512769414\n",
      "obj  0.025884287144902877\n",
      "obj  0.02589542237440035\n",
      "obj  0.02587778981155262\n",
      "obj  0.025880048784473617\n",
      "obj  0.025878796237773168\n",
      "obj  0.025877593193119528\n",
      "obj  0.02586330268658735\n",
      "obj  0.025861001617397548\n",
      "obj  0.025859046755510637\n",
      "obj  0.02585903993561329\n",
      "obj  0.02585883242945965\n",
      "obj  0.025858704218064417\n",
      "obj  0.025858678940518007\n",
      "obj  0.025858673313854368\n",
      "obj  0.02585867233220478\n",
      "obj  0.025858672225161587\n",
      "obj  0.02585867222516016\n",
      "v20 d1 f1 t3: original ll 0.0252 auc 0.9965, ensemble ll 0.0251 auc 0.9965\n",
      "running time 4.0838706493377686\n",
      "starting model 1 fold 1 target 4\n",
      "obj  0.0669044813172015\n",
      "obj  0.06687441821272863\n",
      "obj  0.06681377585731925\n",
      "obj  0.06710158743006098\n",
      "obj  0.06678057695590366\n",
      "obj  0.06678352039967095\n",
      "obj  0.06678056418121815\n",
      "obj  0.0667855792824525\n",
      "obj  0.06676573578819608\n",
      "obj  0.06671021751361182\n",
      "obj  0.0666935063467185\n",
      "obj  0.06669350127002045\n",
      "obj  0.06668864421634571\n",
      "obj  0.06668698142301185\n",
      "obj  0.06668634786473818\n",
      "obj  0.0666862779981905\n",
      "obj  0.06668626226214887\n",
      "obj  0.06668625802579509\n",
      "v20 d1 f1 t4: original ll 0.0653 auc 0.9795, ensemble ll 0.0654 auc 0.9795\n",
      "running time 3.717599630355835\n",
      "starting model 1 fold 1 target 5\n",
      "obj  0.08119280250762681\n",
      "obj  0.08103225465615936\n",
      "obj  0.0808333885948831\n",
      "obj  0.08104843328161561\n",
      "obj  0.08081275715556817\n",
      "obj  0.08085472433195885\n",
      "obj  0.08085038748452653\n",
      "obj  0.08085466302909537\n",
      "obj  0.0807330896604457\n",
      "obj  0.08063827060524\n",
      "obj  0.08060759397236017\n",
      "obj  0.08060148310493498\n",
      "obj  0.08059969925599544\n",
      "obj  0.08059874698686287\n",
      "obj  0.08059856958871556\n",
      "obj  0.08059854046110781\n",
      "obj  0.08059853254253108\n",
      "v20 d1 f1 t5: original ll 0.0833 auc 0.9769, ensemble ll 0.0829 auc 0.9769\n",
      "running time 3.6315648555755615\n",
      "starting model 2 fold 1 target 0\n",
      "obj  0.09886423760691898\n",
      "obj  0.09877241369448887\n",
      "obj  0.09872590852079\n",
      "obj  0.09880914732829661\n",
      "obj  0.09868769838981167\n",
      "obj  0.09869719217201728\n",
      "obj  0.09867091749411089\n",
      "obj  0.09867451148705021\n",
      "obj  0.09860540994819261\n",
      "obj  0.09860537169125617\n",
      "obj  0.09859426018147911\n",
      "obj  0.09859208718799639\n",
      "obj  0.09859058392025645\n",
      "obj  0.0985899625844395\n",
      "obj  0.09858981723019657\n",
      "obj  0.098589772874585\n",
      "obj  0.09858975296363186\n",
      "obj  0.09858975021842978\n",
      "obj  0.09858975006292127\n",
      "obj  0.09858975002886143\n",
      "v20 d2 f1 t0: original ll 0.1007 auc 0.9859, ensemble ll 0.1008 auc 0.9859\n",
      "running time 4.064108848571777\n",
      "starting model 2 fold 1 target 1\n",
      "obj  0.017964917550253534\n",
      "obj  0.01791819233431083\n",
      "obj  0.01777464230188051\n",
      "obj  0.01767789548404595\n",
      "obj  0.017650187101092417\n",
      "obj  0.017664802545016196\n",
      "obj  0.017655168886401673\n",
      "obj  0.017656884186081613\n",
      "obj  0.01758374310017635\n",
      "obj  0.017549118818190948\n",
      "obj  0.01754005799917376\n",
      "obj  0.017533301969583834\n",
      "obj  0.017530906343506146\n",
      "obj  0.01753079626671383\n",
      "obj  0.017530666544698672\n",
      "obj  0.017530648054620176\n",
      "obj  0.01753064310618156\n",
      "v20 d2 f1 t1: original ll 0.0143 auc 0.9570, ensemble ll 0.0149 auc 0.9569\n",
      "running time 3.625225067138672\n",
      "starting model 2 fold 1 target 2\n",
      "obj  0.04382851703487227\n",
      "obj  0.043797681319292715\n",
      "obj  0.0438305377366084\n",
      "obj  0.04372901492143865\n",
      "obj  0.04382971422699036\n",
      "obj  0.043787869219016\n",
      "obj  0.04379292337892144\n",
      "obj  0.04378713936927839\n",
      "obj  0.043740793097278165\n",
      "obj  0.0437065024115805\n",
      "obj  0.04370113818699675\n",
      "obj  0.04370024985604491\n",
      "obj  0.04369959928536988\n",
      "obj  0.043699393144050226\n",
      "obj  0.04369939313520566\n",
      "obj  0.043699380755984146\n",
      "obj  0.0436993747325466\n",
      "obj  0.04369937320434\n",
      "v20 d2 f1 t2: original ll 0.0456 auc 0.9904, ensemble ll 0.0458 auc 0.9904\n",
      "running time 3.773730516433716\n",
      "starting model 2 fold 1 target 3\n",
      "obj  0.02725387524221057\n",
      "obj  0.02726187817430346\n",
      "obj  0.027286187185987062\n",
      "obj  0.027223954304591916\n",
      "obj  0.027279732998831\n",
      "obj  0.027265054955834908\n",
      "obj  0.02726774406073513\n",
      "obj  0.027265259134439227\n",
      "obj  0.027250984275582653\n",
      "obj  0.027222996789784473\n",
      "obj  0.027216892140614138\n",
      "obj  0.02721689165545332\n",
      "obj  0.027216253986397654\n",
      "obj  0.027216193473879758\n",
      "obj  0.027215920487141814\n",
      "obj  0.027215889456287834\n",
      "obj  0.02721582566000547\n",
      "obj  0.027215824645916598\n",
      "obj  0.02721582421509584\n",
      "obj  0.027215824180522413\n",
      "v20 d2 f1 t3: original ll 0.0257 auc 0.9963, ensemble ll 0.0255 auc 0.9963\n",
      "running time 4.077939510345459\n",
      "starting model 2 fold 1 target 4\n",
      "obj  0.06707550088647209\n",
      "obj  0.06710085090067673\n",
      "obj  0.06708349455650414\n",
      "obj  0.0671621014785249\n",
      "obj  0.06707242677540569\n",
      "obj  0.06706771400302837\n",
      "obj  0.06706682101835588\n",
      "obj  0.06706672833306526\n",
      "obj  0.06706144551879943\n",
      "obj  0.06705880385153659\n",
      "obj  0.06705319808015452\n",
      "obj  0.06705235835809102\n",
      "obj  0.06705053756762706\n",
      "obj  0.06705049226296507\n",
      "obj  0.06705043915025367\n",
      "obj  0.06705043899232072\n",
      "obj  0.06705042805132591\n",
      "v20 d2 f1 t4: original ll 0.0664 auc 0.9787, ensemble ll 0.0663 auc 0.9787\n",
      "running time 3.564208745956421\n",
      "starting model 2 fold 1 target 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.08096238867837098\n",
      "obj  0.08084191085405514\n",
      "obj  0.08078359889794033\n",
      "obj  0.08076294576631896\n",
      "obj  0.08073438830290959\n",
      "obj  0.08069232746548827\n",
      "obj  0.08069684946716049\n",
      "obj  0.08067640189861143\n",
      "obj  0.08064090666093979\n",
      "obj  0.080623382716102\n",
      "obj  0.08061070546536317\n",
      "obj  0.08060692327280362\n",
      "obj  0.08060501079691065\n",
      "obj  0.08060463801131182\n",
      "obj  0.08060461809258501\n",
      "obj  0.08060460102636131\n",
      "obj  0.0806045982113213\n",
      "v20 d2 f1 t5: original ll 0.0831 auc 0.9774, ensemble ll 0.0833 auc 0.9774\n",
      "running time 3.5893442630767822\n",
      "starting model 3 fold 1 target 0\n",
      "obj  0.09783820679287132\n",
      "obj  0.09773335289388112\n",
      "obj  0.09754946263212338\n",
      "obj  0.09792513246752574\n",
      "obj  0.09747230101032445\n",
      "obj  0.09760050518350946\n",
      "obj  0.09753715058183049\n",
      "obj  0.09755575201061728\n",
      "obj  0.09733025899021336\n",
      "obj  0.09722753512956608\n",
      "obj  0.09719260410256016\n",
      "obj  0.09717833692244532\n",
      "obj  0.09717448938014972\n",
      "obj  0.09717310057102721\n",
      "obj  0.09717282748879905\n",
      "obj  0.0971727822266441\n",
      "obj  0.097172781720303\n",
      "obj  0.09717278171812471\n",
      "obj  0.0971727719718729\n",
      "obj  0.09717277197182864\n",
      "obj  0.09717277057668597\n",
      "obj  0.09717277030697571\n",
      "v20 d3 f1 t0: original ll 0.0993 auc 0.9862, ensemble ll 0.0986 auc 0.9862\n",
      "running time 4.399276494979858\n",
      "starting model 3 fold 1 target 1\n",
      "obj  0.017664724143935245\n",
      "obj  0.01761947313769958\n",
      "obj  0.017524588144479242\n",
      "obj  0.017582214220937205\n",
      "obj  0.017554970124985896\n",
      "obj  0.01755699560702928\n",
      "obj  0.01755760014705525\n",
      "obj  0.0175525215349202\n",
      "obj  0.017528570051749293\n",
      "obj  0.01751454966092808\n",
      "obj  0.01750432155904327\n",
      "obj  0.017502006766887967\n",
      "obj  0.017501543397322492\n",
      "obj  0.017501441873357077\n",
      "obj  0.0175014139874096\n",
      "obj  0.0175014114571505\n",
      "obj  0.01750141078797053\n",
      "v20 d3 f1 t1: original ll 0.0150 auc 0.9574, ensemble ll 0.0153 auc 0.9574\n",
      "running time 3.59098482131958\n",
      "starting model 3 fold 1 target 2\n",
      "obj  0.042042852606458105\n",
      "obj  0.04203494482156812\n",
      "obj  0.04204538976392484\n",
      "obj  0.04204798680588175\n",
      "obj  0.042019989361874656\n",
      "obj  0.04200079182193048\n",
      "obj  0.04200315928166611\n",
      "obj  0.04200199147140919\n",
      "obj  0.04199671524242598\n",
      "obj  0.0419864575206972\n",
      "obj  0.04198267760530347\n",
      "obj  0.04198217164151893\n",
      "obj  0.04198212131636525\n",
      "obj  0.041982111193232655\n",
      "obj  0.04198211115701704\n",
      "obj  0.04198210766448521\n",
      "obj  0.04198210766443244\n",
      "obj  0.041982107416872354\n",
      "v20 d3 f1 t2: original ll 0.0423 auc 0.9918, ensemble ll 0.0423 auc 0.9918\n",
      "running time 3.732356548309326\n",
      "starting model 3 fold 1 target 3\n",
      "obj  0.02638691725568865\n",
      "obj  0.026386943527463014\n",
      "obj  0.026414567634959595\n",
      "obj  0.026324809520046358\n",
      "obj  0.026396104938380852\n",
      "obj  0.026368183493943598\n",
      "obj  0.026373192630171575\n",
      "obj  0.02637024127752132\n",
      "obj  0.0263406361170196\n",
      "obj  0.02629161632451778\n",
      "obj  0.026288516262745497\n",
      "obj  0.026280765260256852\n",
      "obj  0.026279483250366786\n",
      "obj  0.02627901418129613\n",
      "obj  0.026278899721337904\n",
      "obj  0.02627883760185079\n",
      "obj  0.026278836611483836\n",
      "obj  0.02627883387923233\n",
      "v20 d3 f1 t3: original ll 0.0247 auc 0.9964, ensemble ll 0.0245 auc 0.9964\n",
      "running time 3.724196195602417\n",
      "starting model 3 fold 1 target 4\n",
      "obj  0.06608836158647824\n",
      "obj  0.06609344931740736\n",
      "obj  0.06604569496022375\n",
      "obj  0.0661680934565071\n",
      "obj  0.06602101661323515\n",
      "obj  0.06601588149688958\n",
      "obj  0.06601649319923003\n",
      "obj  0.06601790357241293\n",
      "obj  0.06601449673470096\n",
      "obj  0.0660040198944962\n",
      "obj  0.06599665576425685\n",
      "obj  0.06599160998605542\n",
      "obj  0.06599009433772669\n",
      "obj  0.06599008533475727\n",
      "obj  0.06599005172472726\n",
      "obj  0.0659900411046702\n",
      "obj  0.06599004018176714\n",
      "v20 d3 f1 t4: original ll 0.0650 auc 0.9796, ensemble ll 0.0649 auc 0.9796\n",
      "running time 3.599489688873291\n",
      "starting model 3 fold 1 target 5\n",
      "obj  0.08111474780681921\n",
      "obj  0.08100138969398593\n",
      "obj  0.08090161660701488\n",
      "obj  0.08104549965533689\n",
      "obj  0.08081957519098835\n",
      "obj  0.0808165480413344\n",
      "obj  0.08081717177528705\n",
      "obj  0.08081715031093249\n",
      "obj  0.08072729727540653\n",
      "obj  0.08066254177685257\n",
      "obj  0.08064888205589113\n",
      "obj  0.08064531976668562\n",
      "obj  0.08064463539037704\n",
      "obj  0.08064449331813726\n",
      "obj  0.08064448268280691\n",
      "v20 d3 f1 t5: original ll 0.0814 auc 0.9780, ensemble ll 0.0811 auc 0.9780\n",
      "running time 3.3625919818878174\n",
      "starting model 4 fold 1 target 0\n",
      "obj  0.0984012642752763\n",
      "obj  0.09832294185928504\n",
      "obj  0.09828767044597192\n",
      "obj  0.09835636398880898\n",
      "obj  0.09827211757640905\n",
      "obj  0.09827049340246038\n",
      "obj  0.09826597129431662\n",
      "obj  0.09826770090123885\n",
      "obj  0.09824586698265245\n",
      "obj  0.09824478337708463\n",
      "obj  0.09824384631134403\n",
      "obj  0.09823925013849663\n",
      "obj  0.0982392480421554\n",
      "obj  0.09823821634858092\n",
      "obj  0.09823818623873677\n",
      "obj  0.09823813235687695\n",
      "obj  0.0982381323554732\n",
      "obj  0.09823813214060167\n",
      "obj  0.09823812855693918\n",
      "v20 d4 f1 t0: original ll 0.1015 auc 0.9855, ensemble ll 0.1014 auc 0.9855\n",
      "running time 3.9503726959228516\n",
      "starting model 4 fold 1 target 1\n",
      "obj  0.017959386935231816\n",
      "obj  0.017927699939737404\n",
      "obj  0.017814029627461526\n",
      "obj  0.017733102042870607\n",
      "obj  0.017545831476605142\n",
      "obj  0.01739733153282362\n",
      "obj  0.017365539542294698\n",
      "obj  0.017293452837103703\n",
      "obj  0.01700702479461005\n",
      "obj  0.016829522135407584\n",
      "obj  0.016720857792849063\n",
      "obj  0.016684167920649234\n",
      "obj  0.016672524400620888\n",
      "obj  0.016671301365466754\n",
      "obj  0.016670994951596296\n",
      "obj  0.01667088559525876\n",
      "v20 d4 f1 t1: original ll 0.0150 auc 0.9503, ensemble ll 0.0136 auc 0.9503\n",
      "running time 3.4669883251190186\n",
      "starting model 4 fold 1 target 2\n",
      "obj  0.041868529578409794\n",
      "obj  0.0418540706714604\n",
      "obj  0.04187338718221579\n",
      "obj  0.04181743064251463\n",
      "obj  0.041868851169065115\n",
      "obj  0.04184323620527674\n",
      "obj  0.04184582235602787\n",
      "obj  0.041842550336700014\n",
      "obj  0.04182251850969239\n",
      "obj  0.04180408882141451\n",
      "obj  0.04180269344491976\n",
      "obj  0.041800466520118554\n",
      "obj  0.04180026326610835\n",
      "obj  0.04179991512439107\n",
      "obj  0.0417999147564811\n",
      "obj  0.04179991446986975\n",
      "obj  0.04179990883343121\n",
      "obj  0.04179990883307978\n",
      "obj  0.041799907700898066\n",
      "v20 d4 f1 t2: original ll 0.0423 auc 0.9920, ensemble ll 0.0423 auc 0.9920\n",
      "running time 3.8720195293426514\n",
      "starting model 4 fold 1 target 3\n",
      "obj  0.025926069521174214\n",
      "obj  0.025907499202052434\n",
      "obj  0.02589782249012083\n",
      "obj  0.02591794554017086\n",
      "obj  0.025899820243346576\n",
      "obj  0.025905746358764824\n",
      "obj  0.025904403081099498\n",
      "obj  0.025905258457351282\n",
      "obj  0.025877754236985104\n",
      "obj  0.025874653452840596\n",
      "obj  0.025864901673843862\n",
      "obj  0.025863654304368097\n",
      "obj  0.025862011174573273\n",
      "obj  0.02586148420674543\n",
      "obj  0.025861398820237424\n",
      "obj  0.025861398758976136\n",
      "obj  0.025861394043418032\n",
      "obj  0.02586139329369403\n",
      "v20 d4 f1 t3: original ll 0.0245 auc 0.9968, ensemble ll 0.0243 auc 0.9968\n",
      "running time 3.7549362182617188\n",
      "starting model 4 fold 1 target 4\n",
      "obj  0.06605835256735594\n",
      "obj  0.06603444183485449\n",
      "obj  0.06606747527784919\n",
      "obj  0.06600829154085705\n",
      "obj  0.0660941416004083\n",
      "obj  0.0660413619864623\n",
      "obj  0.06604898864646412\n",
      "obj  0.06597324759712819\n",
      "obj  0.06586045747776803\n",
      "obj  0.06585924559183716\n",
      "obj  0.06581897421015269\n",
      "obj  0.0658157310940607\n",
      "obj  0.06581444201290075\n",
      "obj  0.06581428679924944\n",
      "obj  0.06581410990578544\n",
      "obj  0.06581395584512957\n",
      "obj  0.06581395433086366\n",
      "obj  0.06581395305448383\n",
      "obj  0.06581394304621355\n",
      "obj  0.06581394149144525\n",
      "obj  0.06581394147809937\n",
      "obj  0.0658139411692253\n",
      "v20 d4 f1 t4: original ll 0.0652 auc 0.9797, ensemble ll 0.0655 auc 0.9797\n",
      "running time 4.262474060058594\n",
      "starting model 4 fold 1 target 5\n",
      "obj  0.08031621785624986\n",
      "obj  0.08026803998324133\n",
      "obj  0.08019466537515958\n",
      "obj  0.08032977819185977\n",
      "obj  0.08013638830167637\n",
      "obj  0.08014057154812514\n",
      "obj  0.08013466447737948\n",
      "obj  0.08014310427084237\n",
      "obj  0.08007733191990127\n",
      "obj  0.08001747254275966\n",
      "obj  0.0799980394287225\n",
      "obj  0.07999003670929364\n",
      "obj  0.07998714264151943\n",
      "obj  0.07998673586264946\n",
      "obj  0.07998662673506736\n",
      "obj  0.07998660194026921\n",
      "obj  0.0799866018534186\n",
      "obj  0.07998659641694399\n",
      "v20 d4 f1 t5: original ll 0.0831 auc 0.9771, ensemble ll 0.0836 auc 0.9771\n",
      "running time 3.6671013832092285\n",
      "starting model 5 fold 1 target 0\n",
      "obj  0.0989213146088256\n",
      "obj  0.09876670538401529\n",
      "obj  0.09860884479009581\n",
      "obj  0.09877768458926507\n",
      "obj  0.09853128046447751\n",
      "obj  0.09858363050136422\n",
      "obj  0.09853962246204842\n",
      "obj  0.09854855558144061\n",
      "obj  0.09840535577321395\n",
      "obj  0.09840529225646275\n",
      "obj  0.0983834205513408\n",
      "obj  0.09837910594539039\n",
      "obj  0.0983731400842842\n",
      "obj  0.0983719373765393\n",
      "obj  0.09837156483581926\n",
      "obj  0.09837155059133702\n",
      "obj  0.09837149062942649\n",
      "obj  0.0983714400598728\n",
      "obj  0.09837143970384486\n",
      "obj  0.09837143725434269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.09837143716492458\n",
      "obj  0.09837143675179588\n",
      "v20 d5 f1 t0: original ll 0.1016 auc 0.9858, ensemble ll 0.1010 auc 0.9858\n",
      "running time 4.261920213699341\n",
      "starting model 5 fold 1 target 1\n",
      "obj  0.017565871871619426\n",
      "obj  0.017514261709415117\n",
      "obj  0.017381206240682498\n",
      "obj  0.017215689248779937\n",
      "obj  0.01689263242079055\n",
      "obj  0.01695472156120683\n",
      "obj  0.01694035599809017\n",
      "obj  0.016867402997298882\n",
      "obj  0.016588692783052215\n",
      "obj  0.016426051968923536\n",
      "obj  0.01636034412907371\n",
      "obj  0.016330689512117958\n",
      "obj  0.016323700702491242\n",
      "obj  0.01632353331976163\n",
      "obj  0.016321527712493882\n",
      "obj  0.016321223559645527\n",
      "obj  0.016321124719839722\n",
      "obj  0.016321112166272567\n",
      "obj  0.016321108145479882\n",
      "obj  0.016321106898976246\n",
      "v20 d5 f1 t1: original ll 0.0162 auc 0.9577, ensemble ll 0.0142 auc 0.9578\n",
      "running time 4.0439207553863525\n",
      "starting model 5 fold 1 target 2\n",
      "obj  0.04144816078882437\n",
      "obj  0.041419567777959694\n",
      "obj  0.041409174334171996\n",
      "obj  0.04141522275942621\n",
      "obj  0.0413959987904991\n",
      "obj  0.04139033431895925\n",
      "obj  0.04139024757649323\n",
      "obj  0.04139060235871241\n",
      "obj  0.04138791809486196\n",
      "obj  0.04138537448058848\n",
      "obj  0.04138292929806364\n",
      "obj  0.04138231230747279\n",
      "obj  0.041381328674892234\n",
      "obj  0.0413813247380435\n",
      "obj  0.04138129545817396\n",
      "obj  0.04138128512022389\n",
      "obj  0.041381285098253805\n",
      "obj  0.04138128322880608\n",
      "obj  0.04138128286298314\n",
      "v20 d5 f1 t2: original ll 0.0425 auc 0.9919, ensemble ll 0.0424 auc 0.9919\n",
      "running time 3.8968703746795654\n",
      "starting model 5 fold 1 target 3\n",
      "obj  0.025743144795771666\n",
      "obj  0.025705381728034712\n",
      "obj  0.025680766982208836\n",
      "obj  0.02565641341451618\n",
      "obj  0.025671475184184236\n",
      "obj  0.02567065903983369\n",
      "obj  0.025669979671625622\n",
      "obj  0.025668913024430286\n",
      "obj  0.025663576202374867\n",
      "obj  0.025645529262196515\n",
      "obj  0.025644520852918247\n",
      "obj  0.02564233576735038\n",
      "obj  0.02564230687231494\n",
      "obj  0.02564226903713369\n",
      "obj  0.025642233379991088\n",
      "obj  0.025642229030814628\n",
      "obj  0.025642229030797683\n",
      "v20 d5 f1 t3: original ll 0.0241 auc 0.9968, ensemble ll 0.0240 auc 0.9968\n",
      "running time 3.679616928100586\n",
      "starting model 5 fold 1 target 4\n",
      "obj  0.0658701772252988\n",
      "obj  0.06590387006514185\n",
      "obj  0.06579533773798295\n",
      "obj  0.06599857990947389\n",
      "obj  0.06579253912391056\n",
      "obj  0.06580959631984344\n",
      "obj  0.06580976711456382\n",
      "obj  0.06581335478001876\n",
      "obj  0.06579076803954485\n",
      "obj  0.06576660540774186\n",
      "obj  0.06576505158656298\n",
      "obj  0.06576420913183785\n",
      "obj  0.06576380347401363\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380489819499\n",
      "obj  0.06576380418328717\n",
      "obj  0.06576380418328717\n",
      "obj  0.06576380365708052\n",
      "obj  0.06576380365708052\n",
      "obj  0.0657638035397879\n",
      "obj  0.0657638035397879\n",
      "obj  0.06576380349950353\n",
      "obj  0.06576380349950353\n",
      "obj  0.06576380348415849\n",
      "obj  0.06576380348415849\n",
      "obj  0.06576380347809506\n",
      "obj  0.06576380347809506\n",
      "obj  0.06576380347566518\n",
      "obj  0.06576380347468602\n",
      "obj  0.06576380347468602\n",
      "obj  0.06576380347429038\n",
      "obj  0.06576380347429038\n",
      "obj  0.06576380347401363\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380489624149\n",
      "obj  0.06576380370315159\n",
      "obj  0.06576380370315159\n",
      "obj  0.06576380355386377\n",
      "obj  0.06576380355386377\n",
      "obj  0.06576380350464156\n",
      "obj  0.06576380350464155\n",
      "obj  0.06576380348614827\n",
      "obj  0.06576380348614827\n",
      "obj  0.06576380347888308\n",
      "obj  0.06576380347888308\n",
      "obj  0.06576380347598004\n",
      "obj  0.06576380347598004\n",
      "obj  0.06576380347481223\n",
      "obj  0.06576380347481223\n",
      "obj  0.06576380347434109\n",
      "obj  0.06576380347434109\n",
      "obj  0.06576380347415085\n",
      "obj  0.06576380347415085\n",
      "v20 d5 f1 t4: original ll 0.0651 auc 0.9802, ensemble ll 0.0649 auc 0.9802\n",
      "running time 4.111293792724609\n",
      "starting model 5 fold 1 target 5\n",
      "obj  0.0804587217107382\n",
      "obj  0.08034480933177823\n",
      "obj  0.08029504307155343\n",
      "obj  0.0802617907500562\n",
      "obj  0.08022458527750455\n",
      "obj  0.08017106216246636\n",
      "obj  0.0801771818504987\n",
      "obj  0.08016144084996572\n",
      "obj  0.08013308970630133\n",
      "obj  0.08009603114841782\n",
      "obj  0.08008585225421892\n",
      "obj  0.08008432547325606\n",
      "obj  0.0800840889552148\n",
      "obj  0.08008408889271358\n",
      "obj  0.08008405109989508\n",
      "obj  0.08008405108240024\n",
      "v20 d5 f1 t5: original ll 0.0826 auc 0.9779, ensemble ll 0.0822 auc 0.9779\n",
      "running time 3.5030860900878906\n",
      "starting model 6 fold 1 target 0\n",
      "obj  0.09940070159408375\n",
      "obj  0.09940361127431643\n",
      "obj  0.09944289075382277\n",
      "obj  0.0995105555066326\n",
      "obj  0.09949677409230585\n",
      "obj  0.09947693620035539\n",
      "obj  0.09946153516043768\n",
      "obj  0.09946424831281939\n",
      "obj  0.0991126539528328\n",
      "obj  0.09911217149985374\n",
      "obj  0.09907404368027585\n",
      "obj  0.09907402903942938\n",
      "obj  0.09905186192305843\n",
      "obj  0.09904123369941839\n",
      "obj  0.09904041027963016\n",
      "obj  0.09903829391678846\n",
      "obj  0.09903826829935636\n",
      "obj  0.09903818540657183\n",
      "obj  0.0990381713545395\n",
      "obj  0.09903817135453706\n",
      "obj  0.09903816644323885\n",
      "obj  0.0990381664432388\n",
      "obj  0.09903816586009062\n",
      "v20 d6 f1 t0: original ll 0.1021 auc 0.9853, ensemble ll 0.1020 auc 0.9853\n",
      "running time 4.411185264587402\n",
      "starting model 6 fold 1 target 1\n",
      "obj  0.018168050704862108\n",
      "obj  0.018095728235114704\n",
      "obj  0.017713230895630688\n",
      "obj  0.017543248045181724\n",
      "obj  0.017512143249566795\n",
      "obj  0.017599115304183857\n",
      "obj  0.017508733593907536\n",
      "obj  0.017523568181754164\n",
      "obj  0.017153061247796614\n",
      "obj  0.01692649630408863\n",
      "obj  0.016832407208402424\n",
      "obj  0.016809901002775532\n",
      "obj  0.016807843441112094\n",
      "obj  0.016807152670926962\n",
      "obj  0.01680697606926275\n",
      "obj  0.016806946410903956\n",
      "obj  0.01680693457071704\n",
      "obj  0.016806932925324976\n",
      "obj  0.01680693231306751\n",
      "v20 d6 f1 t1: original ll 0.0147 auc 0.9632, ensemble ll 0.0138 auc 0.9632\n",
      "running time 3.8880367279052734\n",
      "starting model 6 fold 1 target 2\n",
      "obj  0.04256353845157735\n",
      "obj  0.04256485449068357\n",
      "obj  0.042647844602948404\n",
      "obj  0.042491406507452804\n",
      "obj  0.04270257727965038\n",
      "obj  0.04265745307204149\n",
      "obj  0.042664027262867464\n",
      "obj  0.04265292018064723\n",
      "obj  0.04247675138391556\n",
      "obj  0.04233025930214229\n",
      "obj  0.04230867531766731\n",
      "obj  0.042305436882948265\n",
      "obj  0.04230480664429213\n",
      "obj  0.04230456166237395\n",
      "obj  0.042304541462052266\n",
      "v20 d6 f1 t2: original ll 0.0441 auc 0.9913, ensemble ll 0.0440 auc 0.9913\n",
      "running time 3.406113624572754\n",
      "starting model 6 fold 1 target 3\n",
      "obj  0.02667390388612237\n",
      "obj  0.026652010533931916\n",
      "obj  0.026638032599752268\n",
      "obj  0.02678754918649728\n",
      "obj  0.026672247028766305\n",
      "obj  0.026695833863554085\n",
      "obj  0.026694180188241757\n",
      "obj  0.026697016839940607\n",
      "obj  0.026454239300679656\n",
      "obj  0.026336464415804423\n",
      "obj  0.02633631619882823\n",
      "obj  0.026296589576079724\n",
      "obj  0.026279208649274115\n",
      "obj  0.0262670335267498\n",
      "obj  0.026263331485167532\n",
      "obj  0.026262637489490166\n",
      "obj  0.026262565483514636\n",
      "obj  0.026262326866915875\n",
      "obj  0.026262304291761233\n",
      "obj  0.026262298808279228\n",
      "obj  0.02626229780341765\n",
      "obj  0.026262297802351255\n",
      "obj  0.026262297701626757\n",
      "v20 d6 f1 t3: original ll 0.0255 auc 0.9967, ensemble ll 0.0251 auc 0.9967\n",
      "running time 4.407552003860474\n",
      "starting model 6 fold 1 target 4\n",
      "obj  0.06636406778049643\n",
      "obj  0.06639753441809662\n",
      "obj  0.06641334646897817\n",
      "obj  0.06649391117286298\n",
      "obj  0.06640418838202466\n",
      "obj  0.0663956150154515\n",
      "obj  0.06639686182254788\n",
      "obj  0.06639654175863692\n",
      "obj  0.06639601024582467\n",
      "obj  0.06639585953174555\n",
      "obj  0.06639575636672142\n",
      "obj  0.06639569370590899\n",
      "obj  0.06639566630551168\n",
      "obj  0.06639567019324502\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575868624598\n",
      "obj  0.06639575868624596\n",
      "obj  0.06639575868624598\n",
      "obj  0.06639575868624596\n",
      "obj  0.06639575868624598\n",
      "obj  0.06639575868624596\n",
      "obj  0.06639575868624598\n",
      "obj  0.06639575868624596\n",
      "obj  0.06639575868624598\n",
      "obj  0.06639575868624596\n",
      "obj  0.06639575868624598\n",
      "obj  0.06639575868624596\n",
      "obj  0.06639575256285381\n",
      "obj  0.06639575256285381\n",
      "obj  0.06639572490110938\n",
      "obj  0.06639572490110938\n",
      "obj  0.06639571288642535\n",
      "obj  0.0663957073166244\n",
      "obj  0.0663957073166244\n",
      "obj  0.06639570465305014\n",
      "obj  0.06639570465305014\n",
      "obj  0.06639570334897897\n",
      "obj  0.06639570334897897\n",
      "obj  0.06639570270389501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.06639570270389501\n",
      "obj  0.0663957023830938\n",
      "obj  0.0663957023830938\n",
      "obj  0.0663957022231287\n",
      "obj  0.0663957022231287\n",
      "obj  0.0663957021432551\n",
      "obj  0.0663957021432551\n",
      "obj  0.06639570210334553\n",
      "obj  0.06639570210334553\n",
      "obj  0.06639570208339758\n",
      "obj  0.06639570208339758\n",
      "obj  0.0663957020734253\n",
      "obj  0.0663957020734253\n",
      "obj  0.0663957020684396\n",
      "obj  0.0663957020684396\n",
      "obj  0.06639570206594683\n",
      "obj  0.06639570206594683\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575856033994\n",
      "obj  0.06639575856033994\n",
      "obj  0.06639575856033994\n",
      "obj  0.06639575856033994\n",
      "obj  0.06639575856033994\n",
      "obj  0.06639575856033994\n",
      "obj  0.06639575830813879\n",
      "obj  0.06639575830813879\n",
      "obj  0.06639572728605128\n",
      "obj  0.06639572728605128\n",
      "obj  0.06639571396501708\n",
      "obj  0.06639571396501708\n",
      "obj  0.06639570782459919\n",
      "obj  0.06639570782459919\n",
      "obj  0.06639570489973337\n",
      "obj  0.06639570489973337\n",
      "obj  0.0663957034704865\n",
      "obj  0.0663957034704865\n",
      "obj  0.06639570276418924\n",
      "obj  0.06639570276418924\n",
      "obj  0.06639570241312591\n",
      "obj  0.06639570241312591\n",
      "obj  0.06639570223811599\n",
      "obj  0.06639570223811599\n",
      "obj  0.06639570215074153\n",
      "obj  0.06639570215074153\n",
      "obj  0.06639570210708697\n",
      "obj  0.06639570210708697\n",
      "obj  0.06639570208526784\n",
      "obj  0.06639570208526784\n",
      "obj  0.06639570207436031\n",
      "obj  0.06639570207436031\n",
      "obj  0.06639570206890703\n",
      "obj  0.06639570206890703\n",
      "obj  0.06639570206618053\n",
      "obj  0.06639570206618053\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575853706406\n",
      "obj  0.06639575853706406\n",
      "obj  0.06639575853706406\n",
      "obj  0.06639575853706406\n",
      "obj  0.06639575853706406\n",
      "obj  0.06639575853706406\n",
      "obj  0.06639575825214954\n",
      "obj  0.06639575825214954\n",
      "obj  0.06639572726232452\n",
      "obj  0.06639572726232452\n",
      "obj  0.06639571395415561\n",
      "obj  0.06639571395415561\n",
      "obj  0.06639570781944336\n",
      "obj  0.06639570781944336\n",
      "obj  0.06639570489721977\n",
      "obj  0.06639570489721977\n",
      "obj  0.06639570346924586\n",
      "obj  0.06639570346924586\n",
      "obj  0.06639570276357297\n",
      "obj  0.06639570276357297\n",
      "obj  0.06639570241281875\n",
      "obj  0.06639570241281875\n",
      "obj  0.06639570223796268\n",
      "obj  0.06639570223796268\n",
      "obj  0.06639570215066498\n",
      "obj  0.06639570215066498\n",
      "obj  0.06639570210704869\n",
      "obj  0.06639570210704869\n",
      "obj  0.06639570208524867\n",
      "obj  0.06639570208524867\n",
      "obj  0.0663957020743507\n",
      "obj  0.06639570207435071\n",
      "obj  0.06639570206890229\n",
      "obj  0.06639570206890229\n",
      "obj  0.06639570206617815\n",
      "obj  0.06639570206617813\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575853248512\n",
      "obj  0.06639575853248512\n",
      "obj  0.06639575853248512\n",
      "obj  0.06639575853248512\n",
      "obj  0.06639575853248512\n",
      "obj  0.06639575853248512\n",
      "obj  0.06639575824118417\n",
      "obj  0.06639575824118417\n",
      "obj  0.06639572725767517\n",
      "obj  0.06639572725767517\n",
      "obj  0.0663957139520266\n",
      "obj  0.0663957139520266\n",
      "obj  0.06639570781843251\n",
      "obj  0.06639570781843251\n",
      "obj  0.0663957048967269\n",
      "obj  0.0663957048967269\n",
      "obj  0.06639570346900259\n",
      "obj  0.06639570346900257\n",
      "obj  0.06639570276345214\n",
      "obj  0.06639570276345214\n",
      "obj  0.06639570241275854\n",
      "obj  0.06639570241275854\n",
      "obj  0.06639570223793262\n",
      "obj  0.06639570223793262\n",
      "obj  0.06639570215064997\n",
      "obj  0.06639570215064997\n",
      "obj  0.06639570210704117\n",
      "obj  0.06639570210704117\n",
      "obj  0.06639570208524495\n",
      "obj  0.06639570208524495\n",
      "obj  0.06639570207434888\n",
      "obj  0.06639570207434888\n",
      "obj  0.06639570206890133\n",
      "obj  0.06639570206890133\n",
      "obj  0.06639570206617769\n",
      "obj  0.06639570206617769\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575853157238\n",
      "obj  0.06639575853157238\n",
      "obj  0.06639575853157238\n",
      "obj  0.06639575853157238\n",
      "obj  0.06639575853157238\n",
      "obj  0.06639575853157238\n",
      "obj  0.0663957582390004\n",
      "obj  0.0663957582390004\n",
      "obj  0.06639572725674915\n",
      "obj  0.06639572725674915\n",
      "obj  0.06639571395160251\n",
      "obj  0.06639571395160251\n",
      "obj  0.06639570781823112\n",
      "obj  0.06639570781823112\n",
      "obj  0.06639570489662874\n",
      "obj  0.06639570489662874\n",
      "obj  0.06639570346895413\n",
      "obj  0.06639570346895413\n",
      "obj  0.06639570276342803\n",
      "obj  0.06639570276342803\n",
      "obj  0.06639570241274656\n",
      "obj  0.06639570241274656\n",
      "obj  0.06639570223792662\n",
      "obj  0.06639570223792662\n",
      "obj  0.06639570215064694\n",
      "obj  0.06639570215064694\n",
      "obj  0.06639570210703967\n",
      "obj  0.06639570210703967\n",
      "obj  0.06639570208524417\n",
      "obj  0.06639570208524417\n",
      "obj  0.06639570207434849\n",
      "obj  0.0663957020743485\n",
      "obj  0.06639570206890114\n",
      "obj  0.06639570206890114\n",
      "obj  0.06639570206617758\n",
      "obj  0.06639570206617758\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575853138996\n",
      "obj  0.06639575853138995\n",
      "obj  0.06639575853138996\n",
      "obj  0.06639575853138995\n",
      "obj  0.06639575853138996\n",
      "obj  0.06639575853138995\n",
      "obj  0.06639575823856403\n",
      "obj  0.06639572725656412\n",
      "obj  0.06639572725656412\n",
      "obj  0.06639571395151778\n",
      "obj  0.06639571395151778\n",
      "obj  0.06639570781819089\n",
      "obj  0.06639570781819089\n",
      "obj  0.06639570489660912\n",
      "obj  0.06639570489660912\n",
      "obj  0.06639570346894447\n",
      "obj  0.06639570276342324\n",
      "obj  0.06639570276342324\n",
      "obj  0.06639570241274413\n",
      "obj  0.06639570241274413\n",
      "obj  0.06639570223792542\n",
      "obj  0.06639570223792542\n",
      "obj  0.06639570215064632\n",
      "obj  0.06639570210703936\n",
      "obj  0.06639570210703936\n",
      "obj  0.06639570208524405\n",
      "obj  0.06639570208524405\n",
      "obj  0.0663957020743484\n",
      "obj  0.06639570207434842\n",
      "obj  0.06639570206890112\n",
      "obj  0.06639570206617759\n",
      "obj  0.06639570206617759\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575853135349\n",
      "obj  0.06639575823847678\n",
      "obj  0.06639575823847678\n",
      "obj  0.0663957272565271\n",
      "obj  0.0663957272565271\n",
      "obj  0.06639571395150083\n",
      "obj  0.06639571395150083\n",
      "obj  0.06639570781818285\n",
      "obj  0.06639570781818285\n",
      "obj  0.0663957048966052\n",
      "obj  0.0663957048966052\n",
      "obj  0.0663957034689425\n",
      "obj  0.0663957034689425\n",
      "obj  0.06639570276342227\n",
      "obj  0.06639570276342227\n",
      "obj  0.06639570241274365\n",
      "obj  0.06639570241274365\n",
      "obj  0.06639570223792521\n",
      "obj  0.06639570215064622\n",
      "obj  0.06639570210703931\n",
      "obj  0.06639570210703931\n",
      "obj  0.06639570208524401\n",
      "obj  0.06639570207434842\n",
      "obj  0.06639570207434842\n",
      "obj  0.06639570206890111\n",
      "obj  0.0663957020689011\n",
      "obj  0.06639570206617756\n",
      "obj  0.06639570206617756\n",
      "obj  0.06639570206345415\n",
      "obj  0.0663957585313462\n",
      "obj  0.06639575823845932\n",
      "obj  0.06639575823845932\n",
      "obj  0.0663957272565197\n",
      "obj  0.06639571395149742\n",
      "obj  0.06639571395149742\n",
      "obj  0.06639570781818126\n",
      "obj  0.06639570489660439\n",
      "obj  0.06639570489660439\n",
      "obj  0.06639570346894211\n",
      "obj  0.06639570346894211\n",
      "obj  0.06639570276342209\n",
      "obj  0.06639570241274356\n",
      "obj  0.06639570241274356\n",
      "obj  0.06639570223792517\n",
      "obj  0.06639570223792517\n",
      "obj  0.06639570215064622\n",
      "obj  0.06639570215064622\n",
      "obj  0.06639570210703932\n",
      "obj  0.06639570210703932\n",
      "obj  0.06639570208524401\n",
      "obj  0.06639570208524401\n",
      "obj  0.06639570207434838\n",
      "obj  0.06639570207434838\n",
      "obj  0.06639570206890111\n",
      "obj  0.06639570206890111\n",
      "obj  0.06639570206617755\n",
      "obj  0.06639570206617756\n",
      "obj  0.06639570206345415\n",
      "obj  0.06639575853134475\n",
      "obj  0.06639575853134475\n",
      "obj  0.06639575853134475\n",
      "obj  0.06639575853134475\n",
      "obj  0.06639575853134475\n",
      "obj  0.06639575853134475\n",
      "obj  0.06639575823845581\n",
      "obj  0.06639575823845581\n",
      "obj  0.0663957272565182\n",
      "obj  0.0663957272565182\n",
      "obj  0.06639571395149678\n",
      "obj  0.06639571395149678\n",
      "obj  0.06639570781818092\n",
      "obj  0.06639570781818092\n",
      "obj  0.06639570489660424\n",
      "obj  0.06639570489660424\n",
      "obj  0.06639570346894205\n",
      "obj  0.06639570346894205\n",
      "obj  0.06639570276342205\n",
      "obj  0.06639570276342205\n",
      "obj  0.06639570241274355\n",
      "obj  0.06639570241274355\n",
      "obj  0.06639570223792512\n",
      "obj  0.06639570223792512\n",
      "obj  0.0663957021506462\n",
      "obj  0.06639570215064622\n",
      "obj  0.06639570210703932\n",
      "obj  0.06639570210703932\n",
      "obj  0.06639570208524401\n",
      "obj  0.06639570207434839\n",
      "obj  0.06639570207434839\n",
      "obj  0.06639570206890111\n",
      "obj  0.06639570206890111\n",
      "obj  0.06639570206617755\n",
      "obj  0.06639570206617755\n",
      "v20 d6 f1 t4: original ll 0.0660 auc 0.9790, ensemble ll 0.0666 auc 0.9790\n",
      "running time 8.083453178405762\n",
      "starting model 6 fold 1 target 5\n",
      "obj  0.08103206223541555\n",
      "obj  0.08103679041935107\n",
      "obj  0.08111109757229441\n",
      "obj  0.08095380851122988\n",
      "obj  0.08107031085632983\n",
      "obj  0.08100088514924578\n",
      "obj  0.08101390711803014\n",
      "obj  0.08100736626787904\n",
      "obj  0.08090097993345347\n",
      "obj  0.08087263457812406\n",
      "obj  0.08087261774204182\n",
      "obj  0.08087112976908366\n",
      "obj  0.08086927033628093\n",
      "obj  0.08086927029094068\n",
      "obj  0.08086913275828785\n",
      "obj  0.08086911140097706\n",
      "obj  0.08086910861605989\n",
      "obj  0.08086910860561239\n",
      "obj  0.08086910860512408\n",
      "obj  0.08086910814965566\n",
      "v20 d6 f1 t5: original ll 0.0825 auc 0.9776, ensemble ll 0.0824 auc 0.9776\n",
      "running time 4.074429750442505\n",
      "starting model 7 fold 1 target 0\n",
      "obj  0.09763784904661266\n",
      "obj  0.0975528630171346\n",
      "obj  0.09752189328169764\n",
      "obj  0.09754954787316937\n",
      "obj  0.09748046207924027\n",
      "obj  0.09746956209123839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.09744377001542702\n",
      "obj  0.0974452999601501\n",
      "obj  0.09736614469353091\n",
      "obj  0.09736609469661449\n",
      "obj  0.0973620826962016\n",
      "obj  0.0973583858615557\n",
      "obj  0.09735644469343434\n",
      "obj  0.09735555800066695\n",
      "obj  0.09735540061848123\n",
      "obj  0.09735532361552658\n",
      "obj  0.09735529309603705\n",
      "obj  0.09735529289136678\n",
      "obj  0.09735529016901553\n",
      "v20 d7 f1 t0: original ll 0.1005 auc 0.9862, ensemble ll 0.1003 auc 0.9862\n",
      "running time 4.055017471313477\n",
      "starting model 7 fold 1 target 1\n",
      "obj  0.015398836020553398\n",
      "obj  0.015376888335462366\n",
      "obj  0.01530190530542656\n",
      "obj  0.015203714217047538\n",
      "obj  0.01521127753605891\n",
      "obj  0.015210111287625732\n",
      "obj  0.015211374526382868\n",
      "obj  0.015206090991442992\n",
      "obj  0.015178605092978385\n",
      "obj  0.015165833225969549\n",
      "obj  0.015145268291100715\n",
      "obj  0.015142539861170937\n",
      "obj  0.01514137879945772\n",
      "obj  0.015140976626221955\n",
      "obj  0.015140860633759703\n",
      "obj  0.01514082815854376\n",
      "obj  0.015140816038193419\n",
      "obj  0.015140816037451222\n",
      "obj  0.01514081367048154\n",
      "obj  0.015140813355956259\n",
      "v20 d7 f1 t1: original ll 0.0134 auc 0.9661, ensemble ll 0.0132 auc 0.9661\n",
      "running time 4.0978147983551025\n",
      "starting model 7 fold 1 target 2\n",
      "obj  0.04161552221805479\n",
      "obj  0.04159406670020284\n",
      "obj  0.04162279408549306\n",
      "obj  0.04155459147556317\n",
      "obj  0.04163002138079327\n",
      "obj  0.04160425012453911\n",
      "obj  0.041606825970192794\n",
      "obj  0.04160249073904553\n",
      "obj  0.0415658203915948\n",
      "obj  0.04153179320216894\n",
      "obj  0.04152413120267353\n",
      "obj  0.041522242051966106\n",
      "obj  0.041520118472590586\n",
      "obj  0.041520000471595354\n",
      "obj  0.04151966811717621\n",
      "obj  0.04151954066949805\n",
      "obj  0.041519506865799825\n",
      "obj  0.04151950034764326\n",
      "v20 d7 f1 t2: original ll 0.0421 auc 0.9919, ensemble ll 0.0422 auc 0.9919\n",
      "running time 3.835394859313965\n",
      "starting model 7 fold 1 target 3\n",
      "obj  0.026111739078748943\n",
      "obj  0.026104551849333003\n",
      "obj  0.026108897398527696\n",
      "obj  0.026095491861487147\n",
      "obj  0.02610511386795595\n",
      "obj  0.02609402402046642\n",
      "obj  0.02609520290176385\n",
      "obj  0.02609458483897044\n",
      "obj  0.02603597789636798\n",
      "obj  0.026027252688777803\n",
      "obj  0.026016487015152304\n",
      "obj  0.026013777608443246\n",
      "obj  0.026011317100258197\n",
      "obj  0.026011297840854018\n",
      "obj  0.026011116477379064\n",
      "obj  0.026011092840789368\n",
      "obj  0.02601108037137336\n",
      "obj  0.026011080334806713\n",
      "obj  0.026011077688559186\n",
      "obj  0.026011077314441595\n",
      "v20 d7 f1 t3: original ll 0.0244 auc 0.9965, ensemble ll 0.0243 auc 0.9965\n",
      "running time 4.054321765899658\n",
      "starting model 7 fold 1 target 4\n",
      "obj  0.06546992552696373\n",
      "obj  0.06547481540614779\n",
      "obj  0.06549904057805164\n",
      "obj  0.06533054889098654\n",
      "obj  0.06552001387370229\n",
      "obj  0.06548702304810972\n",
      "obj  0.06549845791616936\n",
      "obj  0.06541598113375591\n",
      "obj  0.06530241346334047\n",
      "obj  0.06530201354032611\n",
      "obj  0.06530175032943988\n",
      "obj  0.06530158159586033\n",
      "obj  0.0653014817305251\n",
      "obj  0.06530143474876685\n",
      "obj  0.06530143007409774\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145980096347\n",
      "obj  0.06530145870734902\n",
      "obj  0.06530145870734905\n",
      "obj  0.06530144062065267\n",
      "obj  0.06530144062065267\n",
      "obj  0.0653014343731624\n",
      "obj  0.0653014319759107\n",
      "obj  0.0653014319759107\n",
      "obj  0.0653014309625401\n",
      "obj  0.0653014309625401\n",
      "obj  0.0653014305026352\n",
      "obj  0.0653014305026352\n",
      "obj  0.06530143028443702\n",
      "obj  0.06530143028443702\n",
      "obj  0.06530143017828395\n",
      "obj  0.06530143017828396\n",
      "obj  0.06530143012594486\n",
      "obj  0.06530143012594486\n",
      "obj  0.06530143009995978\n",
      "obj  0.06530143009995978\n",
      "obj  0.06530143008701338\n",
      "obj  0.06530143008701338\n",
      "obj  0.06530143008055173\n",
      "obj  0.0653014300805517\n",
      "obj  0.06530143007732377\n",
      "obj  0.06530143007732377\n",
      "obj  0.06530143007571053\n",
      "obj  0.06530143007571053\n",
      "obj  0.06530143007490406\n",
      "obj  0.06530143007490406\n",
      "obj  0.06530143007409774\n",
      "obj  0.0653014596336973\n",
      "obj  0.0653014596336973\n",
      "obj  0.0653014596336973\n",
      "obj  0.0653014596336973\n",
      "obj  0.0653014596336973\n",
      "obj  0.0653014596336973\n",
      "obj  0.06530145846661435\n",
      "obj  0.06530145846661435\n",
      "obj  0.06530144051995239\n",
      "obj  0.06530144051995239\n",
      "obj  0.06530143432797932\n",
      "obj  0.06530143432797932\n",
      "obj  0.0653014319546444\n",
      "obj  0.0653014319546444\n",
      "obj  0.06530143095224256\n",
      "obj  0.06530143049757091\n",
      "obj  0.06530143049757094\n",
      "obj  0.06530143028192607\n",
      "obj  0.06530143028192606\n",
      "obj  0.06530143017703378\n",
      "obj  0.06530143017703378\n",
      "obj  0.06530143012532111\n",
      "obj  0.06530143012532111\n",
      "obj  0.06530143009964821\n",
      "obj  0.06530143009964821\n",
      "obj  0.0653014300868577\n",
      "obj  0.06530143008685768\n",
      "obj  0.06530143008047389\n",
      "obj  0.06530143008047389\n",
      "obj  0.06530143007728485\n",
      "obj  0.06530143007728485\n",
      "obj  0.06530143007569104\n",
      "obj  0.06530143007569104\n",
      "obj  0.06530143007489435\n",
      "obj  0.06530143007489435\n",
      "obj  0.06530143007409774\n",
      "obj  0.06530145960054176\n",
      "obj  0.06530145960054176\n",
      "obj  0.06530145960054176\n",
      "obj  0.06530145960054176\n",
      "obj  0.06530145960054176\n",
      "obj  0.06530145960054176\n",
      "obj  0.06530145841941828\n",
      "obj  0.06530145841941828\n",
      "obj  0.06530144050013456\n",
      "obj  0.06530144050013457\n",
      "obj  0.06530143431906353\n",
      "obj  0.06530143431906352\n",
      "obj  0.06530143195044118\n",
      "obj  0.06530143195044118\n",
      "obj  0.06530143095020544\n",
      "obj  0.06530143095020544\n",
      "obj  0.06530143049656859\n",
      "obj  0.06530143049656859\n",
      "obj  0.065301430281429\n",
      "obj  0.065301430281429\n",
      "obj  0.06530143017678623\n",
      "obj  0.06530143017678623\n",
      "obj  0.06530143012519758\n",
      "obj  0.06530143012519758\n",
      "obj  0.06530143009958654\n",
      "obj  0.06530143009958654\n",
      "obj  0.06530143008682686\n",
      "obj  0.06530143008682686\n",
      "obj  0.06530143008045847\n",
      "obj  0.06530143008045847\n",
      "obj  0.06530143007727716\n",
      "obj  0.06530143007727716\n",
      "obj  0.06530143007568721\n",
      "obj  0.06530143007568721\n",
      "obj  0.06530143007489242\n",
      "obj  0.0653014300748924\n",
      "obj  0.06530143007409774\n",
      "obj  0.06530145959392251\n",
      "obj  0.06530145959392251\n",
      "obj  0.06530145959392251\n",
      "obj  0.06530145959392251\n",
      "obj  0.06530145959392251\n",
      "obj  0.06530145959392251\n",
      "obj  0.06530145841001686\n",
      "obj  0.06530145841001686\n",
      "obj  0.06530144049618378\n",
      "obj  0.06530144049618378\n",
      "obj  0.06530143431728516\n",
      "obj  0.06530143431728516\n",
      "obj  0.06530143194960254\n",
      "obj  0.06530143194960254\n",
      "obj  0.06530143094979891\n",
      "obj  0.06530143094979891\n",
      "obj  0.06530143049636854\n",
      "obj  0.06530143049636852\n",
      "obj  0.06530143028132979\n",
      "obj  0.06530143028132979\n",
      "obj  0.06530143017673685\n",
      "obj  0.06530143017673685\n",
      "obj  0.06530143012517294\n",
      "obj  0.06530143012517294\n",
      "obj  0.06530143009957423\n",
      "obj  0.06530143009957423\n",
      "obj  0.0653014300868207\n",
      "obj  0.0653014300868207\n",
      "obj  0.06530143008045541\n",
      "obj  0.06530143008045541\n",
      "obj  0.06530143007727562\n",
      "obj  0.06530143007727562\n",
      "obj  0.06530143007568644\n",
      "obj  0.06530143007568644\n",
      "obj  0.06530143007489202\n",
      "obj  0.06530143007489202\n",
      "obj  0.06530143007409774\n",
      "obj  0.06530145959259914\n",
      "obj  0.06530145959259914\n",
      "obj  0.06530145959259914\n",
      "obj  0.06530145959259914\n",
      "obj  0.06530145959259914\n",
      "obj  0.06530145959259914\n",
      "obj  0.0653014584081381\n",
      "obj  0.0653014584081381\n",
      "obj  0.06530144049539416\n",
      "obj  0.06530144049539416\n",
      "obj  0.06530143431692965\n",
      "obj  0.06530143431692965\n",
      "obj  0.06530143194943488\n",
      "obj  0.06530143194943488\n",
      "obj  0.06530143094971766\n",
      "obj  0.06530143094971765\n",
      "obj  0.06530143049632856\n",
      "obj  0.06530143049632856\n",
      "obj  0.06530143028130994\n",
      "obj  0.06530143028130994\n",
      "obj  0.06530143017672699\n",
      "obj  0.06530143017672699\n",
      "obj  0.06530143012516801\n",
      "obj  0.06530143012516801\n",
      "obj  0.06530143009957178\n",
      "obj  0.06530143009957176\n",
      "obj  0.06530143008681948\n",
      "obj  0.06530143008681948\n",
      "obj  0.0653014300804548\n",
      "obj  0.0653014300804548\n",
      "obj  0.06530143007727532\n",
      "obj  0.06530143007727532\n",
      "obj  0.06530143007568628\n",
      "obj  0.06530143007568628\n",
      "obj  0.06530143007489193\n",
      "obj  0.06530143007489193\n",
      "obj  0.06530143007409774\n",
      "obj  0.06530145959233448\n",
      "obj  0.06530145959233448\n",
      "obj  0.06530145959233448\n",
      "obj  0.06530145959233448\n",
      "obj  0.06530145959233448\n",
      "obj  0.06530145959233448\n",
      "obj  0.0653014584077624\n",
      "obj  0.0653014584077624\n",
      "obj  0.06530144049523627\n",
      "obj  0.06530144049523624\n",
      "obj  0.06530143431685859\n",
      "obj  0.06530143431685857\n",
      "obj  0.06530143194940136\n",
      "obj  0.06530143194940136\n",
      "obj  0.0653014309497014\n",
      "obj  0.0653014309497014\n",
      "obj  0.06530143049632056\n",
      "obj  0.06530143049632056\n",
      "obj  0.06530143028130596\n",
      "obj  0.06530143028130596\n",
      "obj  0.06530143017672502\n",
      "obj  0.06530143017672502\n",
      "obj  0.06530143012516702\n",
      "obj  0.06530143012516702\n",
      "obj  0.06530143009957126\n",
      "obj  0.06530143009957126\n",
      "obj  0.06530143008681923\n",
      "obj  0.06530143008681923\n",
      "obj  0.06530143008045466\n",
      "obj  0.06530143007727525\n",
      "obj  0.06530143007727525\n",
      "obj  0.06530143007568626\n",
      "obj  0.06530143007568626\n",
      "obj  0.06530143007489192\n",
      "obj  0.06530143007489192\n",
      "obj  0.06530143007409774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.06530145959228155\n",
      "obj  0.06530145959228155\n",
      "obj  0.06530145959228155\n",
      "obj  0.06530145959228155\n",
      "obj  0.06530145959228155\n",
      "obj  0.06530145959228155\n",
      "obj  0.06530145840768724\n",
      "obj  0.06530145840768724\n",
      "obj  0.06530144049520469\n",
      "obj  0.06530144049520469\n",
      "obj  0.06530143431684438\n",
      "obj  0.06530143431684438\n",
      "obj  0.06530143194939464\n",
      "obj  0.06530143194939464\n",
      "obj  0.06530143094969813\n",
      "obj  0.06530143094969813\n",
      "obj  0.06530143049631898\n",
      "obj  0.06530143049631898\n",
      "obj  0.06530143028130518\n",
      "obj  0.06530143028130518\n",
      "obj  0.0653014301767246\n",
      "obj  0.0653014301767246\n",
      "obj  0.06530143012516683\n",
      "obj  0.06530143012516683\n",
      "obj  0.06530143009957116\n",
      "obj  0.06530143009957116\n",
      "obj  0.06530143008681917\n",
      "obj  0.06530143008681917\n",
      "obj  0.06530143008045465\n",
      "obj  0.06530143008045465\n",
      "obj  0.06530143007727525\n",
      "obj  0.06530143007727525\n",
      "obj  0.06530143007568624\n",
      "obj  0.06530143007568624\n",
      "obj  0.06530143007489192\n",
      "obj  0.06530143007489192\n",
      "v20 d7 f1 t4: original ll 0.0647 auc 0.9798, ensemble ll 0.0647 auc 0.9798\n",
      "running time 7.083127498626709\n",
      "starting model 7 fold 1 target 5\n",
      "obj  0.07946195116508797\n",
      "obj  0.07936828590453084\n",
      "obj  0.07933029480578792\n",
      "obj  0.07934726989439045\n",
      "obj  0.07928117967042411\n",
      "obj  0.07925241822805401\n",
      "obj  0.07925474579772367\n",
      "obj  0.07925605562862213\n",
      "obj  0.07923495652503419\n",
      "obj  0.07920926748596895\n",
      "obj  0.07919825345062308\n",
      "obj  0.07919452430472412\n",
      "obj  0.07919394086763193\n",
      "obj  0.07919185159577175\n",
      "obj  0.0791918044454031\n",
      "obj  0.07919163792006188\n",
      "obj  0.07919161852154481\n",
      "obj  0.07919161286077629\n",
      "v20 d7 f1 t5: original ll 0.0814 auc 0.9786, ensemble ll 0.0812 auc 0.9786\n",
      "running time 3.7958273887634277\n",
      "starting model 0 fold 2 target 0\n",
      "obj  0.10122632944027712\n",
      "obj  0.10112422877218633\n",
      "obj  0.10096928466386026\n",
      "obj  0.10134006997660429\n",
      "obj  0.10090616627674384\n",
      "obj  0.10102693298640429\n",
      "obj  0.10096842522692312\n",
      "obj  0.10098594846609603\n",
      "obj  0.10075943289995697\n",
      "obj  0.10066388232806306\n",
      "obj  0.10063712549181669\n",
      "obj  0.10062285685229139\n",
      "obj  0.10062003088287545\n",
      "obj  0.10061872560339628\n",
      "obj  0.1006183910989017\n",
      "obj  0.10061836351742412\n",
      "v20 d0 f2 t0: original ll 0.0979 auc 0.9871, ensemble ll 0.0971 auc 0.9871\n",
      "running time 3.593717098236084\n",
      "starting model 0 fold 2 target 1\n",
      "obj  0.015855921121926655\n",
      "obj  0.015784316600890906\n",
      "obj  0.015621220770220146\n",
      "obj  0.015253169198644244\n",
      "obj  0.015251264646577282\n",
      "obj  0.015333382341024448\n",
      "obj  0.015307246867533764\n",
      "obj  0.01517651155182998\n",
      "obj  0.015065449515825243\n",
      "obj  0.014903323631972934\n",
      "obj  0.014852265862266508\n",
      "obj  0.014835476202273707\n",
      "obj  0.014825763826078902\n",
      "obj  0.014824048333930563\n",
      "obj  0.014823683218480793\n",
      "obj  0.014823639946701293\n",
      "obj  0.014823618825724375\n",
      "obj  0.014823616753335283\n",
      "obj  0.014823610871952138\n",
      "v20 d0 f2 t1: original ll 0.0163 auc 0.9715, ensemble ll 0.0152 auc 0.9715\n",
      "running time 3.914820671081543\n",
      "starting model 0 fold 2 target 2\n",
      "obj  0.04533713448846632\n",
      "obj  0.0452661641856596\n",
      "obj  0.0452347179137711\n",
      "obj  0.04522135873417448\n",
      "obj  0.04520445709777837\n",
      "obj  0.04518594039118843\n",
      "obj  0.04518750348952749\n",
      "obj  0.045187366103250214\n",
      "obj  0.04518160479237332\n",
      "obj  0.045160410401041184\n",
      "obj  0.04515564504048993\n",
      "obj  0.04515393798694963\n",
      "obj  0.04515279326258507\n",
      "obj  0.04515279255962266\n",
      "obj  0.04515268797273461\n",
      "obj  0.0451526743717726\n",
      "obj  0.04515266935427194\n",
      "v20 d0 f2 t2: original ll 0.0411 auc 0.9914, ensemble ll 0.0413 auc 0.9914\n",
      "running time 3.6844310760498047\n",
      "starting model 0 fold 2 target 3\n",
      "obj  0.026347143507579118\n",
      "obj  0.02635659407757331\n",
      "obj  0.026378855438142126\n",
      "obj  0.026295876018439822\n",
      "obj  0.026363067659158978\n",
      "obj  0.026338330304373544\n",
      "obj  0.026342651159218963\n",
      "obj  0.026339775491336904\n",
      "obj  0.02631010854170025\n",
      "obj  0.026270823655133446\n",
      "obj  0.026265229679610532\n",
      "obj  0.026263889048195193\n",
      "obj  0.026263240407277788\n",
      "obj  0.026263060708623397\n",
      "obj  0.026262986696224015\n",
      "obj  0.02626298158872467\n",
      "obj  0.026262977074178497\n",
      "v20 d0 f2 t3: original ll 0.0262 auc 0.9962, ensemble ll 0.0261 auc 0.9962\n",
      "running time 3.68411922454834\n",
      "starting model 0 fold 2 target 4\n",
      "obj  0.06772748910376752\n",
      "obj  0.06774728336248863\n",
      "obj  0.06770797904466787\n",
      "obj  0.06777313988983764\n",
      "obj  0.06769366344647706\n",
      "obj  0.06768798233478611\n",
      "obj  0.06769077869466786\n",
      "obj  0.06766203086261001\n",
      "obj  0.06761452758338443\n",
      "obj  0.06761403806643014\n",
      "obj  0.06761264250589116\n",
      "obj  0.0676065773517272\n",
      "obj  0.06760656615381794\n",
      "obj  0.06760547752296216\n",
      "obj  0.06760527038727354\n",
      "obj  0.06760514335053078\n",
      "obj  0.06760498833926568\n",
      "obj  0.06760498557183196\n",
      "obj  0.06760497867978622\n",
      "obj  0.06760497671542756\n",
      "obj  0.06760497624307413\n",
      "obj  0.06760497624172589\n",
      "v20 d0 f2 t4: original ll 0.0666 auc 0.9802, ensemble ll 0.0665 auc 0.9802\n",
      "running time 4.295226097106934\n",
      "starting model 0 fold 2 target 5\n",
      "obj  0.084248569297273\n",
      "obj  0.08416176092961629\n",
      "obj  0.08406762720450713\n",
      "obj  0.08424808579835762\n",
      "obj  0.08400240230859603\n",
      "obj  0.08401835413076265\n",
      "obj  0.0840096464484192\n",
      "obj  0.08401746165857313\n",
      "obj  0.08392725286037121\n",
      "obj  0.08386762206815056\n",
      "obj  0.08384957093172929\n",
      "obj  0.0838460434779133\n",
      "obj  0.0838452630027303\n",
      "obj  0.08384511328980787\n",
      "obj  0.08384511189802943\n",
      "obj  0.08384508185977499\n",
      "v20 d0 f2 t5: original ll 0.0788 auc 0.9799, ensemble ll 0.0783 auc 0.9799\n",
      "running time 3.4751346111297607\n",
      "starting model 1 fold 2 target 0\n",
      "obj  0.10097203191243949\n",
      "obj  0.10085928754538916\n",
      "obj  0.1006289965275601\n",
      "obj  0.1011247334441362\n",
      "obj  0.10055065780730899\n",
      "obj  0.10072300439312255\n",
      "obj  0.10064829959463532\n",
      "obj  0.10067325988702008\n",
      "obj  0.10034788651611723\n",
      "obj  0.1001874552871507\n",
      "obj  0.10012210993220805\n",
      "obj  0.10009546178894785\n",
      "obj  0.10009530659622734\n",
      "obj  0.10008877833421903\n",
      "obj  0.10008792802086056\n",
      "obj  0.1000877560694561\n",
      "obj  0.10008775605057704\n",
      "obj  0.10008769674979658\n",
      "obj  0.10008769673657951\n",
      "obj  0.10008767973033733\n",
      "obj  0.10008767970787429\n",
      "obj  0.10008767838782265\n",
      "v20 d1 f2 t0: original ll 0.0959 auc 0.9877, ensemble ll 0.0952 auc 0.9877\n",
      "running time 4.315757989883423\n",
      "starting model 1 fold 2 target 1\n",
      "obj  0.01683462205786702\n",
      "obj  0.016778795825410777\n",
      "obj  0.016648509853229496\n",
      "obj  0.016416283044391546\n",
      "obj  0.016123090207084013\n",
      "obj  0.016100532050374733\n",
      "obj  0.016128457703817125\n",
      "obj  0.01600337674068488\n",
      "obj  0.015758965786472703\n",
      "obj  0.01561495126415979\n",
      "obj  0.015556750195792123\n",
      "obj  0.015535439812508444\n",
      "obj  0.015528584067161313\n",
      "obj  0.015527186552639112\n",
      "obj  0.015527020886200296\n",
      "obj  0.015526948102579024\n",
      "obj  0.01552693495640455\n",
      "obj  0.015526931681523245\n",
      "v20 d1 f2 t1: original ll 0.0172 auc 0.9636, ensemble ll 0.0162 auc 0.9635\n",
      "running time 3.7882466316223145\n",
      "starting model 1 fold 2 target 2\n",
      "obj  0.04409780563596011\n",
      "obj  0.04401807714228142\n",
      "obj  0.04398116149049649\n",
      "obj  0.04399553278224583\n",
      "obj  0.04395071214586594\n",
      "obj  0.043940157284048154\n",
      "obj  0.04394073435085469\n",
      "obj  0.04394197938879771\n",
      "obj  0.04393672027604464\n",
      "obj  0.0439164538449342\n",
      "obj  0.04391645341674591\n",
      "obj  0.04391309903852568\n",
      "obj  0.04391262816029211\n",
      "obj  0.04391116169899762\n",
      "obj  0.043910883654063454\n",
      "obj  0.04391085287840228\n",
      "obj  0.04391078849463444\n",
      "obj  0.043910769899705215\n",
      "obj  0.043910765404856625\n",
      "v20 d1 f2 t2: original ll 0.0394 auc 0.9922, ensemble ll 0.0395 auc 0.9922\n",
      "running time 3.91637921333313\n",
      "starting model 1 fold 2 target 3\n",
      "obj  0.02608651463926581\n",
      "obj  0.026060181572193305\n",
      "obj  0.026087489763851283\n",
      "obj  0.026003893018411176\n",
      "obj  0.026086926962137397\n",
      "obj  0.02605261523504746\n",
      "obj  0.026057347897496905\n",
      "obj  0.02605331912638487\n",
      "obj  0.026003752232408268\n",
      "obj  0.025962910611930304\n",
      "obj  0.025952718381040803\n",
      "obj  0.025950473176821618\n",
      "obj  0.025950217711651426\n",
      "obj  0.025950119656845145\n",
      "obj  0.02595010878406127\n",
      "v20 d1 f2 t3: original ll 0.0248 auc 0.9965, ensemble ll 0.0248 auc 0.9965\n",
      "running time 3.382237672805786\n",
      "starting model 1 fold 2 target 4\n",
      "obj  0.06670737268233491\n",
      "obj  0.06667984016354254\n",
      "obj  0.06665634340699804\n",
      "obj  0.06680645791664279\n",
      "obj  0.06662821127532895\n",
      "obj  0.0666185790628117\n",
      "obj  0.0666169308819411\n",
      "obj  0.06661906075291839\n",
      "obj  0.0666155715652788\n",
      "obj  0.0665992313730276\n",
      "obj  0.06659446945117496\n",
      "obj  0.0665921701597095\n",
      "obj  0.06659082651165674\n",
      "obj  0.06659075421395777\n",
      "obj  0.06659060988255616\n",
      "obj  0.06659059608249925\n",
      "obj  0.06659058509675336\n",
      "obj  0.06659058303868087\n",
      "obj  0.0665905825808584\n",
      "obj  0.06659058248730554\n",
      "v20 d1 f2 t4: original ll 0.0657 auc 0.9809, ensemble ll 0.0655 auc 0.9809\n",
      "running time 4.030828475952148\n",
      "starting model 1 fold 2 target 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.08411059703524801\n",
      "obj  0.08399015957852951\n",
      "obj  0.08385837874892892\n",
      "obj  0.08414120958723524\n",
      "obj  0.08380228064254311\n",
      "obj  0.08384700740869001\n",
      "obj  0.08384385129249552\n",
      "obj  0.08384116990615269\n",
      "obj  0.08371004866651525\n",
      "obj  0.08361340220326367\n",
      "obj  0.0835748728975242\n",
      "obj  0.08356816301046223\n",
      "obj  0.08356539293245732\n",
      "obj  0.08356464581467747\n",
      "obj  0.08356444830274098\n",
      "v20 d1 f2 t5: original ll 0.0774 auc 0.9807, ensemble ll 0.0770 auc 0.9807\n",
      "running time 3.3984920978546143\n",
      "starting model 2 fold 2 target 0\n",
      "obj  0.10042359847535624\n",
      "obj  0.1003751169811648\n",
      "obj  0.10028537427748656\n",
      "obj  0.10057810523771678\n",
      "obj  0.10026149743258783\n",
      "obj  0.1003449765171641\n",
      "obj  0.10031874603970152\n",
      "obj  0.10033044768846774\n",
      "obj  0.10023315882768949\n",
      "obj  0.10018276794087662\n",
      "obj  0.10017727235121589\n",
      "obj  0.10017532580955203\n",
      "obj  0.1001739736942124\n",
      "obj  0.10017377146576491\n",
      "obj  0.10017368756431756\n",
      "obj  0.10017366508166947\n",
      "obj  0.10017363295691875\n",
      "obj  0.10017363281468655\n",
      "obj  0.10017363281300574\n",
      "obj  0.1001736328112825\n",
      "v20 d2 f2 t0: original ll 0.0976 auc 0.9870, ensemble ll 0.0977 auc 0.9870\n",
      "running time 4.059029579162598\n",
      "starting model 2 fold 2 target 1\n",
      "obj  0.01652374723045188\n",
      "obj  0.016506218231602855\n",
      "obj  0.01647542817792721\n",
      "obj  0.016489261030335413\n",
      "obj  0.01646705597168229\n",
      "obj  0.016470991710157055\n",
      "obj  0.01647053372545315\n",
      "obj  0.016464723011203383\n",
      "obj  0.01645890861538292\n",
      "obj  0.016438780622081338\n",
      "obj  0.016436529362868036\n",
      "obj  0.016435533880052464\n",
      "obj  0.01643514597617634\n",
      "obj  0.016435140175173286\n",
      "obj  0.016435076286143442\n",
      "obj  0.016435060956079266\n",
      "obj  0.016435058235375992\n",
      "obj  0.01643505758084306\n",
      "obj  0.016435057580840615\n",
      "v20 d2 f2 t1: original ll 0.0172 auc 0.9605, ensemble ll 0.0179 auc 0.9605\n",
      "running time 3.8262851238250732\n",
      "starting model 2 fold 2 target 2\n",
      "obj  0.04586916714899744\n",
      "obj  0.04581870299216382\n",
      "obj  0.045820574978291624\n",
      "obj  0.04577326419640769\n",
      "obj  0.0458087113838567\n",
      "obj  0.045783207941317204\n",
      "obj  0.04578557026550414\n",
      "obj  0.045783037302843006\n",
      "obj  0.045770299338344714\n",
      "obj  0.045758968206819184\n",
      "obj  0.045756867845304146\n",
      "obj  0.04575488420672737\n",
      "obj  0.04575481853450586\n",
      "obj  0.045754693230746844\n",
      "obj  0.04575468617250561\n",
      "obj  0.045754686163593246\n",
      "obj  0.04575468472884019\n",
      "v20 d2 f2 t2: original ll 0.0415 auc 0.9912, ensemble ll 0.0417 auc 0.9912\n",
      "running time 3.6541552543640137\n",
      "starting model 2 fold 2 target 3\n",
      "obj  0.026838942479399434\n",
      "obj  0.026847441812989384\n",
      "obj  0.026890307435848856\n",
      "obj  0.026794511527633035\n",
      "obj  0.02689530305044014\n",
      "obj  0.026881435020423235\n",
      "obj  0.026884611408608285\n",
      "obj  0.026881040832589628\n",
      "obj  0.026846380636754413\n",
      "obj  0.02676285669960623\n",
      "obj  0.02675640714593873\n",
      "obj  0.026754693018981406\n",
      "obj  0.026754188915857353\n",
      "obj  0.026754028064858444\n",
      "obj  0.026753986943663963\n",
      "obj  0.02675398237519441\n",
      "v20 d2 f2 t3: original ll 0.0265 auc 0.9959, ensemble ll 0.0264 auc 0.9959\n",
      "running time 3.451981544494629\n",
      "starting model 2 fold 2 target 4\n",
      "obj  0.06737883652060916\n",
      "obj  0.06743212059268305\n",
      "obj  0.06740470504304773\n",
      "obj  0.06748211638547019\n",
      "obj  0.06739378321838427\n",
      "obj  0.06739383947042549\n",
      "obj  0.0673923833409778\n",
      "obj  0.06739234324866128\n",
      "obj  0.06737928607526861\n",
      "obj  0.06737921578531153\n",
      "obj  0.06737171485239707\n",
      "obj  0.06736784332660424\n",
      "obj  0.06736651446582936\n",
      "obj  0.0673663157049985\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.06736631840728947\n",
      "obj  0.0673663160440651\n",
      "obj  0.0673663160440651\n",
      "obj  0.0673663157606445\n",
      "obj  0.0673663157606445\n",
      "obj  0.06736631571481044\n",
      "obj  0.06736631571481044\n",
      "obj  0.06736631570676077\n",
      "obj  0.06736631570676077\n",
      "obj  0.06736631570532828\n",
      "obj  0.06736631570532828\n",
      "obj  0.0673663157049985\n",
      "obj  0.06736631840974741\n",
      "obj  0.06736631840974741\n",
      "obj  0.06736631840974741\n",
      "obj  0.06736631840974741\n",
      "obj  0.06736631840974741\n",
      "obj  0.06736631840974741\n",
      "obj  0.06736631649263958\n",
      "obj  0.06736631649263958\n",
      "obj  0.06736631582023371\n",
      "obj  0.06736631582023371\n",
      "obj  0.06736631572503039\n",
      "obj  0.06736631572503038\n",
      "obj  0.0673663157085757\n",
      "obj  0.06736631570857568\n",
      "obj  0.06736631570565252\n",
      "obj  0.06736631570565252\n",
      "obj  0.06736631570513074\n",
      "obj  0.06736631570513074\n",
      "v20 d2 f2 t4: original ll 0.0658 auc 0.9805, ensemble ll 0.0657 auc 0.9805\n",
      "running time 3.968756914138794\n",
      "starting model 2 fold 2 target 5\n",
      "obj  0.08354041141220717\n",
      "obj  0.08349507109256438\n",
      "obj  0.08343188999474195\n",
      "obj  0.08378593246004792\n",
      "obj  0.08340537807682043\n",
      "obj  0.08341787188678822\n",
      "obj  0.08341340401518317\n",
      "obj  0.08341933150448547\n",
      "obj  0.08339630669202394\n",
      "obj  0.08334843702022968\n",
      "obj  0.08332947101420557\n",
      "obj  0.0833284115581129\n",
      "obj  0.08332500684138643\n",
      "obj  0.08332412366261978\n",
      "obj  0.08332405256600654\n",
      "obj  0.0833240414616994\n",
      "obj  0.08332404145175003\n",
      "obj  0.08332403746071129\n",
      "obj  0.0833240372648467\n",
      "v20 d2 f2 t5: original ll 0.0780 auc 0.9802, ensemble ll 0.0780 auc 0.9802\n",
      "running time 3.8220810890197754\n",
      "starting model 3 fold 2 target 0\n",
      "obj  0.09963729706687942\n",
      "obj  0.0995551027215914\n",
      "obj  0.09935359865050848\n",
      "obj  0.0998765747001617\n",
      "obj  0.09929071634162963\n",
      "obj  0.09947037340022505\n",
      "obj  0.09939792507990866\n",
      "obj  0.09942350687322457\n",
      "obj  0.09907286130063533\n",
      "obj  0.09889422448748982\n",
      "obj  0.09883507517881099\n",
      "obj  0.09882568498143517\n",
      "obj  0.0988245026660038\n",
      "obj  0.09882440921296713\n",
      "obj  0.09882440335794682\n",
      "obj  0.0988239386928575\n",
      "obj  0.09882387499763477\n",
      "obj  0.0988238644622735\n",
      "v20 d3 f2 t0: original ll 0.0957 auc 0.9878, ensemble ll 0.0954 auc 0.9878\n",
      "running time 3.72727370262146\n",
      "starting model 3 fold 2 target 1\n",
      "obj  0.01645357715339767\n",
      "obj  0.016450627552226444\n",
      "obj  0.01647771160713864\n",
      "obj  0.01652609873633082\n",
      "obj  0.01651632828756718\n",
      "obj  0.0165186754385763\n",
      "obj  0.016519348340217656\n",
      "obj  0.01650126874759575\n",
      "obj  0.016483831631833173\n",
      "obj  0.016447951252265672\n",
      "obj  0.016440804339571898\n",
      "obj  0.01643948971678858\n",
      "obj  0.016439259185256225\n",
      "obj  0.016439215018919835\n",
      "obj  0.016439193807743332\n",
      "obj  0.016439183912030135\n",
      "obj  0.016439182780109557\n",
      "obj  0.016439182574508406\n",
      "v20 d3 f2 t1: original ll 0.0174 auc 0.9592, ensemble ll 0.0173 auc 0.9592\n",
      "running time 3.6820240020751953\n",
      "starting model 3 fold 2 target 2\n",
      "obj  0.04333148211247226\n",
      "obj  0.043318461489290715\n",
      "obj  0.04330556571878597\n",
      "obj  0.04331848968537545\n",
      "obj  0.043279993527893\n",
      "obj  0.04327227589393773\n",
      "obj  0.043272600502503256\n",
      "obj  0.04327377704629061\n",
      "obj  0.04327258700789585\n",
      "obj  0.04326059222248674\n",
      "obj  0.0432605909503778\n",
      "obj  0.04325734497366809\n",
      "obj  0.04325545017845133\n",
      "obj  0.043255076090294935\n",
      "obj  0.043254976882577144\n",
      "obj  0.04325496414030183\n",
      "obj  0.043254962597247044\n",
      "v20 d3 f2 t2: original ll 0.0398 auc 0.9924, ensemble ll 0.0398 auc 0.9924\n",
      "running time 3.629063367843628\n",
      "starting model 3 fold 2 target 3\n",
      "obj  0.02606937781612293\n",
      "obj  0.026075137701632112\n",
      "obj  0.026107853937850502\n",
      "obj  0.026007008343802318\n",
      "obj  0.026094838858076452\n",
      "obj  0.026067671532877954\n",
      "obj  0.026072925401377758\n",
      "obj  0.02606963478423649\n",
      "obj  0.02602286949108804\n",
      "obj  0.025959238890566325\n",
      "obj  0.025957101268843746\n",
      "obj  0.02594252280291791\n",
      "obj  0.02594001125948068\n",
      "obj  0.02593883289267478\n",
      "obj  0.025938692633779882\n",
      "obj  0.025938549728350826\n",
      "obj  0.025938523459965588\n",
      "obj  0.0259385145255866\n",
      "v20 d3 f2 t3: original ll 0.0253 auc 0.9965, ensemble ll 0.0252 auc 0.9965\n",
      "running time 3.7607741355895996\n",
      "starting model 3 fold 2 target 4\n",
      "obj  0.06578584634278546\n",
      "obj  0.06581919676460594\n",
      "obj  0.06574244415316757\n",
      "obj  0.06589663232091851\n",
      "obj  0.06572532874946643\n",
      "obj  0.06573230470164348\n",
      "obj  0.06573169700416415\n",
      "obj  0.06573419973925464\n",
      "obj  0.06572237987843817\n",
      "obj  0.06571207405657009\n",
      "obj  0.06571093064705207\n",
      "obj  0.06571033418780213\n",
      "obj  0.06570977816973654\n",
      "obj  0.06570977469425483\n",
      "obj  0.06570972750679838\n",
      "obj  0.06570963860119439\n",
      "obj  0.06570962158084104\n",
      "obj  0.06570961599082047\n",
      "obj  0.06570961253324452\n",
      "obj  0.06570961196941759\n",
      "v20 d3 f2 t4: original ll 0.0656 auc 0.9810, ensemble ll 0.0655 auc 0.9810\n",
      "running time 3.9298324584960938\n",
      "starting model 3 fold 2 target 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.08279278728740466\n",
      "obj  0.08271764545493734\n",
      "obj  0.08259661477501094\n",
      "obj  0.0831678890775698\n",
      "obj  0.08257877027378867\n",
      "obj  0.08261746081380439\n",
      "obj  0.08260984032394796\n",
      "obj  0.08262067512304913\n",
      "obj  0.08255529736204299\n",
      "obj  0.08240334234976168\n",
      "obj  0.08235316159765185\n",
      "obj  0.08233531650933612\n",
      "obj  0.08233093237271795\n",
      "obj  0.08232971854757906\n",
      "obj  0.08232971205174829\n",
      "obj  0.08232939969797501\n",
      "obj  0.0823293993526748\n",
      "obj  0.0823293740684321\n",
      "obj  0.08232936753602717\n",
      "obj  0.08232936589864917\n",
      "obj  0.08232936551926195\n",
      "v20 d3 f2 t5: original ll 0.0780 auc 0.9806, ensemble ll 0.0778 auc 0.9806\n",
      "running time 4.109831094741821\n",
      "starting model 4 fold 2 target 0\n",
      "obj  0.10042787833694208\n",
      "obj  0.10043294245902824\n",
      "obj  0.10051317573074839\n",
      "obj  0.10040812900136557\n",
      "obj  0.10054631970431166\n",
      "obj  0.10046317803998875\n",
      "obj  0.10047345064731092\n",
      "obj  0.10046506206225289\n",
      "obj  0.10023837554479972\n",
      "obj  0.10023810012488651\n",
      "obj  0.10016090750546362\n",
      "obj  0.10016089735196806\n",
      "obj  0.10014658832813526\n",
      "obj  0.10014033404968388\n",
      "obj  0.10013930155624672\n",
      "obj  0.10013911991920976\n",
      "obj  0.10013910459585476\n",
      "obj  0.10013910020941263\n",
      "obj  0.10013910020941139\n",
      "obj  0.1001391002083563\n",
      "obj  0.10013909914984663\n",
      "obj  0.10013909914984447\n",
      "obj  0.10013909914984132\n",
      "obj  0.10013909905562186\n",
      "v20 d4 f2 t0: original ll 0.0975 auc 0.9872, ensemble ll 0.0978 auc 0.9872\n",
      "running time 4.4485924243927\n",
      "starting model 4 fold 2 target 1\n",
      "obj  0.0161170447958706\n",
      "obj  0.016084668278699293\n",
      "obj  0.015989998532458673\n",
      "obj  0.015894494267663387\n",
      "obj  0.01575380452313675\n",
      "obj  0.015617966366369999\n",
      "obj  0.015575145331485922\n",
      "obj  0.015495635454828464\n",
      "obj  0.015317751823919815\n",
      "obj  0.01519601712163893\n",
      "obj  0.015145736120704025\n",
      "obj  0.015117096163082972\n",
      "obj  0.015108783750576827\n",
      "obj  0.015106381010232376\n",
      "obj  0.015106008098008904\n",
      "obj  0.015105861932928774\n",
      "obj  0.015105834112319208\n",
      "obj  0.015105825738093596\n",
      "obj  0.01510582483192123\n",
      "obj  0.015105824496109884\n",
      "v20 d4 f2 t1: original ll 0.0187 auc 0.9663, ensemble ll 0.0166 auc 0.9662\n",
      "running time 3.8902523517608643\n",
      "starting model 4 fold 2 target 2\n",
      "obj  0.04358471380624821\n",
      "obj  0.04358817751837643\n",
      "obj  0.043625941527328294\n",
      "obj  0.04353606839282145\n",
      "obj  0.04362432203154784\n",
      "obj  0.04358686136478268\n",
      "obj  0.0435912099418172\n",
      "obj  0.043585943536169514\n",
      "obj  0.04354337398559194\n",
      "obj  0.04350138258761551\n",
      "obj  0.04349663429501674\n",
      "obj  0.043492368448621165\n",
      "obj  0.043492134511551005\n",
      "obj  0.043492062853493996\n",
      "obj  0.043492045261195655\n",
      "obj  0.043492014119526065\n",
      "obj  0.043492011789599674\n",
      "v20 d4 f2 t2: original ll 0.0388 auc 0.9926, ensemble ll 0.0390 auc 0.9926\n",
      "running time 3.529524564743042\n",
      "starting model 4 fold 2 target 3\n",
      "obj  0.02575123057364417\n",
      "obj  0.02574746582123732\n",
      "obj  0.025742267815004907\n",
      "obj  0.02577444067854369\n",
      "obj  0.025750341024664627\n",
      "obj  0.025762232429389256\n",
      "obj  0.025758638658492386\n",
      "obj  0.025759504352345336\n",
      "obj  0.025543828803823734\n",
      "obj  0.02548604782304126\n",
      "obj  0.025471994697689848\n",
      "obj  0.02546873635881959\n",
      "obj  0.02546201312526331\n",
      "obj  0.02545947968532867\n",
      "obj  0.025458622441334844\n",
      "obj  0.025458597403593512\n",
      "obj  0.025458406865404012\n",
      "obj  0.025458406637230282\n",
      "obj  0.025458395149344046\n",
      "obj  0.025458392676114935\n",
      "obj  0.025458392676114928\n",
      "obj  0.02545839218563678\n",
      "v20 d4 f2 t3: original ll 0.0248 auc 0.9967, ensemble ll 0.0252 auc 0.9967\n",
      "running time 4.165364027023315\n",
      "starting model 4 fold 2 target 4\n",
      "obj  0.06633194814267522\n",
      "obj  0.06635218671778874\n",
      "obj  0.06646796509056603\n",
      "obj  0.06619830068338485\n",
      "obj  0.06646511388268403\n",
      "obj  0.06641046910277529\n",
      "obj  0.06642307785695131\n",
      "obj  0.06641321365932355\n",
      "obj  0.06624330344051871\n",
      "obj  0.06614233711344743\n",
      "obj  0.06611999879859327\n",
      "obj  0.06611265788864126\n",
      "obj  0.06611058836815475\n",
      "obj  0.06610987076095759\n",
      "obj  0.06610978978546786\n",
      "obj  0.06610976912013948\n",
      "obj  0.06610976467036833\n",
      "v20 d4 f2 t4: original ll 0.0647 auc 0.9815, ensemble ll 0.0647 auc 0.9815\n",
      "running time 3.60250186920166\n",
      "starting model 4 fold 2 target 5\n",
      "obj  0.08308948051248086\n",
      "obj  0.08307625043771334\n",
      "obj  0.08310981306944204\n",
      "obj  0.08300213777573849\n",
      "obj  0.08307998039452917\n",
      "obj  0.08300880838556193\n",
      "obj  0.08301821552995087\n",
      "obj  0.08301287657298075\n",
      "obj  0.08295094939895765\n",
      "obj  0.08289821506318233\n",
      "obj  0.0828981869106038\n",
      "obj  0.08289038657943079\n",
      "obj  0.08288696451103553\n",
      "obj  0.08288636949237345\n",
      "obj  0.08288620462727778\n",
      "obj  0.08288616602743125\n",
      "obj  0.08288616117843645\n",
      "obj  0.08288615953637286\n",
      "v20 d4 f2 t5: original ll 0.0776 auc 0.9805, ensemble ll 0.0775 auc 0.9805\n",
      "running time 3.7809555530548096\n",
      "starting model 5 fold 2 target 0\n",
      "obj  0.10142240254951392\n",
      "obj  0.10135165639502254\n",
      "obj  0.10114779248187616\n",
      "obj  0.10137007538117986\n",
      "obj  0.10092556562817241\n",
      "obj  0.10101682362935538\n",
      "obj  0.10095098754594242\n",
      "obj  0.1009674543665093\n",
      "obj  0.10072532674550615\n",
      "obj  0.10069025679869895\n",
      "obj  0.10063570018611048\n",
      "obj  0.1006154250615056\n",
      "obj  0.10060968046674065\n",
      "obj  0.10060838630102271\n",
      "obj  0.10060798801466254\n",
      "obj  0.10060791037770415\n",
      "obj  0.1006079088948591\n",
      "obj  0.10060790515328942\n",
      "v20 d5 f2 t0: original ll 0.0966 auc 0.9874, ensemble ll 0.0965 auc 0.9874\n",
      "running time 3.77306866645813\n",
      "starting model 5 fold 2 target 1\n",
      "obj  0.016522511656572716\n",
      "obj  0.016434921077219524\n",
      "obj  0.016231267448357466\n",
      "obj  0.01576148961502273\n",
      "obj  0.01572294393735739\n",
      "obj  0.015813479590650714\n",
      "obj  0.01578359193547924\n",
      "obj  0.015636824024257933\n",
      "obj  0.01550100259648168\n",
      "obj  0.015264327004834351\n",
      "obj  0.015183798676914212\n",
      "obj  0.015150006318912756\n",
      "obj  0.015139774448035713\n",
      "obj  0.015136239457151205\n",
      "obj  0.015136197450896024\n",
      "obj  0.01513535258739898\n",
      "obj  0.0151352035528447\n",
      "obj  0.015135201502036356\n",
      "obj  0.015135165774603408\n",
      "obj  0.015135165773783352\n",
      "obj  0.015135150984868574\n",
      "obj  0.015135150008606817\n",
      "obj  0.015135149642167936\n",
      "obj  0.015135149564660359\n",
      "v20 d5 f2 t1: original ll 0.0183 auc 0.9626, ensemble ll 0.0165 auc 0.9626\n",
      "running time 4.431583404541016\n",
      "starting model 5 fold 2 target 2\n",
      "obj  0.04344250121750527\n",
      "obj  0.04336863851920229\n",
      "obj  0.04330918727930995\n",
      "obj  0.043349834482870525\n",
      "obj  0.04327738637554913\n",
      "obj  0.04328147378683115\n",
      "obj  0.04328050946960923\n",
      "obj  0.04328321397200699\n",
      "obj  0.0432700556946792\n",
      "obj  0.04325858580451439\n",
      "obj  0.043253210557446485\n",
      "obj  0.043249985543396\n",
      "obj  0.04324998278745464\n",
      "obj  0.04324936363548973\n",
      "obj  0.04324927162030174\n",
      "obj  0.0432492584870901\n",
      "obj  0.0432492568834886\n",
      "v20 d5 f2 t2: original ll 0.0385 auc 0.9929, ensemble ll 0.0387 auc 0.9929\n",
      "running time 3.5253355503082275\n",
      "starting model 5 fold 2 target 3\n",
      "obj  0.025528356856501015\n",
      "obj  0.02546538728886713\n",
      "obj  0.025424111414090577\n",
      "obj  0.025327844213993485\n",
      "obj  0.025390508698796714\n",
      "obj  0.025368540400038338\n",
      "obj  0.025370836382450954\n",
      "obj  0.025367003521749112\n",
      "obj  0.02532781933169452\n",
      "obj  0.025270081241170618\n",
      "obj  0.025264813477817675\n",
      "obj  0.025244096044186305\n",
      "obj  0.025242086650386103\n",
      "obj  0.02524096449833982\n",
      "obj  0.025240689138665163\n",
      "obj  0.025240627024707616\n",
      "obj  0.02524062050102538\n",
      "v20 d5 f2 t3: original ll 0.0246 auc 0.9968, ensemble ll 0.0250 auc 0.9968\n",
      "running time 3.5559580326080322\n",
      "starting model 5 fold 2 target 4\n",
      "obj  0.06606600780616335\n",
      "obj  0.06603898849371855\n",
      "obj  0.06597312632993947\n",
      "obj  0.06611138434517932\n",
      "obj  0.06592786987059104\n",
      "obj  0.06594011287458919\n",
      "obj  0.06594118080871451\n",
      "obj  0.06594961234891372\n",
      "obj  0.06584971104103711\n",
      "obj  0.06574438521270087\n",
      "obj  0.06573500542545054\n",
      "obj  0.0657287867025698\n",
      "obj  0.06572685942231053\n",
      "obj  0.06572608157892704\n",
      "obj  0.0657258307065161\n",
      "obj  0.06572575332883812\n",
      "obj  0.06572574213867874\n",
      "obj  0.06572574208175203\n",
      "obj  0.06572573885498066\n",
      "obj  0.06572573852764903\n",
      "v20 d5 f2 t4: original ll 0.0647 auc 0.9815, ensemble ll 0.0648 auc 0.9815\n",
      "running time 4.05838418006897\n",
      "starting model 5 fold 2 target 5\n",
      "obj  0.08279580303055768\n",
      "obj  0.08268863900215223\n",
      "obj  0.08259733760445653\n",
      "obj  0.0826258542919475\n",
      "obj  0.08253318428088405\n",
      "obj  0.08251203151079235\n",
      "obj  0.08251390187951668\n",
      "obj  0.08251608751570258\n",
      "obj  0.08249566302555168\n",
      "obj  0.08246912042992428\n",
      "obj  0.08245355899090995\n",
      "obj  0.08245099909435748\n",
      "obj  0.08245016275675482\n",
      "obj  0.08245015452507766\n",
      "obj  0.0824500623480092\n",
      "obj  0.08245004366332548\n",
      "obj  0.08245003903842263\n",
      "obj  0.08245003806716136\n",
      "v20 d5 f2 t5: original ll 0.0779 auc 0.9804, ensemble ll 0.0774 auc 0.9804\n",
      "running time 3.772766590118408\n",
      "starting model 6 fold 2 target 0\n",
      "obj  0.10122465964861435\n",
      "obj  0.10119524221381186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.1011703526197463\n",
      "obj  0.10139147932667651\n",
      "obj  0.10121226396490575\n",
      "obj  0.10125143581064992\n",
      "obj  0.101225796940772\n",
      "obj  0.10123454346236561\n",
      "obj  0.10091088911535409\n",
      "obj  0.10091058966991576\n",
      "obj  0.10087477338641503\n",
      "obj  0.10087476409221204\n",
      "obj  0.10085462205998454\n",
      "obj  0.10084540722184808\n",
      "obj  0.10084397565922361\n",
      "obj  0.10084258328432558\n",
      "obj  0.10084257509251797\n",
      "obj  0.10084234817506958\n",
      "obj  0.10084227802714246\n",
      "obj  0.100842268689567\n",
      "v20 d6 f2 t0: original ll 0.0985 auc 0.9867, ensemble ll 0.0985 auc 0.9867\n",
      "running time 4.068848371505737\n",
      "starting model 6 fold 2 target 1\n",
      "obj  0.016752764765547698\n",
      "obj  0.016723520073269636\n",
      "obj  0.01660885839851061\n",
      "obj  0.016487297116965716\n",
      "obj  0.016145595533978496\n",
      "obj  0.016233960930407847\n",
      "obj  0.01622354236128695\n",
      "obj  0.016161168136637788\n",
      "obj  0.01587737656133659\n",
      "obj  0.015689728462597877\n",
      "obj  0.015586910161379666\n",
      "obj  0.015574180928710856\n",
      "obj  0.015569790111300273\n",
      "obj  0.015569272761714539\n",
      "obj  0.01556906410391248\n",
      "obj  0.01556901528071181\n",
      "obj  0.015569005795037102\n",
      "obj  0.015569002663815194\n",
      "obj  0.015569002142660698\n",
      "obj  0.015569001967357258\n",
      "v20 d6 f2 t1: original ll 0.0175 auc 0.9633, ensemble ll 0.0162 auc 0.9633\n",
      "running time 4.071743726730347\n",
      "starting model 6 fold 2 target 2\n",
      "obj  0.04450306387828117\n",
      "obj  0.044454985719064054\n",
      "obj  0.04448021813854367\n",
      "obj  0.044292438678695374\n",
      "obj  0.044480336988413034\n",
      "obj  0.044403815012344\n",
      "obj  0.0444154415947715\n",
      "obj  0.044405316595587475\n",
      "obj  0.04424437967461576\n",
      "obj  0.044123022641983235\n",
      "obj  0.044090244918087974\n",
      "obj  0.044057811686735074\n",
      "obj  0.0440406283806521\n",
      "obj  0.044039211565415626\n",
      "obj  0.044038364368955175\n",
      "obj  0.04403818635917289\n",
      "obj  0.0440381415160944\n",
      "obj  0.04403814140710151\n",
      "obj  0.044038132474588286\n",
      "obj  0.0440381300354526\n",
      "v20 d6 f2 t2: original ll 0.0403 auc 0.9923, ensemble ll 0.0405 auc 0.9923\n",
      "running time 4.064213991165161\n",
      "starting model 6 fold 2 target 3\n",
      "obj  0.026678786066948897\n",
      "obj  0.02667510212059965\n",
      "obj  0.026668408195815677\n",
      "obj  0.02671152756446029\n",
      "obj  0.026681650122720706\n",
      "obj  0.026692970751257213\n",
      "obj  0.026664974337851057\n",
      "obj  0.026668480544299922\n",
      "obj  0.026202428132038474\n",
      "obj  0.026109367030948117\n",
      "obj  0.026074636676783752\n",
      "obj  0.02606331154398922\n",
      "obj  0.02605809553456429\n",
      "obj  0.026053772605743902\n",
      "obj  0.026051918398695757\n",
      "obj  0.026051841337879945\n",
      "obj  0.026051711412918923\n",
      "obj  0.026051697687159328\n",
      "obj  0.026051694560656365\n",
      "obj  0.026051693630075052\n",
      "obj  0.026051693630074972\n",
      "obj  0.026051693444415113\n",
      "v20 d6 f2 t3: original ll 0.0255 auc 0.9965, ensemble ll 0.0255 auc 0.9965\n",
      "running time 4.330422639846802\n",
      "starting model 6 fold 2 target 4\n",
      "obj  0.06660025601704735\n",
      "obj  0.06663263802982715\n",
      "obj  0.06669152711917523\n",
      "obj  0.06669985876154662\n",
      "obj  0.06669986528804908\n",
      "obj  0.06667127901563255\n",
      "obj  0.0666751825962677\n",
      "obj  0.06667275303335128\n",
      "obj  0.06667230999302368\n",
      "obj  0.06667178624051198\n",
      "obj  0.06667133278294683\n",
      "obj  0.06667093964355092\n",
      "obj  0.06667059914898403\n",
      "obj  0.06667030487539294\n",
      "obj  0.06667005343610174\n",
      "obj  0.0666698408044281\n",
      "obj  0.06666966234123513\n",
      "obj  0.06666951503270531\n",
      "obj  0.06666829298221526\n",
      "obj  0.06666697842000732\n",
      "obj  0.06666611782238048\n",
      "obj  0.06666551681683033\n",
      "obj  0.06666507340087241\n",
      "obj  0.06666473629072447\n",
      "obj  0.06666447705384747\n",
      "obj  0.06666427772532144\n",
      "obj  0.06666412714241945\n",
      "obj  0.06666401878187575\n",
      "obj  0.06666375238774366\n",
      "obj  0.06666215781746183\n",
      "obj  0.06666065849411983\n",
      "obj  0.06665956281787659\n",
      "obj  0.06665915150262805\n",
      "obj  0.06665147877536588\n",
      "obj  0.06660177084370789\n",
      "obj  0.0666017519992322\n",
      "obj  0.0665878867910898\n",
      "obj  0.06658327646097728\n",
      "obj  0.06658252114707507\n",
      "obj  0.06658234304634111\n",
      "obj  0.06658231165617522\n",
      "v20 d6 f2 t4: original ll 0.0656 auc 0.9807, ensemble ll 0.0656 auc 0.9807\n",
      "running time 6.691047430038452\n",
      "starting model 6 fold 2 target 5\n",
      "obj  0.08302224038043023\n",
      "obj  0.08300041578846974\n",
      "obj  0.08298924591157833\n",
      "obj  0.083173270522113\n",
      "obj  0.08296232042948826\n",
      "obj  0.0829350517761991\n",
      "obj  0.08293969495243679\n",
      "obj  0.08294181763924884\n",
      "obj  0.08284624953520114\n",
      "obj  0.08282660238420816\n",
      "obj  0.08282654490830149\n",
      "obj  0.08281892304465586\n",
      "obj  0.08281190968126784\n",
      "obj  0.08280895005730936\n",
      "obj  0.0828082803642166\n",
      "obj  0.08280814371482655\n",
      "obj  0.08280811982402742\n",
      "obj  0.08280811532528522\n",
      "v20 d6 f2 t5: original ll 0.0785 auc 0.9800, ensemble ll 0.0789 auc 0.9800\n",
      "running time 3.7879769802093506\n",
      "starting model 7 fold 2 target 0\n",
      "obj  0.10011610598997808\n",
      "obj  0.09998039238493939\n",
      "obj  0.09973840475627385\n",
      "obj  0.10030327325159287\n",
      "obj  0.09966719293317543\n",
      "obj  0.09986378929297832\n",
      "obj  0.09978225527953243\n",
      "obj  0.09981077477747698\n",
      "obj  0.09941436080680326\n",
      "obj  0.09922929460253281\n",
      "obj  0.09915322651219399\n",
      "obj  0.09913232470831547\n",
      "obj  0.09913214857700307\n",
      "obj  0.0991259100222957\n",
      "obj  0.09912480425333552\n",
      "obj  0.09912470190969852\n",
      "obj  0.09912470190637256\n",
      "obj  0.0991246868295154\n",
      "obj  0.0991246818089527\n",
      "obj  0.09912468096858325\n",
      "v20 d7 f2 t0: original ll 0.0956 auc 0.9877, ensemble ll 0.0964 auc 0.9877\n",
      "running time 4.082603931427002\n",
      "starting model 7 fold 2 target 1\n",
      "obj  0.014549635135067285\n",
      "obj  0.014502313939899139\n",
      "obj  0.014375730080560265\n",
      "obj  0.014284261592843125\n",
      "obj  0.014329996347089594\n",
      "obj  0.014385143448396512\n",
      "obj  0.014387919451782609\n",
      "obj  0.014345234013564584\n",
      "obj  0.014303805919104715\n",
      "obj  0.014269352857150345\n",
      "obj  0.01426386997999651\n",
      "obj  0.014258615629150723\n",
      "obj  0.014257674815563575\n",
      "obj  0.014257051716618865\n",
      "obj  0.014256994608525426\n",
      "obj  0.014256985783566538\n",
      "v20 d7 f2 t1: original ll 0.0151 auc 0.9730, ensemble ll 0.0148 auc 0.9730\n",
      "running time 3.463193416595459\n",
      "starting model 7 fold 2 target 2\n",
      "obj  0.04291828734293821\n",
      "obj  0.04285645119713472\n",
      "obj  0.04280235989333098\n",
      "obj  0.04284744835336907\n",
      "obj  0.04276798010172093\n",
      "obj  0.04277136908311717\n",
      "obj  0.042770602572942476\n",
      "obj  0.04277369333692898\n",
      "obj  0.042764107475189404\n",
      "obj  0.04274212463649453\n",
      "obj  0.042741422741722906\n",
      "obj  0.04273870339037578\n",
      "obj  0.042737669487498284\n",
      "obj  0.04273760235106348\n",
      "obj  0.042737582121558836\n",
      "obj  0.04273757809918855\n",
      "v20 d7 f2 t2: original ll 0.0395 auc 0.9926, ensemble ll 0.0398 auc 0.9926\n",
      "running time 3.519672155380249\n",
      "starting model 7 fold 2 target 3\n",
      "obj  0.025566832135964505\n",
      "obj  0.02552372818108154\n",
      "obj  0.02551554202946665\n",
      "obj  0.02551155461000922\n",
      "obj  0.025515764443020353\n",
      "obj  0.02551248699987296\n",
      "obj  0.025512289820430648\n",
      "obj  0.025511927417899784\n",
      "obj  0.025495246963784496\n",
      "obj  0.025489556914456396\n",
      "obj  0.025486664890763393\n",
      "obj  0.025485426623130004\n",
      "obj  0.025484221857351556\n",
      "obj  0.025484191870667628\n",
      "obj  0.025484117427088872\n",
      "obj  0.025484108895452343\n",
      "obj  0.025484107503164186\n",
      "v20 d7 f2 t3: original ll 0.0255 auc 0.9966, ensemble ll 0.0255 auc 0.9966\n",
      "running time 3.5933244228363037\n",
      "starting model 7 fold 2 target 4\n",
      "obj  0.0652542877015537\n",
      "obj  0.06521612856756119\n",
      "obj  0.06518843264379183\n",
      "obj  0.06523318171089698\n",
      "obj  0.06517669178107705\n",
      "obj  0.06516621811942658\n",
      "obj  0.0651640982250565\n",
      "obj  0.06513831458327055\n",
      "obj  0.06509861684966779\n",
      "obj  0.06507786060597796\n",
      "obj  0.06507457424746454\n",
      "obj  0.065068968568582\n",
      "obj  0.06506881062635686\n",
      "obj  0.06506873101784476\n",
      "obj  0.06506863634072194\n",
      "obj  0.06506862587693389\n",
      "obj  0.06506862445579709\n",
      "obj  0.06506862445205823\n",
      "obj  0.06506862421863362\n",
      "v20 d7 f2 t4: original ll 0.0651 auc 0.9815, ensemble ll 0.0653 auc 0.9815\n",
      "running time 3.832096815109253\n",
      "starting model 7 fold 2 target 5\n",
      "obj  0.08205777298089308\n",
      "obj  0.08197213825580073\n",
      "obj  0.08182914090554909\n",
      "obj  0.08210804403164114\n",
      "obj  0.08175828981732676\n",
      "obj  0.08180689607928864\n",
      "obj  0.08179518199884284\n",
      "obj  0.08179824691534272\n",
      "obj  0.08162309020738615\n",
      "obj  0.08148541771317853\n",
      "obj  0.08144577276215707\n",
      "obj  0.08144518114962965\n",
      "obj  0.0814338029712421\n",
      "obj  0.08143133638032406\n",
      "obj  0.08143133294520802\n",
      "obj  0.08143083057061999\n",
      "obj  0.08143074964475852\n",
      "obj  0.08143073021154494\n",
      "obj  0.08143072554853156\n",
      "obj  0.08143072446761412\n",
      "v20 d7 f2 t5: original ll 0.0762 auc 0.9813, ensemble ll 0.0766 auc 0.9813\n",
      "running time 4.01112699508667\n",
      "total running time 578.6535203456879\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for fold in range(3):\n",
    "    for ds_idx in range(len(preds_all)):\n",
    "        for target in range(6):\n",
    "            train_ensemble(train_md, preds_all, fold=fold, target=target, ds_idx=ds_idx, first_step=True)\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total running time 578.6535203456879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.06172 ensemble ll 0.06133\n",
      "valid original ll 0.06172 ensemble ll 0.06154\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx != -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.06180 ensemble ll 0.06140\n",
      "valid original ll 0.06180 ensemble ll 0.06162\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx != -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0 target 0\n",
      "obj  0.09501792354779708\n",
      "obj  0.0985011898693669\n",
      "obj  0.09849351893079067\n",
      "obj  0.09848670749721332\n",
      "obj  0.09848072627751504\n",
      "obj  0.09846057045685626\n",
      "obj  0.09845020372758904\n",
      "obj  0.09819590182162913\n",
      "obj  0.09574531828818722\n",
      "obj  0.09550297952604746\n",
      "obj  0.0954043939011891\n",
      "obj  0.09536515021587263\n",
      "obj  0.09533667326093011\n",
      "obj  0.09531712447249034\n",
      "obj  0.0953094465113473\n",
      "obj  0.09530170607644826\n",
      "obj  0.09529892700135546\n",
      "obj  0.09526036979860891\n",
      "obj  0.09520585777830862\n",
      "obj  0.09517672412340164\n",
      "obj  0.09515666739006323\n",
      "obj  0.09513760117599729\n",
      "obj  0.0951283647696575\n",
      "obj  0.09512002955348592\n",
      "obj  0.09511305345646942\n",
      "obj  0.09510650755201215\n",
      "obj  0.09509381077590065\n",
      "obj  0.09507740931888436\n",
      "obj  0.09506250444758464\n",
      "obj  0.09504957982201445\n",
      "obj  0.09503696057326923\n",
      "obj  0.09502484158750399\n",
      "obj  0.09501267334448854\n",
      "obj  0.09500097539173524\n",
      "obj  0.09499095542120657\n",
      "obj  0.09498217276579875\n",
      "obj  0.09497435236696772\n",
      "obj  0.09496722745181276\n",
      "obj  0.09495789972652566\n",
      "obj  0.09494787427054283\n",
      "obj  0.0949372954003704\n",
      "obj  0.09492808883792783\n",
      "obj  0.09491698617063815\n",
      "obj  0.09490551663954845\n",
      "obj  0.09489312981347899\n",
      "obj  0.0948803027621565\n",
      "obj  0.09486530351597094\n",
      "obj  0.09482820961013913\n",
      "obj  0.09480271477670703\n",
      "obj  0.09479435641208801\n",
      "obj  0.09479215937195609\n",
      "obj  0.09474064794839361\n",
      "obj  0.09458502622364996\n",
      "obj  0.09458328134989681\n",
      "obj  0.09458323305951884\n",
      "obj  0.09458317024149397\n",
      "obj  0.09458301399006921\n",
      "obj  0.09458300590818243\n",
      "v20 d-1 f0 t0: original ll 0.0964 auc 0.9871, ensemble ll 0.0963 auc 0.9871\n",
      "running time 26.492915153503418\n",
      "starting fold 0 target 1\n",
      "obj  0.013846231793941953\n",
      "obj  0.01379677031780156\n",
      "obj  0.013764031174796692\n",
      "obj  0.013780892593287571\n",
      "obj  0.013847641254278596\n",
      "obj  0.013819422265088211\n",
      "obj  0.013835631789686121\n",
      "obj  0.013827615725106483\n",
      "obj  0.013765686667452454\n",
      "obj  0.0135084725151444\n",
      "obj  0.013461137265499258\n",
      "obj  0.01343974461471066\n",
      "obj  0.013428955969249616\n",
      "obj  0.013427063023255102\n",
      "obj  0.013426036780516402\n",
      "obj  0.013425890450534411\n",
      "obj  0.013425843157808917\n",
      "obj  0.013425835998375608\n",
      "obj  0.013425831876966969\n",
      "obj  0.01342583112999673\n",
      "v20 d-1 f0 t1: original ll 0.0158 auc 0.9785, ensemble ll 0.0155 auc 0.9782\n",
      "running time 9.55867314338684\n",
      "starting fold 0 target 2\n",
      "obj  0.039198270922904115\n",
      "obj  0.03985426268427904\n",
      "obj  0.0398524266329365\n",
      "obj  0.03985143157144734\n",
      "obj  0.03985389080029016\n",
      "obj  0.03981342775796479\n",
      "obj  0.03982444310763317\n",
      "obj  0.03971484846170631\n",
      "obj  0.0391450823191852\n",
      "obj  0.03911714966992072\n",
      "obj  0.03909559358802565\n",
      "obj  0.039078430015038954\n",
      "obj  0.03907466759424765\n",
      "obj  0.039071520805906625\n",
      "obj  0.0390689094875531\n",
      "obj  0.0390667747957913\n",
      "obj  0.0390650685931821\n",
      "obj  0.03906292721401493\n",
      "obj  0.03905969577514211\n",
      "obj  0.03905736079798649\n",
      "obj  0.03903817267968035\n",
      "obj  0.03903623566821123\n",
      "obj  0.03903522983322456\n",
      "obj  0.039034850651870644\n",
      "obj  0.03901378461089552\n",
      "obj  0.039013410399080205\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.039013654818282804\n",
      "obj  0.0390136548182828\n",
      "obj  0.03901351988994106\n",
      "obj  0.03901351988994106\n",
      "obj  0.03901343112095269\n",
      "obj  0.03901343112095269\n",
      "obj  0.0390134121105251\n",
      "obj  0.03901343037819326\n",
      "obj  0.03901343037819326\n",
      "obj  0.03901341911354859\n",
      "obj  0.03901341911354858\n",
      "obj  0.03901341507573936\n",
      "obj  0.03901341507573936\n",
      "obj  0.039013413458737496\n",
      "obj  0.03901341345873749\n",
      "obj  0.039013412750709395\n",
      "obj  0.039013412750709395\n",
      "obj  0.03901341242181793\n",
      "obj  0.039013412263927814\n",
      "obj  0.039013412263927814\n",
      "obj  0.03901341218670248\n",
      "obj  0.03901341218670248\n",
      "obj  0.03901341214848278\n",
      "obj  0.03901341214848278\n",
      "obj  0.03901341212947118\n",
      "obj  0.03901341212947119\n",
      "obj  0.03901341211998993\n",
      "obj  0.03901341211998993\n",
      "obj  0.03901341211525546\n",
      "obj  0.03901341211525546\n",
      "obj  0.039013412112889764\n",
      "obj  0.039013412112889764\n",
      "obj  0.03901341211170729\n",
      "obj  0.03901341211170729\n",
      "obj  0.03901341211111616\n",
      "obj  0.03901341211111616\n",
      "obj  0.039013412110820614\n",
      "obj  0.039013412110820614\n",
      "obj  0.03901341211067285\n",
      "obj  0.03901341211067285\n",
      "obj  0.03901341211059896\n",
      "obj  0.03901341211059896\n",
      "obj  0.03901341211056202\n",
      "obj  0.03901341211056202\n",
      "obj  0.03901341211054355\n",
      "obj  0.03901341211054355\n",
      "obj  0.0390134121105251\n",
      "obj  0.039013706085093365\n",
      "obj  0.03901370608509336\n",
      "obj  0.03901366403964852\n",
      "obj  0.03901366403964852\n",
      "obj  0.0390134807533039\n",
      "obj  0.0390134807533039\n",
      "obj  0.03901343181419293\n",
      "obj  0.03901343181419293\n",
      "obj  0.039013418282662825\n",
      "obj  0.039013414272043585\n",
      "obj  0.039013414272043585\n",
      "obj  0.039013412958969304\n",
      "obj  0.039013412958969304\n",
      "obj  0.03901341247642692\n",
      "obj  0.03901341247642692\n",
      "obj  0.03901341227857146\n",
      "obj  0.03901341227857147\n",
      "obj  0.03901341219059769\n",
      "obj  0.039013412149655556\n",
      "obj  0.039013412149655556\n",
      "obj  0.039013412129863846\n",
      "obj  0.03901341212986385\n",
      "obj  0.03901341212013785\n",
      "obj  0.03901341212013785\n",
      "obj  0.0390134121153173\n",
      "obj  0.0390134121153173\n",
      "obj  0.039013412112917666\n",
      "obj  0.039013412112917666\n",
      "obj  0.03901341211172049\n",
      "obj  0.03901341211172049\n",
      "obj  0.039013412111122574\n",
      "obj  0.039013412111122574\n",
      "obj  0.03901341211082377\n",
      "obj  0.03901341211082377\n",
      "obj  0.039013412110674404\n",
      "obj  0.039013412110674404\n",
      "obj  0.03901341211059974\n",
      "obj  0.03901341211056242\n",
      "obj  0.03901341211056242\n",
      "obj  0.03901341211054375\n",
      "obj  0.03901341211053442\n",
      "obj  0.0390134121105251\n",
      "obj  0.03901369921912491\n",
      "obj  0.03901369921912491\n",
      "obj  0.03901365825595442\n",
      "obj  0.03901365825595442\n",
      "obj  0.039013477747173134\n",
      "obj  0.039013477747173134\n",
      "obj  0.03901343028184359\n",
      "obj  0.03901343028184359\n",
      "obj  0.03901341750913095\n",
      "obj  0.03901341750913094\n",
      "obj  0.03901341388343462\n",
      "obj  0.03901341388343462\n",
      "obj  0.03901341276420251\n",
      "obj  0.03901341276420251\n",
      "obj  0.039013412378927845\n",
      "obj  0.039013412378927845\n",
      "obj  0.03901341222979296\n",
      "obj  0.03901341222979295\n",
      "obj  0.03901341216620021\n",
      "obj  0.03901341216620021\n",
      "obj  0.03901341213745503\n",
      "obj  0.03901341213745503\n",
      "obj  0.039013412123763115\n",
      "obj  0.039013412123763115\n",
      "obj  0.03901341211708737\n",
      "obj  0.03901341211708737\n",
      "obj  0.03901341211379206\n",
      "obj  0.039013412113792056\n",
      "obj  0.03901341211215501\n",
      "obj  0.03901341211215501\n",
      "obj  0.039013412111339164\n",
      "obj  0.03901341211133916\n",
      "obj  0.039013412110931914\n",
      "obj  0.039013412110931914\n",
      "obj  0.03901341211072844\n",
      "obj  0.03901341211072844\n",
      "obj  0.03901341211062676\n",
      "obj  0.039013412110626755\n",
      "obj  0.0390134121105759\n",
      "obj  0.0390134121105759\n",
      "obj  0.03901341211055049\n",
      "obj  0.039013412110550504\n",
      "obj  0.03901341211053779\n",
      "obj  0.039013412110537785\n",
      "obj  0.03901341211053143\n",
      "obj  0.03901341211053143\n",
      "obj  0.0390134121105251\n",
      "obj  0.03901369785246863\n",
      "obj  0.03901369785246863\n",
      "obj  0.03901365711273962\n",
      "obj  0.03901365711273962\n",
      "obj  0.03901347714922429\n",
      "obj  0.039013477149224284\n",
      "obj  0.0390134299761176\n",
      "obj  0.0390134299761176\n",
      "obj  0.039013417354569264\n",
      "obj  0.039013417354569264\n",
      "obj  0.039013413805728286\n",
      "obj  0.039013413805728286\n",
      "obj  0.039013412725242565\n",
      "obj  0.03901341272524256\n",
      "obj  0.039013412359421136\n",
      "obj  0.039013412359421136\n",
      "obj  0.03901341222003291\n",
      "obj  0.03901341222003291\n",
      "obj  0.03901341216131829\n",
      "obj  0.03901341216131829\n",
      "obj  0.039013412135013664\n",
      "obj  0.039013412135013636\n",
      "obj  0.039013412122542335\n",
      "obj  0.039013412122542335\n",
      "obj  0.03901341211647695\n",
      "obj  0.03901341211647694\n",
      "obj  0.03901341211348683\n",
      "obj  0.03901341211200241\n",
      "obj  0.03901341211200241\n",
      "obj  0.039013412111262864\n",
      "obj  0.03901341211089374\n",
      "obj  0.03901341211089376\n",
      "obj  0.03901341211070936\n",
      "obj  0.03901341211070936\n",
      "obj  0.03901341211061721\n",
      "obj  0.03901341211061721\n",
      "obj  0.03901341211057115\n",
      "obj  0.03901341211057114\n",
      "obj  0.03901341211054812\n",
      "obj  0.03901341211054812\n",
      "obj  0.0390134121105366\n",
      "obj  0.0390134121105366\n",
      "obj  0.039013412110530846\n",
      "obj  0.039013412110530846\n",
      "obj  0.0390134121105251\n",
      "obj  0.03901369757939564\n",
      "obj  0.03901369757939564\n",
      "obj  0.039013656884630585\n",
      "obj  0.039013656884630585\n",
      "obj  0.039013477029761504\n",
      "obj  0.03901347702976151\n",
      "obj  0.03901342991499995\n",
      "obj  0.03901342991499995\n",
      "obj  0.03901341732366158\n",
      "obj  0.039013417323661564\n",
      "obj  0.03901341379018707\n",
      "obj  0.03901341379018707\n",
      "obj  0.039013412717450006\n",
      "obj  0.039013412717450006\n",
      "obj  0.03901341235551937\n",
      "obj  0.03901341235551936\n",
      "obj  0.039013412218080676\n",
      "obj  0.039013412218080676\n",
      "obj  0.03901341216034178\n",
      "obj  0.03901341216034177\n",
      "obj  0.039013412134525305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.039013412134525305\n",
      "obj  0.03901341212229815\n",
      "obj  0.03901341212229815\n",
      "obj  0.039013412116354826\n",
      "obj  0.03901341211635484\n",
      "obj  0.039013412113425766\n",
      "obj  0.03901341211342576\n",
      "obj  0.039013412111971874\n",
      "obj  0.03901341211197186\n",
      "obj  0.0390134121112476\n",
      "obj  0.03901341211124759\n",
      "obj  0.03901341211088612\n",
      "obj  0.03901341211088612\n",
      "obj  0.03901341211070554\n",
      "obj  0.03901341211070553\n",
      "obj  0.03901341211061531\n",
      "obj  0.039013412110615306\n",
      "obj  0.039013412110570196\n",
      "obj  0.03901341211057019\n",
      "obj  0.039013412110547645\n",
      "obj  0.03901341211054764\n",
      "obj  0.03901341211053636\n",
      "obj  0.03901341211053636\n",
      "obj  0.039013412110530735\n",
      "obj  0.039013412110530735\n",
      "v20 d-1 f0 t2: original ll 0.0426 auc 0.9927, ensemble ll 0.0434 auc 0.9927\n",
      "running time 22.175931692123413\n",
      "starting fold 0 target 3\n",
      "obj  0.02355589995871336\n",
      "obj  0.024358465642652545\n",
      "obj  0.024357053676253154\n",
      "obj  0.024355389905898465\n",
      "obj  0.02435816807142902\n",
      "obj  0.024296433240304567\n",
      "obj  0.024309672451025527\n",
      "obj  0.02425456984905536\n",
      "obj  0.024040709469007226\n",
      "obj  0.02403300335377256\n",
      "obj  0.024025444954085973\n",
      "obj  0.024018024085288626\n",
      "obj  0.024010060057254864\n",
      "obj  0.024001506606481197\n",
      "obj  0.023993553211203833\n",
      "obj  0.02398469635820611\n",
      "obj  0.023976368292437895\n",
      "obj  0.023968530185056288\n",
      "obj  0.023961024698787747\n",
      "obj  0.023953773522824996\n",
      "obj  0.02394673169893155\n",
      "obj  0.02393986996783265\n",
      "obj  0.023933167867456823\n",
      "obj  0.023926599457240648\n",
      "obj  0.02391823087221136\n",
      "obj  0.023910684296920785\n",
      "obj  0.02390361091915031\n",
      "obj  0.023896846528945873\n",
      "obj  0.023890313570463687\n",
      "obj  0.023883970961224597\n",
      "obj  0.023877794454519388\n",
      "obj  0.02387157945387764\n",
      "obj  0.023864245540457962\n",
      "obj  0.023856212810170477\n",
      "obj  0.02384903300830282\n",
      "obj  0.023841918138081526\n",
      "obj  0.023833098889797285\n",
      "obj  0.023824931787347205\n",
      "obj  0.02381759340757895\n",
      "obj  0.02381078184765718\n",
      "obj  0.023804351118088103\n",
      "obj  0.023798218494058433\n",
      "obj  0.023792332172908926\n",
      "obj  0.023786657287022343\n",
      "obj  0.02377840821304704\n",
      "obj  0.02377053639306102\n",
      "obj  0.023763616724350938\n",
      "obj  0.023757269022412684\n",
      "obj  0.023750740927370662\n",
      "obj  0.02374214699825376\n",
      "obj  0.02373435460677396\n",
      "obj  0.023727488062576994\n",
      "obj  0.02372004708620734\n",
      "obj  0.023711090656286102\n",
      "obj  0.023703432406369785\n",
      "obj  0.0236966187996781\n",
      "obj  0.023690372256632952\n",
      "obj  0.02368388421614841\n",
      "obj  0.023676674874196522\n",
      "obj  0.023670241418454824\n",
      "obj  0.023664349072575263\n",
      "obj  0.023657822550615316\n",
      "obj  0.023650652170687382\n",
      "obj  0.02364424801343188\n",
      "obj  0.023638386022838298\n",
      "obj  0.02363291794409737\n",
      "obj  0.023627759729073997\n",
      "obj  0.023622860546994317\n",
      "obj  0.02361702979144507\n",
      "obj  0.023610425001547385\n",
      "obj  0.02360453306596259\n",
      "obj  0.02359915031091091\n",
      "obj  0.02359413110112049\n",
      "obj  0.023589395338388337\n",
      "obj  0.023584892307101257\n",
      "obj  0.023580588692540965\n",
      "obj  0.023575011424414902\n",
      "obj  0.023568734595675798\n",
      "obj  0.023562974553500714\n",
      "obj  0.023557594099384484\n",
      "obj  0.02355248064468313\n",
      "obj  0.023547571543532708\n",
      "obj  0.0235423987989133\n",
      "obj  0.023499389278226916\n",
      "obj  0.023494198487251438\n",
      "obj  0.02348933604734905\n",
      "obj  0.023485135833053453\n",
      "obj  0.023481280246804365\n",
      "obj  0.023476914687448152\n",
      "obj  0.023469923365410213\n",
      "obj  0.023447772486549865\n",
      "obj  0.02342567894264235\n",
      "obj  0.023421871549479674\n",
      "obj  0.0234188871516417\n",
      "obj  0.023416517274083535\n",
      "obj  0.023414636096007434\n",
      "obj  0.02340942423755573\n",
      "obj  0.023408397348446446\n",
      "obj  0.02340770118227326\n",
      "obj  0.023407256508981632\n",
      "obj  0.023406998001014933\n",
      "obj  0.023404705059873618\n",
      "obj  0.02340448744553253\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.023404499781516964\n",
      "obj  0.02340449978151696\n",
      "obj  0.02340449721119129\n",
      "obj  0.02340449721119129\n",
      "obj  0.023404467503609177\n",
      "obj  0.023404489108553146\n",
      "obj  0.02340448910855314\n",
      "obj  0.023404472539037997\n",
      "obj  0.023404472539037997\n",
      "obj  0.023404468581937482\n",
      "obj  0.023404468581937482\n",
      "obj  0.023404467682893046\n",
      "obj  0.02340446768289305\n",
      "obj  0.023404467503276752\n",
      "obj  0.02340446750327675\n",
      "obj  0.023404467480948838\n",
      "obj  0.023404467480948838\n",
      "obj  0.02340446748665541\n",
      "obj  0.02340446748665541\n",
      "obj  0.0234044674937264\n",
      "obj  0.023404467493726395\n",
      "obj  0.023404467498316303\n",
      "obj  0.023404467498316303\n",
      "obj  0.023404467500874878\n",
      "obj  0.023404467500874878\n",
      "obj  0.023404467502220073\n",
      "obj  0.023404467502220073\n",
      "obj  0.02340446750290914\n",
      "obj  0.02340446750290914\n",
      "obj  0.02340446750325779\n",
      "obj  0.023404467503257788\n",
      "obj  0.023404467503433144\n",
      "obj  0.023404467503433144\n",
      "obj  0.02340446750352108\n",
      "obj  0.023404467503565115\n",
      "obj  0.023404467503565115\n",
      "obj  0.023404467503587146\n",
      "obj  0.02340446750358714\n",
      "obj  0.02340446750359817\n",
      "obj  0.02340446750359817\n",
      "obj  0.023404467503603678\n",
      "obj  0.023404467503603678\n",
      "obj  0.023404467503606433\n",
      "obj  0.023404467503606433\n",
      "obj  0.023404467503607813\n",
      "obj  0.023404467503607813\n",
      "obj  0.023404467503608493\n",
      "obj  0.023404467503608493\n",
      "obj  0.023404467503609177\n",
      "obj  0.023404553376876247\n",
      "obj  0.023404553376876247\n",
      "obj  0.023404538830852358\n",
      "obj  0.023404538830852358\n",
      "obj  0.02340448389296353\n",
      "obj  0.02340448389296353\n",
      "obj  0.02340447090135925\n",
      "obj  0.02340447090135925\n",
      "obj  0.023404468004681413\n",
      "obj  0.023404468004681413\n",
      "obj  0.023404467454669304\n",
      "obj  0.023404467454669304\n",
      "obj  0.023404467404267035\n",
      "obj  0.02340446743337338\n",
      "obj  0.02340446743337338\n",
      "obj  0.023404467400181934\n",
      "obj  0.023404467400181934\n",
      "obj  0.023404467397564868\n",
      "obj  0.023404467397564875\n",
      "obj  0.023404467399751036\n",
      "obj  0.023404467399751036\n",
      "obj  0.023404467401717807\n",
      "obj  0.023404467401717807\n",
      "obj  0.023404467402919613\n",
      "obj  0.023404467402919616\n",
      "obj  0.023404467403575133\n",
      "obj  0.02340446740357513\n",
      "obj  0.023404467403916523\n",
      "obj  0.023404467403916527\n",
      "obj  0.02340446740409064\n",
      "obj  0.02340446740409064\n",
      "obj  0.02340446740417855\n",
      "obj  0.023404467404178553\n",
      "obj  0.02340446740422272\n",
      "obj  0.02340446740422272\n",
      "obj  0.02340446740424486\n",
      "obj  0.02340446740424486\n",
      "obj  0.023404467404255953\n",
      "obj  0.023404467404255953\n",
      "obj  0.02340446740426149\n",
      "obj  0.02340446740426149\n",
      "obj  0.023404467404264252\n",
      "obj  0.023404467404264252\n",
      "obj  0.02340446740426565\n",
      "obj  0.02340446740426565\n",
      "obj  0.02340446740426634\n",
      "obj  0.02340446740426634\n",
      "obj  0.02340446740426668\n",
      "obj  0.02340446740426634\n",
      "obj  0.02340446740426634\n",
      "obj  0.02340446740426668\n",
      "obj  0.023404556713164253\n",
      "obj  0.023404556713164253\n",
      "obj  0.02340454169170285\n",
      "obj  0.02340454169170285\n",
      "obj  0.023404485416984835\n",
      "obj  0.023404485416984835\n",
      "obj  0.023404471648678996\n",
      "obj  0.02340447164867899\n",
      "obj  0.023404468338089523\n",
      "obj  0.023404468338089523\n",
      "obj  0.02340446757405754\n",
      "obj  0.02340446757405754\n",
      "obj  0.023404467414878838\n",
      "obj  0.023404467414878838\n",
      "obj  0.023404467391001545\n",
      "obj  0.02340446740957662\n",
      "obj  0.023404467409576624\n",
      "obj  0.02340446739565619\n",
      "obj  0.023404467395656194\n",
      "obj  0.023404467392170645\n",
      "obj  0.02340446739129653\n",
      "obj  0.023404467391296528\n",
      "obj  0.023404467391076645\n",
      "obj  0.02340446739107665\n",
      "obj  0.023404467391021002\n",
      "obj  0.023404467391021002\n",
      "obj  0.02340446739100675\n",
      "obj  0.023404467391006756\n",
      "obj  0.02340446739100302\n",
      "obj  0.023404467391003027\n",
      "obj  0.02340446739100199\n",
      "obj  0.02340446739100199\n",
      "obj  0.023404467391001698\n",
      "obj  0.023404467391001698\n",
      "obj  0.02340446739100161\n",
      "obj  0.023404467391001615\n",
      "obj  0.023404467391001566\n",
      "obj  0.023404467391001566\n",
      "obj  0.02340446739100156\n",
      "obj  0.023404467391001552\n",
      "obj  0.02340446739100156\n",
      "obj  0.02340446739100156\n",
      "obj  0.023404467391001542\n",
      "obj  0.023404467391001545\n",
      "obj  0.02340446739100155\n",
      "obj  0.02340446739100155\n",
      "obj  0.023404467391001542\n",
      "obj  0.023404467391001542\n",
      "obj  0.023404467391001545\n",
      "obj  0.02340455853239949\n",
      "obj  0.023404558532399495\n",
      "obj  0.02340454314747141\n",
      "obj  0.023404543147471417\n",
      "obj  0.02340448625144094\n",
      "obj  0.023404486251440943\n",
      "obj  0.023404472087121635\n",
      "obj  0.023404472087121635\n",
      "obj  0.023404468557961515\n",
      "obj  0.02340446855796151\n",
      "obj  0.023404467679182115\n",
      "obj  0.023404467679182115\n",
      "obj  0.023404467461263873\n",
      "obj  0.023404467461263873\n",
      "obj  0.023404467407675333\n",
      "obj  0.023404467407675333\n",
      "obj  0.023404467394724047\n",
      "obj  0.023404467394724047\n",
      "obj  0.023404467391709188\n",
      "obj  0.023404467391709188\n",
      "obj  0.02340446739106696\n",
      "obj  0.02340446739106696\n",
      "obj  0.023404467390962146\n",
      "obj  0.023404467390962146\n",
      "obj  0.02340446739096382\n",
      "obj  0.023404467390963822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.02340446739097817\n",
      "obj  0.023404467390962552\n",
      "obj  0.023404467390962552\n",
      "obj  0.023404467390969234\n",
      "obj  0.023404467390969234\n",
      "obj  0.023404467390973422\n",
      "obj  0.023404467390973422\n",
      "obj  0.023404467390975736\n",
      "obj  0.023404467390975736\n",
      "obj  0.02340446739097694\n",
      "obj  0.023404467390975722\n",
      "obj  0.023404467390975722\n",
      "obj  0.023404467390976326\n",
      "obj  0.023404467390976322\n",
      "obj  0.02340446739097663\n",
      "obj  0.023404467390976628\n",
      "obj  0.02340446739097678\n",
      "obj  0.023404467390976777\n",
      "obj  0.023404467390976853\n",
      "obj  0.023404467390976864\n",
      "obj  0.023404467390976777\n",
      "obj  0.023404467390976704\n",
      "obj  0.023404467390976624\n",
      "obj  0.02340446739097663\n",
      "obj  0.02340446739097667\n",
      "obj  0.02340446739097667\n",
      "obj  0.023404467390976628\n",
      "obj  0.023404467390976628\n",
      "obj  0.023404467390976652\n",
      "obj  0.023404467390976652\n",
      "v20 d-1 f0 t3: original ll 0.0257 auc 0.9964, ensemble ll 0.0261 auc 0.9964\n",
      "running time 58.501359939575195\n",
      "starting fold 0 target 4\n",
      "obj  0.06295573168869423\n",
      "obj  0.0635228633220118\n",
      "obj  0.06351949691371905\n",
      "obj  0.06351709882686139\n",
      "obj  0.06351457369449216\n",
      "obj  0.0635325267140186\n",
      "obj  0.06351677194030236\n",
      "obj  0.06342377267182511\n",
      "obj  0.06329002887601026\n",
      "obj  0.06294756462486706\n",
      "obj  0.06289612162759471\n",
      "obj  0.06284651690538648\n",
      "obj  0.06284086663330962\n",
      "obj  0.06283100551834596\n",
      "obj  0.06277789774702906\n",
      "obj  0.06277467374775404\n",
      "obj  0.06277449258812955\n",
      "obj  0.06277433373498761\n",
      "obj  0.06277430421417922\n",
      "obj  0.06277429854032202\n",
      "v20 d-1 f0 t4: original ll 0.0653 auc 0.9817, ensemble ll 0.0650 auc 0.9818\n",
      "running time 9.45165729522705\n",
      "starting fold 0 target 5\n",
      "obj  0.07715903878021836\n",
      "obj  0.07776767742146742\n",
      "obj  0.07776363497407279\n",
      "obj  0.07776031574692048\n",
      "obj  0.07776341212685385\n",
      "obj  0.0777094386431734\n",
      "obj  0.07771730745880523\n",
      "obj  0.07764275778507503\n",
      "obj  0.07725691644638807\n",
      "obj  0.07709051232157058\n",
      "obj  0.07704299965621787\n",
      "obj  0.07703879570970303\n",
      "obj  0.07703123132037859\n",
      "obj  0.07694774622378317\n",
      "obj  0.07693826842417356\n",
      "obj  0.07693550981221706\n",
      "obj  0.07693475987335595\n",
      "obj  0.07693456329353654\n",
      "obj  0.07693454082525891\n",
      "v20 d-1 f0 t5: original ll 0.0809 auc 0.9791, ensemble ll 0.0807 auc 0.9791\n",
      "running time 9.057739019393921\n",
      "starting fold 1 target 0\n",
      "obj  0.09472019991910413\n",
      "obj  0.09818603270303078\n",
      "obj  0.0981762975399618\n",
      "obj  0.09816550865657832\n",
      "obj  0.09815677659769582\n",
      "obj  0.09812592783926767\n",
      "obj  0.09810832199493864\n",
      "obj  0.09787521310219155\n",
      "obj  0.09552851929804687\n",
      "obj  0.09540155929854738\n",
      "obj  0.0953109608230024\n",
      "obj  0.0952474239168819\n",
      "obj  0.0952050600187406\n",
      "obj  0.0951707767821968\n",
      "obj  0.09514620603367939\n",
      "obj  0.09512761627675309\n",
      "obj  0.09511658389289414\n",
      "obj  0.09511031631493064\n",
      "obj  0.09510593392567748\n",
      "obj  0.09510212151076015\n",
      "obj  0.09509249133658072\n",
      "obj  0.0950858100519934\n",
      "obj  0.09507825942023053\n",
      "obj  0.09507137927499679\n",
      "obj  0.09506782922769196\n",
      "obj  0.09506676130179771\n",
      "obj  0.09506535202079867\n",
      "obj  0.09506076260431139\n",
      "obj  0.09505570970580211\n",
      "obj  0.09505242434000376\n",
      "obj  0.09505011346694782\n",
      "obj  0.09504996165175182\n",
      "obj  0.09504767946898934\n",
      "obj  0.09504440056929635\n",
      "obj  0.09501783274257286\n",
      "obj  0.09496343715561643\n",
      "obj  0.09492961194441432\n",
      "obj  0.0949097049571981\n",
      "obj  0.09488539860850206\n",
      "obj  0.09486081295513048\n",
      "obj  0.09484843171405187\n",
      "obj  0.0948331219035858\n",
      "obj  0.09481554992658538\n",
      "obj  0.0947959334907441\n",
      "obj  0.09477867486767465\n",
      "obj  0.09476453398730351\n",
      "obj  0.09475100575942548\n",
      "obj  0.09473503270157589\n",
      "obj  0.09472057584979705\n",
      "obj  0.09470685025651389\n",
      "obj  0.09469439340770601\n",
      "obj  0.09468054220166687\n",
      "obj  0.09466563457528564\n",
      "obj  0.0946515543025622\n",
      "obj  0.09463955687122892\n",
      "obj  0.0946294063053275\n",
      "obj  0.09461935896242422\n",
      "obj  0.09460971013294558\n",
      "obj  0.09459983874339922\n",
      "obj  0.0945914212406808\n",
      "obj  0.09458415443704474\n",
      "obj  0.09457776046555602\n",
      "obj  0.09457206679776445\n",
      "obj  0.09456469865847093\n",
      "obj  0.09455563774884454\n",
      "obj  0.09454546747808637\n",
      "obj  0.09453523007317359\n",
      "obj  0.09452578320395631\n",
      "obj  0.09451603481075256\n",
      "obj  0.09448045192467151\n",
      "obj  0.09447463581313073\n",
      "obj  0.09447024549918084\n",
      "obj  0.09446525464326523\n",
      "obj  0.09443678919401043\n",
      "obj  0.09443223052882888\n",
      "obj  0.09442875811571859\n",
      "obj  0.09442770589988132\n",
      "obj  0.09442740990455148\n",
      "obj  0.09442731991962447\n",
      "obj  0.09442729199091586\n",
      "obj  0.09442728462863824\n",
      "v20 d-1 f1 t0: original ll 0.0970 auc 0.9869, ensemble ll 0.0967 auc 0.9869\n",
      "running time 36.64317321777344\n",
      "starting fold 1 target 1\n",
      "obj  0.0150960445432726\n",
      "obj  0.01503262262066602\n",
      "obj  0.014988871222253258\n",
      "obj  0.015010822282481826\n",
      "obj  0.015086660782584653\n",
      "obj  0.015061358671805988\n",
      "obj  0.015082616668832705\n",
      "obj  0.015073622133380185\n",
      "obj  0.015002761317515179\n",
      "obj  0.014748501986762546\n",
      "obj  0.014716004840328555\n",
      "obj  0.014690020231170652\n",
      "obj  0.014684370053998187\n",
      "obj  0.014682961283763557\n",
      "obj  0.01468291266392542\n",
      "obj  0.014682474703028478\n",
      "obj  0.014682427929257632\n",
      "obj  0.014682419279083763\n",
      "v20 d-1 f1 t1: original ll 0.0129 auc 0.9660, ensemble ll 0.0127 auc 0.9667\n",
      "running time 8.982362508773804\n",
      "starting fold 1 target 2\n",
      "obj  0.04010135681862539\n",
      "obj  0.041083747901113694\n",
      "obj  0.04107966449775558\n",
      "obj  0.041076121061429764\n",
      "obj  0.04107580359518549\n",
      "obj  0.041016271021106214\n",
      "obj  0.04102838668112937\n",
      "obj  0.04089498831465358\n",
      "obj  0.040076270377876665\n",
      "obj  0.04001452767160573\n",
      "obj  0.039950135428339716\n",
      "obj  0.03991515858889329\n",
      "obj  0.039904174957046575\n",
      "obj  0.03990067286043638\n",
      "obj  0.03989076829822133\n",
      "obj  0.03988000688874188\n",
      "obj  0.03987527542320051\n",
      "obj  0.03987104527848787\n",
      "obj  0.0398619502613819\n",
      "obj  0.03986162429078888\n",
      "obj  0.03986162164776565\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162167486342\n",
      "obj  0.03986162162808341\n",
      "obj  0.0398616216017409\n",
      "obj  0.03986161935024513\n",
      "obj  0.03986161887683495\n",
      "obj  0.039861618866514355\n",
      "obj  0.03986161633203789\n",
      "v20 d-1 f1 t2: original ll 0.0407 auc 0.9927, ensemble ll 0.0405 auc 0.9927\n",
      "running time 13.85965609550476\n",
      "starting fold 1 target 3\n",
      "obj  0.024803978802564984\n",
      "obj  0.02557161809824066\n",
      "obj  0.02557032327158848\n",
      "obj  0.025569481319233676\n",
      "obj  0.025570928560301676\n",
      "obj  0.025540971269404335\n",
      "obj  0.025548075190833828\n",
      "obj  0.025471654401270506\n",
      "obj  0.024807612440911675\n",
      "obj  0.024741904480577812\n",
      "obj  0.02472105380699628\n",
      "obj  0.024694914180184616\n",
      "obj  0.02468993051082698\n",
      "obj  0.024686179363967695\n",
      "obj  0.024686107786960124\n",
      "obj  0.024682719181731802\n",
      "obj  0.024681204113234035\n",
      "obj  0.02468061546836755\n",
      "obj  0.024679043880339757\n",
      "obj  0.02467836382795095\n",
      "obj  0.024676885066268386\n",
      "obj  0.024673304266767292\n",
      "obj  0.024668044071955816\n",
      "obj  0.02466320318539051\n",
      "obj  0.02466194703736709\n",
      "obj  0.02466161910582966\n",
      "obj  0.024661556370854532\n",
      "obj  0.024661542904863942\n",
      "obj  0.024661531280673693\n",
      "obj  0.024661527560972903\n",
      "v20 d-1 f1 t3: original ll 0.0233 auc 0.9971, ensemble ll 0.0233 auc 0.9971\n",
      "running time 14.279965162277222\n",
      "starting fold 1 target 4\n",
      "obj  0.06408288902479159\n",
      "obj  0.06443310328880372\n",
      "obj  0.06443150091066101\n",
      "obj  0.0644301290159616\n",
      "obj  0.06442509344623935\n",
      "obj  0.06447084902406197\n",
      "obj  0.06444256318925184\n",
      "obj  0.06441142501824511\n",
      "obj  0.06476874940754104\n",
      "obj  0.06476231954626131\n",
      "obj  0.06475612011181239\n",
      "obj  0.06475014564019486\n",
      "obj  0.06474210273443695\n",
      "obj  0.06473361497982127\n",
      "obj  0.06472591517793352\n",
      "obj  0.06471876302570205\n",
      "obj  0.06471202690152004\n",
      "obj  0.06470563114576537\n",
      "obj  0.06469952448836187\n",
      "obj  0.06464255796254328\n",
      "obj  0.06463692789350405\n",
      "obj  0.06463156076471935\n",
      "obj  0.06462643441879747\n",
      "obj  0.06462153144678941\n",
      "obj  0.0646168327965542\n",
      "obj  0.06461232313197145\n",
      "obj  0.06457222471382135\n",
      "obj  0.06456686808844692\n",
      "obj  0.06453166150778646\n",
      "obj  0.06452751053993908\n",
      "obj  0.0645236174262209\n",
      "obj  0.06449228993164434\n",
      "obj  0.0644578271701812\n",
      "obj  0.06442349872797767\n",
      "obj  0.06438749321148951\n",
      "obj  0.06435297990214284\n",
      "obj  0.06432277112740642\n",
      "obj  0.06429276964575789\n",
      "obj  0.06425426970391886\n",
      "obj  0.06422154905023345\n",
      "obj  0.06419494153630875\n",
      "obj  0.06417583036503827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.06415417585627811\n",
      "obj  0.06413414307382945\n",
      "obj  0.06411605834833829\n",
      "obj  0.06410001277242743\n",
      "obj  0.06408564850122238\n",
      "obj  0.06406559546793893\n",
      "obj  0.06404903992514785\n",
      "obj  0.06403204987974903\n",
      "obj  0.06401988215239073\n",
      "obj  0.06401359624473833\n",
      "obj  0.06400927364253349\n",
      "obj  0.06400259458084459\n",
      "obj  0.0639997445070301\n",
      "obj  0.06399620019143554\n",
      "obj  0.06399232789617439\n",
      "obj  0.06398907377678024\n",
      "obj  0.06398626888895763\n",
      "obj  0.06398304278264187\n",
      "obj  0.06397966615154316\n",
      "obj  0.06397955194856803\n",
      "obj  0.06397645928155055\n",
      "obj  0.06397565649991747\n",
      "obj  0.06397533774453759\n",
      "obj  0.06396832384713508\n",
      "obj  0.06396828271821123\n",
      "obj  0.06396835244695807\n",
      "obj  0.06396840870271751\n",
      "obj  0.06396716877610117\n",
      "obj  0.06396645111043867\n",
      "obj  0.06395988460824376\n",
      "obj  0.06395939181519518\n",
      "obj  0.06395905968187744\n",
      "obj  0.06395883895453147\n",
      "obj  0.06395870053613617\n",
      "obj  0.06395862505447666\n",
      "obj  0.0639585980683189\n",
      "obj  0.06395860968991059\n",
      "obj  0.06395865323901459\n",
      "obj  0.06395872251175763\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881413166837\n",
      "obj  0.06395881366017853\n",
      "obj  0.06395881366017854\n",
      "obj  0.06395876299585486\n",
      "obj  0.06395880920093042\n",
      "obj  0.06395880920093043\n",
      "obj  0.06395878485637972\n",
      "obj  0.06395878485637972\n",
      "obj  0.06395877361771363\n",
      "obj  0.06395877361771364\n",
      "obj  0.06395876823145626\n",
      "obj  0.06395876823145627\n",
      "obj  0.06395876559478389\n",
      "obj  0.06395876559478389\n",
      "obj  0.06395876429059648\n",
      "obj  0.06395876429059648\n",
      "obj  0.06395876364204432\n",
      "obj  0.06395876364204432\n",
      "obj  0.06395876331865419\n",
      "obj  0.06395876331865419\n",
      "obj  0.06395876315718063\n",
      "obj  0.06395876315718063\n",
      "obj  0.06395876307649931\n",
      "obj  0.0639587631571639\n",
      "obj  0.0639587631571639\n",
      "obj  0.063958763116827\n",
      "obj  0.06395876315715972\n",
      "obj  0.0639587631571597\n",
      "obj  0.06395876313699221\n",
      "obj  0.0639587631369922\n",
      "obj  0.0639587631269093\n",
      "obj  0.06395876313699196\n",
      "obj  0.06395876313195055\n",
      "obj  0.06395876313195055\n",
      "obj  0.06395876312942993\n",
      "obj  0.06395876312942993\n",
      "obj  0.06395876312816959\n",
      "obj  0.06395876312816959\n",
      "obj  0.06395876312942991\n",
      "obj  0.06395876312942993\n",
      "obj  0.06395876312879975\n",
      "obj  0.06395876312879975\n",
      "obj  0.06395876312848467\n",
      "obj  0.06395876312848467\n",
      "obj  0.06395876312832714\n",
      "obj  0.06395876312832714\n",
      "obj  0.0639587631282484\n",
      "obj  0.06395876312824839\n",
      "obj  0.063958763128209\n",
      "obj  0.063958763128209\n",
      "obj  0.06395876312816959\n",
      "obj  0.06395885352917437\n",
      "obj  0.06395885352917437\n",
      "obj  0.06395884980090452\n",
      "obj  0.06395884980090452\n",
      "obj  0.06395880205753915\n",
      "obj  0.06395880205753915\n",
      "obj  0.06395878150213478\n",
      "obj  0.06395878150213478\n",
      "obj  0.06395877204332584\n",
      "obj  0.06395877204332584\n",
      "obj  0.06395876751928449\n",
      "obj  0.06395876530707724\n",
      "obj  0.06395876530707724\n",
      "obj  0.06395876421345668\n",
      "obj  0.06395876421345668\n",
      "obj  0.0639587636697709\n",
      "obj  0.0639587636697709\n",
      "obj  0.06395876339870965\n",
      "obj  0.06395876339870965\n",
      "obj  0.06395876326337446\n",
      "obj  0.06395876326337446\n",
      "obj  0.06395876319575573\n",
      "obj  0.06395876319575573\n",
      "obj  0.06395876316195857\n",
      "obj  0.06395876316195857\n",
      "obj  0.06395876314506307\n",
      "obj  0.06395876314506307\n",
      "obj  0.06395876313661608\n",
      "obj  0.06395876313661608\n",
      "obj  0.06395876313239278\n",
      "obj  0.06395876313239278\n",
      "obj  0.06395876313028116\n",
      "obj  0.06395876313028116\n",
      "obj  0.06395876312922538\n",
      "obj  0.06395876312922538\n",
      "obj  0.06395876312869749\n",
      "obj  0.06395876312869749\n",
      "obj  0.06395876312843354\n",
      "obj  0.06395876312843354\n",
      "obj  0.06395876312830158\n",
      "obj  0.06395876312830157\n",
      "obj  0.0639587631282356\n",
      "obj  0.0639587631282026\n",
      "obj  0.0639587631282026\n",
      "obj  0.06395876312816959\n",
      "obj  0.06395885129489738\n",
      "obj  0.06395885129489738\n",
      "obj  0.06395884716117854\n",
      "obj  0.06395884716117854\n",
      "obj  0.06395880081298903\n",
      "obj  0.06395880081298903\n",
      "obj  0.06395878089957686\n",
      "obj  0.06395878089957686\n",
      "obj  0.06395877174692707\n",
      "obj  0.06395877174692707\n",
      "obj  0.06395876737226262\n",
      "obj  0.06395876737226262\n",
      "obj  0.06395876523386133\n",
      "obj  0.06395876523386133\n",
      "obj  0.06395876417692258\n",
      "obj  0.06395876417692258\n",
      "obj  0.06395876365152234\n",
      "obj  0.06395876365152234\n",
      "obj  0.06395876338958999\n",
      "obj  0.06395876338958999\n",
      "obj  0.06395876325881579\n",
      "obj  0.06395876325881579\n",
      "obj  0.06395876319347668\n",
      "obj  0.06395876316081914\n",
      "obj  0.06395876316081914\n",
      "obj  0.06395876314449338\n",
      "obj  0.06395876313633121\n",
      "obj  0.06395876313633121\n",
      "obj  0.06395876313225035\n",
      "obj  0.06395876313225035\n",
      "obj  0.06395876313020994\n",
      "obj  0.06395876313020994\n",
      "obj  0.06395876312918976\n",
      "obj  0.06395876312867971\n",
      "obj  0.06395876312867971\n",
      "obj  0.06395876312842463\n",
      "obj  0.06395876312842463\n",
      "obj  0.06395876312829715\n",
      "obj  0.06395876312829715\n",
      "obj  0.06395876312823337\n",
      "obj  0.06395876312823337\n",
      "obj  0.06395876312820148\n",
      "obj  0.06395876312816959\n",
      "obj  0.06395885084842871\n",
      "obj  0.06395885084842874\n",
      "obj  0.06395884663789067\n",
      "obj  0.06395884663789066\n",
      "obj  0.06395880056614899\n",
      "obj  0.06395880056614899\n",
      "obj  0.0639587807799902\n",
      "obj  0.0639587807799902\n",
      "obj  0.06395877168808933\n",
      "obj  0.06395877168808933\n",
      "obj  0.06395876734307432\n",
      "obj  0.06395876734307432\n",
      "obj  0.06395876521932493\n",
      "obj  0.06395876416966886\n",
      "obj  0.06395876416966886\n",
      "obj  0.06395876364789908\n",
      "obj  0.06395876364789908\n",
      "obj  0.06395876338777925\n",
      "obj  0.06395876338777927\n",
      "obj  0.06395876325791067\n",
      "obj  0.06395876325791065\n",
      "obj  0.06395876319302414\n",
      "obj  0.06395876319302414\n",
      "obj  0.0639587631605929\n",
      "obj  0.0639587631605929\n",
      "obj  0.06395876314438025\n",
      "obj  0.06395876314438025\n",
      "obj  0.06395876313627466\n",
      "obj  0.06395876313627466\n",
      "obj  0.0639587631322221\n",
      "obj  0.0639587631322221\n",
      "obj  0.06395876313019583\n",
      "obj  0.06395876313019581\n",
      "obj  0.06395876312918274\n",
      "obj  0.06395876312918274\n",
      "obj  0.06395876312867615\n",
      "obj  0.06395876312842287\n",
      "obj  0.06395876312829626\n",
      "obj  0.06395876312829626\n",
      "obj  0.0639587631282329\n",
      "obj  0.0639587631282329\n",
      "obj  0.06395876312820126\n",
      "obj  0.06395876312820126\n",
      "obj  0.06395876312816959\n",
      "obj  0.0639588507591498\n",
      "obj  0.0639588507591498\n",
      "obj  0.06395884653341655\n",
      "obj  0.06395884653341655\n",
      "obj  0.06395880051686023\n",
      "obj  0.06395880051686023\n",
      "obj  0.06395878075610928\n",
      "obj  0.06395878075610928\n",
      "obj  0.06395877167633919\n",
      "obj  0.06395877167633919\n",
      "obj  0.06395876733724515\n",
      "obj  0.06395876733724515\n",
      "obj  0.06395876521642187\n",
      "obj  0.06395876521642188\n",
      "obj  0.06395876416822019\n",
      "obj  0.06395876416822019\n",
      "obj  0.06395876364717548\n",
      "obj  0.06395876364717548\n",
      "obj  0.06395876338741761\n",
      "obj  0.06395876338741761\n",
      "obj  0.06395876325772985\n",
      "obj  0.0639587631929338\n",
      "obj  0.06395876319293382\n",
      "obj  0.06395876316054772\n",
      "obj  0.06395876316054772\n",
      "obj  0.06395876314435764\n",
      "obj  0.06395876314435764\n",
      "obj  0.06395876313626339\n",
      "obj  0.06395876313626339\n",
      "obj  0.06395876313221645\n",
      "obj  0.06395876313221642\n",
      "obj  0.06395876313019298\n",
      "obj  0.0639587631291813\n",
      "obj  0.0639587631291813\n",
      "obj  0.06395876312867546\n",
      "obj  0.06395876312867546\n",
      "obj  0.06395876312842251\n",
      "obj  0.06395876312842251\n",
      "obj  0.06395876312829604\n",
      "obj  0.06395876312829604\n",
      "obj  0.06395876312823284\n",
      "obj  0.06395876312823284\n",
      "obj  0.06395876312820124\n",
      "obj  0.06395876312820124\n",
      "v20 d-1 f1 t4: original ll 0.0630 auc 0.9814, ensemble ll 0.0632 auc 0.9814\n",
      "running time 51.06687307357788\n",
      "starting fold 1 target 5\n",
      "obj  0.07783167797519104\n",
      "obj  0.07836338202202164\n",
      "obj  0.07835892234915103\n",
      "obj  0.07835627088195035\n",
      "obj  0.07835598715371299\n",
      "obj  0.0783511739186729\n",
      "obj  0.07834179162908414\n",
      "obj  0.07829441337581947\n",
      "obj  0.07807473517184402\n",
      "obj  0.07769059326252452\n",
      "obj  0.07764162821694601\n",
      "obj  0.07762355638318641\n",
      "obj  0.07761889148618183\n",
      "obj  0.07761294847865889\n",
      "obj  0.07757748685489076\n",
      "obj  0.07755393505765949\n",
      "obj  0.07755304332784117\n",
      "obj  0.07755294484637444\n",
      "obj  0.07755285766853046\n",
      "obj  0.07755285087103085\n",
      "obj  0.07755284880253159\n",
      "v20 d-1 f1 t5: original ll 0.0796 auc 0.9793, ensemble ll 0.0795 auc 0.9792\n",
      "running time 10.598271608352661\n",
      "starting fold 2 target 0\n",
      "obj  0.09659635551194669\n",
      "obj  0.099695024698987\n",
      "obj  0.09968601961836379\n",
      "obj  0.09967893748513734\n",
      "obj  0.09967299480915848\n",
      "obj  0.09964649902741779\n",
      "obj  0.09963570536631954\n",
      "obj  0.09943008453195834\n",
      "obj  0.09732155972381555\n",
      "obj  0.09721400740230424\n",
      "obj  0.0971364343074328\n",
      "obj  0.09708148074493841\n",
      "obj  0.09704349364840671\n",
      "obj  0.09700415034291351\n",
      "obj  0.09697450457658567\n",
      "obj  0.09695116004439024\n",
      "obj  0.09693421339125155\n",
      "obj  0.09692216657508743\n",
      "obj  0.09691136210293141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.09689541001528162\n",
      "obj  0.09688907755288796\n",
      "obj  0.096884755248136\n",
      "obj  0.09688101224882756\n",
      "obj  0.09687777523080188\n",
      "obj  0.09687490710398053\n",
      "obj  0.09687251073036823\n",
      "obj  0.09687083531062413\n",
      "obj  0.09686946787928635\n",
      "obj  0.09686864472820479\n",
      "obj  0.09686822201938913\n",
      "obj  0.09686809668430921\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686849670572319\n",
      "obj  0.09686849670572041\n",
      "obj  0.09686905460643068\n",
      "obj  0.09686905460642903\n",
      "obj  0.09686982754763813\n",
      "obj  0.09686982754763801\n",
      "obj  0.09686846399887122\n",
      "obj  0.09686846399887125\n",
      "obj  0.09686819841841239\n",
      "obj  0.09686812675827423\n",
      "obj  0.09686812675827423\n",
      "obj  0.0968681057236874\n",
      "obj  0.0968681057236874\n",
      "obj  0.09686809941441217\n",
      "obj  0.09686809941441218\n",
      "obj  0.09686809751006822\n",
      "obj  0.0968680975100682\n",
      "obj  0.09686809693419851\n",
      "obj  0.09686809693419847\n",
      "obj  0.09686809675995844\n",
      "obj  0.09686809675995844\n",
      "obj  0.09686809670722986\n",
      "obj  0.09686809670722982\n",
      "obj  0.09686809669127229\n",
      "obj  0.09686809669127228\n",
      "obj  0.09686809668644283\n",
      "obj  0.09686809668430921\n",
      "obj  0.09686855170329137\n",
      "obj  0.09686855170327767\n",
      "obj  0.0968691078691254\n",
      "obj  0.09686910786911752\n",
      "obj  0.09686986335279961\n",
      "obj  0.0968698633527991\n",
      "obj  0.0968684580876199\n",
      "obj  0.09686845808761994\n",
      "obj  0.09686819753398668\n",
      "obj  0.09686819753398668\n",
      "obj  0.09686812665451143\n",
      "obj  0.09686812665451147\n",
      "obj  0.09686810573643656\n",
      "obj  0.09686810573643656\n",
      "obj  0.0968680994313453\n",
      "obj  0.09686809943134525\n",
      "obj  0.09686809751914846\n",
      "obj  0.0968680969381487\n",
      "obj  0.09686809693814867\n",
      "obj  0.09686809676151947\n",
      "obj  0.09686809676151949\n",
      "obj  0.0968680967078135\n",
      "obj  0.09686809670781345\n",
      "obj  0.09686809669148275\n",
      "obj  0.09686809668651689\n",
      "obj  0.09686809668651687\n",
      "obj  0.09686809668430921\n",
      "obj  0.09686856265199306\n",
      "obj  0.09686856265197095\n",
      "obj  0.09686911766126423\n",
      "obj  0.09686911766125149\n",
      "obj  0.09686986880626441\n",
      "obj  0.09686986880626358\n",
      "obj  0.09686845868468677\n",
      "obj  0.0968684586846868\n",
      "obj  0.09686819781471882\n",
      "obj  0.09686819781471882\n",
      "obj  0.09686812676885083\n",
      "obj  0.09686812676885083\n",
      "obj  0.09686810578025165\n",
      "obj  0.09686810578025165\n",
      "obj  0.09686809944746821\n",
      "obj  0.09686809944746821\n",
      "obj  0.09686809752490998\n",
      "obj  0.09686809752490995\n",
      "obj  0.09686809694016286\n",
      "obj  0.09686809694016285\n",
      "obj  0.0968680967622119\n",
      "obj  0.0968680967622119\n",
      "obj  0.0968680967080484\n",
      "obj  0.09686809670804837\n",
      "obj  0.09686809669156161\n",
      "obj  0.09686809669156157\n",
      "obj  0.0968680966865431\n",
      "obj  0.09686809668654306\n",
      "obj  0.09686809668430921\n",
      "obj  0.09686856483998905\n",
      "obj  0.09686856483997426\n",
      "obj  0.09686911958829267\n",
      "obj  0.09686911958828412\n",
      "obj  0.09686986983460659\n",
      "obj  0.09686986983460603\n",
      "obj  0.09686845887226633\n",
      "obj  0.0968684588722663\n",
      "obj  0.096868197888584\n",
      "obj  0.09686819788858397\n",
      "obj  0.09686812679698775\n",
      "obj  0.09686812679698775\n",
      "obj  0.09686810579063512\n",
      "obj  0.0968681057906351\n",
      "obj  0.09686809945119633\n",
      "obj  0.09686809945119637\n",
      "obj  0.09686809752621929\n",
      "obj  0.09686809752621925\n",
      "obj  0.09686809694061473\n",
      "obj  0.09686809694061473\n",
      "obj  0.09686809676236567\n",
      "obj  0.09686809676236567\n",
      "obj  0.09686809670810018\n",
      "obj  0.09686809670810018\n",
      "obj  0.09686809669157896\n",
      "obj  0.0968680966865489\n",
      "obj  0.09686809668654887\n",
      "v20 d-1 f2 t0: original ll 0.0933 auc 0.9884, ensemble ll 0.0942 auc 0.9885\n",
      "running time 21.39896535873413\n",
      "starting fold 2 target 1\n",
      "obj  0.014196809175808055\n",
      "obj  0.014155892368269593\n",
      "obj  0.014133327743230673\n",
      "obj  0.014144957608746159\n",
      "obj  0.014226713792437663\n",
      "obj  0.01417236537268323\n",
      "obj  0.014187011855940821\n",
      "obj  0.014178406853994234\n",
      "obj  0.014122659927254382\n",
      "obj  0.01391273616962019\n",
      "obj  0.013887520281312408\n",
      "obj  0.013867756394763689\n",
      "obj  0.013861415298855618\n",
      "obj  0.013860197755574306\n",
      "obj  0.013860004055886185\n",
      "obj  0.013859973356935947\n",
      "obj  0.01385997012123686\n",
      "v20 d-1 f2 t1: original ll 0.0149 auc 0.9726, ensemble ll 0.0145 auc 0.9752\n",
      "running time 8.915140628814697\n",
      "starting fold 2 target 2\n",
      "obj  0.04167121479656551\n",
      "obj  0.04261278786261392\n",
      "obj  0.042608233244858976\n",
      "obj  0.042605381813909535\n",
      "obj  0.04260878942376248\n",
      "obj  0.04253937207183761\n",
      "obj  0.042557302395081\n",
      "obj  0.04244200364106042\n",
      "obj  0.04147203917791002\n",
      "obj  0.04143761316723078\n",
      "obj  0.041434374303149245\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.041434390415895105\n",
      "obj  0.04143438911678584\n",
      "obj  0.04143438911678584\n",
      "obj  0.04143434358554022\n",
      "obj  0.04143438724049621\n",
      "obj  0.04143438724049621\n",
      "obj  0.04143435629616567\n",
      "obj  0.04143435629616567\n",
      "obj  0.04143434765969955\n",
      "obj  0.04143434765969955\n",
      "obj  0.041434345052552723\n",
      "obj  0.041434345052552723\n",
      "obj  0.04143434417759797\n",
      "obj  0.04143434417759797\n",
      "obj  0.04143434384620621\n",
      "obj  0.04143434384620621\n",
      "obj  0.04143434370703241\n",
      "obj  0.04143434370703241\n",
      "obj  0.04143434364407608\n",
      "obj  0.04143434364407608\n",
      "obj  0.0414343436142556\n",
      "obj  0.041434343599759775\n",
      "obj  0.04143434359975977\n",
      "obj  0.04143434359261545\n",
      "obj  0.04143434358906918\n",
      "obj  0.041434343589069174\n",
      "obj  0.04143434358730254\n",
      "obj  0.041434343587302545\n",
      "obj  0.041434343586420834\n",
      "obj  0.041434343586420834\n",
      "obj  0.04143434358598039\n",
      "obj  0.04143434358598039\n",
      "obj  0.041434343585760265\n",
      "obj  0.041434343585760265\n",
      "obj  0.04143434358565023\n",
      "obj  0.04143434358565023\n",
      "obj  0.04143434358559521\n",
      "obj  0.04143434358556772\n",
      "obj  0.04143434358555395\n",
      "obj  0.04143434358555395\n",
      "obj  0.041434343585547075\n",
      "obj  0.041434343585547075\n",
      "obj  0.04143434358554365\n",
      "obj  0.04143434358554022\n",
      "obj  0.041433961471586955\n",
      "obj  0.041433187372905224\n",
      "obj  0.04143198887284365\n",
      "obj  0.041425734807232203\n",
      "obj  0.041417798535548306\n",
      "obj  0.04141454033344227\n",
      "obj  0.04141432150372722\n",
      "obj  0.041414319165559675\n",
      "obj  0.04141427436857977\n",
      "obj  0.041414266412742415\n",
      "v20 d-1 f2 t2: original ll 0.0379 auc 0.9933, ensemble ll 0.0377 auc 0.9934\n",
      "running time 13.337298154830933\n",
      "starting fold 2 target 3\n",
      "obj  0.02446661270482108\n",
      "obj  0.025393279195486704\n",
      "obj  0.025390219385607073\n",
      "obj  0.025387431985941664\n",
      "obj  0.025387765408161185\n",
      "obj  0.02535916174648208\n",
      "obj  0.025362927996059076\n",
      "obj  0.025280528050139386\n",
      "obj  0.024643678449676437\n",
      "obj  0.024520532551747715\n",
      "obj  0.02448544358704175\n",
      "obj  0.024447208904560234\n",
      "obj  0.024425300907983737\n",
      "obj  0.024390009894652284\n",
      "obj  0.02438385461728391\n",
      "obj  0.024375029252843496\n",
      "obj  0.024359976829728163\n",
      "obj  0.0243452721344837\n",
      "obj  0.024345063920143576\n",
      "obj  0.024344996729215362\n",
      "obj  0.024344981168777837\n",
      "obj  0.024344980945620282\n",
      "obj  0.02434498092258828\n",
      "obj  0.02434498092252976\n",
      "obj  0.024344980922520493\n",
      "v20 d-1 f2 t3: original ll 0.0239 auc 0.9970, ensemble ll 0.0238 auc 0.9970\n",
      "running time 12.526605129241943\n",
      "starting fold 2 target 4\n",
      "obj  0.06405215923756957\n",
      "obj  0.06445977514009256\n",
      "obj  0.06445903992422364\n",
      "obj  0.06445899705745059\n",
      "obj  0.06445854875911147\n",
      "obj  0.06446446739099276\n",
      "obj  0.06445899264308479\n",
      "obj  0.0644336098107188\n",
      "obj  0.06424055360880962\n",
      "obj  0.06415303950601933\n",
      "obj  0.06407716951943722\n",
      "obj  0.0639976718608569\n",
      "obj  0.06392021217076319\n",
      "obj  0.06388426308270298\n",
      "obj  0.0638768592624368\n",
      "obj  0.06386494223810871\n",
      "obj  0.06385510664802535\n",
      "obj  0.06385283851339359\n",
      "obj  0.0638514170820282\n",
      "obj  0.06384938614663858\n",
      "obj  0.06384652213081224\n",
      "obj  0.06384107489878216\n",
      "obj  0.06383536691820355\n",
      "obj  0.06383200042342627\n",
      "obj  0.06382072591824643\n",
      "obj  0.06379236474919914\n",
      "obj  0.06379204106672758\n",
      "obj  0.06379139197612417\n",
      "obj  0.06379120788123843\n",
      "obj  0.06379115077443466\n",
      "obj  0.06379113880332622\n",
      "v20 d-1 f2 t4: original ll 0.0630 auc 0.9828, ensemble ll 0.0631 auc 0.9828\n",
      "running time 15.204179525375366\n",
      "starting fold 2 target 5\n",
      "obj  0.08017497313132747\n",
      "obj  0.08072464883560992\n",
      "obj  0.0807196567468799\n",
      "obj  0.08071700898106295\n",
      "obj  0.08071403537842915\n",
      "obj  0.08071823547621992\n",
      "obj  0.08070468839906973\n",
      "obj  0.08063391267591283\n",
      "obj  0.08035053908261756\n",
      "obj  0.08006565474163907\n",
      "obj  0.0799422850652063\n",
      "obj  0.07994070920864947\n",
      "obj  0.07993645591564945\n",
      "obj  0.0799299013905697\n",
      "obj  0.07991547619367528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.0799153203595179\n",
      "obj  0.0799153121104425\n",
      "obj  0.07991531105628634\n",
      "obj  0.07991531104549046\n",
      "obj  0.07991531104225029\n",
      "obj  0.07991531104213886\n",
      "obj  0.07991531104212285\n",
      "obj  0.0799153110421225\n",
      "v20 d-1 f2 t5: original ll 0.0750 auc 0.9823, ensemble ll 0.0750 auc 0.9823\n",
      "running time 11.25537896156311\n",
      "total running time 353.5499176979065\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for fold in range(3):\n",
    "    for target in range(6):\n",
    "        train_ensemble(train_md, preds_all, fold=fold, target=target, ds_idx=-1, first_step=False)\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total running time 353.5499176979065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.05888 ensemble ll 0.05879\n",
      "valid original ll 0.05897 ensemble ll 0.05903\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx == -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.05891 ensemble ll 0.05887\n",
      "valid original ll 0.05900 ensemble ll 0.05908\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx == -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuval_test = pickle.load(open(PATH_DISK/'ensemble/ensemble_test_image_ids.pkl','rb'))\n",
    "assert len(yuval_test) == len(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del test_md['yuval_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(len(yuval_test)), columns=['yuval_idx'])\n",
    "df.index = yuval_test\n",
    "test_md = test_md.join(df, on = 'img_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_y = [\n",
    "           'model_Densenet201_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           'model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           'model_Densenet169_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           'model_se_resnext101_32x4d_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = np.stack([torch.sigmoid(torch.stack([torch.stack(pickle.load(\n",
    "    open(PATH_DISK/'ensemble'/name.format(fold),'rb'))) for fold in range(3)])).numpy() for name in names_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = preds_y[:,:,:,test_md.yuval_idx]\n",
    "#preds_y = preds_y[:,:,:8]\n",
    "preds_y = preds_y[:,:,:,:,np.array([5,0,1,2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(ds, VERSION),'rb')) for ds in range(6,10)])\n",
    "preds = np.concatenate([preds, preds_y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 32, 78545, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any too low inconsistencies\n",
      "1 class: 0.007826740111825492\n",
      "2 class: 0.027612803568018332\n",
      "3 class: 0.015038784826108176\n",
      "4 class: 0.04545294496785282\n",
      "5 class: 0.10785616525558597\n",
      "total 0.16007210237761793\n",
      "any too high inconsistencies\n",
      "total 0.18830389492753624\n"
     ]
    }
   ],
   "source": [
    "preds = predBounding(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total running time 6.308442115783691\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "\n",
    "test_preds_trgt = []\n",
    "for target in range(6):\n",
    "    \n",
    "    test_preds_folds = []\n",
    "    for fold in range(3):\n",
    "        \n",
    "        test_preds = []\n",
    "        for ds_idx in range(len(preds)):\n",
    "            model = pickle.load(open(PATH_DISK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                     .format(ds_idx,fold,target,VERSION),'rb'))\n",
    "            X,y,ll_train,auc_train =  getFirstStepX(None, preds[:,fold], TH=model.prior, \n",
    "                                                    powerLow=model.powerLow, powerHigh=model.powerHigh, \n",
    "                                                    fold=fold, target=target, ds_idx=ds_idx, mode='test')\n",
    "            test_preds.append((X*np.expand_dims(model.x, axis=1)).sum(0))\n",
    "        \n",
    "        X = np.stack(test_preds)\n",
    "        model = pickle.load(open(PATH_DISK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                 .format(-1,fold,target,VERSION),'rb'))\n",
    "        test_preds_folds.append((X*np.expand_dims(model.x, axis=1)).sum(0))\n",
    "    \n",
    "    X = np.stack(test_preds_folds).mean(0)\n",
    "    test_preds_trgt.append(X)\n",
    "\n",
    "predictions = np.stack(test_preds_trgt,axis=1)\n",
    "\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99510113, 0.99522632, 0.99240634, 0.99679458,\n",
       "        0.99379468, 0.99430179, 0.99116944],\n",
       "       [0.99510113, 1.        , 0.99511448, 0.99292783, 0.99379086,\n",
       "        0.99709681, 0.99428716, 0.99158033],\n",
       "       [0.99522632, 0.99511448, 1.        , 0.99273869, 0.9935439 ,\n",
       "        0.99375568, 0.99644583, 0.9913405 ],\n",
       "       [0.99240634, 0.99292783, 0.99273869, 1.        , 0.99134228,\n",
       "        0.99214717, 0.99170904, 0.99803406],\n",
       "       [0.99679458, 0.99379086, 0.9935439 , 0.99134228, 1.        ,\n",
       "        0.99558101, 0.99641115, 0.99219774],\n",
       "       [0.99379468, 0.99709681, 0.99375568, 0.99214717, 0.99558101,\n",
       "        1.        , 0.99572296, 0.99281574],\n",
       "       [0.99430179, 0.99428716, 0.99644583, 0.99170904, 0.99641115,\n",
       "        0.99572296, 1.        , 0.99220243],\n",
       "       [0.99116944, 0.99158033, 0.9913405 , 0.99803406, 0.99219774,\n",
       "        0.99281574, 0.99220243, 1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(preds.mean((1,2))[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78545, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(9, 20),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0.5* (pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 51),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 52),'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 51),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 52),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 53),'rb'))) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet161', 72),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 73),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 74),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 78),'rb'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00797, 0.00125, 0.0039 , 0.0026 , 0.00511, 0.00504],\n",
       "       [0.00727, 0.00117, 0.00363, 0.00238, 0.00469, 0.00434],\n",
       "       [0.00687, 0.00118, 0.00313, 0.00217, 0.00415, 0.00443],\n",
       "       [0.00905, 0.00102, 0.00443, 0.00315, 0.00575, 0.00509]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.std(2).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15249, 0.01507, 0.03719, 0.02508, 0.05596, 0.06206],\n",
       "       [0.14765, 0.01445, 0.03652, 0.02455, 0.05567, 0.05837],\n",
       "       [0.14786, 0.01586, 0.0346 , 0.02439, 0.05371, 0.06038],\n",
       "       [0.1466 , 0.01732, 0.03613, 0.02529, 0.05583, 0.05959]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds.mean((1,2), keepdims=True) * np.log(np.clip(preds,1e-15,1-1e-15)) \n",
    "  - (1 - preds.mean((1,2), keepdims=True)) * np.log(np.clip(1 - preds,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54027, 0.54585, 0.53983, 0.54938])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds.mean((1,2,3), keepdims=True) * np.log(np.clip(preds,1e-15,1-1e-15)) \n",
    "  - (1 - preds.mean((1,2,3), keepdims=True)) * np.log(np.clip(1 - preds,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 75),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 78545, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.quantile(preds,q=0.5,axis=(1)).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scalePreds(predictions, 1.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md['pred_any'] = predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8c78b21b10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_md[['pos_idx1','pred_any']].groupby('pos_idx1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.exp(np.log(preds).mean((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = 1 / (1 + np.exp(-(np.log(preds/(1-preds)).mean((0,1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13209345, 0.00535793, 0.04274146, 0.03008586, 0.04659054,\n",
       "       0.05527701])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13278, 0.00531, 0.04268, 0.03012, 0.04659, 0.05525])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1280228 , 0.00678272, 0.04317398, 0.03195811, 0.04593468,\n",
       "       0.05528003], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.137883,0.004889,0.045248,0.031052,0.045235,0.0594456,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = np.array([a + '_' + b for a in test_md.SOPInstanceUID for b in all_ich])\n",
    "sub = pd.DataFrame({'ID': id_column, 'Label': predictions.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13209345070307849"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1281835436820984"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission_061.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13475628267250275"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9569675239389986, pvalue=0.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.spearmanr(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "                   best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994205342026138"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944464662920349"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 20.8M/20.8M [00:04<00:00, 4.50MB/s]\n",
      "Successfully submitted to RSNA Intracranial Hemorrhage Detection"
     ]
    }
   ],
   "source": [
    "!~/.local/bin/kaggle competitions submit rsna-intracranial-hemorrhage-detection -f ~/sub.csv -m \"GCP, 8 models, 32TTA, 3folds, ensemble, bounding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit rsna-intracranial-hemorrhage-detection -f C:/StudioProjects/Hemorrhage/sub.csv -m \"GCP, d161+d169+d201+s101+yd161, 8TTA, ensemble, bounds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
