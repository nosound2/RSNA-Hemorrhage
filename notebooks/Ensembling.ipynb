{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 20\n",
    "CLOUD_SINGLE = True\n",
    "DATA_SMALL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_md' not in globals() or 'test_md' not in globals():\n",
    "    train_md, test_md = loadMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 8\n",
      "DataSet 6 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.162 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 16.978 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 24.873 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.300 time per batch: 0.161\n",
      "ver 20, iter 0, fold 0, val ll: 0.0652, cor: 0.8369, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.334 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.476 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 26.070 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.429 time per batch: 0.167\n",
      "ver 20, iter 1, fold 0, val ll: 0.0653, cor: 0.8367, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.420 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.547 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 26.239 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.988 time per batch: 0.170\n",
      "ver 20, iter 2, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 10.689 time per batch: 0.214\n",
      "Batch 100 device: cuda time passed: 18.450 time per batch: 0.184\n",
      "Batch 150 device: cuda time passed: 26.127 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.409 time per batch: 0.167\n",
      "ver 20, iter 3, fold 0, val ll: 0.0651, cor: 0.8372, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.270 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.211 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.085 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.516 time per batch: 0.163\n",
      "ver 20, iter 4, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.363 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.298 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.383 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.893 time per batch: 0.164\n",
      "ver 20, iter 5, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.165 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.052 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 25.027 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.586 time per batch: 0.163\n",
      "ver 20, iter 6, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.159 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.178 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.081 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.620 time per batch: 0.163\n",
      "ver 20, iter 7, fold 0, val ll: 0.0653, cor: 0.8367, auc: 0.9874\n",
      "total running time 314.33739256858826\n",
      "total time 314.51741337776184\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 12\n",
      "DataSet 6 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.302 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.350 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.373 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.128 time per batch: 0.166\n",
      "ver 20, iter 0, fold 1, val ll: 0.0630, cor: 0.8385, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.244 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.358 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.435 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.325 time per batch: 0.167\n",
      "ver 20, iter 1, fold 1, val ll: 0.0632, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.328 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.314 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.470 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.282 time per batch: 0.166\n",
      "ver 20, iter 2, fold 1, val ll: 0.0632, cor: 0.8385, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.407 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.522 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.560 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.886 time per batch: 0.169\n",
      "ver 20, iter 3, fold 1, val ll: 0.0630, cor: 0.8389, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.121 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.403 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.398 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.185 time per batch: 0.166\n",
      "ver 20, iter 4, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.493 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.762 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.968 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.799 time per batch: 0.169\n",
      "ver 20, iter 5, fold 1, val ll: 0.0631, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.635 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.796 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.894 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.603 time per batch: 0.168\n",
      "ver 20, iter 6, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.300 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.380 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.353 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.248 time per batch: 0.166\n",
      "ver 20, iter 7, fold 1, val ll: 0.0629, cor: 0.8391, auc: 0.9879\n",
      "total running time 316.0654339790344\n",
      "total time 630.7728626728058\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 2\n",
      "DataSet 6 valid size 6496 fold 2\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f2.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.370 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.687 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.805 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.410 time per batch: 0.167\n",
      "ver 20, iter 0, fold 2, val ll: 0.0617, cor: 0.8393, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.467 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.585 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.606 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.100 time per batch: 0.166\n",
      "ver 20, iter 1, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.173 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.247 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.296 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.060 time per batch: 0.165\n",
      "ver 20, iter 2, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.436 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.607 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.667 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.123 time per batch: 0.166\n",
      "ver 20, iter 3, fold 2, val ll: 0.0616, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.270 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.298 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.296 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.681 time per batch: 0.163\n",
      "ver 20, iter 4, fold 2, val ll: 0.0615, cor: 0.8392, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.402 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.274 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.183 time per batch: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 device: cuda time passed: 32.468 time per batch: 0.162\n",
      "ver 20, iter 5, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.191 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.036 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 24.868 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.011 time per batch: 0.160\n",
      "ver 20, iter 6, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 8.998 time per batch: 0.180\n",
      "Batch 100 device: cuda time passed: 17.103 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 24.890 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.050 time per batch: 0.160\n",
      "ver 20, iter 7, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "total running time 309.2684922218323\n",
      "total time 940.213463306427\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 8\n",
      "DataSet 7 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.121 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.066 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 24.729 time per batch: 0.165\n",
      "Batch 200 device: cuda time passed: 32.034 time per batch: 0.160\n",
      "ver 20, iter 0, fold 0, val ll: 0.0641, cor: 0.8415, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.135 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.564 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.743 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.458 time per batch: 0.167\n",
      "ver 20, iter 1, fold 0, val ll: 0.0643, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.102 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 16.728 time per batch: 0.167\n",
      "Batch 150 device: cuda time passed: 24.613 time per batch: 0.164\n",
      "Batch 200 device: cuda time passed: 31.952 time per batch: 0.160\n",
      "ver 20, iter 2, fold 0, val ll: 0.0642, cor: 0.8413, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.219 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 16.976 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 24.876 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.253 time per batch: 0.161\n",
      "ver 20, iter 3, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.077 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.190 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.324 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.727 time per batch: 0.164\n",
      "ver 20, iter 4, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.426 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.356 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.445 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.881 time per batch: 0.164\n",
      "ver 20, iter 5, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.261 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.163 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.228 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.716 time per batch: 0.164\n",
      "ver 20, iter 6, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.259 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.326 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.413 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.769 time per batch: 0.164\n",
      "ver 20, iter 7, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "total running time 357.43421268463135\n",
      "total time 1297.8505425453186\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 12\n",
      "DataSet 7 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.248 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.073 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 24.936 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.546 time per batch: 0.163\n",
      "ver 20, iter 0, fold 1, val ll: 0.0635, cor: 0.8379, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.508 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.826 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.806 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.270 time per batch: 0.166\n",
      "ver 20, iter 1, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.326 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 18.139 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.841 time per batch: 0.179\n",
      "Batch 200 device: cuda time passed: 34.694 time per batch: 0.173\n",
      "ver 20, iter 2, fold 1, val ll: 0.0634, cor: 0.8383, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.147 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.308 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.279 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.926 time per batch: 0.165\n",
      "ver 20, iter 3, fold 1, val ll: 0.0633, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.165 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.524 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 26.481 time per batch: 0.177\n",
      "Batch 200 device: cuda time passed: 34.586 time per batch: 0.173\n",
      "ver 20, iter 4, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.541 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.652 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.678 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.543 time per batch: 0.168\n",
      "ver 20, iter 5, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.316 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.571 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.564 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.155 time per batch: 0.166\n",
      "ver 20, iter 6, fold 1, val ll: 0.0634, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.341 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.561 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.654 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.034 time per batch: 0.165\n",
      "ver 20, iter 7, fold 1, val ll: 0.0634, cor: 0.8381, auc: 0.9879\n",
      "total running time 355.3134915828705\n",
      "total time 1653.3613729476929\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 2\n",
      "DataSet 7 valid size 6496 fold 2\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f2.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 11.199 time per batch: 0.224\n",
      "Batch 100 device: cuda time passed: 20.042 time per batch: 0.200\n",
      "Batch 150 device: cuda time passed: 28.947 time per batch: 0.193\n",
      "Batch 200 device: cuda time passed: 37.163 time per batch: 0.186\n",
      "ver 20, iter 0, fold 2, val ll: 0.0603, cor: 0.8430, auc: 0.9894\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 10.807 time per batch: 0.216\n",
      "Batch 100 device: cuda time passed: 19.162 time per batch: 0.192\n",
      "Batch 150 device: cuda time passed: 27.920 time per batch: 0.186\n",
      "Batch 200 device: cuda time passed: 36.396 time per batch: 0.182\n",
      "ver 20, iter 1, fold 2, val ll: 0.0603, cor: 0.8432, auc: 0.9893\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 10.313 time per batch: 0.206\n",
      "Batch 100 device: cuda time passed: 19.139 time per batch: 0.191\n",
      "Batch 150 device: cuda time passed: 28.058 time per batch: 0.187\n",
      "Batch 200 device: cuda time passed: 37.458 time per batch: 0.187\n",
      "ver 20, iter 2, fold 2, val ll: 0.0604, cor: 0.8429, auc: 0.9893\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 10.715 time per batch: 0.214\n",
      "Batch 100 device: cuda time passed: 20.365 time per batch: 0.204\n",
      "Batch 150 device: cuda time passed: 28.452 time per batch: 0.190\n",
      "Batch 200 device: cuda time passed: 36.948 time per batch: 0.185\n",
      "ver 20, iter 3, fold 2, val ll: 0.0603, cor: 0.8429, auc: 0.9893\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 10.531 time per batch: 0.211\n",
      "Batch 100 device: cuda time passed: 19.684 time per batch: 0.197\n",
      "Batch 150 device: cuda time passed: 28.593 time per batch: 0.191\n",
      "Batch 200 device: cuda time passed: 37.111 time per batch: 0.186\n",
      "ver 20, iter 4, fold 2, val ll: 0.0605, cor: 0.8430, auc: 0.9893\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 10.294 time per batch: 0.206\n",
      "Batch 100 device: cuda time passed: 19.240 time per batch: 0.192\n",
      "Batch 150 device: cuda time passed: 27.197 time per batch: 0.181\n",
      "Batch 200 device: cuda time passed: 34.763 time per batch: 0.174\n",
      "ver 20, iter 5, fold 2, val ll: 0.0603, cor: 0.8431, auc: 0.9893\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.528 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.495 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.707 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.128 time per batch: 0.166\n",
      "ver 20, iter 6, fold 2, val ll: 0.0605, cor: 0.8426, auc: 0.9893\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.289 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.426 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.426 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.990 time per batch: 0.165\n",
      "ver 20, iter 7, fold 2, val ll: 0.0604, cor: 0.8428, auc: 0.9893\n",
      "total running time 373.21713304519653\n",
      "total time 2026.7751169204712\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 8\n",
      "DataSet 8 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d8.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.363 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.482 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.448 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.706 time per batch: 0.164\n",
      "ver 20, iter 0, fold 0, val ll: 0.0657, cor: 0.8364, auc: 0.9871\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.363 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.414 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.363 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.539 time per batch: 0.163\n",
      "ver 20, iter 1, fold 0, val ll: 0.0657, cor: 0.8365, auc: 0.9871\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.306 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.342 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.459 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.844 time per batch: 0.164\n",
      "ver 20, iter 2, fold 0, val ll: 0.0659, cor: 0.8358, auc: 0.9870\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 8.977 time per batch: 0.180\n",
      "Batch 100 device: cuda time passed: 17.034 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 25.032 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.450 time per batch: 0.162\n",
      "ver 20, iter 3, fold 0, val ll: 0.0655, cor: 0.8365, auc: 0.9873\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.254 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.170 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.141 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.529 time per batch: 0.163\n",
      "ver 20, iter 4, fold 0, val ll: 0.0657, cor: 0.8364, auc: 0.9870\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.169 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.040 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 25.077 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.608 time per batch: 0.163\n",
      "ver 20, iter 5, fold 0, val ll: 0.0656, cor: 0.8368, auc: 0.9871\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.085 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.093 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 25.049 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.544 time per batch: 0.163\n",
      "ver 20, iter 6, fold 0, val ll: 0.0655, cor: 0.8365, auc: 0.9873\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.169 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.016 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 24.948 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.430 time per batch: 0.162\n",
      "ver 20, iter 7, fold 0, val ll: 0.0658, cor: 0.8363, auc: 0.9871\n",
      "total running time 303.7190225124359\n",
      "total time 2330.6731622219086\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 12\n",
      "DataSet 8 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d8.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.194 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.098 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 24.991 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.554 time per batch: 0.163\n",
      "ver 20, iter 0, fold 1, val ll: 0.0643, cor: 0.8343, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.289 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.221 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.197 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.831 time per batch: 0.164\n",
      "ver 20, iter 1, fold 1, val ll: 0.0643, cor: 0.8340, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.170 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.179 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.025 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.605 time per batch: 0.163\n",
      "ver 20, iter 2, fold 1, val ll: 0.0643, cor: 0.8343, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.141 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.171 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.075 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.819 time per batch: 0.164\n",
      "ver 20, iter 3, fold 1, val ll: 0.0643, cor: 0.8343, auc: 0.9873\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.197 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.262 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.289 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.924 time per batch: 0.165\n",
      "ver 20, iter 4, fold 1, val ll: 0.0644, cor: 0.8340, auc: 0.9873\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.367 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.420 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.419 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.963 time per batch: 0.165\n",
      "ver 20, iter 5, fold 1, val ll: 0.0643, cor: 0.8341, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.332 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.397 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.542 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.495 time per batch: 0.167\n",
      "ver 20, iter 6, fold 1, val ll: 0.0644, cor: 0.8343, auc: 0.9873\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.524 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.897 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 25.838 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.488 time per batch: 0.167\n",
      "ver 20, iter 7, fold 1, val ll: 0.0642, cor: 0.8343, auc: 0.9875\n",
      "total running time 307.81212973594666\n",
      "total time 2638.6536962985992\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 2\n",
      "DataSet 8 valid size 6496 fold 2\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f2.d8.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.408 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.261 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.235 time per batch: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 device: cuda time passed: 32.605 time per batch: 0.163\n",
      "ver 20, iter 0, fold 2, val ll: 0.0626, cor: 0.8366, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.184 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 16.992 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 24.975 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.662 time per batch: 0.163\n",
      "ver 20, iter 1, fold 2, val ll: 0.0626, cor: 0.8366, auc: 0.9882\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.546 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.585 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.753 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.146 time per batch: 0.166\n",
      "ver 20, iter 2, fold 2, val ll: 0.0626, cor: 0.8369, auc: 0.9882\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.126 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.177 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.147 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.461 time per batch: 0.162\n",
      "ver 20, iter 3, fold 2, val ll: 0.0625, cor: 0.8375, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.229 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.278 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.131 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.403 time per batch: 0.162\n",
      "ver 20, iter 4, fold 2, val ll: 0.0624, cor: 0.8374, auc: 0.9882\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.049 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 16.890 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 24.863 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.335 time per batch: 0.162\n",
      "ver 20, iter 5, fold 2, val ll: 0.0626, cor: 0.8372, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.384 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.397 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.451 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.814 time per batch: 0.164\n",
      "ver 20, iter 6, fold 2, val ll: 0.0627, cor: 0.8364, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.136 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 16.966 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 25.011 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.486 time per batch: 0.162\n",
      "ver 20, iter 7, fold 2, val ll: 0.0626, cor: 0.8369, auc: 0.9881\n",
      "total running time 302.5886027812958\n",
      "total time 2941.4162724018097\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 8\n",
      "DataSet 9 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d9.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.152 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.310 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.243 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.719 time per batch: 0.164\n",
      "ver 20, iter 0, fold 0, val ll: 0.0642, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.203 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.210 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.096 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.546 time per batch: 0.163\n",
      "ver 20, iter 1, fold 0, val ll: 0.0639, cor: 0.8417, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.083 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.122 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 25.018 time per batch: 0.167\n",
      "Batch 200 device: cuda time passed: 32.524 time per batch: 0.163\n",
      "ver 20, iter 2, fold 0, val ll: 0.0642, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.240 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.297 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.205 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.643 time per batch: 0.163\n",
      "ver 20, iter 3, fold 0, val ll: 0.0640, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.258 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.106 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 24.938 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.424 time per batch: 0.162\n",
      "ver 20, iter 4, fold 0, val ll: 0.0641, cor: 0.8410, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.561 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.556 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.641 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.035 time per batch: 0.165\n",
      "ver 20, iter 5, fold 0, val ll: 0.0642, cor: 0.8408, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.383 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.410 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.556 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.101 time per batch: 0.166\n",
      "ver 20, iter 6, fold 0, val ll: 0.0644, cor: 0.8405, auc: 0.9877\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.668 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.916 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.099 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.529 time per batch: 0.168\n",
      "ver 20, iter 7, fold 0, val ll: 0.0640, cor: 0.8412, auc: 0.9878\n",
      "total running time 303.8378052711487\n",
      "total time 3245.46883893013\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 12\n",
      "DataSet 9 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d9.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.618 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.824 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.088 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.658 time per batch: 0.168\n",
      "ver 20, iter 0, fold 1, val ll: 0.0624, cor: 0.8406, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.146 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.287 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.674 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.510 time per batch: 0.168\n",
      "ver 20, iter 1, fold 1, val ll: 0.0623, cor: 0.8411, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.793 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 17.849 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.099 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.748 time per batch: 0.169\n",
      "ver 20, iter 2, fold 1, val ll: 0.0626, cor: 0.8402, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.234 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.088 time per batch: 0.171\n",
      "Batch 150 device: cuda time passed: 25.128 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.776 time per batch: 0.164\n",
      "ver 20, iter 3, fold 1, val ll: 0.0624, cor: 0.8405, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.359 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.651 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.913 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.596 time per batch: 0.168\n",
      "ver 20, iter 4, fold 1, val ll: 0.0624, cor: 0.8403, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.727 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 17.863 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.080 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.899 time per batch: 0.169\n",
      "ver 20, iter 5, fold 1, val ll: 0.0623, cor: 0.8408, auc: 0.9882\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.525 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.642 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.848 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.710 time per batch: 0.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver 20, iter 6, fold 1, val ll: 0.0626, cor: 0.8404, auc: 0.9881\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.644 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.776 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.066 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.986 time per batch: 0.170\n",
      "ver 20, iter 7, fold 1, val ll: 0.0624, cor: 0.8406, auc: 0.9881\n",
      "total running time 310.90257143974304\n",
      "total time 3556.5488913059235\n",
      "completed epochs: 10 iters starting now: 8\n",
      "adding dummy serieses 2\n",
      "DataSet 9 valid size 6496 fold 2\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f2.d9.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.322 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.375 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.351 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.601 time per batch: 0.163\n",
      "ver 20, iter 0, fold 2, val ll: 0.0606, cor: 0.8411, auc: 0.9893\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.000 time per batch: 0.180\n",
      "Batch 100 device: cuda time passed: 17.019 time per batch: 0.170\n",
      "Batch 150 device: cuda time passed: 24.860 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.231 time per batch: 0.161\n",
      "ver 20, iter 1, fold 2, val ll: 0.0609, cor: 0.8407, auc: 0.9891\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.038 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 16.920 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 24.948 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.448 time per batch: 0.162\n",
      "ver 20, iter 2, fold 2, val ll: 0.0607, cor: 0.8409, auc: 0.9892\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.124 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 16.937 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 24.927 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.691 time per batch: 0.163\n",
      "ver 20, iter 3, fold 2, val ll: 0.0609, cor: 0.8404, auc: 0.9892\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.480 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.621 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.725 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.316 time per batch: 0.167\n",
      "ver 20, iter 4, fold 2, val ll: 0.0611, cor: 0.8399, auc: 0.9892\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.368 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.626 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.724 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.300 time per batch: 0.166\n",
      "ver 20, iter 5, fold 2, val ll: 0.0608, cor: 0.8408, auc: 0.9892\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.571 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.758 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.924 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.355 time per batch: 0.167\n",
      "ver 20, iter 6, fold 2, val ll: 0.0607, cor: 0.8410, auc: 0.9892\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.558 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.581 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.752 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.304 time per batch: 0.167\n",
      "ver 20, iter 7, fold 2, val ll: 0.0608, cor: 0.8409, auc: 0.9891\n",
      "total running time 304.3275783061981\n",
      "total time 3861.053881883621\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for ds in range(6,10):\n",
    "    for fold in range(3):\n",
    "        predictions = oof_one(num_iter=8, bs=32, fold=fold, dataset=ds)\n",
    "        pickle.dump(predictions, open(PATH_WORK/'oof_d{}_f{}_v{}'.format(ds, fold, VERSION),'wb'))\n",
    "        print('total time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.231111111111111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "476*8*4/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between models\n",
    "# scores per slice\n",
    "# what is the best way to agg oof, model\\run levels\n",
    "# best aggregation theoretically\n",
    "# distribution of oof preds\n",
    "# score - what uniform p will get\n",
    "# 0.5 + np.sign(x-0.5) *2*(x-0.5)**2 - makes it less aggressive, is it a good transform above mean?\n",
    "# does scaling help for single runs, or is it aggregation artifact.\n",
    "\n",
    "# s101 problem.\n",
    "    # maybe 8 and 32 behave differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting runs aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbd70c0e8d0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(101)/100\n",
    "plt.plot(scalePreds(x, center=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "mean    [0.06429 0.06347 0.06388 0.06304] [0.03816 0.03822 0.0384  0.03748]\n",
      "gmean   [0.06444 0.06361 0.06411 0.06326] [0.03824 0.03834 0.03854 0.03766]\n",
      "q50     [0.06454 0.06372 0.06428 0.06335] [0.03833 0.03843 0.03866 0.03772]\n",
      "q25     [0.06518 0.06432 0.06533 0.06426] [0.03866 0.0388  0.03924 0.0383 ]\n",
      "q75     [0.0646  0.06367 0.06456 0.06314] [0.03832 0.03838 0.03889 0.03755]\n",
      "psig    [0.06443 0.06362 0.06407 0.06324] [0.03823 0.03836 0.03853 0.03765]\n",
      "fold 1\n",
      "mean    [0.06225 0.06248 0.06258 0.06124] [0.03745 0.0385  0.03817 0.03723]\n",
      "gmean   [0.06232 0.06259 0.06286 0.06144] [0.03755 0.03864 0.0384  0.03744]\n",
      "q50     [0.06246 0.06274 0.06298 0.06153] [0.03764 0.03872 0.03849 0.03745]\n",
      "q25     [0.06279 0.06314 0.06421 0.06238] [0.03804 0.03919 0.03941 0.03828]\n",
      "q75     [0.0627  0.06297 0.06296 0.06155] [0.03752 0.03861 0.03817 0.03711]\n",
      "psig    [0.06237 0.06263 0.06278 0.06143] [0.03756 0.03865 0.03834 0.03742]\n",
      "fold 2\n",
      "mean    [0.06078 0.05956 0.06078 0.05974] [0.03823 0.03747 0.0383  0.03753]\n",
      "gmean   [0.06092 0.05969 0.06094 0.05986] [0.03832 0.03755 0.03841 0.03759]\n",
      "q50     [0.06105 0.05981 0.06111 0.05995] [0.03841 0.03765 0.03857 0.03767]\n",
      "q25     [0.06159 0.0603  0.06181 0.06045] [0.03876 0.03796 0.03896 0.03795]\n",
      "q75     [0.06104 0.05986 0.0618  0.06027] [0.03837 0.0377  0.03894 0.03785]\n",
      "psig    [0.06093 0.05971 0.06093 0.05987] [0.03833 0.03757 0.03842 0.0376 ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5)\n",
    "\n",
    "for fold in range(3):\n",
    "    print('fold', fold)\n",
    "    data_fold = train_md.loc[train_md.fold == fold]\n",
    "    ww = data_fold.weights.values\n",
    "    ww = ww/ww.mean()\n",
    "\n",
    "    preds = np.stack([pickle.load(open(PATH_WORK/'oof_d{}_f{}_v{}'.format(ds, fold, VERSION),'rb')) \\\n",
    "        for ds in range(6,10)])\n",
    "\n",
    "    assert len(data_fold) == preds.shape[2]\n",
    "    \n",
    "    preds = np.clip(preds, 1e-15, 1-1e-15)\n",
    "    for afunc in afuncs_names:\n",
    "        apreds = applyAggFunc(preds, afunc)\n",
    "        res = ((- data_fold[all_ich].values * np.log(apreds) - (1 - data_fold[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean((1,2))\n",
    "        resw = (((- data_fold[all_ich].values * np.log(apreds) - (1 - data_fold[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean(2)*ww).mean(1)\n",
    "        \n",
    "        #roc = [roc_auc_score(data_fold[all_ich].values.reshape(-1), apreds[i].reshape(-1)) for i in range(4)]\n",
    "        print('{:7s} {} {}'.format(afunc,res,resw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = getPredsOOF(aug=8,datasets=range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06332, 0.06269, 0.06419, 0.06245])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06244, 0.06184, 0.06241, 0.06134])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all.mean(1)) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all.mean(1),1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_afunc = 'mean'\n",
    "preds2 = applyAggFunc(preds_all, runs_afunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting models aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    0.059314\n",
      "gmean   0.059584\n",
      "q50     0.059622\n",
      "q25     0.060828\n",
      "q75     0.060114\n",
      "psig    0.059538\n"
     ]
    }
   ],
   "source": [
    "for afunc in afuncs_names:\n",
    "    #print(afunc)\n",
    "    apreds = applyAggFunc(preds2, afunc, axis=0)\n",
    "    res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()\n",
    "    \n",
    "    if False:\n",
    "        best_score = res\n",
    "        best_k = 0\n",
    "        for k in range(1,50):\n",
    "            apreds2 = scalePreds(apreds, 1.0 + 0.01 * k)\n",
    "            apreds2 = np.clip(apreds2, 1e-15, 1-1e-15)\n",
    "\n",
    "            res2 = ((- train_md[all_ich].values * np.log(apreds2) - (1 - train_md[all_ich].values) * np.log(1 - apreds2))\\\n",
    "                    * class_weights).mean()\n",
    "\n",
    "            if res2 > best_score: break\n",
    "            best_score = res2\n",
    "            best_k = k\n",
    "\n",
    "        print('{:7s} {:5f}   {:2f} {:5f}'.format(afunc,res,1+0.01*best_k,best_score))\n",
    "    else:\n",
    "        print('{:7s} {:5f}'.format(afunc,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059038001710494545"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*np.array([0.25,0.25,0.25,0.25])[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058951267412781026"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*np.array([0.2,0.2,0.2,0.4])[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_afunc = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 674252, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06268, 0.06259, 0.06242, 0.06195])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    best_score = res\n",
    "    best_k = 0\n",
    "    for k in range(1,50):\n",
    "        apreds = scalePreds(preds_all, 1.0 + 0.01 * k)\n",
    "        apreds = np.clip(apreds, 1e-15, 1-1e-15)\n",
    "\n",
    "        res2 = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "                * class_weights).mean()\n",
    "\n",
    "        if res2 > best_score: break\n",
    "        best_score = res2\n",
    "        best_k = k\n",
    "\n",
    "    print('{{:5f}   {:2f} {:5f}'.format(res,1+0.01*best_k,best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models behavior per groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WindowCenter_1_le     0 248151   2157 [0.03754 0.03719 0.03679 0.03699]\n",
      "WindowCenter_1_le     2  10377     34 [0.11828 0.11642 0.11726 0.11536]\n",
      "WindowCenter_1_le     3 341674  75369 [0.06474 0.06439 0.06526 0.06359]\n",
      "WindowCenter_1_le     1  70894    985 [0.12907 0.12632 0.12904 0.12675]\n",
      "WindowCenter_1_le     4   3156      0 [0.09075 0.09554 0.09205 0.08595]\n",
      "BitType_le            1 323550   3088 [0.05799 0.0573  0.05758 0.05716]\n",
      "BitType_le            0 338723  75369 [0.06411 0.06378 0.0646  0.06293]\n",
      "BitType_le            2   2252     60 [0.12818 0.12513 0.12613 0.12392]\n",
      "BitType_le            4   6776     28 [0.13693 0.12889 0.12844 0.12693]\n",
      "BitType_le            3   2951      0 [0.13769 0.13434 0.14018 0.13928]\n",
      "WindowCenter_0_le     1 248151   2157 [0.03754 0.03719 0.03679 0.03699]\n",
      "WindowCenter_0_le     4  10343     34 [0.11838 0.11662 0.1173  0.11543]\n",
      "WindowCenter_0_le     2 151196   2148 [0.1232  0.12122 0.12367 0.12085]\n",
      "WindowCenter_0_le     0 213404  69272 [0.0356  0.03576 0.03592 0.03505]\n",
      "WindowCenter_0_le     3  43648   4934 [0.10603 0.10517 0.10645 0.10424]\n",
      "WindowCenter_0_le     6   3553      0 [0.0863  0.0899  0.08581 0.08013]\n",
      "WindowCenter_0_le     5   3957      0 [0.10166 0.09817 0.1068  0.10114]\n",
      "pos_inc1_grp_le       3 589641  59576 [0.06549 0.0647  0.06535 0.06444]\n",
      "pos_inc1_grp_le       0  25148   3724 [0.03066 0.0299  0.03029 0.02929]\n",
      "pos_inc1_grp_le       1  51896  14995 [0.03733 0.0386  0.03823 0.0359 ]\n",
      "pos_inc1_grp_le       2   7567    250 [0.10276 0.1043  0.10583 0.1005 ]\n",
      "pos_inc2_grp_le       3 589642  59576 [0.06603 0.06522 0.06589 0.06498]\n",
      "pos_inc2_grp_le       0  25147   3724 [0.02662 0.02652 0.02648 0.0254 ]\n",
      "pos_inc2_grp_le       1  51896  14995 [0.03446 0.03574 0.03538 0.0331 ]\n",
      "pos_inc2_grp_le       2   7567    250 [0.09397 0.09426 0.09629 0.09117]\n",
      "pos_size_le          10 113357   7349 [0.05377 0.05336 0.05314 0.05246]\n",
      "pos_size_le           2  78912   9072 [0.05846 0.05841 0.05939 0.05796]\n",
      "pos_size_le           3  52218   9884 [0.07602 0.07416 0.07576 0.07413]\n",
      "pos_size_le           0 156544  21824 [0.07402 0.07334 0.07436 0.07271]\n",
      "pos_size_le           7  30393    231 [0.03408 0.03338 0.03309 0.03375]\n",
      "pos_size_le           8  25270   1596 [0.05737 0.05755 0.05649 0.05675]\n",
      "pos_size_le           4  51508    884 [0.07359 0.07292 0.07389 0.07346]\n",
      "pos_size_le           5  33180    930 [0.10807 0.10402 0.1057  0.10399]\n",
      "pos_size_le           1  79040  21840 [0.04457 0.04484 0.04527 0.04399]\n",
      "pos_size_le           6  32270    315 [0.04138 0.04146 0.04155 0.0416 ]\n",
      "pos_size_le           9  21560   4620 [0.05172 0.05214 0.0515  0.04966]\n",
      "pos_zeros_le          0 669377  77188 [0.06225 0.06165 0.0622  0.06117]\n",
      "pos_zeros_le          3   2665    917 [0.10061 0.09651 0.10214 0.09344]\n",
      "pos_zeros_le          2   1132    332 [0.08937 0.08674 0.08746 0.08854]\n",
      "pos_zeros_le          1   1078    108 [0.05822 0.0633  0.06831 0.06056]\n",
      "WindowWidth_0_le      0 541489  72448 [0.05015 0.04967 0.04991 0.04935]\n",
      "WindowWidth_0_le      1  63927    921 [0.1146  0.11291 0.11504 0.11176]\n",
      "WindowWidth_0_le      2  30067   4308 [0.09336 0.0928  0.09517 0.09161]\n",
      "WindowWidth_0_le      3  31237    762 [0.13246 0.13112 0.13263 0.13015]\n",
      "WindowWidth_0_le      5   5389     90 [0.08139 0.08339 0.08448 0.08302]\n",
      "WindowWidth_0_le      4   2143     16 [0.1088  0.11343 0.11194 0.1049 ]\n",
      "WindowWidth_1_le      0 329597   3176 [0.05977 0.05886 0.05917 0.05877]\n",
      "WindowWidth_1_le      1 341674  75369 [0.06474 0.06439 0.06526 0.06359]\n",
      "WindowWidth_1_le      2   2981      0 [0.09309 0.09853 0.09519 0.08769]\n",
      "PxlMin_grp_le         2 363504   3934 [0.06615 0.06525 0.06563 0.065  ]\n",
      "PxlMin_grp_le         1  83433   1095 [0.11636 0.11505 0.11728 0.11371]\n",
      "PxlMin_grp_le         0 227315  73516 [0.03671 0.03685 0.03712 0.03627]\n"
     ]
    }
   ],
   "source": [
    "for col in cols_le:\n",
    "    for i in train_md[col].unique():\n",
    "        res = ((- train_md[all_ich].values * np.log(preds_all.mean(1)) - (1 - train_md[all_ich].values) \\\n",
    "                * np.log(1 - preds_all.mean(1))) * class_weights)[:,(train_md[col] == i)].mean((1,2))\n",
    "        sz = (train_md[col] == i).sum()\n",
    "        sz_test = (test_md[col] == i).sum()\n",
    "        print('{:20s} {:2d} {:6d} {:6d} {}'.format(col,i,sz,sz_test,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 674252, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PxlMin_grp_le         2 any                  363504   3934 [0.10395 0.10279 0.10281 0.10252]\n",
      "PxlMin_grp_le         1 any                   83433   1095 [0.18196 0.17981 0.1821  0.17766]\n",
      "PxlMin_grp_le         0 any                  227315  73516 [0.06435 0.06464 0.06487 0.06336]\n",
      "PxlMin_grp_le         2 epidural             363504   3934 [0.01702 0.01776 0.01722 0.01757]\n",
      "PxlMin_grp_le         1 epidural              83433   1095 [0.02218 0.02326 0.02527 0.0242 ]\n",
      "PxlMin_grp_le         0 epidural             227315  73516 [0.01231 0.01366 0.01299 0.01279]\n",
      "PxlMin_grp_le         2 intraparenchymal     363504   3934 [0.04702 0.04555 0.04753 0.04491]\n",
      "PxlMin_grp_le         1 intraparenchymal      83433   1095 [0.0879  0.08405 0.08973 0.0842 ]\n",
      "PxlMin_grp_le         0 intraparenchymal     227315  73516 [0.02321 0.02288 0.02356 0.02277]\n",
      "PxlMin_grp_le         2 intraventricular     363504   3934 [0.02567 0.02499 0.02586 0.02512]\n",
      "PxlMin_grp_le         1 intraventricular      83433   1095 [0.06925 0.06802 0.07146 0.06848]\n",
      "PxlMin_grp_le         0 intraventricular     227315  73516 [0.01181 0.01142 0.01221 0.01157]\n",
      "PxlMin_grp_le         2 subarachnoid         363504   3934 [0.07405 0.07273 0.07322 0.07215]\n",
      "PxlMin_grp_le         1 subarachnoid          83433   1095 [0.12831 0.12705 0.12803 0.12445]\n",
      "PxlMin_grp_le         0 subarachnoid         227315  73516 [0.03469 0.03427 0.03478 0.03424]\n",
      "PxlMin_grp_le         2 subdural             363504   3934 [0.09141 0.09011 0.08999 0.09023]\n",
      "PxlMin_grp_le         1 subdural              83433   1095 [0.14299 0.14334 0.1423  0.13929]\n",
      "PxlMin_grp_le         0 subdural             227315  73516 [0.04624 0.04648 0.04659 0.04578]\n"
     ]
    }
   ],
   "source": [
    "col = 'PxlMin_grp_le'\n",
    "for k in range(6):\n",
    "    for i in train_md[col].unique():\n",
    "        res = (- train_md[all_ich[k]].values * np.log(preds_all.mean(1)[:,:,k]) - (1 - train_md[all_ich[k]].values) \\\n",
    "                * np.log(1 - preds_all.mean(1)[:,:,k]))[:,(train_md[col] == i)].mean(1)\n",
    "        sz = (train_md[col] == i).sum()\n",
    "        sz_test = (test_md[col] == i).sum()\n",
    "        print('{:20s} {:2d} {:20s} {:6d} {:6d} {}'.format(col,i,all_ich[k],sz,sz_test,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>any</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PxlMin_grp_le</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>212492</td>\n",
       "      <td>14823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>56254</td>\n",
       "      <td>27179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>308403</td>\n",
       "      <td>55101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "any                 0      1\n",
       "PxlMin_grp_le               \n",
       "0              212492  14823\n",
       "1               56254  27179\n",
       "2              308403  55101"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab([train_md['PxlMin_grp_le']], [train_md[all_ich[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = preds_all.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00663, 0.00082, 0.00371, 0.00237, 0.00463, 0.00465],\n",
       "       [0.00653, 0.00076, 0.00331, 0.00226, 0.00419, 0.00432],\n",
       "       [0.01035, 0.00107, 0.00553, 0.00373, 0.00675, 0.00676],\n",
       "       [0.00783, 0.00065, 0.00383, 0.00267, 0.00484, 0.00487]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds.mean((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 674252, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0721  0.69844 0.04717 0.87074 0.90913 0.38538 0.47888 0.49287]\n",
      "[0.65942 0.14143 0.80356 0.20604 0.03734 0.7852  0.74105 0.29836]\n",
      "[0.93923 0.87878 0.88173 0.10275 0.9006  0.17714 0.87711 0.22097]\n",
      "[0.92357 0.05838 0.82988 0.1811  0.91063 0.91305 0.1835  0.28412]\n",
      "[0.23838 0.77077 0.26534 0.11955 0.63966 0.28781 0.76715 0.17522]\n",
      "[0.75192 0.22898 0.87654 0.65612 0.38861 0.84263 0.21847 0.60288]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    idx = stds[0,:,i].argmax()\n",
    "    print(preds_all[0,:,idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89607 0.12613 0.89643 0.10395 0.8919  0.10412 0.12296 0.10019]\n",
      "[0.29146 0.09448 0.08381 0.29124 0.25786 0.27932 0.26    0.17203]\n",
      "[0.9805  0.96471 0.96605 0.97915 0.96169 0.12889 0.20027 0.15312]\n",
      "[0.88048 0.84696 0.0523  0.05313 0.06338 0.23104 0.20848 0.92539]\n",
      "[0.79051 0.40486 0.24571 0.92017 0.90041 0.22817 0.2481  0.90389]\n",
      "[0.14481 0.74231 0.74153 0.14874 0.15549 0.66152 0.74362 0.17278]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    idx = stds[3,:,i].argmax()\n",
    "    print(preds_all[3,:,idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14491, 0.00945, 0.03508, 0.02361, 0.05398, 0.06132],\n",
       "       [0.14669, 0.01034, 0.03552, 0.02403, 0.05463, 0.06025],\n",
       "       [0.14752, 0.00944, 0.03492, 0.02384, 0.05311, 0.06174],\n",
       "       [0.14552, 0.01318, 0.03636, 0.02443, 0.05468, 0.06079]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean(1, keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean(1, keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05472, 0.05524, 0.05509, 0.05582])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean(1, keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean(1, keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6043 , 0.60165, 0.59441, 0.6038 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean((1,2), keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean((1,2), keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.362 time per batch: 0.118\n",
      "B30 -> time passed: 3.266 time per batch: 0.109\n",
      "B40 -> time passed: 4.109 time per batch: 0.103\n",
      "B50 -> time passed: 5.558 time per batch: 0.111\n",
      "B60 -> time passed: 6.227 time per batch: 0.104\n",
      "B70 -> time passed: 6.670 time per batch: 0.095\n",
      "test processing time: 11.566713809967041\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.587 time per batch: 0.159\n",
      "B20 -> time passed: 2.497 time per batch: 0.125\n",
      "B30 -> time passed: 3.266 time per batch: 0.109\n",
      "B40 -> time passed: 4.156 time per batch: 0.104\n",
      "B50 -> time passed: 5.589 time per batch: 0.112\n",
      "B60 -> time passed: 6.353 time per batch: 0.106\n",
      "B70 -> time passed: 6.819 time per batch: 0.097\n",
      "test processing time: 11.686899423599243\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.507 time per batch: 0.151\n",
      "B20 -> time passed: 2.324 time per batch: 0.116\n",
      "B30 -> time passed: 3.121 time per batch: 0.104\n",
      "B40 -> time passed: 3.902 time per batch: 0.098\n",
      "B50 -> time passed: 5.168 time per batch: 0.103\n",
      "B60 -> time passed: 6.054 time per batch: 0.101\n",
      "B70 -> time passed: 6.520 time per batch: 0.093\n",
      "test processing time: 11.421162366867065\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.575 time per batch: 0.158\n",
      "B20 -> time passed: 2.463 time per batch: 0.123\n",
      "B30 -> time passed: 3.244 time per batch: 0.108\n",
      "B40 -> time passed: 4.043 time per batch: 0.101\n",
      "B50 -> time passed: 5.507 time per batch: 0.110\n",
      "B60 -> time passed: 6.257 time per batch: 0.104\n",
      "B70 -> time passed: 6.713 time per batch: 0.096\n",
      "test processing time: 11.60112714767456\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.496 time per batch: 0.150\n",
      "B20 -> time passed: 2.337 time per batch: 0.117\n",
      "B30 -> time passed: 3.095 time per batch: 0.103\n",
      "B40 -> time passed: 3.918 time per batch: 0.098\n",
      "B50 -> time passed: 5.215 time per batch: 0.104\n",
      "B60 -> time passed: 6.118 time per batch: 0.102\n",
      "B70 -> time passed: 6.677 time per batch: 0.095\n",
      "test processing time: 11.574501037597656\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.348 time per batch: 0.117\n",
      "B30 -> time passed: 3.198 time per batch: 0.107\n",
      "B40 -> time passed: 3.958 time per batch: 0.099\n",
      "B50 -> time passed: 5.340 time per batch: 0.107\n",
      "B60 -> time passed: 6.095 time per batch: 0.102\n",
      "B70 -> time passed: 6.636 time per batch: 0.095\n",
      "test processing time: 11.495140075683594\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.322 time per batch: 0.116\n",
      "B30 -> time passed: 3.090 time per batch: 0.103\n",
      "B40 -> time passed: 3.953 time per batch: 0.099\n",
      "B50 -> time passed: 5.335 time per batch: 0.107\n",
      "B60 -> time passed: 6.112 time per batch: 0.102\n",
      "B70 -> time passed: 6.648 time per batch: 0.095\n",
      "test processing time: 11.55446720123291\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.567 time per batch: 0.157\n",
      "B20 -> time passed: 2.399 time per batch: 0.120\n",
      "B30 -> time passed: 3.176 time per batch: 0.106\n",
      "B40 -> time passed: 3.953 time per batch: 0.099\n",
      "B50 -> time passed: 5.427 time per batch: 0.109\n",
      "B60 -> time passed: 6.173 time per batch: 0.103\n",
      "B70 -> time passed: 6.682 time per batch: 0.095\n",
      "test processing time: 11.56597352027893\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.544 time per batch: 0.154\n",
      "B20 -> time passed: 2.365 time per batch: 0.118\n",
      "B30 -> time passed: 3.186 time per batch: 0.106\n",
      "B40 -> time passed: 3.984 time per batch: 0.100\n",
      "B50 -> time passed: 5.374 time per batch: 0.107\n",
      "B60 -> time passed: 6.219 time per batch: 0.104\n",
      "B70 -> time passed: 6.688 time per batch: 0.096\n",
      "test processing time: 21.329533576965332\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.602 time per batch: 0.160\n",
      "B20 -> time passed: 2.430 time per batch: 0.121\n",
      "B30 -> time passed: 3.251 time per batch: 0.108\n",
      "B40 -> time passed: 4.105 time per batch: 0.103\n",
      "B50 -> time passed: 5.548 time per batch: 0.111\n",
      "B60 -> time passed: 6.314 time per batch: 0.105\n",
      "B70 -> time passed: 6.822 time per batch: 0.097\n",
      "test processing time: 11.768672704696655\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.324 time per batch: 0.116\n",
      "B30 -> time passed: 3.122 time per batch: 0.104\n",
      "B40 -> time passed: 3.927 time per batch: 0.098\n",
      "B50 -> time passed: 5.286 time per batch: 0.106\n",
      "B60 -> time passed: 6.118 time per batch: 0.102\n",
      "B70 -> time passed: 6.596 time per batch: 0.094\n",
      "test processing time: 11.49284839630127\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.537 time per batch: 0.154\n",
      "B20 -> time passed: 2.395 time per batch: 0.120\n",
      "B30 -> time passed: 3.253 time per batch: 0.108\n",
      "B40 -> time passed: 4.084 time per batch: 0.102\n",
      "B50 -> time passed: 5.423 time per batch: 0.108\n",
      "B60 -> time passed: 6.159 time per batch: 0.103\n",
      "B70 -> time passed: 6.668 time per batch: 0.095\n",
      "test processing time: 11.621638298034668\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.547 time per batch: 0.155\n",
      "B20 -> time passed: 2.342 time per batch: 0.117\n",
      "B30 -> time passed: 3.132 time per batch: 0.104\n",
      "B40 -> time passed: 3.946 time per batch: 0.099\n",
      "B50 -> time passed: 5.307 time per batch: 0.106\n",
      "B60 -> time passed: 6.040 time per batch: 0.101\n",
      "B70 -> time passed: 6.668 time per batch: 0.095\n",
      "test processing time: 11.547635078430176\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.576 time per batch: 0.158\n",
      "B20 -> time passed: 2.355 time per batch: 0.118\n",
      "B30 -> time passed: 3.155 time per batch: 0.105\n",
      "B40 -> time passed: 3.998 time per batch: 0.100\n",
      "B50 -> time passed: 5.244 time per batch: 0.105\n",
      "B60 -> time passed: 6.122 time per batch: 0.102\n",
      "B70 -> time passed: 6.687 time per batch: 0.096\n",
      "test processing time: 11.532374143600464\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.591 time per batch: 0.159\n",
      "B20 -> time passed: 2.368 time per batch: 0.118\n",
      "B30 -> time passed: 3.212 time per batch: 0.107\n",
      "B40 -> time passed: 3.993 time per batch: 0.100\n",
      "B50 -> time passed: 5.399 time per batch: 0.108\n",
      "B60 -> time passed: 6.143 time per batch: 0.102\n",
      "B70 -> time passed: 6.662 time per batch: 0.095\n",
      "test processing time: 11.565739393234253\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d7.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.560 time per batch: 0.156\n",
      "B20 -> time passed: 2.432 time per batch: 0.122\n",
      "B30 -> time passed: 3.284 time per batch: 0.109\n",
      "B40 -> time passed: 4.143 time per batch: 0.104\n",
      "B50 -> time passed: 5.454 time per batch: 0.109\n",
      "B60 -> time passed: 6.186 time per batch: 0.103\n",
      "B70 -> time passed: 6.679 time per batch: 0.095\n",
      "test processing time: 11.56418514251709\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.561 time per batch: 0.156\n",
      "B20 -> time passed: 2.391 time per batch: 0.120\n",
      "B30 -> time passed: 3.176 time per batch: 0.106\n",
      "B40 -> time passed: 4.024 time per batch: 0.101\n",
      "B50 -> time passed: 5.401 time per batch: 0.108\n",
      "B60 -> time passed: 6.270 time per batch: 0.105\n",
      "B70 -> time passed: 6.820 time per batch: 0.097\n",
      "test processing time: 21.799904108047485\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.351 time per batch: 0.118\n",
      "B30 -> time passed: 3.140 time per batch: 0.105\n",
      "B40 -> time passed: 3.964 time per batch: 0.099\n",
      "B50 -> time passed: 5.307 time per batch: 0.106\n",
      "B60 -> time passed: 6.253 time per batch: 0.104\n",
      "B70 -> time passed: 6.756 time per batch: 0.097\n",
      "test processing time: 11.694639444351196\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.607 time per batch: 0.161\n",
      "B20 -> time passed: 2.473 time per batch: 0.124\n",
      "B30 -> time passed: 3.289 time per batch: 0.110\n",
      "B40 -> time passed: 4.117 time per batch: 0.103\n",
      "B50 -> time passed: 5.578 time per batch: 0.112\n",
      "B60 -> time passed: 6.329 time per batch: 0.105\n",
      "B70 -> time passed: 6.806 time per batch: 0.097\n",
      "test processing time: 11.721887826919556\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.620 time per batch: 0.162\n",
      "B20 -> time passed: 2.436 time per batch: 0.122\n",
      "B30 -> time passed: 3.315 time per batch: 0.110\n",
      "B40 -> time passed: 4.220 time per batch: 0.105\n",
      "B50 -> time passed: 5.648 time per batch: 0.113\n",
      "B60 -> time passed: 6.338 time per batch: 0.106\n",
      "B70 -> time passed: 6.803 time per batch: 0.097\n",
      "test processing time: 11.713546752929688\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.581 time per batch: 0.158\n",
      "B20 -> time passed: 2.421 time per batch: 0.121\n",
      "B30 -> time passed: 3.182 time per batch: 0.106\n",
      "B40 -> time passed: 4.009 time per batch: 0.100\n",
      "B50 -> time passed: 5.476 time per batch: 0.110\n",
      "B60 -> time passed: 6.368 time per batch: 0.106\n",
      "B70 -> time passed: 6.827 time per batch: 0.098\n",
      "test processing time: 11.738307476043701\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.540 time per batch: 0.154\n",
      "B20 -> time passed: 2.407 time per batch: 0.120\n",
      "B30 -> time passed: 3.248 time per batch: 0.108\n",
      "B40 -> time passed: 4.119 time per batch: 0.103\n",
      "B50 -> time passed: 5.545 time per batch: 0.111\n",
      "B60 -> time passed: 6.414 time per batch: 0.107\n",
      "B70 -> time passed: 6.875 time per batch: 0.098\n",
      "test processing time: 11.800673961639404\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.578 time per batch: 0.158\n",
      "B20 -> time passed: 2.401 time per batch: 0.120\n",
      "B30 -> time passed: 3.232 time per batch: 0.108\n",
      "B40 -> time passed: 4.082 time per batch: 0.102\n",
      "B50 -> time passed: 5.573 time per batch: 0.111\n",
      "B60 -> time passed: 6.282 time per batch: 0.105\n",
      "B70 -> time passed: 6.769 time per batch: 0.097\n",
      "test processing time: 11.72349500656128\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d7.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 7 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.567 time per batch: 0.157\n",
      "B20 -> time passed: 2.371 time per batch: 0.119\n",
      "B30 -> time passed: 3.183 time per batch: 0.106\n",
      "B40 -> time passed: 4.016 time per batch: 0.100\n",
      "B50 -> time passed: 5.394 time per batch: 0.108\n",
      "B60 -> time passed: 6.207 time per batch: 0.103\n",
      "B70 -> time passed: 6.762 time per batch: 0.097\n",
      "test processing time: 11.67383861541748\n",
      "total time 299.7425308227539\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.489 time per batch: 0.149\n",
      "B20 -> time passed: 2.232 time per batch: 0.112\n",
      "B30 -> time passed: 3.035 time per batch: 0.101\n",
      "B40 -> time passed: 3.836 time per batch: 0.096\n",
      "B50 -> time passed: 5.246 time per batch: 0.105\n",
      "B60 -> time passed: 6.047 time per batch: 0.101\n",
      "B70 -> time passed: 6.526 time per batch: 0.093\n",
      "test processing time: 12.169445514678955\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.488 time per batch: 0.149\n",
      "B20 -> time passed: 2.250 time per batch: 0.112\n",
      "B30 -> time passed: 3.029 time per batch: 0.101\n",
      "B40 -> time passed: 3.813 time per batch: 0.095\n",
      "B50 -> time passed: 5.245 time per batch: 0.105\n",
      "B60 -> time passed: 5.981 time per batch: 0.100\n",
      "B70 -> time passed: 6.480 time per batch: 0.093\n",
      "test processing time: 8.78039026260376\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.291 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.915 time per batch: 0.098\n",
      "B50 -> time passed: 5.395 time per batch: 0.108\n",
      "B60 -> time passed: 6.091 time per batch: 0.102\n",
      "B70 -> time passed: 6.561 time per batch: 0.094\n",
      "test processing time: 8.847892045974731\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.468 time per batch: 0.147\n",
      "B20 -> time passed: 2.300 time per batch: 0.115\n",
      "B30 -> time passed: 3.129 time per batch: 0.104\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.064 time per batch: 0.101\n",
      "B60 -> time passed: 6.107 time per batch: 0.102\n",
      "B70 -> time passed: 6.566 time per batch: 0.094\n",
      "test processing time: 8.87236213684082\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.527 time per batch: 0.153\n",
      "B20 -> time passed: 2.334 time per batch: 0.117\n",
      "B30 -> time passed: 3.124 time per batch: 0.104\n",
      "B40 -> time passed: 3.895 time per batch: 0.097\n",
      "B50 -> time passed: 5.303 time per batch: 0.106\n",
      "B60 -> time passed: 6.092 time per batch: 0.102\n",
      "B70 -> time passed: 6.545 time per batch: 0.093\n",
      "test processing time: 8.844186544418335\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.489 time per batch: 0.149\n",
      "B20 -> time passed: 2.322 time per batch: 0.116\n",
      "B30 -> time passed: 3.078 time per batch: 0.103\n",
      "B40 -> time passed: 3.889 time per batch: 0.097\n",
      "B50 -> time passed: 5.112 time per batch: 0.102\n",
      "B60 -> time passed: 5.983 time per batch: 0.100\n",
      "B70 -> time passed: 6.480 time per batch: 0.093\n",
      "test processing time: 8.760201215744019\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.465 time per batch: 0.147\n",
      "B20 -> time passed: 2.257 time per batch: 0.113\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.825 time per batch: 0.096\n",
      "B50 -> time passed: 5.077 time per batch: 0.102\n",
      "B60 -> time passed: 5.959 time per batch: 0.099\n",
      "B70 -> time passed: 6.465 time per batch: 0.092\n",
      "test processing time: 8.736656188964844\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.728 time per batch: 0.173\n",
      "B20 -> time passed: 2.595 time per batch: 0.130\n",
      "B30 -> time passed: 3.453 time per batch: 0.115\n",
      "B40 -> time passed: 4.217 time per batch: 0.105\n",
      "B50 -> time passed: 5.516 time per batch: 0.110\n",
      "B60 -> time passed: 6.332 time per batch: 0.106\n",
      "B70 -> time passed: 6.830 time per batch: 0.098\n",
      "test processing time: 9.15454387664795\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.561 time per batch: 0.156\n",
      "B20 -> time passed: 2.321 time per batch: 0.116\n",
      "B30 -> time passed: 3.079 time per batch: 0.103\n",
      "B40 -> time passed: 3.858 time per batch: 0.096\n",
      "B50 -> time passed: 5.279 time per batch: 0.106\n",
      "B60 -> time passed: 5.973 time per batch: 0.100\n",
      "B70 -> time passed: 6.502 time per batch: 0.093\n",
      "test processing time: 12.08299994468689\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.486 time per batch: 0.149\n",
      "B20 -> time passed: 2.263 time per batch: 0.113\n",
      "B30 -> time passed: 3.030 time per batch: 0.101\n",
      "B40 -> time passed: 3.826 time per batch: 0.096\n",
      "B50 -> time passed: 5.195 time per batch: 0.104\n",
      "B60 -> time passed: 5.985 time per batch: 0.100\n",
      "B70 -> time passed: 6.486 time per batch: 0.093\n",
      "test processing time: 8.581599235534668\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.218 time per batch: 0.111\n",
      "B30 -> time passed: 3.009 time per batch: 0.100\n",
      "B40 -> time passed: 3.766 time per batch: 0.094\n",
      "B50 -> time passed: 5.209 time per batch: 0.104\n",
      "B60 -> time passed: 5.975 time per batch: 0.100\n",
      "B70 -> time passed: 6.473 time per batch: 0.092\n",
      "test processing time: 8.56675410270691\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.482 time per batch: 0.148\n",
      "B20 -> time passed: 2.263 time per batch: 0.113\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.841 time per batch: 0.096\n",
      "B50 -> time passed: 5.222 time per batch: 0.104\n",
      "B60 -> time passed: 6.011 time per batch: 0.100\n",
      "B70 -> time passed: 6.520 time per batch: 0.093\n",
      "test processing time: 8.69559121131897\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.480 time per batch: 0.148\n",
      "B20 -> time passed: 2.227 time per batch: 0.111\n",
      "B30 -> time passed: 3.051 time per batch: 0.102\n",
      "B40 -> time passed: 3.795 time per batch: 0.095\n",
      "B50 -> time passed: 5.247 time per batch: 0.105\n",
      "B60 -> time passed: 5.973 time per batch: 0.100\n",
      "B70 -> time passed: 6.432 time per batch: 0.092\n",
      "test processing time: 8.666771173477173\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.447 time per batch: 0.145\n",
      "B20 -> time passed: 2.211 time per batch: 0.111\n",
      "B30 -> time passed: 2.989 time per batch: 0.100\n",
      "B40 -> time passed: 3.755 time per batch: 0.094\n",
      "B50 -> time passed: 5.134 time per batch: 0.103\n",
      "B60 -> time passed: 5.911 time per batch: 0.099\n",
      "B70 -> time passed: 6.409 time per batch: 0.092\n",
      "test processing time: 8.628254652023315\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.491 time per batch: 0.149\n",
      "B20 -> time passed: 2.248 time per batch: 0.112\n",
      "B30 -> time passed: 3.009 time per batch: 0.100\n",
      "B40 -> time passed: 3.790 time per batch: 0.095\n",
      "B50 -> time passed: 5.173 time per batch: 0.103\n",
      "B60 -> time passed: 5.922 time per batch: 0.099\n",
      "B70 -> time passed: 6.440 time per batch: 0.092\n",
      "test processing time: 8.6037278175354\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.242 time per batch: 0.112\n",
      "B30 -> time passed: 3.019 time per batch: 0.101\n",
      "B40 -> time passed: 3.784 time per batch: 0.095\n",
      "B50 -> time passed: 5.134 time per batch: 0.103\n",
      "B60 -> time passed: 5.936 time per batch: 0.099\n",
      "B70 -> time passed: 6.473 time per batch: 0.092\n",
      "test processing time: 8.639649868011475\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.502 time per batch: 0.150\n",
      "B20 -> time passed: 2.278 time per batch: 0.114\n",
      "B30 -> time passed: 3.072 time per batch: 0.102\n",
      "B40 -> time passed: 3.838 time per batch: 0.096\n",
      "B50 -> time passed: 5.161 time per batch: 0.103\n",
      "B60 -> time passed: 6.100 time per batch: 0.102\n",
      "B70 -> time passed: 6.527 time per batch: 0.093\n",
      "test processing time: 12.103047847747803\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.515 time per batch: 0.151\n",
      "B20 -> time passed: 2.260 time per batch: 0.113\n",
      "B30 -> time passed: 3.039 time per batch: 0.101\n",
      "B40 -> time passed: 3.818 time per batch: 0.095\n",
      "B50 -> time passed: 5.209 time per batch: 0.104\n",
      "B60 -> time passed: 5.958 time per batch: 0.099\n",
      "B70 -> time passed: 6.439 time per batch: 0.092\n",
      "test processing time: 8.647602081298828\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.495 time per batch: 0.149\n",
      "B20 -> time passed: 2.320 time per batch: 0.116\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.841 time per batch: 0.096\n",
      "B50 -> time passed: 5.306 time per batch: 0.106\n",
      "B60 -> time passed: 5.986 time per batch: 0.100\n",
      "B70 -> time passed: 6.468 time per batch: 0.092\n",
      "test processing time: 8.650329351425171\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.498 time per batch: 0.150\n",
      "B20 -> time passed: 2.226 time per batch: 0.111\n",
      "B30 -> time passed: 3.055 time per batch: 0.102\n",
      "B40 -> time passed: 3.818 time per batch: 0.095\n",
      "B50 -> time passed: 5.192 time per batch: 0.104\n",
      "B60 -> time passed: 5.925 time per batch: 0.099\n",
      "B70 -> time passed: 6.517 time per batch: 0.093\n",
      "test processing time: 8.74188232421875\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.455 time per batch: 0.145\n",
      "B20 -> time passed: 2.380 time per batch: 0.119\n",
      "B30 -> time passed: 3.174 time per batch: 0.106\n",
      "B40 -> time passed: 3.948 time per batch: 0.099\n",
      "B50 -> time passed: 5.026 time per batch: 0.101\n",
      "B60 -> time passed: 6.098 time per batch: 0.102\n",
      "B70 -> time passed: 6.560 time per batch: 0.094\n",
      "test processing time: 8.781609535217285\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.552 time per batch: 0.155\n",
      "B20 -> time passed: 2.321 time per batch: 0.116\n",
      "B30 -> time passed: 3.074 time per batch: 0.102\n",
      "B40 -> time passed: 3.914 time per batch: 0.098\n",
      "B50 -> time passed: 5.272 time per batch: 0.105\n",
      "B60 -> time passed: 6.018 time per batch: 0.100\n",
      "B70 -> time passed: 6.479 time per batch: 0.093\n",
      "test processing time: 8.563255548477173\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.518 time per batch: 0.152\n",
      "B20 -> time passed: 2.314 time per batch: 0.116\n",
      "B30 -> time passed: 3.117 time per batch: 0.104\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.230 time per batch: 0.105\n",
      "B60 -> time passed: 5.949 time per batch: 0.099\n",
      "B70 -> time passed: 6.458 time per batch: 0.092\n",
      "test processing time: 8.58940076828003\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d8.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 8 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.481 time per batch: 0.148\n",
      "B20 -> time passed: 2.239 time per batch: 0.112\n",
      "B30 -> time passed: 3.051 time per batch: 0.102\n",
      "B40 -> time passed: 3.800 time per batch: 0.095\n",
      "B50 -> time passed: 5.187 time per batch: 0.104\n",
      "B60 -> time passed: 5.998 time per batch: 0.100\n",
      "B70 -> time passed: 6.499 time per batch: 0.093\n",
      "test processing time: 8.61234712600708\n",
      "total time 519.8136651515961\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.308 time per batch: 0.115\n",
      "B30 -> time passed: 3.121 time per batch: 0.104\n",
      "B40 -> time passed: 3.870 time per batch: 0.097\n",
      "B50 -> time passed: 5.343 time per batch: 0.107\n",
      "B60 -> time passed: 6.068 time per batch: 0.101\n",
      "B70 -> time passed: 6.597 time per batch: 0.094\n",
      "test processing time: 13.779090166091919\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.478 time per batch: 0.148\n",
      "B20 -> time passed: 2.322 time per batch: 0.116\n",
      "B30 -> time passed: 3.150 time per batch: 0.105\n",
      "B40 -> time passed: 3.986 time per batch: 0.100\n",
      "B50 -> time passed: 5.213 time per batch: 0.104\n",
      "B60 -> time passed: 6.147 time per batch: 0.102\n",
      "B70 -> time passed: 6.596 time per batch: 0.094\n",
      "test processing time: 9.164077043533325\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.545 time per batch: 0.155\n",
      "B20 -> time passed: 2.304 time per batch: 0.115\n",
      "B30 -> time passed: 3.143 time per batch: 0.105\n",
      "B40 -> time passed: 3.931 time per batch: 0.098\n",
      "B50 -> time passed: 5.349 time per batch: 0.107\n",
      "B60 -> time passed: 6.115 time per batch: 0.102\n",
      "B70 -> time passed: 6.576 time per batch: 0.094\n",
      "test processing time: 9.142718076705933\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.544 time per batch: 0.154\n",
      "B20 -> time passed: 2.357 time per batch: 0.118\n",
      "B30 -> time passed: 3.204 time per batch: 0.107\n",
      "B40 -> time passed: 4.021 time per batch: 0.101\n",
      "B50 -> time passed: 5.440 time per batch: 0.109\n",
      "B60 -> time passed: 6.210 time per batch: 0.104\n",
      "B70 -> time passed: 6.704 time per batch: 0.096\n",
      "test processing time: 9.247377395629883\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.542 time per batch: 0.154\n",
      "B20 -> time passed: 2.331 time per batch: 0.117\n",
      "B30 -> time passed: 3.123 time per batch: 0.104\n",
      "B40 -> time passed: 3.932 time per batch: 0.098\n",
      "B50 -> time passed: 5.234 time per batch: 0.105\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.622 time per batch: 0.095\n",
      "test processing time: 9.181488752365112\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.310 time per batch: 0.116\n",
      "B30 -> time passed: 3.100 time per batch: 0.103\n",
      "B40 -> time passed: 3.887 time per batch: 0.097\n",
      "B50 -> time passed: 5.330 time per batch: 0.107\n",
      "B60 -> time passed: 6.148 time per batch: 0.102\n",
      "B70 -> time passed: 6.574 time per batch: 0.094\n",
      "test processing time: 9.113417863845825\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.547 time per batch: 0.155\n",
      "B20 -> time passed: 2.332 time per batch: 0.117\n",
      "B30 -> time passed: 3.128 time per batch: 0.104\n",
      "B40 -> time passed: 3.953 time per batch: 0.099\n",
      "B50 -> time passed: 5.416 time per batch: 0.108\n",
      "B60 -> time passed: 6.168 time per batch: 0.103\n",
      "B70 -> time passed: 6.636 time per batch: 0.095\n",
      "test processing time: 9.197902917861938\n",
      "completed epochs: 10\n",
      "loading model model.b10.f0.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.150\n",
      "B20 -> time passed: 2.280 time per batch: 0.114\n",
      "B30 -> time passed: 3.051 time per batch: 0.102\n",
      "B40 -> time passed: 3.842 time per batch: 0.096\n",
      "B50 -> time passed: 5.216 time per batch: 0.104\n",
      "B60 -> time passed: 5.962 time per batch: 0.099\n",
      "B70 -> time passed: 6.451 time per batch: 0.092\n",
      "test processing time: 9.062001466751099\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.503 time per batch: 0.150\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.113 time per batch: 0.104\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.243 time per batch: 0.105\n",
      "B60 -> time passed: 6.025 time per batch: 0.100\n",
      "B70 -> time passed: 6.528 time per batch: 0.093\n",
      "test processing time: 13.229307174682617\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.542 time per batch: 0.154\n",
      "B20 -> time passed: 2.306 time per batch: 0.115\n",
      "B30 -> time passed: 3.034 time per batch: 0.101\n",
      "B40 -> time passed: 3.875 time per batch: 0.097\n",
      "B50 -> time passed: 5.247 time per batch: 0.105\n",
      "B60 -> time passed: 6.043 time per batch: 0.101\n",
      "B70 -> time passed: 6.540 time per batch: 0.093\n",
      "test processing time: 9.021817922592163\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.506 time per batch: 0.151\n",
      "B20 -> time passed: 2.295 time per batch: 0.115\n",
      "B30 -> time passed: 3.070 time per batch: 0.102\n",
      "B40 -> time passed: 3.861 time per batch: 0.097\n",
      "B50 -> time passed: 5.208 time per batch: 0.104\n",
      "B60 -> time passed: 5.980 time per batch: 0.100\n",
      "B70 -> time passed: 6.507 time per batch: 0.093\n",
      "test processing time: 8.944814443588257\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.528 time per batch: 0.153\n",
      "B20 -> time passed: 2.327 time per batch: 0.116\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.870 time per batch: 0.097\n",
      "B50 -> time passed: 5.309 time per batch: 0.106\n",
      "B60 -> time passed: 6.060 time per batch: 0.101\n",
      "B70 -> time passed: 6.575 time per batch: 0.094\n",
      "test processing time: 9.006447792053223\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.507 time per batch: 0.151\n",
      "B20 -> time passed: 2.299 time per batch: 0.115\n",
      "B30 -> time passed: 3.099 time per batch: 0.103\n",
      "B40 -> time passed: 3.933 time per batch: 0.098\n",
      "B50 -> time passed: 5.326 time per batch: 0.107\n",
      "B60 -> time passed: 6.070 time per batch: 0.101\n",
      "B70 -> time passed: 6.522 time per batch: 0.093\n",
      "test processing time: 8.935372591018677\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.446 time per batch: 0.145\n",
      "B20 -> time passed: 2.240 time per batch: 0.112\n",
      "B30 -> time passed: 2.999 time per batch: 0.100\n",
      "B40 -> time passed: 3.800 time per batch: 0.095\n",
      "B50 -> time passed: 5.111 time per batch: 0.102\n",
      "B60 -> time passed: 5.963 time per batch: 0.099\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 8.94249701499939\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.089 time per batch: 0.103\n",
      "B40 -> time passed: 3.885 time per batch: 0.097\n",
      "B50 -> time passed: 5.294 time per batch: 0.106\n",
      "B60 -> time passed: 6.065 time per batch: 0.101\n",
      "B70 -> time passed: 6.545 time per batch: 0.093\n",
      "test processing time: 8.955914497375488\n",
      "completed epochs: 10\n",
      "loading model model.b10.f1.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.528 time per batch: 0.153\n",
      "B20 -> time passed: 2.348 time per batch: 0.117\n",
      "B30 -> time passed: 3.149 time per batch: 0.105\n",
      "B40 -> time passed: 3.967 time per batch: 0.099\n",
      "B50 -> time passed: 5.398 time per batch: 0.108\n",
      "B60 -> time passed: 6.158 time per batch: 0.103\n",
      "B70 -> time passed: 6.625 time per batch: 0.095\n",
      "test processing time: 9.072700500488281\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.502 time per batch: 0.150\n",
      "B20 -> time passed: 2.345 time per batch: 0.117\n",
      "B30 -> time passed: 3.172 time per batch: 0.106\n",
      "B40 -> time passed: 3.988 time per batch: 0.100\n",
      "B50 -> time passed: 5.103 time per batch: 0.102\n",
      "B60 -> time passed: 6.089 time per batch: 0.101\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 13.320940256118774\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.455 time per batch: 0.145\n",
      "B20 -> time passed: 2.222 time per batch: 0.111\n",
      "B30 -> time passed: 2.994 time per batch: 0.100\n",
      "B40 -> time passed: 3.784 time per batch: 0.095\n",
      "B50 -> time passed: 5.200 time per batch: 0.104\n",
      "B60 -> time passed: 6.008 time per batch: 0.100\n",
      "B70 -> time passed: 6.483 time per batch: 0.093\n",
      "test processing time: 9.048021078109741\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.490 time per batch: 0.149\n",
      "B20 -> time passed: 2.302 time per batch: 0.115\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.885 time per batch: 0.097\n",
      "B50 -> time passed: 5.308 time per batch: 0.106\n",
      "B60 -> time passed: 6.024 time per batch: 0.100\n",
      "B70 -> time passed: 6.474 time per batch: 0.092\n",
      "test processing time: 8.986980438232422\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.445 time per batch: 0.145\n",
      "B20 -> time passed: 2.268 time per batch: 0.113\n",
      "B30 -> time passed: 3.043 time per batch: 0.101\n",
      "B40 -> time passed: 3.817 time per batch: 0.095\n",
      "B50 -> time passed: 5.036 time per batch: 0.101\n",
      "B60 -> time passed: 5.969 time per batch: 0.099\n",
      "B70 -> time passed: 6.480 time per batch: 0.093\n",
      "test processing time: 8.995705604553223\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.483 time per batch: 0.148\n",
      "B20 -> time passed: 2.239 time per batch: 0.112\n",
      "B30 -> time passed: 3.028 time per batch: 0.101\n",
      "B40 -> time passed: 3.872 time per batch: 0.097\n",
      "B50 -> time passed: 5.212 time per batch: 0.104\n",
      "B60 -> time passed: 5.987 time per batch: 0.100\n",
      "B70 -> time passed: 6.476 time per batch: 0.093\n",
      "test processing time: 9.054488897323608\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.517 time per batch: 0.152\n",
      "B20 -> time passed: 2.283 time per batch: 0.114\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.841 time per batch: 0.096\n",
      "B50 -> time passed: 5.128 time per batch: 0.103\n",
      "B60 -> time passed: 6.054 time per batch: 0.101\n",
      "B70 -> time passed: 6.531 time per batch: 0.093\n",
      "test processing time: 9.09089207649231\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.608 time per batch: 0.161\n",
      "B20 -> time passed: 2.409 time per batch: 0.120\n",
      "B30 -> time passed: 3.187 time per batch: 0.106\n",
      "B40 -> time passed: 4.015 time per batch: 0.100\n",
      "B50 -> time passed: 5.392 time per batch: 0.108\n",
      "B60 -> time passed: 6.089 time per batch: 0.101\n",
      "B70 -> time passed: 6.542 time per batch: 0.093\n",
      "test processing time: 9.036346912384033\n",
      "completed epochs: 10\n",
      "loading model model.b10.f2.d9.v20\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.317 time per batch: 0.116\n",
      "B30 -> time passed: 3.099 time per batch: 0.103\n",
      "B40 -> time passed: 3.936 time per batch: 0.098\n",
      "B50 -> time passed: 5.331 time per batch: 0.107\n",
      "B60 -> time passed: 6.066 time per batch: 0.101\n",
      "B70 -> time passed: 6.540 time per batch: 0.093\n",
      "test processing time: 9.069557905197144\n",
      "total time 751.0970087051392\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "\n",
    "for ds in range(7,10):\n",
    "    preds = []\n",
    "    for fold in range(3):\n",
    "        preds2 = []\n",
    "        for anum in range(8):\n",
    "            predictions = inference_one(fold = fold, anum = anum, bs=bs, dataset=ds)\n",
    "            preds2.append(predictions)\n",
    "        preds.append(np.stack(preds2))\n",
    "    preds = np.stack(preds)\n",
    "    print('total time', time.time() - stg)\n",
    "    \n",
    "    pickle.dump(preds, open(PATH_WORK/'preds_d{}_v{}'.format(ds, VERSION),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "243*4*4/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 78545, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13104, 0.00452, 0.04275, 0.03004, 0.0462 , 0.05505],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Files transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/zahar_chikishev/running/oof_d6_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d6_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d6_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f0_v20 [Content-Type=application/octet-stream]...\n",
      "- [4 files][164.5 MiB/164.5 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f2_v20 [Content-Type=application/octet-stream]...\n",
      "| [12 files][493.8 MiB/493.8 MiB]   35.9 MiB/s                                  \n",
      "Operation completed over 12 objects/493.8 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/zahar_chikishev/running/oof* gs://rsna-hemorrhage/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/zahar_chikishev/running/preds_d6_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d7_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d8_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d9_v20 [Content-Type=application/octet-stream]...\n",
      "\\ [4 files][172.6 MiB/172.6 MiB]                                                \n",
      "Operation completed over 4 objects/172.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/zahar_chikishev/running/preds* gs://rsna-hemorrhage/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!gsutil gs://rsna-hemorrhage/results/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!rm /home/zahar_chikishev/running/*v53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/preds_se_resnext101_32x4d_v53\r\n",
      "/home/zahar_chikishev/running/stats.f0.v53\r\n",
      "/home/zahar_chikishev/running/stats.f1.v53\r\n",
      "/home/zahar_chikishev/running/stats.f2.v53\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/*v53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/oof_Densenet161_f0_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet161_f1_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet161_f2_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f0_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f1_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f2_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f0_v74\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f1_v74\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f2_v74\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f0_v75\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f1_v75\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f2_v75\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/oof*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/preds_Densenet161_v72\r\n",
      "/home/zahar_chikishev/running/preds_Densenet169_v73\r\n",
      "/home/zahar_chikishev/running/preds_Densenet201_v74\r\n",
      "/home/zahar_chikishev/running/preds_se_resnext101_32x4d_v75\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/preds*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = getPredsOOF(aug=8,datasets=range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 674252, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model 0 fold 0 target 0\n",
      "obj  0.09979766095518008\n",
      "obj  0.09961585668029331\n",
      "obj  0.09940183354500212\n",
      "obj  0.0997755135834763\n",
      "obj  0.09933168323073682\n",
      "obj  0.09945748935375663\n",
      "obj  0.09940373951698349\n",
      "obj  0.09942177295444647\n",
      "obj  0.09921536057053071\n",
      "obj  0.099121073907933\n",
      "obj  0.099088423855841\n",
      "obj  0.09907867324851787\n",
      "obj  0.09907624409101681\n",
      "obj  0.09907505118803715\n",
      "obj  0.09907475827537518\n",
      "obj  0.09907470333472539\n",
      "obj  0.09907470330769187\n",
      "obj  0.09907470330732189\n",
      "obj  0.09907468857023731\n",
      "obj  0.09907468703188567\n",
      "v20 d0 f0 t0: original ll 0.1012 auc 0.9858, ensemble ll 0.1007 auc 0.9858\n",
      "running time 3.539911985397339\n",
      "starting model 0 fold 0 target 1\n",
      "obj  0.015673323307283715\n",
      "obj  0.015576802486972807\n",
      "obj  0.015364412957950959\n",
      "obj  0.014857900512090887\n",
      "obj  0.014786759655969383\n",
      "obj  0.014885529683399462\n",
      "obj  0.014855272337509145\n",
      "obj  0.014672268038367752\n",
      "obj  0.01451015362003513\n",
      "obj  0.01424971359498118\n",
      "obj  0.014161990476846645\n",
      "obj  0.014134198794634326\n",
      "obj  0.014126901631697183\n",
      "obj  0.014125877264350788\n",
      "obj  0.014125758900651951\n",
      "obj  0.014125732849049387\n",
      "obj  0.014125725085143604\n",
      "v20 d0 f0 t1: original ll 0.0169 auc 0.9717, ensemble ll 0.0167 auc 0.9716\n",
      "running time 2.970916986465454\n",
      "starting model 0 fold 0 target 2\n",
      "obj  0.04215510061702556\n",
      "obj  0.04213052595557809\n",
      "obj  0.04212410144502233\n",
      "obj  0.04213689968911825\n",
      "obj  0.04211530403887279\n",
      "obj  0.042111803443026105\n",
      "obj  0.04211119271416211\n",
      "obj  0.04211164593544626\n",
      "obj  0.04210699337604284\n",
      "obj  0.04210583243452417\n",
      "obj  0.042101221057637465\n",
      "obj  0.042099434619426106\n",
      "obj  0.0420994213316849\n",
      "obj  0.04209940144696236\n",
      "obj  0.04209938164580238\n",
      "obj  0.04209938164551937\n",
      "obj  0.04209937952717637\n",
      "obj  0.04209937951324421\n",
      "v20 d0 f0 t2: original ll 0.0479 auc 0.9903, ensemble ll 0.0477 auc 0.9903\n",
      "running time 3.1200718879699707\n",
      "starting model 0 fold 0 target 3\n",
      "obj  0.025584332334302972\n",
      "obj  0.02558895486303846\n",
      "obj  0.025601179423625855\n",
      "obj  0.02554490647463725\n",
      "obj  0.025579373429467252\n",
      "obj  0.025555878832457395\n",
      "obj  0.025559618153300417\n",
      "obj  0.02555763317640762\n",
      "obj  0.025543504061299207\n",
      "obj  0.025509773574208784\n",
      "obj  0.02550661848566222\n",
      "obj  0.025502430284124494\n",
      "obj  0.025500493790750964\n",
      "obj  0.025498930520069782\n",
      "obj  0.02549891106794045\n",
      "obj  0.025498571467033278\n",
      "obj  0.025498368620503326\n",
      "obj  0.025498328567216687\n",
      "obj  0.02549831804116824\n",
      "obj  0.02549831803792937\n",
      "v20 d0 f0 t3: original ll 0.0280 auc 0.9955, ensemble ll 0.0280 auc 0.9955\n",
      "running time 3.2933719158172607\n",
      "starting model 0 fold 0 target 4\n",
      "obj  0.06638482259710225\n",
      "obj  0.06634113758869958\n",
      "obj  0.06627688486945489\n",
      "obj  0.06647905365263565\n",
      "obj  0.06627500792395238\n",
      "obj  0.06628679331402008\n",
      "obj  0.06628713427776439\n",
      "obj  0.06627578251216705\n",
      "obj  0.06624915098843182\n",
      "obj  0.06622527377728303\n",
      "obj  0.06621229049923384\n",
      "obj  0.06620419992817089\n",
      "obj  0.06620151825048151\n",
      "obj  0.06620110582000989\n",
      "obj  0.06620105359019457\n",
      "obj  0.06620104413075409\n",
      "obj  0.06620104237717549\n",
      "v20 d0 f0 t4: original ll 0.0697 auc 0.9784, ensemble ll 0.0696 auc 0.9784\n",
      "running time 3.005765676498413\n",
      "starting model 0 fold 0 target 5\n",
      "obj  0.08121655484473948\n",
      "obj  0.08104221217330303\n",
      "obj  0.08091178206202208\n",
      "obj  0.08104142173914856\n",
      "obj  0.08083106445781738\n",
      "obj  0.08082919326982421\n",
      "obj  0.08082970365381219\n",
      "obj  0.08082976492582301\n",
      "obj  0.08076969352089139\n",
      "obj  0.08071237534348247\n",
      "obj  0.08069578357688174\n",
      "obj  0.08069145139872153\n",
      "obj  0.08069076063174647\n",
      "obj  0.0806907259040705\n",
      "obj  0.08069063168838665\n",
      "obj  0.0806906177726468\n",
      "obj  0.08069061357391376\n",
      "v20 d0 f0 t5: original ll 0.0853 auc 0.9768, ensemble ll 0.0850 auc 0.9768\n",
      "running time 3.1142630577087402\n",
      "starting model 1 fold 0 target 0\n",
      "obj  0.09876499556740514\n",
      "obj  0.0986411241546047\n",
      "obj  0.09841245967430602\n",
      "obj  0.0988034300533687\n",
      "obj  0.09831867156029404\n",
      "obj  0.09845749560014304\n",
      "obj  0.0983902302153383\n",
      "obj  0.09841046466787262\n",
      "obj  0.09814954119887563\n",
      "obj  0.09802991524156075\n",
      "obj  0.09799018376314426\n",
      "obj  0.09797471748260295\n",
      "obj  0.09796955855280634\n",
      "obj  0.0979685698297722\n",
      "obj  0.09796855659816582\n",
      "obj  0.0979685560690015\n",
      "obj  0.09796838989211575\n",
      "obj  0.09796838988813161\n",
      "obj  0.0979683687498166\n",
      "v20 d1 f0 t0: original ll 0.1008 auc 0.9859, ensemble ll 0.1001 auc 0.9859\n",
      "running time 3.31313157081604\n",
      "starting model 1 fold 0 target 1\n",
      "obj  0.016744180155405117\n",
      "obj  0.016672431271385926\n",
      "obj  0.016510174303673724\n",
      "obj  0.01627275664278231\n",
      "obj  0.01591537953890579\n",
      "obj  0.015849870662636878\n",
      "obj  0.015929670489985736\n",
      "obj  0.01573400485605853\n",
      "obj  0.01553457240326477\n",
      "obj  0.01526987169719734\n",
      "obj  0.015183214167160385\n",
      "obj  0.015157509017558624\n",
      "obj  0.01515178665720026\n",
      "obj  0.01515089962562649\n",
      "obj  0.015150478384144843\n",
      "obj  0.015150382764855641\n",
      "obj  0.015150368118300114\n",
      "obj  0.015150364585121612\n",
      "obj  0.015150363276374215\n",
      "v20 d1 f0 t1: original ll 0.0177 auc 0.9703, ensemble ll 0.0173 auc 0.9700\n",
      "running time 3.2406585216522217\n",
      "starting model 1 fold 0 target 2\n",
      "obj  0.041745951568481286\n",
      "obj  0.0417321736306885\n",
      "obj  0.04172065423532756\n",
      "obj  0.041756692195759434\n",
      "obj  0.041710074052990105\n",
      "obj  0.04171077110861845\n",
      "obj  0.04170991935215524\n",
      "obj  0.04171173844201555\n",
      "obj  0.04167344693187822\n",
      "obj  0.04167338558807318\n",
      "obj  0.041667664584949436\n",
      "obj  0.041667663368463864\n",
      "obj  0.04166243369591199\n",
      "obj  0.04166243349638365\n",
      "obj  0.04166134196985386\n",
      "obj  0.041660962100899104\n",
      "obj  0.04166095994300851\n",
      "obj  0.04166095729113985\n",
      "obj  0.04166094346358248\n",
      "obj  0.04166093330414451\n",
      "obj  0.04166092973004853\n",
      "obj  0.04166092909566688\n",
      "v20 d1 f0 t2: original ll 0.0445 auc 0.9915, ensemble ll 0.0444 auc 0.9915\n",
      "running time 3.598059892654419\n",
      "starting model 1 fold 0 target 3\n",
      "obj  0.025057710315840313\n",
      "obj  0.025055967606155895\n",
      "obj  0.02508873402397685\n",
      "obj  0.02497282924233273\n",
      "obj  0.025069646014343947\n",
      "obj  0.025037288243787408\n",
      "obj  0.02504297974774666\n",
      "obj  0.025039385967902977\n",
      "obj  0.02501000022783198\n",
      "obj  0.024963422214659765\n",
      "obj  0.024948720136814793\n",
      "obj  0.024946964062276096\n",
      "obj  0.02494619104800339\n",
      "obj  0.024946053991408135\n",
      "obj  0.024946041657694915\n",
      "obj  0.024946039088670484\n",
      "obj  0.0249460383551914\n",
      "v20 d1 f0 t3: original ll 0.0271 auc 0.9958, ensemble ll 0.0271 auc 0.9958\n",
      "running time 3.104348659515381\n",
      "starting model 1 fold 0 target 4\n",
      "obj  0.06562205970358545\n",
      "obj  0.06556460163275374\n",
      "obj  0.06550181577211975\n",
      "obj  0.065764014792816\n",
      "obj  0.06546481236263046\n",
      "obj  0.06546090543238485\n",
      "obj  0.06545773623493324\n",
      "obj  0.06546264151925803\n",
      "obj  0.06544768587885974\n",
      "obj  0.06540018157020823\n",
      "obj  0.06538335988176362\n",
      "obj  0.06537808068032858\n",
      "obj  0.065376319379509\n",
      "obj  0.06537624895873552\n",
      "obj  0.06537598633989257\n",
      "obj  0.06537594591612664\n",
      "obj  0.06537594588477649\n",
      "obj  0.06537593580987802\n",
      "v20 d1 f0 t4: original ll 0.0682 auc 0.9795, ensemble ll 0.0682 auc 0.9795\n",
      "running time 3.251560688018799\n",
      "starting model 1 fold 0 target 5\n",
      "obj  0.08046364290416866\n",
      "obj  0.08030014724226603\n",
      "obj  0.08018074977554679\n",
      "obj  0.08034086414524445\n",
      "obj  0.08011048726912356\n",
      "obj  0.08011778445475431\n",
      "obj  0.08011710559372434\n",
      "obj  0.08011755080030834\n",
      "obj  0.08005473475796222\n",
      "obj  0.07999140462133253\n",
      "obj  0.07997150313806549\n",
      "obj  0.07996639775613233\n",
      "obj  0.07996557542533728\n",
      "obj  0.07996536725177911\n",
      "obj  0.0799653321446502\n",
      "obj  0.07996532330880796\n",
      "obj  0.07996532143084473\n",
      "v20 d1 f0 t5: original ll 0.0851 auc 0.9768, ensemble ll 0.0844 auc 0.9768\n",
      "running time 3.1015074253082275\n",
      "starting model 2 fold 0 target 0\n",
      "obj  0.09953745698044954\n",
      "obj  0.09946278286725047\n",
      "obj  0.09939503747183527\n",
      "obj  0.09955371924235588\n",
      "obj  0.09936803504927527\n",
      "obj  0.09940336071246814\n",
      "obj  0.09938726548010744\n",
      "obj  0.09939314238335509\n",
      "obj  0.09936473781083467\n",
      "obj  0.0993580843044562\n",
      "obj  0.09935236566606806\n",
      "obj  0.09935236562244452\n",
      "obj  0.0993486292395196\n",
      "obj  0.09934862734276662\n",
      "obj  0.09934841033730263\n",
      "obj  0.09934834796813252\n",
      "obj  0.09934833250984516\n",
      "obj  0.09934832739503531\n",
      "obj  0.09934832587908891\n",
      "v20 d2 f0 t0: original ll 0.1004 auc 0.9859, ensemble ll 0.1002 auc 0.9859\n",
      "running time 3.389338970184326\n",
      "starting model 2 fold 0 target 1\n",
      "obj  0.015745487470325503\n",
      "obj  0.01574167082241162\n",
      "obj  0.015709887937255435\n",
      "obj  0.01567704090496781\n",
      "obj  0.01566575387121012\n",
      "obj  0.015699656010446185\n",
      "obj  0.015700689998276996\n",
      "obj  0.015657797288099157\n",
      "obj  0.015618207792351367\n",
      "obj  0.015599475041658954\n",
      "obj  0.015588521600954294\n",
      "obj  0.01558833022058219\n",
      "obj  0.01558758988590166\n",
      "obj  0.015587469334766431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.015587410343224278\n",
      "obj  0.015587406479076537\n",
      "obj  0.015587405733097484\n",
      "v20 d2 f0 t1: original ll 0.0189 auc 0.9614, ensemble ll 0.0188 auc 0.9614\n",
      "running time 3.0857245922088623\n",
      "starting model 2 fold 0 target 2\n",
      "obj  0.04381530752479414\n",
      "obj  0.04382092473354208\n",
      "obj  0.043826213719472776\n",
      "obj  0.0438761375891912\n",
      "obj  0.04382003572466065\n",
      "obj  0.04381854178181301\n",
      "obj  0.04382020529268252\n",
      "obj  0.04381873262497733\n",
      "obj  0.04381574982340534\n",
      "obj  0.0438112403041496\n",
      "obj  0.04380585125878961\n",
      "obj  0.04380581837443902\n",
      "obj  0.04380581821386982\n",
      "obj  0.043804991789500446\n",
      "obj  0.043804986643855154\n",
      "obj  0.04380495235246444\n",
      "obj  0.04380495128328548\n",
      "obj  0.04380494356462415\n",
      "obj  0.0438049412712365\n",
      "obj  0.043804941258758764\n",
      "obj  0.04380494086151709\n",
      "v20 d2 f0 t2: original ll 0.0464 auc 0.9910, ensemble ll 0.0464 auc 0.9910\n",
      "running time 3.6098880767822266\n",
      "starting model 2 fold 0 target 3\n",
      "obj  0.02623857473598352\n",
      "obj  0.026252632708053315\n",
      "obj  0.026290365223252506\n",
      "obj  0.026150729184865214\n",
      "obj  0.026275597396815016\n",
      "obj  0.02624421952904109\n",
      "obj  0.02625046866505739\n",
      "obj  0.026246059252217943\n",
      "obj  0.026202893687442462\n",
      "obj  0.026151336503180855\n",
      "obj  0.02614720348176635\n",
      "obj  0.026128203199050737\n",
      "obj  0.026126899235843222\n",
      "obj  0.02612604282014597\n",
      "obj  0.026125849610542203\n",
      "obj  0.02612579469015988\n",
      "v20 d2 f0 t3: original ll 0.0282 auc 0.9954, ensemble ll 0.0283 auc 0.9954\n",
      "running time 2.964418888092041\n",
      "starting model 2 fold 0 target 4\n",
      "obj  0.066231826543209\n",
      "obj  0.06622148360396689\n",
      "obj  0.06620374676277495\n",
      "obj  0.06632361064728116\n",
      "obj  0.06619096553244706\n",
      "obj  0.06619004287859431\n",
      "obj  0.0661892210126986\n",
      "obj  0.06619048959473164\n",
      "obj  0.06619048985770928\n",
      "obj  0.06617828814278036\n",
      "obj  0.06617332073380867\n",
      "obj  0.06617292140140935\n",
      "obj  0.0661726786179169\n",
      "obj  0.06617264768557249\n",
      "obj  0.06617263936070303\n",
      "obj  0.06617263846802054\n",
      "v20 d2 f0 t4: original ll 0.0687 auc 0.9792, ensemble ll 0.0687 auc 0.9792\n",
      "running time 2.9853992462158203\n",
      "starting model 2 fold 0 target 5\n",
      "obj  0.08066135216937778\n",
      "obj  0.08056656588761141\n",
      "obj  0.08051284381187708\n",
      "obj  0.08051264598530125\n",
      "obj  0.08046184248776213\n",
      "obj  0.08043397193200578\n",
      "obj  0.08043598353645695\n",
      "obj  0.08043657815611367\n",
      "obj  0.08043006201125273\n",
      "obj  0.08040736724163781\n",
      "obj  0.08040694787308893\n",
      "obj  0.08040345736954045\n",
      "obj  0.08040298115982344\n",
      "obj  0.08040134218436687\n",
      "obj  0.08040054905617416\n",
      "obj  0.08040044902230431\n",
      "obj  0.08040042598682037\n",
      "obj  0.08040041932795566\n",
      "obj  0.08040041828098156\n",
      "v20 d2 f0 t5: original ll 0.0842 auc 0.9772, ensemble ll 0.0840 auc 0.9772\n",
      "running time 3.3495113849639893\n",
      "starting model 3 fold 0 target 0\n",
      "obj  0.09786478475673205\n",
      "obj  0.09774131794740548\n",
      "obj  0.09756343531235065\n",
      "obj  0.09781981467378009\n",
      "obj  0.09746810336323834\n",
      "obj  0.09755651838630393\n",
      "obj  0.0974985491467813\n",
      "obj  0.09751198554984873\n",
      "obj  0.09735929321771951\n",
      "obj  0.09729652149976528\n",
      "obj  0.09727089662877357\n",
      "obj  0.09726485805397717\n",
      "obj  0.09726304145432227\n",
      "obj  0.09726277699261103\n",
      "obj  0.09726271983889459\n",
      "obj  0.09726269964382839\n",
      "obj  0.09726269899463902\n",
      "obj  0.09726269899463902\n",
      "v20 d3 f0 t0: original ll 0.1001 auc 0.9862, ensemble ll 0.0994 auc 0.9862\n",
      "running time 3.2452948093414307\n",
      "starting model 3 fold 0 target 1\n",
      "obj  0.0161849651787413\n",
      "obj  0.01617799676677537\n",
      "obj  0.016180513981093745\n",
      "obj  0.016145704673152208\n",
      "obj  0.016174803850993798\n",
      "obj  0.016177179663849572\n",
      "obj  0.016179060597547493\n",
      "obj  0.01615773132283754\n",
      "obj  0.016138323400902547\n",
      "obj  0.01612744016805083\n",
      "obj  0.016126722399627872\n",
      "obj  0.016126191314156216\n",
      "obj  0.01612608813694468\n",
      "obj  0.016126078319135026\n",
      "obj  0.016126076640703355\n",
      "v20 d3 f0 t1: original ll 0.0180 auc 0.9661, ensemble ll 0.0181 auc 0.9661\n",
      "running time 2.815768241882324\n",
      "starting model 3 fold 0 target 2\n",
      "obj  0.041233658839903854\n",
      "obj  0.041228467636668494\n",
      "obj  0.04121053015470861\n",
      "obj  0.0412598573737825\n",
      "obj  0.041196558352031454\n",
      "obj  0.041210926610058526\n",
      "obj  0.04120791118922662\n",
      "obj  0.041210469010721375\n",
      "obj  0.04120416403108851\n",
      "obj  0.041198320869998785\n",
      "obj  0.04119357211170512\n",
      "obj  0.041193570766303915\n",
      "obj  0.04119250365583321\n",
      "obj  0.04119247995626886\n",
      "obj  0.041192463917763704\n",
      "obj  0.0411924639170445\n",
      "obj  0.0411924495998273\n",
      "v20 d3 f0 t2: original ll 0.0445 auc 0.9918, ensemble ll 0.0444 auc 0.9918\n",
      "running time 3.075819969177246\n",
      "starting model 3 fold 0 target 3\n",
      "obj  0.02507853797952349\n",
      "obj  0.025085097326237264\n",
      "obj  0.025122331957599612\n",
      "obj  0.024980175987916655\n",
      "obj  0.025097407217010356\n",
      "obj  0.02505861784500213\n",
      "obj  0.025067764120909664\n",
      "obj  0.025062391464019968\n",
      "obj  0.02503005198618636\n",
      "obj  0.024934029492984403\n",
      "obj  0.02493393308175546\n",
      "obj  0.024906792887353042\n",
      "obj  0.02490547891018716\n",
      "obj  0.02490474343076872\n",
      "obj  0.02490473963681639\n",
      "obj  0.024904543539118366\n",
      "obj  0.024904506755725878\n",
      "obj  0.02490450340825465\n",
      "v20 d3 f0 t3: original ll 0.0276 auc 0.9957, ensemble ll 0.0275 auc 0.9957\n",
      "running time 2.793642520904541\n",
      "starting model 3 fold 0 target 4\n",
      "obj  0.06537545081337902\n",
      "obj  0.06534687728147526\n",
      "obj  0.0652975439910289\n",
      "obj  0.06541731714869557\n",
      "obj  0.0652701245810101\n",
      "obj  0.06526298687578805\n",
      "obj  0.06526425094061299\n",
      "obj  0.06526641428831323\n",
      "obj  0.06524931247316731\n",
      "obj  0.06522171363446394\n",
      "obj  0.06521041116117639\n",
      "obj  0.06520545063297453\n",
      "obj  0.06520536945460545\n",
      "obj  0.0652033310357768\n",
      "obj  0.06520305000294438\n",
      "obj  0.06520302749668508\n",
      "obj  0.06520302188376839\n",
      "obj  0.06520302134438025\n",
      "v20 d3 f0 t4: original ll 0.0668 auc 0.9803, ensemble ll 0.0668 auc 0.9803\n",
      "running time 2.8030669689178467\n",
      "starting model 3 fold 0 target 5\n",
      "obj  0.07983471234854772\n",
      "obj  0.07971129896637766\n",
      "obj  0.079621883706685\n",
      "obj  0.07969765934273923\n",
      "obj  0.0795443357830253\n",
      "obj  0.07952654854176276\n",
      "obj  0.07952821874247151\n",
      "obj  0.07953297999509097\n",
      "obj  0.07947910037345529\n",
      "obj  0.07943814025520178\n",
      "obj  0.07942828645197512\n",
      "obj  0.07942509242089228\n",
      "obj  0.07942459424605254\n",
      "obj  0.07942437560545342\n",
      "obj  0.07942435697492263\n",
      "obj  0.07942435696433617\n",
      "obj  0.07942435509564275\n",
      "obj  0.0794243550955972\n",
      "v20 d3 f0 t5: original ll 0.0843 auc 0.9772, ensemble ll 0.0839 auc 0.9772\n",
      "running time 2.799323558807373\n",
      "starting model 0 fold 1 target 0\n",
      "obj  0.09954141742327241\n",
      "obj  0.09940150769863325\n",
      "obj  0.09923119070194618\n",
      "obj  0.09960295793910028\n",
      "obj  0.09916997465191403\n",
      "obj  0.09929193009477161\n",
      "obj  0.09923653010480023\n",
      "obj  0.09925407228251508\n",
      "obj  0.09904640712752698\n",
      "obj  0.09895463419687262\n",
      "obj  0.09892702157716073\n",
      "obj  0.09891402115186897\n",
      "obj  0.09891138583112906\n",
      "obj  0.09891015387159742\n",
      "obj  0.098909952190558\n",
      "obj  0.09890985217989165\n",
      "obj  0.09890983733491857\n",
      "v20 d0 f1 t0: original ll 0.1017 auc 0.9853, ensemble ll 0.1010 auc 0.9853\n",
      "running time 2.766507625579834\n",
      "starting model 0 fold 1 target 1\n",
      "obj  0.01663672430077912\n",
      "obj  0.016576666864045034\n",
      "obj  0.0163302289415794\n",
      "obj  0.016109476447102\n",
      "obj  0.016168345619630875\n",
      "obj  0.016219358103661895\n",
      "obj  0.01621958837575465\n",
      "obj  0.016172325406092824\n",
      "obj  0.01600132072172271\n",
      "obj  0.015902061221372842\n",
      "obj  0.01586930102238942\n",
      "obj  0.015855967837826963\n",
      "obj  0.015851245409151584\n",
      "obj  0.01584955312732295\n",
      "obj  0.015849545340133015\n",
      "obj  0.01584926103962769\n",
      "obj  0.015849216809805243\n",
      "obj  0.015849210197474622\n",
      "obj  0.015849208273111384\n",
      "v20 d0 f1 t1: original ll 0.0150 auc 0.9626, ensemble ll 0.0135 auc 0.9626\n",
      "running time 2.874387502670288\n",
      "starting model 0 fold 1 target 2\n",
      "obj  0.04455167583328118\n",
      "obj  0.04452259392869696\n",
      "obj  0.044503913559154194\n",
      "obj  0.04455180264506263\n",
      "obj  0.044489310098666\n",
      "obj  0.04449191747277865\n",
      "obj  0.04449100275857364\n",
      "obj  0.044493515860044214\n",
      "obj  0.04445641243839154\n",
      "obj  0.04445304882806373\n",
      "obj  0.04444563054579021\n",
      "obj  0.044443080602625654\n",
      "obj  0.04444262093540345\n",
      "obj  0.04444234064435863\n",
      "obj  0.044442338536717245\n",
      "obj  0.04444231450129593\n",
      "obj  0.04444231449683145\n",
      "obj  0.04444231152491646\n",
      "v20 d0 f1 t2: original ll 0.0431 auc 0.9914, ensemble ll 0.0431 auc 0.9914\n",
      "running time 2.8084816932678223\n",
      "starting model 0 fold 1 target 3\n",
      "obj  0.027148825452795497\n",
      "obj  0.027148784563619834\n",
      "obj  0.027159165868334733\n",
      "obj  0.027127240949532026\n",
      "obj  0.027142147372189653\n",
      "obj  0.02712306025859961\n",
      "obj  0.027125679919414357\n",
      "obj  0.02712421915399339\n",
      "obj  0.02711898844532755\n",
      "obj  0.027097295236043886\n",
      "obj  0.02709536634643914\n",
      "obj  0.027093104098701026\n",
      "obj  0.02709302683076838\n",
      "obj  0.027092805364842574\n",
      "obj  0.02709280535328573\n",
      "obj  0.027092803680827775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.027092799799147287\n",
      "obj  0.02709279906722279\n",
      "v20 d0 f1 t3: original ll 0.0249 auc 0.9964, ensemble ll 0.0248 auc 0.9964\n",
      "running time 2.812549591064453\n",
      "starting model 0 fold 1 target 4\n",
      "obj  0.06821833756093888\n",
      "obj  0.06820198521186313\n",
      "obj  0.06812626740659362\n",
      "obj  0.06833609979844635\n",
      "obj  0.06811388527284636\n",
      "obj  0.06812535115003562\n",
      "obj  0.06812566414209827\n",
      "obj  0.06812973209104302\n",
      "obj  0.06809238048589937\n",
      "obj  0.06807188707410791\n",
      "obj  0.06806139728794137\n",
      "obj  0.0680565199121393\n",
      "obj  0.0680547562444491\n",
      "obj  0.06805475048755669\n",
      "obj  0.06805455078119282\n",
      "obj  0.06805453543470988\n",
      "v20 d0 f1 t4: original ll 0.0660 auc 0.9786, ensemble ll 0.0660 auc 0.9786\n",
      "running time 2.614344596862793\n",
      "starting model 0 fold 1 target 5\n",
      "obj  0.08211417574761934\n",
      "obj  0.08197287435949328\n",
      "obj  0.08186687342318155\n",
      "obj  0.08202624111367793\n",
      "obj  0.0818053769771145\n",
      "obj  0.08181383692885172\n",
      "obj  0.08181258472353789\n",
      "obj  0.08181217045728839\n",
      "obj  0.08174294547350487\n",
      "obj  0.08168610239399467\n",
      "obj  0.08166541604445833\n",
      "obj  0.08166148665988336\n",
      "obj  0.08166065388095665\n",
      "obj  0.08166049256289763\n",
      "obj  0.0816604587512935\n",
      "obj  0.08166045576284989\n",
      "v20 d0 f1 t5: original ll 0.0835 auc 0.9769, ensemble ll 0.0830 auc 0.9769\n",
      "running time 2.6286392211914062\n",
      "starting model 1 fold 1 target 0\n",
      "obj  0.09840430652627424\n",
      "obj  0.0983302104026401\n",
      "obj  0.09815847926996385\n",
      "obj  0.09860768163435324\n",
      "obj  0.09808520105305915\n",
      "obj  0.09823953628741078\n",
      "obj  0.0981633328711804\n",
      "obj  0.09818594767306993\n",
      "obj  0.09786362299061929\n",
      "obj  0.09774220325662164\n",
      "obj  0.09767725260330488\n",
      "obj  0.09765357472232511\n",
      "obj  0.09764691373847549\n",
      "obj  0.09764605626142948\n",
      "obj  0.09764605526785639\n",
      "obj  0.09764582645722285\n",
      "obj  0.09764577649103377\n",
      "obj  0.09764576398421841\n",
      "v20 d1 f1 t0: original ll 0.1016 auc 0.9856, ensemble ll 0.1008 auc 0.9856\n",
      "running time 2.8492588996887207\n",
      "starting model 1 fold 1 target 1\n",
      "obj  0.01749498835532907\n",
      "obj  0.017411407062781877\n",
      "obj  0.017186356974123244\n",
      "obj  0.01690126312358716\n",
      "obj  0.01697223251041593\n",
      "obj  0.017024058463290154\n",
      "obj  0.017026887894880344\n",
      "obj  0.016969255597829146\n",
      "obj  0.016780873319275358\n",
      "obj  0.016681571225714294\n",
      "obj  0.016646936871945312\n",
      "obj  0.016631318036853807\n",
      "obj  0.01662574020163539\n",
      "obj  0.01662314870043825\n",
      "obj  0.016622609588665672\n",
      "obj  0.01662252631472447\n",
      "obj  0.016622500131021983\n",
      "obj  0.016622494732554356\n",
      "obj  0.016622493910025\n",
      "obj  0.01662249369853373\n",
      "v20 d1 f1 t1: original ll 0.0162 auc 0.9578, ensemble ll 0.0144 auc 0.9578\n",
      "running time 2.959167242050171\n",
      "starting model 1 fold 1 target 2\n",
      "obj  0.041996605974248695\n",
      "obj  0.041977465632223675\n",
      "obj  0.04197228176156829\n",
      "obj  0.04202721896884613\n",
      "obj  0.04194454874158519\n",
      "obj  0.041930037766170256\n",
      "obj  0.04193115471642995\n",
      "obj  0.04193134963554901\n",
      "obj  0.04192898486404312\n",
      "obj  0.041914024201650996\n",
      "obj  0.04191058052781774\n",
      "obj  0.04191012328316368\n",
      "obj  0.041908874806457344\n",
      "obj  0.041908869897723036\n",
      "obj  0.041908640704752954\n",
      "obj  0.041908560266879696\n",
      "obj  0.04190850814415503\n",
      "obj  0.041908492361775095\n",
      "v20 d1 f1 t2: original ll 0.0440 auc 0.9910, ensemble ll 0.0439 auc 0.9910\n",
      "running time 2.788614511489868\n",
      "starting model 1 fold 1 target 3\n",
      "obj  0.02599563481750183\n",
      "obj  0.02597788545307483\n",
      "obj  0.02598324967443787\n",
      "obj  0.025965722736489262\n",
      "obj  0.025965119496751572\n",
      "obj  0.02594724179730948\n",
      "obj  0.025949412011684377\n",
      "obj  0.025948441741141262\n",
      "obj  0.02594746975038176\n",
      "obj  0.025936354252554267\n",
      "obj  0.025932610550171133\n",
      "obj  0.02593084146867707\n",
      "obj  0.025930270831914168\n",
      "obj  0.025930269700394443\n",
      "obj  0.02593024188368138\n",
      "v20 d1 f1 t3: original ll 0.0252 auc 0.9965, ensemble ll 0.0252 auc 0.9965\n",
      "running time 2.4563136100769043\n",
      "starting model 1 fold 1 target 4\n",
      "obj  0.06701098691552224\n",
      "obj  0.06697994166207943\n",
      "obj  0.06685436929677661\n",
      "obj  0.06716557035285355\n",
      "obj  0.0668532492447865\n",
      "obj  0.06687953830875831\n",
      "obj  0.06688144289267922\n",
      "obj  0.06688767407762986\n",
      "obj  0.06682194779109102\n",
      "obj  0.0667826176703813\n",
      "obj  0.06676770915640914\n",
      "obj  0.06676764628662292\n",
      "obj  0.06676334117580994\n",
      "obj  0.06676239601208879\n",
      "obj  0.06676236734779077\n",
      "obj  0.06676216063141353\n",
      "obj  0.06676211853461966\n",
      "obj  0.0667621149721437\n",
      "obj  0.06676211367242692\n",
      "v20 d1 f1 t4: original ll 0.0654 auc 0.9795, ensemble ll 0.0655 auc 0.9795\n",
      "running time 2.886662244796753\n",
      "starting model 1 fold 1 target 5\n",
      "obj  0.08129173946559545\n",
      "obj  0.08113582281033514\n",
      "obj  0.0809201870448688\n",
      "obj  0.08116669774805584\n",
      "obj  0.08090853473451406\n",
      "obj  0.08096023564159147\n",
      "obj  0.08095561730041369\n",
      "obj  0.08096080885905953\n",
      "obj  0.08082444309117807\n",
      "obj  0.08071726592099573\n",
      "obj  0.08068284839067896\n",
      "obj  0.08067574102759063\n",
      "obj  0.08067280682170502\n",
      "obj  0.08067202190358173\n",
      "obj  0.08067202159752113\n",
      "obj  0.08067183810361053\n",
      "obj  0.08067181547412394\n",
      "obj  0.08067181094541448\n",
      "obj  0.08067180980188846\n",
      "obj  0.08067180952954624\n",
      "v20 d1 f1 t5: original ll 0.0834 auc 0.9769, ensemble ll 0.0830 auc 0.9769\n",
      "running time 3.3386685848236084\n",
      "starting model 2 fold 1 target 0\n",
      "obj  0.09918978209589789\n",
      "obj  0.09909991670839229\n",
      "obj  0.09904940644468566\n",
      "obj  0.09916001330730109\n",
      "obj  0.0990152969872725\n",
      "obj  0.09903395771801765\n",
      "obj  0.0990088232599604\n",
      "obj  0.09901336443672679\n",
      "obj  0.09894828056158196\n",
      "obj  0.09894824460964599\n",
      "obj  0.09893394708032803\n",
      "obj  0.09893332774747278\n",
      "obj  0.09893142105354823\n",
      "obj  0.09893059056187704\n",
      "obj  0.09893040346804881\n",
      "obj  0.09893036858415616\n",
      "obj  0.0989303665486371\n",
      "obj  0.09893036473795429\n",
      "obj  0.09893036390807951\n",
      "obj  0.09893036316850913\n",
      "obj  0.09893036275047402\n",
      "obj  0.0989303623379051\n",
      "obj  0.09893036208463864\n",
      "obj  0.0989303618176653\n",
      "obj  0.09893036164754983\n",
      "obj  0.09893036145894611\n",
      "obj  0.09893036133685978\n",
      "obj  0.09893036119754119\n",
      "obj  0.09893036109009225\n",
      "obj  0.09893036098308265\n",
      "obj  0.09893036089893609\n",
      "obj  0.0989303608139454\n",
      "obj  0.09893036074619044\n",
      "obj  0.09893036067692804\n",
      "obj  0.09893036062116566\n",
      "obj  0.09893036056355743\n",
      "obj  0.09893036051684924\n",
      "obj  0.09893036046813397\n",
      "obj  0.09893036042843895\n",
      "obj  0.09893036038667506\n",
      "obj  0.09893036035252875\n",
      "obj  0.09893036031630888\n",
      "obj  0.09893036028663196\n",
      "obj  0.09893036025490948\n",
      "obj  0.09893036022888796\n",
      "obj  0.09893036020086717\n",
      "obj  0.0989303601778747\n",
      "obj  0.09893036015293945\n",
      "obj  0.09893036013248609\n",
      "obj  0.098930360110151\n",
      "obj  0.09893036009184747\n",
      "obj  0.09893036007172475\n",
      "obj  0.09893036005525763\n",
      "obj  0.09893036003703351\n",
      "obj  0.09893036002214736\n",
      "obj  0.09893036000556504\n",
      "obj  0.09893035999204974\n",
      "obj  0.09893035997689702\n",
      "obj  0.09893035996457782\n",
      "obj  0.09893035995067763\n",
      "obj  0.09893035993940817\n",
      "obj  0.09893035992661135\n",
      "obj  0.098930359916268\n",
      "obj  0.09893035990444841\n",
      "obj  0.09893035989492593\n",
      "obj  0.09893035988397578\n",
      "obj  0.09893035987518427\n",
      "obj  0.0989303598650111\n",
      "obj  0.09893035985687307\n",
      "obj  0.09893035984739705\n",
      "obj  0.09893035983984536\n",
      "obj  0.09893035983099716\n",
      "obj  0.09893035982397354\n",
      "obj  0.09893035981569269\n",
      "obj  0.09893035980914615\n",
      "obj  0.09893035980178752\n",
      "obj  0.09893035979507375\n",
      "obj  0.09893035978815665\n",
      "obj  0.09893035978184353\n",
      "obj  0.0989303597753295\n",
      "obj  0.0989303597693828\n",
      "obj  0.09893035976323779\n",
      "obj  0.09893035975762708\n",
      "obj  0.09893035975182081\n",
      "obj  0.09893035974651887\n",
      "obj  0.09893035974102432\n",
      "obj  0.09893035973600695\n",
      "obj  0.0989303597307999\n",
      "obj  0.09893035972604523\n",
      "obj  0.09893035972110395\n",
      "obj  0.0989303597165924\n",
      "obj  0.09893035971189713\n",
      "obj  0.09893035970761092\n",
      "obj  0.09893035970314407\n",
      "obj  0.09893035969906717\n",
      "obj  0.09893035969481272\n",
      "obj  0.09893035969093059\n",
      "obj  0.09893035968687373\n",
      "obj  0.0989303596831731\n",
      "obj  0.0989303596793007\n",
      "obj  0.09893035967576948\n",
      "obj  0.09893035967206942\n",
      "obj  0.09893035966869668\n",
      "obj  0.09893035966515785\n",
      "obj  0.09893035966193338\n",
      "obj  0.09893035965854559\n",
      "obj  0.0989303596554602\n",
      "obj  0.0989303596522141\n",
      "obj  0.09893035964925913\n",
      "obj  0.09893035964614617\n",
      "obj  0.09893035964331394\n",
      "obj  0.09893035964032619\n",
      "obj  0.09893035963760931\n",
      "obj  0.09893035963473953\n",
      "obj  0.09893035963213134\n",
      "obj  0.09893035962937279\n",
      "obj  0.09893035962686719\n",
      "obj  0.09893035962421354\n",
      "obj  0.09893035962180477\n",
      "obj  0.09893035961925024\n",
      "obj  0.09893035961693293\n",
      "obj  0.09893035961447215\n",
      "obj  0.09893035961224142\n",
      "obj  0.0989303596098694\n",
      "obj  0.09893035960772062\n",
      "obj  0.09893035960543271\n",
      "obj  0.09893035960336158\n",
      "obj  0.0989303596011535\n",
      "obj  0.09893035959915603\n",
      "obj  0.09893035959702369\n",
      "obj  0.0989303595950962\n",
      "obj  0.09893035959303581\n",
      "obj  0.09893035959117488\n",
      "obj  0.09893035958918296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.0989303595873852\n",
      "obj  0.09893035958545837\n",
      "obj  0.09893035958372083\n",
      "obj  0.09893035958185599\n",
      "obj  0.09893035958017571\n",
      "obj  0.09893035957837\n",
      "obj  0.0989303595767443\n",
      "obj  0.09893035957499502\n",
      "obj  0.0989303595734214\n",
      "obj  0.0989303595717259\n",
      "obj  0.09893035957020199\n",
      "obj  0.09893035956855785\n",
      "obj  0.09893035956708145\n",
      "obj  0.09893035956548636\n",
      "obj  0.09893035956405534\n",
      "obj  0.09893035956250729\n",
      "obj  0.09893035956111958\n",
      "obj  0.0989303595596164\n",
      "obj  0.09893035955827027\n",
      "obj  0.09893035955681011\n",
      "obj  0.09893035955550372\n",
      "obj  0.09893035955408477\n",
      "obj  0.09893035955281644\n",
      "obj  0.09893035955143702\n",
      "obj  0.0989303595502052\n",
      "obj  0.09893035954886363\n",
      "obj  0.09893035954766682\n",
      "obj  0.09893035954636166\n",
      "obj  0.09893035954519835\n",
      "obj  0.09893035954392812\n",
      "obj  0.09893035954279711\n",
      "obj  0.09893035954156044\n",
      "obj  0.09893035954046037\n",
      "obj  0.09893035953925594\n",
      "obj  0.09893035953818557\n",
      "obj  0.09893035953701215\n",
      "obj  0.09893035953597044\n",
      "obj  0.09893035953482682\n",
      "obj  0.0989303595338126\n",
      "obj  0.09893035953269773\n",
      "obj  0.09893035953171\n",
      "obj  0.09893035953062279\n",
      "obj  0.09893035952966053\n",
      "obj  0.09893035952859994\n",
      "obj  0.09893035952766227\n",
      "obj  0.09893035952662743\n",
      "obj  0.09893035952571332\n",
      "obj  0.09893035952470322\n",
      "obj  0.09893035952381195\n",
      "obj  0.09893035952282575\n",
      "obj  0.09893035952195647\n",
      "obj  0.09893035952099331\n",
      "obj  0.09893035952014526\n",
      "obj  0.09893035951920437\n",
      "obj  0.09893035951837684\n",
      "obj  0.09893035951745736\n",
      "obj  0.09893035951664961\n",
      "obj  0.09893035951575094\n",
      "obj  0.09893035951496229\n",
      "obj  0.09893035951408378\n",
      "obj  0.09893035951331353\n",
      "obj  0.09893035951245437\n",
      "obj  0.09893035951170191\n",
      "obj  0.09893035951086156\n",
      "obj  0.09893035951012641\n",
      "obj  0.09893035950930425\n",
      "obj  0.09893035950858575\n",
      "obj  0.09893035950778117\n",
      "obj  0.09893035950707883\n",
      "obj  0.09893035950629132\n",
      "obj  0.09893035950560461\n",
      "obj  0.09893035950483355\n",
      "obj  0.098930359504162\n",
      "obj  0.09893035950340685\n",
      "obj  0.09893035950274999\n",
      "obj  0.09893035950201037\n",
      "obj  0.09893035950136764\n",
      "obj  0.09893035950064306\n",
      "obj  0.09893035950001408\n",
      "obj  0.09893035949930402\n",
      "obj  0.09893035949868843\n",
      "obj  0.0989303594979925\n",
      "obj  0.09893035949738983\n",
      "obj  0.09893035949670759\n",
      "obj  0.09893035949611746\n",
      "obj  0.09893035949544858\n",
      "obj  0.09893035949487054\n",
      "obj  0.0989303594942146\n",
      "obj  0.09893035949364841\n",
      "obj  0.09893035949300498\n",
      "obj  0.0989303594924503\n",
      "obj  0.09893035949181905\n",
      "obj  0.09893035949127547\n",
      "obj  0.09893035949065604\n",
      "obj  0.09893035949012331\n",
      "obj  0.09893035948951541\n",
      "obj  0.09893035948899316\n",
      "obj  0.09893035948839646\n",
      "obj  0.09893035948788441\n",
      "obj  0.0989303594872986\n",
      "obj  0.09893035948679653\n",
      "obj  0.09893035948622131\n",
      "obj  0.09893035948572887\n",
      "obj  0.09893035948516392\n",
      "obj  0.09893035948468087\n",
      "obj  0.09893035948412596\n",
      "obj  0.09893035948365206\n",
      "obj  0.0989303594831069\n",
      "obj  0.09893035948264188\n",
      "obj  0.09893035948210627\n",
      "obj  0.09893035948164985\n",
      "obj  0.0989303594811235\n",
      "obj  0.09893035948067554\n",
      "obj  0.09893035948015816\n",
      "obj  0.09893035947971834\n",
      "obj  0.09893035947920974\n",
      "obj  0.09893035947877793\n",
      "obj  0.09893035947827793\n",
      "obj  0.09893035947785386\n",
      "obj  0.09893035947736213\n",
      "obj  0.0989303594769457\n",
      "obj  0.09893035947646216\n",
      "obj  0.09893035947605307\n",
      "obj  0.09893035947557748\n",
      "obj  0.0989303594751756\n",
      "obj  0.09893035947470773\n",
      "obj  0.09893035947431288\n",
      "obj  0.09893035947385254\n",
      "obj  0.09893035947346453\n",
      "obj  0.09893035947301158\n",
      "obj  0.09893035947263024\n",
      "obj  0.0989303594721845\n",
      "obj  0.09893035947180968\n",
      "obj  0.09893035947137091\n",
      "obj  0.09893035947100241\n",
      "obj  0.09893035947057055\n",
      "obj  0.09893035947020823\n",
      "obj  0.09893035946978307\n",
      "obj  0.0989303594694268\n",
      "obj  0.09893035946900815\n",
      "obj  0.09893035946865779\n",
      "obj  0.09893035946824547\n",
      "obj  0.09893035946790096\n",
      "obj  0.09893035946749489\n",
      "obj  0.09893035946715593\n",
      "obj  0.09893035946675599\n",
      "obj  0.09893035946642256\n",
      "obj  0.0989303594660286\n",
      "obj  0.09893035946570046\n",
      "obj  0.09893035946531235\n",
      "obj  0.09893035946498949\n",
      "obj  0.09893035946460708\n",
      "obj  0.09893035946428931\n",
      "v20 d2 f1 t0: original ll 0.1011 auc 0.9858, ensemble ll 0.1012 auc 0.9858\n",
      "running time 34.68152356147766\n",
      "starting model 2 fold 1 target 1\n",
      "obj  0.018027679140788094\n",
      "obj  0.017980187427535963\n",
      "obj  0.01783342738695727\n",
      "obj  0.017800802310045893\n",
      "obj  0.017715086127115233\n",
      "obj  0.017722570943687198\n",
      "obj  0.017725720359378982\n",
      "obj  0.01771528508997615\n",
      "obj  0.017681730621103623\n",
      "obj  0.017615008874795748\n",
      "obj  0.017598480571308587\n",
      "obj  0.017591843175792838\n",
      "obj  0.01758899224083117\n",
      "obj  0.0175876227468728\n",
      "obj  0.01758755187176005\n",
      "obj  0.017587529773924814\n",
      "obj  0.0175875196488683\n",
      "obj  0.01758751964686431\n",
      "obj  0.017587517332099917\n",
      "obj  0.017587516850967357\n",
      "v20 d2 f1 t1: original ll 0.0143 auc 0.9570, ensemble ll 0.0149 auc 0.9570\n",
      "running time 3.3047099113464355\n",
      "starting model 2 fold 1 target 2\n",
      "obj  0.04405023122435156\n",
      "obj  0.044013878562196365\n",
      "obj  0.04403889335547319\n",
      "obj  0.04394680659711309\n",
      "obj  0.04403289951502392\n",
      "obj  0.043993032875288364\n",
      "obj  0.04399773080937586\n",
      "obj  0.0439926543022655\n",
      "obj  0.04395538245783144\n",
      "obj  0.043927139839588576\n",
      "obj  0.04392404095108113\n",
      "obj  0.043923701867777554\n",
      "obj  0.043922522902686535\n",
      "obj  0.04392247872432832\n",
      "obj  0.04392247377762631\n",
      "obj  0.04392245415784948\n",
      "obj  0.04392245010085344\n",
      "v20 d2 f1 t2: original ll 0.0459 auc 0.9902, ensemble ll 0.0460 auc 0.9902\n",
      "running time 2.984981060028076\n",
      "starting model 2 fold 1 target 3\n",
      "obj  0.02743906707456197\n",
      "obj  0.027445094030354895\n",
      "obj  0.027463294529290416\n",
      "obj  0.02741610264842034\n",
      "obj  0.02745306120988584\n",
      "obj  0.02743827268502499\n",
      "obj  0.027440720740042713\n",
      "obj  0.027438691673222403\n",
      "obj  0.027430508469853423\n",
      "obj  0.027410820490486897\n",
      "obj  0.027408809020061025\n",
      "obj  0.027408573441850704\n",
      "obj  0.027408031280269873\n",
      "obj  0.027407923522704446\n",
      "obj  0.02740792352249004\n",
      "obj  0.02740792350238964\n",
      "obj  0.027407922239259103\n",
      "obj  0.02740792223770865\n",
      "obj  0.027407922231768248\n",
      "v20 d2 f1 t3: original ll 0.0258 auc 0.9963, ensemble ll 0.0257 auc 0.9963\n",
      "running time 3.1926302909851074\n",
      "starting model 2 fold 1 target 4\n",
      "obj  0.06728121066551039\n",
      "obj  0.06729424228806166\n",
      "obj  0.06727339576686213\n",
      "obj  0.0673818450468536\n",
      "obj  0.06726268937023003\n",
      "obj  0.06726214611921083\n",
      "obj  0.06726110518427415\n",
      "obj  0.06726184716940022\n",
      "obj  0.06725826251319683\n",
      "obj  0.06725825878726761\n",
      "obj  0.0672520568101531\n",
      "obj  0.06724876195324915\n",
      "obj  0.06724840004954023\n",
      "obj  0.06724830939528594\n",
      "obj  0.06724828529694131\n",
      "obj  0.06724828171529246\n",
      "v20 d2 f1 t4: original ll 0.0666 auc 0.9786, ensemble ll 0.0665 auc 0.9786\n",
      "running time 3.0535154342651367\n",
      "starting model 2 fold 1 target 5\n",
      "obj  0.08113523231311531\n",
      "obj  0.08101375604850093\n",
      "obj  0.08095023751210842\n",
      "obj  0.08094496140652359\n",
      "obj  0.08089697981276\n",
      "obj  0.08086033882551022\n",
      "obj  0.08086398791994351\n",
      "obj  0.08084942281442666\n",
      "obj  0.08082295942209776\n",
      "obj  0.08080069286016536\n",
      "obj  0.08078977011648311\n",
      "obj  0.08078653738182735\n",
      "obj  0.08078643884382533\n",
      "obj  0.08078499875443888\n",
      "obj  0.0807848785656045\n",
      "obj  0.0807848776554658\n",
      "obj  0.08078486892561396\n",
      "obj  0.08078486892305521\n",
      "obj  0.0807848672066298\n",
      "v20 d2 f1 t5: original ll 0.0832 auc 0.9774, ensemble ll 0.0833 auc 0.9774\n",
      "running time 3.3994650840759277\n",
      "starting model 3 fold 1 target 0\n",
      "obj  0.0979912551896887\n",
      "obj  0.09789549423734395\n",
      "obj  0.09772219609309477\n",
      "obj  0.09808737717124659\n",
      "obj  0.09764743992608038\n",
      "obj  0.09777130313182913\n",
      "obj  0.09770904702384954\n",
      "obj  0.09772701792597381\n",
      "obj  0.09750052041631072\n",
      "obj  0.09739895462925066\n",
      "obj  0.09736560115554854\n",
      "obj  0.09735079762741879\n",
      "obj  0.09734721296747806\n",
      "obj  0.0973457070954236\n",
      "obj  0.09734542246097162\n",
      "obj  0.09734538438669556\n",
      "obj  0.09734538431490941\n",
      "obj  0.09734537018172941\n",
      "obj  0.09734537017808527\n",
      "obj  0.09734536764672123\n",
      "v20 d3 f1 t0: original ll 0.0999 auc 0.9861, ensemble ll 0.0991 auc 0.9861\n",
      "running time 3.056105375289917\n",
      "starting model 3 fold 1 target 1\n",
      "obj  0.017681681138747785\n",
      "obj  0.017634995306146366\n",
      "obj  0.01753424675205181\n",
      "obj  0.017589129817084614\n",
      "obj  0.017561917861370284\n",
      "obj  0.01756497218269723\n",
      "obj  0.01756563277674303\n",
      "obj  0.017560158700846325\n",
      "obj  0.017537526263127177\n",
      "obj  0.017524774050519828\n",
      "obj  0.017515369857277356\n",
      "obj  0.017512832044949977\n",
      "obj  0.017512475376105764\n",
      "obj  0.0175123510629322\n",
      "obj  0.017512337605423124\n",
      "obj  0.017512335931975268\n",
      "obj  0.01751233573292498\n",
      "v20 d3 f1 t1: original ll 0.0150 auc 0.9573, ensemble ll 0.0154 auc 0.9573\n",
      "running time 2.6974568367004395\n",
      "starting model 3 fold 1 target 2\n",
      "obj  0.04220596677740873\n",
      "obj  0.042195782391053004\n",
      "obj  0.04219845811114047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.04222818744167189\n",
      "obj  0.042172353144604456\n",
      "obj  0.04215619157451302\n",
      "obj  0.042157832848372795\n",
      "obj  0.04215735994548541\n",
      "obj  0.04215595188802026\n",
      "obj  0.042144990965827064\n",
      "obj  0.04214499061227583\n",
      "obj  0.042141637341748736\n",
      "obj  0.04214066003194807\n",
      "obj  0.042140538491598614\n",
      "obj  0.04214052500601829\n",
      "v20 d3 f1 t2: original ll 0.0425 auc 0.9917, ensemble ll 0.0425 auc 0.9917\n",
      "running time 2.43468976020813\n",
      "starting model 3 fold 1 target 3\n",
      "obj  0.02649221159990656\n",
      "obj  0.026491370441489234\n",
      "obj  0.026509088626245205\n",
      "obj  0.026444408670417054\n",
      "obj  0.026495500846752732\n",
      "obj  0.02646456118072573\n",
      "obj  0.026468503638545523\n",
      "obj  0.02646545562220254\n",
      "obj  0.026433944892348207\n",
      "obj  0.026385889045800876\n",
      "obj  0.02638535135890489\n",
      "obj  0.026379606208886176\n",
      "obj  0.02637752697811413\n",
      "obj  0.026377319390595684\n",
      "obj  0.02637728936343165\n",
      "obj  0.026377285281153514\n",
      "obj  0.026377284498365003\n",
      "v20 d3 f1 t3: original ll 0.0248 auc 0.9963, ensemble ll 0.0246 auc 0.9963\n",
      "running time 2.682366132736206\n",
      "starting model 3 fold 1 target 4\n",
      "obj  0.06619204727257419\n",
      "obj  0.06619428724434043\n",
      "obj  0.06613466055577577\n",
      "obj  0.06628627975534336\n",
      "obj  0.06611175095650526\n",
      "obj  0.06611093543591214\n",
      "obj  0.06611147100589806\n",
      "obj  0.06611364813534466\n",
      "obj  0.06611014012937438\n",
      "obj  0.06609463275807423\n",
      "obj  0.0660868304141841\n",
      "obj  0.06608134556092835\n",
      "obj  0.06607917106870866\n",
      "obj  0.06607913474247054\n",
      "obj  0.06607903798413343\n",
      "obj  0.06607902312577617\n",
      "obj  0.06607902017978264\n",
      "v20 d3 f1 t4: original ll 0.0651 auc 0.9795, ensemble ll 0.0651 auc 0.9795\n",
      "running time 2.6993207931518555\n",
      "starting model 3 fold 1 target 5\n",
      "obj  0.08118473775203672\n",
      "obj  0.08107228102022485\n",
      "obj  0.08096473431922918\n",
      "obj  0.08113392424996702\n",
      "obj  0.08088242196373772\n",
      "obj  0.08088647995938625\n",
      "obj  0.0808866682367951\n",
      "obj  0.0808865073684418\n",
      "obj  0.08079868397796869\n",
      "obj  0.08071661460945341\n",
      "obj  0.08069479198074621\n",
      "obj  0.08069188476507556\n",
      "obj  0.08068985946467283\n",
      "obj  0.0806894671250869\n",
      "obj  0.08068946589048763\n",
      "obj  0.08068944677112828\n",
      "obj  0.08068944233625917\n",
      "v20 d3 f1 t5: original ll 0.0816 auc 0.9780, ensemble ll 0.0812 auc 0.9780\n",
      "running time 2.688340425491333\n",
      "starting model 0 fold 2 target 0\n",
      "obj  0.10141735397529103\n",
      "obj  0.10131717583517663\n",
      "obj  0.10116259612266419\n",
      "obj  0.101547004197672\n",
      "obj  0.10110482360344575\n",
      "obj  0.10122930431850026\n",
      "obj  0.10117354341885296\n",
      "obj  0.10119143914015598\n",
      "obj  0.10096777661623825\n",
      "obj  0.1008715396291702\n",
      "obj  0.10084549658155036\n",
      "obj  0.1008317537719727\n",
      "obj  0.10082880086998997\n",
      "obj  0.10082746612338628\n",
      "obj  0.10082725473436242\n",
      "obj  0.10082718547884852\n",
      "obj  0.10082718543940283\n",
      "obj  0.10082718543566872\n",
      "obj  0.10082716951511886\n",
      "v20 d0 f2 t0: original ll 0.0979 auc 0.9871, ensemble ll 0.0972 auc 0.9871\n",
      "running time 2.916208505630493\n",
      "starting model 0 fold 2 target 1\n",
      "obj  0.01591158556496201\n",
      "obj  0.015838106197551927\n",
      "obj  0.015670828467173444\n",
      "obj  0.01529871607786128\n",
      "obj  0.015292040532756823\n",
      "obj  0.015375998492399545\n",
      "obj  0.015349222413329212\n",
      "obj  0.015216673632072785\n",
      "obj  0.015103445006704203\n",
      "obj  0.014935329402847083\n",
      "obj  0.014882289167874414\n",
      "obj  0.01486491180642927\n",
      "obj  0.014855589362782478\n",
      "obj  0.014853889892429441\n",
      "obj  0.014853539280205849\n",
      "obj  0.014853438546888998\n",
      "obj  0.014853417967852136\n",
      "obj  0.014853412907761732\n",
      "obj  0.014853411611894813\n",
      "v20 d0 f2 t1: original ll 0.0164 auc 0.9714, ensemble ll 0.0153 auc 0.9713\n",
      "running time 2.863402843475342\n",
      "starting model 0 fold 2 target 2\n",
      "obj  0.04545584816799587\n",
      "obj  0.04538188999121735\n",
      "obj  0.04534293544282615\n",
      "obj  0.04534497000242473\n",
      "obj  0.045310634903529955\n",
      "obj  0.0452967702634819\n",
      "obj  0.04529774783372006\n",
      "obj  0.04529844468911819\n",
      "obj  0.045293987078936594\n",
      "obj  0.04527271141926368\n",
      "obj  0.045267240051317555\n",
      "obj  0.04526458121192805\n",
      "obj  0.045264155900629426\n",
      "obj  0.0452641486107761\n",
      "obj  0.045264031593367275\n",
      "obj  0.04526398734906491\n",
      "obj  0.04526398734623949\n",
      "obj  0.04526397149496554\n",
      "obj  0.045263970264758195\n",
      "v20 d0 f2 t2: original ll 0.0412 auc 0.9913, ensemble ll 0.0414 auc 0.9913\n",
      "running time 2.9130375385284424\n",
      "starting model 0 fold 2 target 3\n",
      "obj  0.026445257140282\n",
      "obj  0.026453624274832423\n",
      "obj  0.026473079819255885\n",
      "obj  0.02639541242336012\n",
      "obj  0.026454826252356282\n",
      "obj  0.026429460418327857\n",
      "obj  0.026433785637998596\n",
      "obj  0.026431099901260614\n",
      "obj  0.026413407758351555\n",
      "obj  0.02637144488989541\n",
      "obj  0.026369650086785087\n",
      "obj  0.02636490999578065\n",
      "obj  0.0263643861803565\n",
      "obj  0.026363408475528143\n",
      "obj  0.026363368138145896\n",
      "obj  0.026363302713078265\n",
      "obj  0.0263632746879909\n",
      "obj  0.0263632426301068\n",
      "obj  0.026363239635328047\n",
      "v20 d0 f2 t3: original ll 0.0263 auc 0.9962, ensemble ll 0.0262 auc 0.9962\n",
      "running time 2.9046051502227783\n",
      "starting model 0 fold 2 target 4\n",
      "obj  0.0678778448173398\n",
      "obj  0.0678902445882387\n",
      "obj  0.06784412772933314\n",
      "obj  0.06793330964347481\n",
      "obj  0.06782958420340741\n",
      "obj  0.06782608694951173\n",
      "obj  0.06782848294474494\n",
      "obj  0.06780367512597346\n",
      "obj  0.06776073360177702\n",
      "obj  0.06776040834957468\n",
      "obj  0.06775175318370656\n",
      "obj  0.06774858471468269\n",
      "obj  0.0677455025294771\n",
      "obj  0.0677454986149605\n",
      "obj  0.06774456477638698\n",
      "obj  0.06774435777304447\n",
      "obj  0.06774422910158652\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423809032755\n",
      "obj  0.06774423012488467\n",
      "obj  0.06774423012488467\n",
      "obj  0.06774422920341336\n",
      "obj  0.06774422920341336\n",
      "obj  0.06774422911176413\n",
      "obj  0.06774422911176413\n",
      "obj  0.06774422910274332\n",
      "obj  0.06774422910274332\n",
      "v20 d0 f2 t4: original ll 0.0667 auc 0.9802, ensemble ll 0.0666 auc 0.9802\n",
      "running time 3.0780277252197266\n",
      "starting model 0 fold 2 target 5\n",
      "obj  0.08435904909270424\n",
      "obj  0.08427116568317776\n",
      "obj  0.08417129558492856\n",
      "obj  0.08436119151024381\n",
      "obj  0.08410217628895221\n",
      "obj  0.0841193506104026\n",
      "obj  0.08411028131548519\n",
      "obj  0.08411753500258304\n",
      "obj  0.08401563468403335\n",
      "obj  0.08394976397982729\n",
      "obj  0.08393078989395593\n",
      "obj  0.08392823588069884\n",
      "obj  0.08392646862763822\n",
      "obj  0.08392617961345693\n",
      "obj  0.08392617290544503\n",
      "obj  0.083926160831877\n",
      "v20 d0 f2 t5: original ll 0.0790 auc 0.9798, ensemble ll 0.0785 auc 0.9798\n",
      "running time 2.623936891555786\n",
      "starting model 1 fold 2 target 0\n",
      "obj  0.10120449847226233\n",
      "obj  0.10109817351813269\n",
      "obj  0.10087878872337011\n",
      "obj  0.10136031856995935\n",
      "obj  0.1008035837318631\n",
      "obj  0.10096981608929656\n",
      "obj  0.10089783437288645\n",
      "obj  0.10092182927641948\n",
      "obj  0.10060831217747443\n",
      "obj  0.10045323983703057\n",
      "obj  0.10039169215036994\n",
      "obj  0.10036515886805435\n",
      "obj  0.10035891639554403\n",
      "obj  0.10035810407178748\n",
      "obj  0.10035795781517456\n",
      "obj  0.10035795213832621\n",
      "obj  0.10035790985163588\n",
      "obj  0.10035790173695393\n",
      "v20 d1 f2 t0: original ll 0.0960 auc 0.9876, ensemble ll 0.0953 auc 0.9876\n",
      "running time 2.828167200088501\n",
      "starting model 1 fold 2 target 1\n",
      "obj  0.01693309900148761\n",
      "obj  0.016875876371086094\n",
      "obj  0.016741729336320694\n",
      "obj  0.01650751536879217\n",
      "obj  0.01620384319480355\n",
      "obj  0.016184635713369727\n",
      "obj  0.016213196259716598\n",
      "obj  0.016085405316877837\n",
      "obj  0.01582888359110876\n",
      "obj  0.015678178065316743\n",
      "obj  0.01561730249670304\n",
      "obj  0.015595881101121636\n",
      "obj  0.015589833595755598\n",
      "obj  0.015588787111201412\n",
      "obj  0.015588678816967476\n",
      "obj  0.015588676748797844\n",
      "obj  0.015588631386766147\n",
      "obj  0.015588628608419723\n",
      "v20 d1 f2 t1: original ll 0.0173 auc 0.9633, ensemble ll 0.0163 auc 0.9631\n",
      "running time 2.779151439666748\n",
      "starting model 1 fold 2 target 2\n",
      "obj  0.044261400246393176\n",
      "obj  0.04417554937587039\n",
      "obj  0.044130273186145076\n",
      "obj  0.04415775413012592\n",
      "obj  0.044096973591889035\n",
      "obj  0.04409010306798007\n",
      "obj  0.04409028329184658\n",
      "obj  0.04409225251579909\n",
      "obj  0.04408336611148021\n",
      "obj  0.04406318815145812\n",
      "obj  0.04405971836121975\n",
      "obj  0.044058173954954746\n",
      "obj  0.04405815170694498\n",
      "obj  0.04405802068119302\n",
      "obj  0.044058003740143396\n",
      "obj  0.04405799791789447\n",
      "v20 d1 f2 t2: original ll 0.0395 auc 0.9922, ensemble ll 0.0396 auc 0.9922\n",
      "running time 2.5615837574005127\n",
      "starting model 1 fold 2 target 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.026174941194704256\n",
      "obj  0.026147219465655007\n",
      "obj  0.02617059361095052\n",
      "obj  0.026089159275892494\n",
      "obj  0.026164778814304842\n",
      "obj  0.026129806327837523\n",
      "obj  0.02613417253615349\n",
      "obj  0.026130463104815642\n",
      "obj  0.02609173807876032\n",
      "obj  0.02605476676671462\n",
      "obj  0.026046761434253426\n",
      "obj  0.026044985369089394\n",
      "obj  0.02604430655998637\n",
      "obj  0.02604429674357044\n",
      "obj  0.026044217633360584\n",
      "obj  0.026044212479883307\n",
      "obj  0.026044211330410395\n",
      "v20 d1 f2 t3: original ll 0.0249 auc 0.9965, ensemble ll 0.0249 auc 0.9965\n",
      "running time 2.9579856395721436\n",
      "starting model 1 fold 2 target 4\n",
      "obj  0.0668269885476289\n",
      "obj  0.06679452484913335\n",
      "obj  0.06676107021296061\n",
      "obj  0.06694647449879597\n",
      "obj  0.06673329586495953\n",
      "obj  0.06672785046997745\n",
      "obj  0.06672537753305355\n",
      "obj  0.0667283739934056\n",
      "obj  0.06672256002140288\n",
      "obj  0.06669677208649254\n",
      "obj  0.06669001350174837\n",
      "obj  0.06668753536260635\n",
      "obj  0.06668634848933934\n",
      "obj  0.06668598445473992\n",
      "obj  0.06668589070732027\n",
      "obj  0.066685887953592\n",
      "obj  0.06668587457383696\n",
      "obj  0.06668586384140086\n",
      "obj  0.0666858632456599\n",
      "obj  0.06668586324565987\n",
      "v20 d1 f2 t4: original ll 0.0658 auc 0.9808, ensemble ll 0.0655 auc 0.9808\n",
      "running time 3.305563449859619\n",
      "starting model 1 fold 2 target 5\n",
      "obj  0.08421492432082157\n",
      "obj  0.08409437968655896\n",
      "obj  0.08395321048725597\n",
      "obj  0.0842650507766005\n",
      "obj  0.08389748348057502\n",
      "obj  0.08394970319956745\n",
      "obj  0.08394656787538278\n",
      "obj  0.08394120769421784\n",
      "obj  0.08378646657474369\n",
      "obj  0.08367694204907543\n",
      "obj  0.08363551807339219\n",
      "obj  0.08362596237932768\n",
      "obj  0.08362415444493868\n",
      "obj  0.08362414916389824\n",
      "obj  0.08362381938868493\n",
      "obj  0.083623818506782\n",
      "obj  0.08362375108168599\n",
      "obj  0.0836237510308755\n",
      "obj  0.083623739289568\n",
      "obj  0.0836237392492229\n",
      "obj  0.08362373924907933\n",
      "obj  0.08362373661258227\n",
      "v20 d1 f2 t5: original ll 0.0775 auc 0.9807, ensemble ll 0.0771 auc 0.9807\n",
      "running time 3.5547256469726562\n",
      "starting model 2 fold 2 target 0\n",
      "obj  0.10076242063038\n",
      "obj  0.10071488043554656\n",
      "obj  0.10061901673498372\n",
      "obj  0.10094272815196742\n",
      "obj  0.10060168135789084\n",
      "obj  0.10069536803488811\n",
      "obj  0.10067011408899375\n",
      "obj  0.10068302738518163\n",
      "obj  0.10056158809943021\n",
      "obj  0.10051409834748784\n",
      "obj  0.10050692580771231\n",
      "obj  0.100506200059738\n",
      "obj  0.10050551683491611\n",
      "obj  0.10050550375033014\n",
      "obj  0.10050537036770349\n",
      "obj  0.10050537032865141\n",
      "obj  0.1005053324980296\n",
      "obj  0.10050532829926977\n",
      "obj  0.10050532700659534\n",
      "obj  0.10050532700659537\n",
      "obj  0.1005053268157671\n",
      "v20 d2 f2 t0: original ll 0.0980 auc 0.9868, ensemble ll 0.0981 auc 0.9868\n",
      "running time 3.4778854846954346\n",
      "starting model 2 fold 2 target 1\n",
      "obj  0.01659679341756149\n",
      "obj  0.016578037115241525\n",
      "obj  0.01654176906937312\n",
      "obj  0.01655873643332995\n",
      "obj  0.016531322970518018\n",
      "obj  0.01653673630712312\n",
      "obj  0.0165360840861513\n",
      "obj  0.016530719242722907\n",
      "obj  0.016525352495564114\n",
      "obj  0.016507636430931342\n",
      "obj  0.01650549505417913\n",
      "obj  0.016504631986632736\n",
      "obj  0.01650442241857411\n",
      "obj  0.01650434599888823\n",
      "obj  0.016504337119681533\n",
      "obj  0.01650433544684688\n",
      "obj  0.016504335026998444\n",
      "v20 d2 f2 t1: original ll 0.0172 auc 0.9599, ensemble ll 0.0177 auc 0.9599\n",
      "running time 2.941746950149536\n",
      "starting model 2 fold 2 target 2\n",
      "obj  0.04614515913792354\n",
      "obj  0.04608855250114256\n",
      "obj  0.04608116332206848\n",
      "obj  0.04603873656508683\n",
      "obj  0.04606043819410286\n",
      "obj  0.04603408901276705\n",
      "obj  0.046036659409015385\n",
      "obj  0.04603470814949661\n",
      "obj  0.04602597712254959\n",
      "obj  0.04601783524207798\n",
      "obj  0.046013532516887945\n",
      "obj  0.046010705452684875\n",
      "obj  0.04601036460847287\n",
      "obj  0.04601030960099932\n",
      "obj  0.046010296207540435\n",
      "obj  0.04601029318425849\n",
      "v20 d2 f2 t2: original ll 0.0417 auc 0.9912, ensemble ll 0.0419 auc 0.9912\n",
      "running time 2.8483262062072754\n",
      "starting model 2 fold 2 target 3\n",
      "obj  0.027023611809708463\n",
      "obj  0.027029365667980563\n",
      "obj  0.027067603128510438\n",
      "obj  0.026976207305742614\n",
      "obj  0.027066675230349974\n",
      "obj  0.027049988571931142\n",
      "obj  0.02705346098685251\n",
      "obj  0.027050122265867768\n",
      "obj  0.0270205357929553\n",
      "obj  0.026954833666806413\n",
      "obj  0.02694994282839845\n",
      "obj  0.026947431935733054\n",
      "obj  0.026947028952522753\n",
      "obj  0.026946913814676076\n",
      "obj  0.026946866930236017\n",
      "v20 d2 f2 t3: original ll 0.0267 auc 0.9958, ensemble ll 0.0266 auc 0.9958\n",
      "running time 2.480135917663574\n",
      "starting model 2 fold 2 target 4\n",
      "obj  0.06761623460828432\n",
      "obj  0.0676741265885303\n",
      "obj  0.06763733684716412\n",
      "obj  0.06771816317920165\n",
      "obj  0.06761422229303844\n",
      "obj  0.06761455159067041\n",
      "obj  0.06761332695301019\n",
      "obj  0.0676137640864708\n",
      "obj  0.06760393801534968\n",
      "obj  0.0676038912805267\n",
      "obj  0.06760124265026742\n",
      "obj  0.06759851366708007\n",
      "obj  0.06759749056030637\n",
      "obj  0.06759738094269252\n",
      "obj  0.06759737802819313\n",
      "obj  0.0675973764648334\n",
      "obj  0.06759737064367378\n",
      "v20 d2 f2 t4: original ll 0.0659 auc 0.9804, ensemble ll 0.0659 auc 0.9804\n",
      "running time 2.7103776931762695\n",
      "starting model 2 fold 2 target 5\n",
      "obj  0.0836925405919578\n",
      "obj  0.08364408465037784\n",
      "obj  0.08357254582714017\n",
      "obj  0.08395502376529236\n",
      "obj  0.0835456019630248\n",
      "obj  0.08355939547334282\n",
      "obj  0.08355497226495143\n",
      "obj  0.08356155052739254\n",
      "obj  0.08352767629221916\n",
      "obj  0.0834665886363838\n",
      "obj  0.08344812475871315\n",
      "obj  0.08344236722842974\n",
      "obj  0.08343943742926206\n",
      "obj  0.08343893574145911\n",
      "obj  0.08343890033395794\n",
      "obj  0.08343878548069865\n",
      "obj  0.08343876080819286\n",
      "v20 d2 f2 t5: original ll 0.0781 auc 0.9800, ensemble ll 0.0781 auc 0.9800\n",
      "running time 2.7165417671203613\n",
      "starting model 3 fold 2 target 0\n",
      "obj  0.09998272091664157\n",
      "obj  0.09990183641480431\n",
      "obj  0.09970082394119346\n",
      "obj  0.1002328547701405\n",
      "obj  0.09964101609912032\n",
      "obj  0.09982337585481696\n",
      "obj  0.09975149819897897\n",
      "obj  0.099777412026199\n",
      "obj  0.09941845568208217\n",
      "obj  0.09923716679089742\n",
      "obj  0.09917803574083871\n",
      "obj  0.09916866277484312\n",
      "obj  0.0991668840280251\n",
      "obj  0.09916657187424481\n",
      "obj  0.09916657181243309\n",
      "obj  0.0991664826700184\n",
      "obj  0.0991664826663424\n",
      "obj  0.09916646854500245\n",
      "obj  0.09916646516723994\n",
      "v20 d3 f2 t0: original ll 0.0959 auc 0.9877, ensemble ll 0.0956 auc 0.9877\n",
      "running time 2.8977272510528564\n",
      "starting model 3 fold 2 target 1\n",
      "obj  0.016469356755182588\n",
      "obj  0.01646582954171452\n",
      "obj  0.01649023439214066\n",
      "obj  0.01653952322819908\n",
      "obj  0.01652715924177041\n",
      "obj  0.016530005506341375\n",
      "obj  0.016530545282578708\n",
      "obj  0.016513142074488535\n",
      "obj  0.01649645940951866\n",
      "obj  0.01646618461782536\n",
      "obj  0.016459034991622854\n",
      "obj  0.01645800351099779\n",
      "obj  0.016457808498906133\n",
      "obj  0.016457716583216757\n",
      "obj  0.016457686897452542\n",
      "obj  0.01645768615055775\n",
      "obj  0.016457683080545082\n",
      "v20 d3 f2 t1: original ll 0.0174 auc 0.9593, ensemble ll 0.0173 auc 0.9593\n",
      "running time 2.675200939178467\n",
      "starting model 3 fold 2 target 2\n",
      "obj  0.043486260329266974\n",
      "obj  0.0434714664606255\n",
      "obj  0.04345246356902581\n",
      "obj  0.04347377237190418\n",
      "obj  0.04342109580677774\n",
      "obj  0.04341410119258016\n",
      "obj  0.043414489840634556\n",
      "obj  0.04341633098228996\n",
      "obj  0.04341334004566013\n",
      "obj  0.043394482094008\n",
      "obj  0.04339448011718594\n",
      "obj  0.043391202902021954\n",
      "obj  0.04338968482802081\n",
      "obj  0.04338951586646326\n",
      "obj  0.04338949617800632\n",
      "obj  0.04338949161403421\n",
      "v20 d3 f2 t2: original ll 0.0400 auc 0.9922, ensemble ll 0.0400 auc 0.9922\n",
      "running time 2.5767557621002197\n",
      "starting model 3 fold 2 target 3\n",
      "obj  0.02617608597147866\n",
      "obj  0.026180222270714096\n",
      "obj  0.026207702062765258\n",
      "obj  0.026118905577622878\n",
      "obj  0.026191658040759794\n",
      "obj  0.02616412055244579\n",
      "obj  0.026169252385701624\n",
      "obj  0.026166348517411543\n",
      "obj  0.02611575946649723\n",
      "obj  0.026058221194966605\n",
      "obj  0.026058208943286844\n",
      "obj  0.026048546175467962\n",
      "obj  0.026046935866115152\n",
      "obj  0.02604630170335762\n",
      "obj  0.026046156707795375\n",
      "obj  0.026046096186875794\n",
      "obj  0.026046095343094933\n",
      "obj  0.0260460909027871\n",
      "v20 d3 f2 t3: original ll 0.0254 auc 0.9964, ensemble ll 0.0253 auc 0.9964\n",
      "running time 2.761021375656128\n",
      "starting model 3 fold 2 target 4\n",
      "obj  0.06595115353415847\n",
      "obj  0.06597751361181\n",
      "obj  0.06588955306167117\n",
      "obj  0.06608046054807039\n",
      "obj  0.06587743962440828\n",
      "obj  0.06589025904213014\n",
      "obj  0.06588952266570104\n",
      "obj  0.0658929357794775\n",
      "obj  0.06587395267595927\n",
      "obj  0.06585758481957922\n",
      "obj  0.06585506049008372\n",
      "obj  0.06585412128552819\n",
      "obj  0.06585387590304308\n",
      "obj  0.06585322005002747\n",
      "obj  0.0658532120398107\n",
      "obj  0.06585310485939666\n",
      "obj  0.06585310485292555\n",
      "obj  0.06585309777237744\n",
      "obj  0.06585309766397214\n",
      "obj  0.06585309642611722\n",
      "v20 d3 f2 t4: original ll 0.0656 auc 0.9810, ensemble ll 0.0655 auc 0.9810\n",
      "running time 2.994365930557251\n",
      "starting model 3 fold 2 target 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.08292002271059397\n",
      "obj  0.08284080505121437\n",
      "obj  0.08270929111961367\n",
      "obj  0.08332481621888413\n",
      "obj  0.08269388959055977\n",
      "obj  0.08273682747620306\n",
      "obj  0.08272899436643559\n",
      "obj  0.08274071883213764\n",
      "obj  0.08266271078234402\n",
      "obj  0.08249377484880656\n",
      "obj  0.08243783504811492\n",
      "obj  0.0824189902823918\n",
      "obj  0.08241470814088508\n",
      "obj  0.08241367175982899\n",
      "obj  0.0824134517340829\n",
      "obj  0.08241338561110807\n",
      "obj  0.08241337856333344\n",
      "obj  0.08241337681737425\n",
      "obj  0.08241337636550593\n",
      "v20 d3 f2 t5: original ll 0.0781 auc 0.9806, ensemble ll 0.0778 auc 0.9806\n",
      "running time 2.9063892364501953\n",
      "total running time 246.0906846523285\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for fold in range(3):\n",
    "    for ds_idx in range(4):\n",
    "        for target in range(6):\n",
    "            train_ensemble(train_md, preds_all, fold=fold, target=target, ds_idx=ds_idx, first_step=True)\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.06201 ensemble ll 0.06163\n",
      "valid original ll 0.06201 ensemble ll 0.06176\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_WORK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx != -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0 target 0\n",
      "obj  0.09511851406100497\n",
      "obj  0.0954536226875524\n",
      "obj  0.09544142308835316\n",
      "obj  0.09543048763728462\n",
      "obj  0.09542182681398828\n",
      "obj  0.09540077466874508\n",
      "obj  0.09538881386152563\n",
      "obj  0.09537407147454356\n",
      "obj  0.09535363475254388\n",
      "obj  0.09521298035026012\n",
      "obj  0.09514909516588742\n",
      "obj  0.09511634932259257\n",
      "obj  0.09510725228159315\n",
      "obj  0.09509637638177196\n",
      "obj  0.09508299925819323\n",
      "obj  0.09506970949528888\n",
      "obj  0.09505844743564151\n",
      "obj  0.09504713774998874\n",
      "obj  0.09503726832951753\n",
      "obj  0.09502832567660698\n",
      "obj  0.09501906356540837\n",
      "obj  0.09501118328753744\n",
      "obj  0.09500430220830547\n",
      "obj  0.0949981842031018\n",
      "obj  0.0949915662807384\n",
      "obj  0.0949837405853833\n",
      "obj  0.0949752407639445\n",
      "obj  0.09496713036765675\n",
      "obj  0.09495979766657388\n",
      "obj  0.09495217394795065\n",
      "obj  0.09494159749549856\n",
      "obj  0.09493284515434527\n",
      "obj  0.09492434140498296\n",
      "obj  0.09491582573276632\n",
      "obj  0.09490576647761279\n",
      "obj  0.09489093703026923\n",
      "obj  0.09486472438164556\n",
      "obj  0.09484994884727373\n",
      "obj  0.09484886660084008\n",
      "obj  0.09484884289690057\n",
      "obj  0.09484884266639394\n",
      "obj  0.09484884265622708\n",
      "obj  0.09484884265575352\n",
      "obj  0.09484884265571511\n",
      "obj  0.0948488426557137\n",
      "obj  0.09484884265571364\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571362\n",
      "obj  0.09484884265571361\n",
      "obj  0.09484884265571362\n",
      "obj  0.09484884265571362\n",
      "obj  0.09484884265571362\n",
      "obj  0.09484884265571362\n",
      "v20 d-1 f0 t0: original ll 0.0968 auc 0.9870, ensemble ll 0.0967 auc 0.9870\n",
      "running time 9.77193832397461\n",
      "starting fold 0 target 1\n",
      "obj  0.014410790867553118\n",
      "obj  0.014370907237083745\n",
      "obj  0.014347951978916406\n",
      "obj  0.01436946359615858\n",
      "obj  0.014401154561087188\n",
      "obj  0.014391196021995014\n",
      "obj  0.014343730068158434\n",
      "obj  0.014357470328777591\n",
      "obj  0.014040687139493063\n",
      "obj  0.013998186404680247\n",
      "obj  0.013988199516237549\n",
      "obj  0.01398419427710609\n",
      "obj  0.013983131486620068\n",
      "obj  0.013982825499841697\n",
      "obj  0.013982752215546311\n",
      "obj  0.013982736842312287\n",
      "v20 d-1 f0 t1: original ll 0.0168 auc 0.9739, ensemble ll 0.0165 auc 0.9740\n",
      "running time 3.445333480834961\n",
      "starting fold 0 target 2\n",
      "obj  0.039799124688387186\n",
      "obj  0.03983515591131757\n",
      "obj  0.03983541341822612\n",
      "obj  0.03983506405047824\n",
      "obj  0.03983602215237764\n",
      "obj  0.03983218491242363\n",
      "obj  0.03983167138245432\n",
      "obj  0.0398281176797973\n",
      "obj  0.03976383170548199\n",
      "obj  0.039699946081535334\n",
      "obj  0.03966297303242085\n",
      "obj  0.0396359534352051\n",
      "obj  0.0396247565508731\n",
      "obj  0.03962076773928396\n",
      "obj  0.039617910050656485\n",
      "obj  0.039615854796857135\n",
      "obj  0.03960056304648459\n",
      "obj  0.039593358566318605\n",
      "obj  0.03959031757816654\n",
      "obj  0.03958862806926657\n",
      "obj  0.03958830401269939\n",
      "obj  0.039586838929920105\n",
      "obj  0.039586640143535724\n",
      "obj  0.039586421721461006\n",
      "obj  0.039586052070598655\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.03958647256485203\n",
      "obj  0.039586425144527905\n",
      "obj  0.039586425144527905\n",
      "obj  0.03958619281628338\n",
      "obj  0.03958619281628338\n",
      "obj  0.039586110929578436\n",
      "obj  0.039586110929578436\n",
      "obj  0.039586078625677035\n",
      "obj  0.039586078625677035\n",
      "obj  0.03958606463036943\n",
      "obj  0.03958606463036943\n",
      "obj  0.03958605817260878\n",
      "obj  0.03958605817260878\n",
      "obj  0.039586055077127244\n",
      "obj  0.039586055077127244\n",
      "obj  0.039586053562742876\n",
      "obj  0.039586053562742876\n",
      "obj  0.039586052813890604\n",
      "obj  0.0395860524415496\n",
      "obj  0.0395860524415496\n",
      "obj  0.039586052255900325\n",
      "obj  0.03958605216320605\n",
      "obj  0.03958605216320605\n",
      "obj  0.03958605211689149\n",
      "obj  0.0395860521168915\n",
      "obj  0.03958605209374236\n",
      "obj  0.03958605209374236\n",
      "obj  0.039586052082169816\n",
      "obj  0.039586052082169816\n",
      "obj  0.039586052076384055\n",
      "obj  0.03958605207638407\n",
      "obj  0.0395860520734913\n",
      "obj  0.03958605207349131\n",
      "obj  0.03958605207204497\n",
      "obj  0.03958605207204498\n",
      "obj  0.0395860520713218\n",
      "obj  0.0395860520713218\n",
      "obj  0.03958605207096022\n",
      "obj  0.03958605207077944\n",
      "obj  0.03958605207068904\n",
      "obj  0.03958605207068904\n",
      "obj  0.03958605207064385\n",
      "obj  0.03958605207064385\n",
      "obj  0.039586052070598655\n",
      "obj  0.03958647106779734\n",
      "obj  0.03958647106779734\n",
      "obj  0.03958637020802297\n",
      "obj  0.03958617423903519\n",
      "obj  0.03958617423903519\n",
      "obj  0.03958610387957967\n",
      "obj  0.03958610387957967\n",
      "obj  0.039586075659681676\n",
      "obj  0.03958606328842107\n",
      "obj  0.03958606328842107\n",
      "obj  0.039586057536265054\n",
      "obj  0.039586057536265054\n",
      "obj  0.039586054767615106\n",
      "obj  0.039586054767615106\n",
      "obj  0.039586053410152\n",
      "obj  0.039586053410152\n",
      "obj  0.039586052738136514\n",
      "obj  0.039586052738136514\n",
      "obj  0.03958605240380788\n",
      "obj  0.03958605240380788\n",
      "obj  0.039586052237063324\n",
      "obj  0.039586052153796\n",
      "obj  0.03958605215379599\n",
      "obj  0.039586052112188574\n",
      "obj  0.039586052112188595\n",
      "obj  0.03958605209139143\n",
      "obj  0.03958605209139143\n",
      "obj  0.039586052080994485\n",
      "obj  0.03958605208099449\n",
      "obj  0.03958605207579643\n",
      "obj  0.03958605207579643\n",
      "obj  0.03958605207319751\n",
      "obj  0.03958605207319751\n",
      "obj  0.03958605207189807\n",
      "obj  0.039586052071898054\n",
      "obj  0.03958605207124836\n",
      "obj  0.03958605207124836\n",
      "obj  0.0395860520709235\n",
      "obj  0.0395860520709235\n",
      "obj  0.03958605207076109\n",
      "obj  0.03958605207067986\n",
      "obj  0.039586052070679854\n",
      "obj  0.03958605207063924\n",
      "obj  0.039586052070598655\n",
      "obj  0.03958647076975615\n",
      "obj  0.03958647076975615\n",
      "obj  0.03958637031820997\n",
      "obj  0.03958637031820996\n",
      "obj  0.039586174283110065\n",
      "obj  0.039586174283110065\n",
      "obj  0.039586103898823125\n",
      "obj  0.039586075668607223\n",
      "obj  0.03958606329271006\n",
      "obj  0.03958606329271006\n",
      "obj  0.03958605753836624\n",
      "obj  0.03958605476865488\n",
      "obj  0.03958605476865488\n",
      "obj  0.03958605341066918\n",
      "obj  0.03958605341066918\n",
      "obj  0.03958605273839444\n",
      "obj  0.03958605273839443\n",
      "obj  0.03958605240393665\n",
      "obj  0.03958605240393665\n",
      "obj  0.039586052237127675\n",
      "obj  0.039586052237127675\n",
      "obj  0.03958605215382817\n",
      "obj  0.039586052153828155\n",
      "obj  0.03958605211220467\n",
      "obj  0.039586052112204666\n",
      "obj  0.03958605209139946\n",
      "obj  0.03958605209139947\n",
      "obj  0.039586052080998496\n",
      "obj  0.039586052080998496\n",
      "obj  0.03958605207579845\n",
      "obj  0.03958605207579845\n",
      "obj  0.03958605207319851\n",
      "obj  0.03958605207319851\n",
      "obj  0.03958605207189857\n",
      "obj  0.03958605207189857\n",
      "obj  0.039586052071248594\n",
      "obj  0.039586052071248594\n",
      "obj  0.03958605207092364\n",
      "obj  0.03958605207092364\n",
      "obj  0.03958605207076113\n",
      "obj  0.03958605207076113\n",
      "obj  0.03958605207067988\n",
      "obj  0.039586052070639276\n",
      "obj  0.039586052070639276\n",
      "obj  0.039586052070598655\n",
      "obj  0.03958647071020286\n",
      "obj  0.03958647071020287\n",
      "obj  0.03958637034025923\n",
      "obj  0.039586370340259226\n",
      "obj  0.039586174291929614\n",
      "obj  0.039586174291929614\n",
      "obj  0.03958610390267374\n",
      "obj  0.03958610390267374\n",
      "obj  0.03958607567039321\n",
      "obj  0.03958607567039321\n",
      "obj  0.03958606329356827\n",
      "obj  0.03958606329356827\n",
      "obj  0.03958605753878668\n",
      "obj  0.03958605753878668\n",
      "obj  0.039586054768862934\n",
      "obj  0.039586054768862934\n",
      "obj  0.03958605341077266\n",
      "obj  0.03958605341077266\n",
      "obj  0.039586052738446044\n",
      "obj  0.039586052738446044\n",
      "obj  0.039586052403962416\n",
      "obj  0.03958605223714055\n",
      "obj  0.039586052237140554\n",
      "obj  0.03958605215383461\n",
      "obj  0.039586052153834615\n",
      "obj  0.03958605211220788\n",
      "obj  0.039586052112207885\n",
      "obj  0.039586052091401064\n",
      "obj  0.039586052080999315\n",
      "obj  0.039586052080999315\n",
      "obj  0.03958605207579884\n",
      "obj  0.03958605207579884\n",
      "obj  0.0395860520731987\n",
      "obj  0.0395860520731987\n",
      "obj  0.03958605207189867\n",
      "obj  0.03958605207189867\n",
      "obj  0.039586052071248656\n",
      "obj  0.039586052071248656\n",
      "obj  0.039586052070923645\n",
      "obj  0.03958605207092365\n",
      "obj  0.03958605207076116\n",
      "obj  0.03958605207076116\n",
      "obj  0.0395860520706799\n",
      "obj  0.03958605207067989\n",
      "obj  0.039586052070639276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.039586052070639276\n",
      "v20 d-1 f0 t2: original ll 0.0432 auc 0.9923, ensemble ll 0.0432 auc 0.9923\n",
      "running time 10.084612607955933\n",
      "starting fold 0 target 3\n",
      "obj  0.023883007738504096\n",
      "obj  0.0239170452827324\n",
      "obj  0.0239155432851283\n",
      "obj  0.023914388758290925\n",
      "obj  0.023912639635809856\n",
      "obj  0.023913936576399043\n",
      "obj  0.023913199311673104\n",
      "obj  0.02391428684726555\n",
      "obj  0.023900117835123778\n",
      "obj  0.023817320375318366\n",
      "obj  0.02376584509559687\n",
      "obj  0.023751711946991227\n",
      "obj  0.02374422777884638\n",
      "obj  0.023738474742026738\n",
      "obj  0.023737098638803262\n",
      "obj  0.023736775087381104\n",
      "obj  0.02373642594463824\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736804980546335\n",
      "obj  0.023736597035675995\n",
      "obj  0.023736597035675995\n",
      "obj  0.023736499161470668\n",
      "obj  0.023736499161470668\n",
      "obj  0.02373645947244484\n",
      "obj  0.023736459472444838\n",
      "obj  0.023736441937532597\n",
      "obj  0.023736441937532597\n",
      "obj  0.02373643374867179\n",
      "obj  0.02373643374867179\n",
      "obj  0.023736429798551367\n",
      "obj  0.02373642785956895\n",
      "obj  0.02373642785956895\n",
      "obj  0.023736426899097246\n",
      "obj  0.023736426899097246\n",
      "obj  0.023736426421116265\n",
      "obj  0.023736426421116265\n",
      "obj  0.023736426182689497\n",
      "obj  0.023736426182689497\n",
      "obj  0.023736426063617054\n",
      "obj  0.023736426063617054\n",
      "obj  0.023736426004116053\n",
      "obj  0.023736426004116053\n",
      "obj  0.023736425974374354\n",
      "obj  0.023736425974374344\n",
      "obj  0.023736425959505723\n",
      "obj  0.023736425959505723\n",
      "obj  0.023736425952071948\n",
      "obj  0.023736425952071944\n",
      "obj  0.0237364259483552\n",
      "obj  0.023736425946496865\n",
      "obj  0.0237364259455677\n",
      "obj  0.0237364259455677\n",
      "obj  0.023736425945103126\n",
      "obj  0.023736425945103123\n",
      "obj  0.023736425944870833\n",
      "obj  0.023736425944870833\n",
      "obj  0.02373642594475469\n",
      "obj  0.02373642594475469\n",
      "obj  0.023736425944696615\n",
      "obj  0.02373642594475469\n",
      "obj  0.02373642594475469\n",
      "obj  0.023736425944696615\n",
      "obj  0.02373681224629858\n",
      "obj  0.023736812246298585\n",
      "obj  0.02373660458016534\n",
      "obj  0.023736604580165337\n",
      "obj  0.0237365021344554\n",
      "obj  0.023736502134455405\n",
      "obj  0.023736460759585264\n",
      "obj  0.023736460759585264\n",
      "obj  0.02373644253121444\n",
      "obj  0.02373643403308159\n",
      "obj  0.023736434033081597\n",
      "obj  0.023736429937670313\n",
      "obj  0.023736429937670313\n",
      "obj  0.023736427928378726\n",
      "obj  0.023736427928378726\n",
      "obj  0.023736426933336476\n",
      "obj  0.023736426933336482\n",
      "obj  0.023736426438216246\n",
      "obj  0.023736426438216246\n",
      "obj  0.023736426191256352\n",
      "obj  0.023736426191256352\n",
      "obj  0.02373642606792646\n",
      "obj  0.02373642606792646\n",
      "obj  0.02373642600629904\n",
      "obj  0.02373642600629904\n",
      "obj  0.023736425975494704\n",
      "obj  0.023736425975494704\n",
      "obj  0.023736425960094867\n",
      "obj  0.023736425960094867\n",
      "obj  0.023736425952395564\n",
      "obj  0.023736425948546035\n",
      "obj  0.023736425948546035\n",
      "obj  0.02373642594662132\n",
      "obj  0.02373642594662132\n",
      "obj  0.023736425945658952\n",
      "obj  0.023736425945658952\n",
      "obj  0.023736425945177785\n",
      "obj  0.023736425945177785\n",
      "obj  0.0237364259449372\n",
      "obj  0.0237364259449372\n",
      "obj  0.023736425944816914\n",
      "obj  0.023736425944816914\n",
      "obj  0.023736425944756754\n",
      "obj  0.023736425944756757\n",
      "obj  0.023736425944696615\n",
      "obj  0.023736813777834338\n",
      "obj  0.02373681377783434\n",
      "obj  0.023736606196486747\n",
      "obj  0.02373650276901623\n",
      "obj  0.023736502769016225\n",
      "obj  0.023736461033560412\n",
      "obj  0.023736461033560412\n",
      "obj  0.023736442657360118\n",
      "obj  0.023736442657360118\n",
      "obj  0.023736434093448115\n",
      "obj  0.02373643409344811\n",
      "obj  0.023736429967177012\n",
      "obj  0.023736429967177015\n",
      "obj  0.023736427942962938\n",
      "obj  0.023736427942962934\n",
      "obj  0.0237364269405863\n",
      "obj  0.0237364269405863\n",
      "obj  0.023736426441830594\n",
      "obj  0.023736426441830594\n",
      "obj  0.02373642619306088\n",
      "obj  0.02373642619306089\n",
      "obj  0.023736426068828063\n",
      "obj  0.02373642606882807\n",
      "obj  0.02373642600674968\n",
      "obj  0.02373642600674968\n",
      "obj  0.023736425975719972\n",
      "obj  0.023736425975719972\n",
      "obj  0.023736425960207506\n",
      "obj  0.02373642596020751\n",
      "obj  0.023736425952451855\n",
      "obj  0.023736425952451855\n",
      "obj  0.023736425948574183\n",
      "obj  0.023736425948574183\n",
      "obj  0.023736425946635394\n",
      "obj  0.023736425946635397\n",
      "obj  0.023736425945666002\n",
      "obj  0.023736425945666002\n",
      "obj  0.02373642594518131\n",
      "obj  0.02373642594493896\n",
      "obj  0.02373642594493896\n",
      "obj  0.02373642594481777\n",
      "obj  0.023736425944817778\n",
      "obj  0.0237364259447572\n",
      "obj  0.023736425944757198\n",
      "obj  0.023736425944696615\n",
      "obj  0.023736814087258747\n",
      "obj  0.023736814087258747\n",
      "obj  0.02373660652416418\n",
      "obj  0.02373660652416418\n",
      "obj  0.023736502897563717\n",
      "obj  0.023736502897563717\n",
      "obj  0.023736461089030558\n",
      "obj  0.023736461089030554\n",
      "obj  0.02373644268289113\n",
      "obj  0.023736442682891132\n",
      "obj  0.023736434105663444\n",
      "obj  0.02373643410566345\n",
      "obj  0.023736429973147136\n",
      "obj  0.023736429973147136\n",
      "obj  0.023736427945913616\n",
      "obj  0.02373642794591362\n",
      "obj  0.023736426942053038\n",
      "obj  0.023736426942053038\n",
      "obj  0.023736426442561808\n",
      "obj  0.023736426193425957\n",
      "obj  0.02373642619342595\n",
      "obj  0.02373642606901048\n",
      "obj  0.02373642606901048\n",
      "obj  0.023736426006840842\n",
      "obj  0.023736426006840842\n",
      "obj  0.023736425975765564\n",
      "obj  0.023736425975765564\n",
      "obj  0.023736425960230297\n",
      "obj  0.023736425960230297\n",
      "obj  0.02373642595246325\n",
      "obj  0.02373642595246325\n",
      "obj  0.02373642594857988\n",
      "obj  0.023736425948579876\n",
      "obj  0.023736425946638235\n",
      "obj  0.023736425946638242\n",
      "obj  0.023736425945667418\n",
      "obj  0.02373642594566742\n",
      "obj  0.02373642594518202\n",
      "obj  0.02373642594518202\n",
      "obj  0.023736425944939316\n",
      "obj  0.023736425944939316\n",
      "obj  0.023736425944817955\n",
      "obj  0.02373642594481796\n",
      "obj  0.023736425944757306\n",
      "obj  0.023736425944757306\n",
      "v20 d-1 f0 t3: original ll 0.0261 auc 0.9962, ensemble ll 0.0262 auc 0.9962\n",
      "running time 8.827832460403442\n",
      "starting fold 0 target 4\n",
      "obj  0.06341978977959031\n",
      "obj  0.06345439519254051\n",
      "obj  0.06345178444644535\n",
      "obj  0.0634501873383087\n",
      "obj  0.06344850887091948\n",
      "obj  0.06345014114344298\n",
      "obj  0.06344638762675452\n",
      "obj  0.06344178389726654\n",
      "obj  0.06342547600607543\n",
      "obj  0.06330023726265231\n",
      "obj  0.06329097493536516\n",
      "obj  0.06329010391742251\n",
      "obj  0.06329008951413351\n",
      "obj  0.06329008866977354\n",
      "obj  0.06329000163116846\n",
      "obj  0.06328989710586087\n",
      "obj  0.06328989477029838\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989482686453\n",
      "obj  0.06328989480983283\n",
      "obj  0.06328989480983283\n",
      "obj  0.06328989477398501\n",
      "obj  0.06328989477398501\n",
      "obj  0.06328989477047609\n",
      "obj  0.06328989477047609\n",
      "obj  0.06328989477031234\n",
      "obj  0.06328989477031233\n",
      "obj  0.06328989477030038\n",
      "obj  0.06328989477029892\n",
      "obj  0.06328989477029892\n",
      "obj  0.06328989477029864\n",
      "obj  0.06328989477029864\n",
      "obj  0.06328989477029853\n",
      "obj  0.06328989477029853\n",
      "v20 d-1 f0 t4: original ll 0.0660 auc 0.9812, ensemble ll 0.0656 auc 0.9814\n",
      "running time 4.552181720733643\n",
      "starting fold 0 target 5\n",
      "obj  0.07751874441525756\n",
      "obj  0.07750510921278374\n",
      "obj  0.07749837024256545\n",
      "obj  0.07750729155861993\n",
      "obj  0.07791572795051716\n",
      "obj  0.07791002004051516\n",
      "obj  0.07790612580955882\n",
      "obj  0.07782636140088382\n",
      "obj  0.07800566495038753\n",
      "obj  0.0776733781030259\n",
      "obj  0.07765373521305806\n",
      "obj  0.07763297677342838\n",
      "obj  0.07743884494528572\n",
      "obj  0.07740141220498425\n",
      "obj  0.07740109443220537\n",
      "obj  0.07740099995272341\n",
      "obj  0.07740097803658219\n",
      "obj  0.0774009743313774\n",
      "obj  0.07740097401490428\n",
      "v20 d-1 f0 t5: original ll 0.0817 auc 0.9787, ensemble ll 0.0815 auc 0.9787\n",
      "running time 3.9697935581207275\n",
      "starting fold 1 target 0\n",
      "obj  0.09493705856539628\n",
      "obj  0.09542776297170255\n",
      "obj  0.09541286125909527\n",
      "obj  0.09540027840942801\n",
      "obj  0.09539138877609378\n",
      "obj  0.09536975932869157\n",
      "obj  0.09535630162054949\n",
      "obj  0.09533858275361039\n",
      "obj  0.09531096903660503\n",
      "obj  0.09523907940917149\n",
      "obj  0.09518712918085562\n",
      "obj  0.09514750430683895\n",
      "obj  0.09513080005240622\n",
      "obj  0.09511455239878734\n",
      "obj  0.09510064108667236\n",
      "obj  0.09508830138538116\n",
      "obj  0.09507429724220696\n",
      "obj  0.09506105238475455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.09504746534504258\n",
      "obj  0.09503440355049349\n",
      "obj  0.09502136291365668\n",
      "obj  0.09500655737047586\n",
      "obj  0.09499260005663875\n",
      "obj  0.09497979249403046\n",
      "obj  0.09496787943775475\n",
      "obj  0.0949540192726833\n",
      "obj  0.09493965987139397\n",
      "obj  0.09492620347494857\n",
      "obj  0.09491351309124799\n",
      "obj  0.09490166714349337\n",
      "obj  0.09489021220351254\n",
      "obj  0.09487981539616344\n",
      "obj  0.09486751609475247\n",
      "obj  0.09481240715087415\n",
      "obj  0.09480426868502033\n",
      "obj  0.09479764770574657\n",
      "obj  0.09479049722685454\n",
      "obj  0.09478400538718487\n",
      "obj  0.09477871950438965\n",
      "obj  0.09477431966810254\n",
      "obj  0.09476892026925579\n",
      "obj  0.09476237480753594\n",
      "obj  0.09475589915456015\n",
      "obj  0.09474890645062792\n",
      "obj  0.09473677600278702\n",
      "obj  0.09472850148841608\n",
      "obj  0.0947276369060547\n",
      "obj  0.09472761969062758\n",
      "obj  0.09472761650562768\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761661263826\n",
      "obj  0.09472761655166825\n",
      "obj  0.09472761655166824\n",
      "obj  0.09472761652300635\n",
      "obj  0.09472761652300635\n",
      "obj  0.09472761651383256\n",
      "obj  0.09472761651383256\n",
      "obj  0.09472761650961867\n",
      "obj  0.09472761650961867\n",
      "obj  0.09472761650759526\n",
      "obj  0.09472761650759526\n",
      "obj  0.09472761650660452\n",
      "obj  0.09472761650660452\n",
      "obj  0.09472761650611433\n",
      "obj  0.09472761650611432\n",
      "obj  0.09472761650587055\n",
      "obj  0.09472761650587055\n",
      "obj  0.09472761650574898\n",
      "obj  0.09472761650574898\n",
      "obj  0.09472761650568831\n",
      "obj  0.09472761650568831\n",
      "obj  0.09472761650565796\n",
      "obj  0.09472761650565797\n",
      "obj  0.0947276165056428\n",
      "obj  0.0947276165056428\n",
      "obj  0.09472761650563521\n",
      "obj  0.09472761650563521\n",
      "obj  0.09472761650563144\n",
      "obj  0.09472761650563147\n",
      "obj  0.09472761650562955\n",
      "obj  0.09472761650562954\n",
      "v20 d-1 f1 t0: original ll 0.0971 auc 0.9868, ensemble ll 0.0970 auc 0.9868\n",
      "running time 10.36232614517212\n",
      "starting fold 1 target 1\n",
      "obj  0.015888320512205296\n",
      "obj  0.015846788732143683\n",
      "obj  0.015827465243699063\n",
      "obj  0.01584565693173246\n",
      "obj  0.015871036486716606\n",
      "obj  0.015870973460351316\n",
      "obj  0.015833170387488348\n",
      "obj  0.015847001298369\n",
      "obj  0.015585221577829657\n",
      "obj  0.015552659120590236\n",
      "obj  0.015544417499555282\n",
      "obj  0.015542555209557992\n",
      "obj  0.015542012899913199\n",
      "obj  0.015541930607117178\n",
      "v20 d-1 f1 t1: original ll 0.0136 auc 0.9637, ensemble ll 0.0133 auc 0.9638\n",
      "running time 3.0536530017852783\n",
      "starting fold 1 target 2\n",
      "obj  0.0407203222141063\n",
      "obj  0.0407560545256146\n",
      "obj  0.040755465085661316\n",
      "obj  0.040755156739393\n",
      "obj  0.04075693930955356\n",
      "obj  0.04074852256144443\n",
      "obj  0.04074729655344704\n",
      "obj  0.04073704751795946\n",
      "obj  0.040639683449119335\n",
      "obj  0.040416688101203684\n",
      "obj  0.04039941570381972\n",
      "obj  0.04039815370709016\n",
      "obj  0.04039811921774086\n",
      "obj  0.04039489316399889\n",
      "obj  0.04038958414151976\n",
      "obj  0.040389014209956865\n",
      "obj  0.04038900633182188\n",
      "obj  0.040389006279412325\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.04038900633794773\n",
      "obj  0.040389006285129085\n",
      "obj  0.040389006279964966\n",
      "obj  0.040389006279467406\n",
      "obj  0.040389006279467406\n",
      "obj  0.04038900627941783\n",
      "v20 d-1 f1 t2: original ll 0.0413 auc 0.9923, ensemble ll 0.0414 auc 0.9922\n",
      "running time 4.533194065093994\n",
      "starting fold 1 target 3\n",
      "obj  0.025205570180647553\n",
      "obj  0.02524255372274568\n",
      "obj  0.02524180358160264\n",
      "obj  0.025240742284920282\n",
      "obj  0.02523896593182751\n",
      "obj  0.025238855342560613\n",
      "obj  0.025238081304330588\n",
      "obj  0.02523821212831437\n",
      "obj  0.025225986675272843\n",
      "obj  0.025131445284455295\n",
      "obj  0.02509461859524722\n",
      "obj  0.025053593291144895\n",
      "obj  0.025049243686894037\n",
      "obj  0.025047406869666673\n",
      "obj  0.02504656228786232\n",
      "obj  0.025045487559408202\n",
      "obj  0.025044857997835516\n",
      "obj  0.02504393993596791\n",
      "obj  0.0250422884042331\n",
      "obj  0.02503929618599696\n",
      "obj  0.025034852338500405\n",
      "obj  0.02503009611377315\n",
      "obj  0.025028574501313672\n",
      "obj  0.02502848789946158\n",
      "obj  0.025028487300549646\n",
      "obj  0.025028487278661058\n",
      "obj  0.025028487276918667\n",
      "obj  0.025028487276829964\n",
      "obj  0.02502848727681937\n",
      "obj  0.02502848727681905\n",
      "v20 d-1 f1 t3: original ll 0.0237 auc 0.9970, ensemble ll 0.0237 auc 0.9970\n",
      "running time 5.783538579940796\n",
      "starting fold 1 target 4\n",
      "obj  0.06467954634608762\n",
      "obj  0.06473149439598247\n",
      "obj  0.06473099281262552\n",
      "obj  0.064731208185045\n",
      "obj  0.06473061636344894\n",
      "obj  0.06473173693621728\n",
      "obj  0.06473148993935905\n",
      "obj  0.06473269812500074\n",
      "obj  0.06471059183232529\n",
      "obj  0.06460821359535296\n",
      "obj  0.06455716750017916\n",
      "obj  0.0645197065136012\n",
      "obj  0.0645081152244973\n",
      "obj  0.06450249732851546\n",
      "obj  0.06450109477781259\n",
      "obj  0.06448563583241472\n",
      "obj  0.06447411240443449\n",
      "obj  0.06447253979490797\n",
      "obj  0.06447217678105\n",
      "obj  0.0644651185516944\n",
      "obj  0.06446457312372401\n",
      "obj  0.06446151076608767\n",
      "obj  0.06445759111811036\n",
      "obj  0.06445687777985419\n",
      "obj  0.06445514054348393\n",
      "obj  0.06445470810575145\n",
      "obj  0.06445463894715117\n",
      "obj  0.06445282854163638\n",
      "obj  0.06445253243204845\n",
      "obj  0.06445247412041083\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445254463396723\n",
      "obj  0.06445253807069981\n",
      "obj  0.06445253807069981\n",
      "obj  0.06445248975454318\n",
      "obj  0.06445248975454318\n",
      "obj  0.06445247779674686\n",
      "obj  0.06445248712576493\n",
      "obj  0.06445248712576493\n",
      "obj  0.06445248148299874\n",
      "obj  0.06445248148299874\n",
      "obj  0.06445247939240469\n",
      "obj  0.06445247853091156\n",
      "obj  0.06445247853091156\n",
      "obj  0.06445247814850939\n",
      "obj  0.06445247814850939\n",
      "obj  0.0644524779687967\n",
      "obj  0.0644524779687967\n",
      "obj  0.06445247788181373\n",
      "obj  0.06445247788181373\n",
      "obj  0.06445247783904075\n",
      "obj  0.06445247781783393\n",
      "obj  0.06445247781783392\n",
      "obj  0.06445247780727542\n",
      "obj  0.0644524778020074\n",
      "obj  0.06445247780200739\n",
      "obj  0.06445247779937618\n",
      "obj  0.06445247779937618\n",
      "obj  0.0644524777980613\n",
      "obj  0.0644524777980613\n",
      "obj  0.06445247779740405\n",
      "obj  0.06445247779740405\n",
      "obj  0.06445247779707541\n",
      "obj  0.06445247779707541\n",
      "obj  0.06445247779691114\n",
      "obj  0.06445247779691114\n",
      "obj  0.064452477796829\n",
      "obj  0.064452477796829\n",
      "obj  0.06445247779678791\n",
      "obj  0.06445247779678791\n",
      "obj  0.06445247779676741\n",
      "obj  0.06445247779676742\n",
      "obj  0.06445247779675711\n",
      "obj  0.06445247779675711\n",
      "obj  0.06445247779674686\n",
      "obj  0.06445221168673727\n",
      "obj  0.0644496772744973\n",
      "obj  0.06444743645654968\n",
      "obj  0.06444569918525912\n",
      "obj  0.06444493600135769\n",
      "obj  0.06444481392875183\n",
      "obj  0.06444481226947826\n",
      "obj  0.06444481218198789\n",
      "obj  0.06444481218709061\n",
      "obj  0.06444481218452577\n",
      "obj  0.06444481218452579\n",
      "obj  0.06444481218220188\n",
      "obj  0.06444481218220188\n",
      "obj  0.0644448121820093\n",
      "obj  0.0644448121820093\n",
      "v20 d-1 f1 t4: original ll 0.0633 auc 0.9811, ensemble ll 0.0633 auc 0.9811\n",
      "running time 8.932530164718628\n",
      "starting fold 1 target 5\n",
      "obj  0.07840867449554682\n",
      "obj  0.07839859636802118\n",
      "obj  0.07838875002136615\n",
      "obj  0.07839508431385497\n",
      "obj  0.0787091110497969\n",
      "obj  0.07870448751610816\n",
      "obj  0.07870181402484341\n",
      "obj  0.0786984120991917\n",
      "obj  0.07872001128952959\n",
      "obj  0.07860709385183867\n",
      "obj  0.07860627872731314\n",
      "obj  0.07855447921085626\n",
      "obj  0.07834159934452409\n",
      "obj  0.07833875746491911\n",
      "obj  0.07833853714350575\n",
      "obj  0.0783385123995255\n",
      "obj  0.07833820129473078\n",
      "obj  0.07833812135951534\n",
      "obj  0.07833810199757306\n",
      "obj  0.07833809629296631\n",
      "obj  0.07833809475084523\n",
      "v20 d-1 f1 t5: original ll 0.0799 auc 0.9790, ensemble ll 0.0798 auc 0.9791\n",
      "running time 4.246876239776611\n",
      "starting fold 2 target 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.09689909157415061\n",
      "obj  0.09728414852532515\n",
      "obj  0.09727271871111413\n",
      "obj  0.09726245377030716\n",
      "obj  0.09725649163404872\n",
      "obj  0.09724108645711926\n",
      "obj  0.09723209027141427\n",
      "obj  0.09722096563434744\n",
      "obj  0.09719886349221624\n",
      "obj  0.09714732541174674\n",
      "obj  0.09710914204371268\n",
      "obj  0.09707815838120158\n",
      "obj  0.09705224730667553\n",
      "obj  0.09704448847899323\n",
      "obj  0.09703750831019696\n",
      "obj  0.09702984820618987\n",
      "obj  0.0970216485891182\n",
      "obj  0.09701276829837562\n",
      "obj  0.09700579578034611\n",
      "obj  0.09699989980791178\n",
      "obj  0.09699338044614057\n",
      "obj  0.0969877013647667\n",
      "obj  0.09697857091460442\n",
      "obj  0.09697071768033746\n",
      "obj  0.0969642080319638\n",
      "obj  0.0969583037393932\n",
      "obj  0.09694967059144816\n",
      "obj  0.09694106332578531\n",
      "obj  0.09693201191292704\n",
      "obj  0.09692455457226254\n",
      "obj  0.09691833845141871\n",
      "obj  0.09691142144347181\n",
      "obj  0.09690572648503311\n",
      "obj  0.09689894662493731\n",
      "obj  0.09689216093484564\n",
      "obj  0.09688594245491514\n",
      "obj  0.09687853600927131\n",
      "obj  0.09687234523644916\n",
      "obj  0.096864322226545\n",
      "obj  0.09685784957387136\n",
      "obj  0.09685248152430073\n",
      "obj  0.096845326326431\n",
      "obj  0.09683920885399337\n",
      "obj  0.09683276121467796\n",
      "obj  0.09682753953577912\n",
      "obj  0.0968232868581404\n",
      "obj  0.09681905949258447\n",
      "obj  0.09681445837603554\n",
      "obj  0.09680934391850522\n",
      "obj  0.09680296627576718\n",
      "obj  0.09679595099622175\n",
      "obj  0.0967889288151468\n",
      "obj  0.09678300836093617\n",
      "obj  0.09677735323867076\n",
      "obj  0.09677022644149524\n",
      "obj  0.09676470770032314\n",
      "obj  0.09675912962424071\n",
      "obj  0.09672112220855753\n",
      "obj  0.09671619779242321\n",
      "obj  0.09670923510890791\n",
      "obj  0.09670155551101607\n",
      "obj  0.09669750625273726\n",
      "obj  0.09669602555006052\n",
      "obj  0.09669599989425252\n",
      "obj  0.09669599889257408\n",
      "obj  0.09669599886011258\n",
      "obj  0.09669599885904746\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884132\n",
      "obj  0.09669599885884139\n",
      "obj  0.09669599885884139\n",
      "obj  0.09669599885884136\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884132\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884132\n",
      "obj  0.09669599885884136\n",
      "obj  0.09669599885884132\n",
      "obj  0.09669599885884132\n",
      "obj  0.09669599885884131\n",
      "obj  0.09669599885884131\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884134\n",
      "obj  0.09669599885884138\n",
      "obj  0.09669599885884138\n",
      "v20 d-1 f2 t0: original ll 0.0932 auc 0.9883, ensemble ll 0.0931 auc 0.9884\n",
      "running time 13.88540244102478\n",
      "starting fold 2 target 1\n",
      "obj  0.014949832094834912\n",
      "obj  0.014916605200051579\n",
      "obj  0.014903356510312835\n",
      "obj  0.01491763820111967\n",
      "obj  0.014944464288275389\n",
      "obj  0.014935134430768236\n",
      "obj  0.014901898649579632\n",
      "obj  0.014913218598028301\n",
      "obj  0.014671799295395716\n",
      "obj  0.01464247377818023\n",
      "obj  0.014632758277418865\n",
      "obj  0.014628821684288808\n",
      "obj  0.014628320528866702\n",
      "obj  0.0146281539489089\n",
      "obj  0.014628134164279681\n",
      "v20 d-1 f2 t1: original ll 0.0155 auc 0.9690, ensemble ll 0.0151 auc 0.9718\n",
      "running time 3.165548086166382\n",
      "starting fold 2 target 2\n",
      "obj  0.04226152716896324\n",
      "obj  0.04229098110858551\n",
      "obj  0.042289538988029306\n",
      "obj  0.04228848636305444\n",
      "obj  0.04229154338910145\n",
      "obj  0.04228085991294253\n",
      "obj  0.04227904924689781\n",
      "obj  0.042266309894983076\n",
      "obj  0.042144409827974794\n",
      "obj  0.04197968191669944\n",
      "obj  0.041968257682589764\n",
      "obj  0.04196619235187505\n",
      "obj  0.04196613514191359\n",
      "obj  0.0419630707676862\n",
      "obj  0.04195857607538806\n",
      "obj  0.041957870415411276\n",
      "obj  0.04195786139951108\n",
      "obj  0.04195786138379403\n",
      "v20 d-1 f2 t2: original ll 0.0385 auc 0.9929, ensemble ll 0.0382 auc 0.9929\n",
      "running time 3.7359166145324707\n",
      "starting fold 2 target 3\n",
      "obj  0.024846520722800945\n",
      "obj  0.024882999339254183\n",
      "obj  0.024880143736097496\n",
      "obj  0.024878288396855307\n",
      "obj  0.02487707964386421\n",
      "obj  0.024876233314629653\n",
      "obj  0.02487531205843952\n",
      "obj  0.024874214564632482\n",
      "obj  0.02484116214520021\n",
      "obj  0.02476727922897016\n",
      "obj  0.024764296133176787\n",
      "obj  0.02476018147466298\n",
      "obj  0.02475732378890371\n",
      "obj  0.024753537662691748\n",
      "obj  0.024749526656887465\n",
      "obj  0.024748247927490613\n",
      "obj  0.024748208797422715\n",
      "obj  0.02474820863859992\n",
      "obj  0.024748208635191053\n",
      "obj  0.024748208635125602\n",
      "obj  0.02474820863512319\n",
      "obj  0.024748208635122563\n",
      "v20 d-1 f2 t3: original ll 0.0242 auc 0.9968, ensemble ll 0.0240 auc 0.9968\n",
      "running time 4.434142351150513\n",
      "starting fold 2 target 4\n",
      "obj  0.06459161958459722\n",
      "obj  0.06466400774077863\n",
      "obj  0.0646638870578368\n",
      "obj  0.06466436247171094\n",
      "obj  0.0646643819538251\n",
      "obj  0.06466340084007548\n",
      "obj  0.06466238816646942\n",
      "obj  0.06466254628854462\n",
      "obj  0.06459751822789614\n",
      "obj  0.06438305349813167\n",
      "obj  0.0643718688399082\n",
      "obj  0.0643715821136909\n",
      "obj  0.0643671719758413\n",
      "obj  0.06436168044591388\n",
      "obj  0.06435949204943266\n",
      "obj  0.06435922290148019\n",
      "obj  0.0643592114124921\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921318955641\n",
      "obj  0.06435921204546469\n",
      "obj  0.06435921204546469\n",
      "obj  0.06435921146287572\n",
      "obj  0.06435921146287572\n",
      "obj  0.06435921141749858\n",
      "obj  0.06435921141749858\n",
      "obj  0.06435921141299242\n",
      "obj  0.06435921141254211\n",
      "obj  0.06435921141254211\n",
      "v20 d-1 f2 t4: original ll 0.0635 auc 0.9824, ensemble ll 0.0635 auc 0.9824\n",
      "running time 4.299889087677002\n",
      "starting fold 2 target 5\n",
      "obj  0.0807095971992614\n",
      "obj  0.08072768329157434\n",
      "obj  0.08072759910689727\n",
      "obj  0.08072801264652245\n",
      "obj  0.08072994331194105\n",
      "obj  0.08072627119533599\n",
      "obj  0.08072589814720048\n",
      "obj  0.08072147368151238\n",
      "obj  0.08065793015634481\n",
      "obj  0.0805488394103065\n",
      "obj  0.08054672424761428\n",
      "obj  0.08054643296574672\n",
      "obj  0.08054643259173946\n",
      "obj  0.08054602059925454\n",
      "obj  0.08054569057436263\n",
      "obj  0.08054568823301883\n",
      "obj  0.08054568822653085\n",
      "v20 d-1 f2 t5: original ll 0.0753 auc 0.9820, ensemble ll 0.0755 auc 0.9820\n",
      "running time 3.6082446575164795\n",
      "total running time 110.85583209991455\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for fold in range(3):\n",
    "    for target in range(6):\n",
    "        train_ensemble(train_md, preds_all, fold=fold, target=target, ds_idx=-1, first_step=False)\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.05930 ensemble ll 0.05908\n",
      "valid original ll 0.05938 ensemble ll 0.05924\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_WORK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx == -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 78545, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total running time 2.675769805908203\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "preds = np.stack([pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(ds, VERSION),'rb')) for ds in range(6,10)])\n",
    "\n",
    "test_preds_trgt = []\n",
    "for target in range(6):\n",
    "    \n",
    "    test_preds_folds = []\n",
    "    for fold in range(3):\n",
    "        \n",
    "        test_preds = []\n",
    "        for ds_idx in range(4):\n",
    "            model = pickle.load(open(PATH_WORK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                     .format(ds_idx,fold,target,VERSION),'rb'))\n",
    "            X,y,ll_train,auc_train =  getFirstStepX(None, preds[:,fold], TH=model.prior, \n",
    "                                                    powerLow=model.powerLow, powerHigh=model.powerHigh, \n",
    "                                                    fold=fold, target=target, ds_idx=ds_idx, mode='test')\n",
    "            test_preds.append((X*np.expand_dims(model.x, axis=1)).sum(0))\n",
    "        \n",
    "        X = np.stack(test_preds)\n",
    "        model = pickle.load(open(PATH_WORK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                 .format(-1,fold,target,VERSION),'rb'))\n",
    "        test_preds_folds.append((X*np.expand_dims(model.x, axis=1)).sum(0))\n",
    "    \n",
    "    X = np.stack(test_preds_folds).mean(0)\n",
    "    test_preds_trgt.append(X)\n",
    "\n",
    "predictions = np.stack(test_preds_trgt,axis=1)\n",
    "\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78545, 6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(9, 20),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0.5* (pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 51),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 52),'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 51),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 52),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 53),'rb'))) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet161', 72),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 73),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 74),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 78),'rb'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00797, 0.00125, 0.0039 , 0.0026 , 0.00511, 0.00504],\n",
       "       [0.00727, 0.00117, 0.00363, 0.00238, 0.00469, 0.00434],\n",
       "       [0.00687, 0.00118, 0.00313, 0.00217, 0.00415, 0.00443],\n",
       "       [0.00905, 0.00102, 0.00443, 0.00315, 0.00575, 0.00509]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.std(2).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15249, 0.01507, 0.03719, 0.02508, 0.05596, 0.06206],\n",
       "       [0.14765, 0.01445, 0.03652, 0.02455, 0.05567, 0.05837],\n",
       "       [0.14786, 0.01586, 0.0346 , 0.02439, 0.05371, 0.06038],\n",
       "       [0.1466 , 0.01732, 0.03613, 0.02529, 0.05583, 0.05959]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds.mean((1,2), keepdims=True) * np.log(np.clip(preds,1e-15,1-1e-15)) \n",
    "  - (1 - preds.mean((1,2), keepdims=True)) * np.log(np.clip(1 - preds,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54027, 0.54585, 0.53983, 0.54938])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds.mean((1,2,3), keepdims=True) * np.log(np.clip(preds,1e-15,1-1e-15)) \n",
    "  - (1 - preds.mean((1,2,3), keepdims=True)) * np.log(np.clip(1 - preds,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 75),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 78545, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.quantile(preds,q=0.5,axis=(1)).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scalePreds(predictions, 1.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md['pred_any'] = predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33d3ee3f10>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd1yc55Xo8d+ZoXfRJKoqCPViVCxZsuTeIpe4xxs7cVlvks0m2bsb7+beFOfuJk52k3uzcW7ije3YiePeZMeObMuSi5qFGhICJEASICQxgED0Ns/9YwYZIRAzMPAOzPl+Pnw0zDzvzGEEh5fznud5xBiDUkqpwGGzOgCllFKjSxO/UkoFGE38SikVYDTxK6VUgNHEr5RSASbI6gD6SkxMNFOmTLE6DKWUGlN27dpVY4xJ8mSs3yX+KVOmkJeXZ3UYSik1pojIMU/HaqlHKaUCjCZ+pZQKMJr4lVIqwGjiV0qpAKOJXymlAowmfqWUCjCa+JVSKsBo4ldDduhUI3/cfozapnarQ1FKecHvJnAp/9bc3sXb+VW8sLOCPeX1APzXxsP8nzsXsmJ6osXRKaU8oYlfDcrpNOwqP82ruyp5a18VzR3dzEiO4n9eP4s5qbF87439fOn3O/j6mhn8wxVZBNv1D0ml/JkmfjWgUkcTb+w5zut7jlN5upXwYDtfWJDCHUsyWZwZh4gA8PbfX8IP1xfw600lbC2t4f/euYiM+AiLo1dKDUT8bevF3Nxco2v1WKer28kbe6t4dttR8isbsAmsnJHIzYvSuHrOJCJDBz5XWL+viu+9th8EvnzxZK6bl8LslJizvyCUUiNHRHYZY3I9GquJX4Er4b++5zi/3lTCsdoWciZFc+tF6axbkEpyTJjHz1Ne28IP1h/g48M1dDsNUxIiuHZeCtfNTWFumv4SUGqkaOJXHuub8OekxvCtK7K5YlbysJJ0XXMH7xWc5C/7T7C1tJZupyEuIph5abHMT49lXloc89NjSYkN018GSvmAJn7lkbbObu596jN2HKnzWcLvz+nmDj4oPMWuY6fJr2zg0KlGupyu77vl0+J54su5xIQF+/Q1lQo0mvjVoLq6nTz8p91sLDrFY7fM57bc9FE7827r7KboZCPbSmv5xfvFzJwUzbNfXUZ8ZMiovL5S45E3iV/77gKQMYZ/fX0/HxSe4tF1c7h9ScaollvCgu0szIjj79ZM54m/yeXwqSbu+N02qs+0jVoMSgUyTfwB6Ocbinkpr5JvXp7F31w8xdJY1uYk8/RXlnC8vpXbfreNytMtlsajVCDQxB9gnvz0CL/ZXMrdyzL59hVZVocDwIrpifzpgWWcbu7g9t9uo8zRZHVISo1rmvgDyJt7j/Pjtw9y7dxJ/PjGuX7VTbM4cwLPP7Sc9i4nX/r9DhpaO60OSalxSxN/gDjR0Mojr+5n6dR4fnnHQuw2/0n6PeakxvLUfUs4daaNn75baHU4So1bmvgDxGPvFtFtDP952wLCgu1WhzOgBRlxPLhqGs9/VsHWkhqrw1FqXNLEHwB2l5/mjb1VPLhq6phYQ+fbV2YzNTGS776WT0tHl9XhKDXuaOIf55xOw4/eOkhydChfWzPD6nA8EhZs56e3zKOirpX/2HDI6nCUGnc08Y9zb+w9zr6Kev75mpwLLrDmb5ZNS+Ce5Zk8vfUIu46dtjocpcYVTfzjWHN7Fz99t4gF6bHcsijN6nC89t1rckiJCeO7r+bT3tVtdThKjRua+Mex/7e5lOrGdr7/hTnY/LCLZzDRYcH8+y3zKKlu4tcfllgdjlLjhib+caqiroUnPinjpoWpXDR5gtXhDNmamcncsjiN/7e5lKr6VqvDUWpc0MQ/Tv303SLsInz32hyrQxm2b1+RTbcxvPBZudWhKDUuaOIfh0odTfxl/wkeXD2NlNhwq8MZtoz4CNZkJ/HCzgo6u51Wh6PUmOdR4heRa0SkWERKROSRfh7/jogcFJF8EdkoIpN7PXaviBx2f9zry+BV/174rJwgm/A3yycPPniMuGf5ZKob2/ng4CmrQ1FqzBs08YuIHXgcuBaYDdwlIrP7DNsD5Bpj5gOvAD9zHxsP/ABYBiwFfiAiY7fgPAa0d3Xzyq5KrpozkaToUKvD8Zk1M5NJiwvnTzuOWR2KUmOeJ2f8S4ESY0yZMaYDeAG4sfcAY8wmY0zPerrbgXT37auB940xdcaY08D7wDW+CV31Z0PBKU63dHLX0kyrQ/Epu024a2kGW0pqdfVOpYbJk8SfBlT0+rzSfd9A7gfe9eZYEXlIRPJEJM/hcHgQkhrI8zvKyYgPZ+X0RKtD8bnbl2QQZBOe26EXeZUaDk8Sf38N4P3u1ygi9wC5wM+9OdYY84QxJtcYk5uUlORBSKo/ZY4mtpXVcueSzDHZtz+Y5Ogwrp47iVd2VdLWqRO6lBoqTxJ/JZDR6/N0oKrvIBG5AvgesM4Y0+7Nsco3XthZQZBNuC03ffDBY9Q9yybT0NrJW/v020ipofIk8e8EskRkqoiEAHcC63sPEJFFwO9wJf3qXg9tAK4SkQnui7pXue9TPtZzUfeKWRNJjg6zOpwRs3xaPNOTIrXco9QwDJr4jTFdwDdwJexC4CVjTIGIPCoi69zDfg5EAS+LyF4RWe8+tg74Ma5fHjuBR933KR97r+AUdc0d3LVsfF3U7UtE+NKyyeytqOfA8Qarw1FqTBJj+i3XWyY3N9fk5eVZHcaYc/d/b+dYbQuf/PPacVnf762htZNl//4BNy9K4ye3zLc6HKX8gojsMsbkejJWZ+6OA0dqmtlaWstdSzPGfdIHiA0PZt2CVN7YU8WZNt2bVylvaeIfB17YWY7dJtyWmzH44HHijiWZtHZ2s6moevDBSqlzaOIf4zq6nLySV8nlOclMjBm/F3X7WpgRR3xkiCZ+pYZAE/8Yt62sltrmDm4PoLN9cM3kXZ2VyMeHa3A6/es6lVL+ThP/GLepqJrQIBuXZI2/mbqDWZuTTF1zB/na3aOUVzTxj3EfHXKwfFoCYcF2q0MZdauykhBByz1KeUkT/xh2rLaZIzXNrJkZmMtcxEeGsDAjjs2HdH0npbyhiX8M21zsSnhrZiZbHIl11mQnk19ZT21T++CDlVKAJv4xbXNxNZMTIpiaGGl1KJZZm5OEMfDxYT3rV8pTmvjHqLbObraV1bImOzDLPD3mpsaSGBXCpiJN/Ep5ShP/GLXjSB1tnU7W5ARumQfAZhNWZyfx8WEH3drWqZRHNPGPUZuLXW2cF09LsDoUy62ZmUx9Syf7KuutDkWpMUET/xj1UXHgtnH2tTorEZvAZm3rVMojmvjHoPLaFsoCuI2zr7iIEBZlTtC2TqU8pIl/DNp8yHVmG8htnH2tnZlEfmUDjkZt61RqMJr4x6DNxY6Ab+Psq+eX4Md61q/UoDTxjzFtnd1sLa0J+DbOvmanxJAUHcqmYq3zKzUYTfxjzGc9bZxa5jmHzSZcmp3EJ4dr6Op2Wh2OUn5NE/8Ys7nYQWiQjeXaxnmetTOTaWjtZG+FtnUqdSGa+MeYzcXVLJ+WQHiItnH2dcmMRERgS0mt1aEo5dc08Y8h2sZ5YbERwcyaFMOOI5r4lboQTfxjSM+FS63vD2zZtHh2l5+mo0vr/EoNRBP/GPJB4SmmJUVqG+cFLJuaQFunk3xdvkGpAWniHyOa2rvYUVbH5QG+KNtglk6NB1yL2Cml+qeJf4z45JCDjm4nl8+aaHUofi0+MoSZE6PZXqZ1fqUGool/jPigsJrY8GByJ0+wOhS/t2xaPLuOnaZT+/mV6pcm/jGg22nYVFzNmplJBNn1v2wwy6Ym0NLRzYHjDVaHopRf0iwyBuytOE1dc4eWeTykdX6lLkwT/xiwsbCaIPeSBGpwSdGhTE+KZIfW+ZXqlyb+MWBjYTVLpsQTGx5sdShjxrJpCeQdPa3bMSrVD038fq6iroXiU41cPkvbOL2xbGo8je1dHKw6Y3UoSvkdTfx+bmPhKQCt73upZxE7Xb5BqfNp4vdzG4uqdbbuEEyMCWNKQgTby/QCr1J9aeL3Y41tnWwvq+UKPdsfkmVTE9h5tA6n1vmVOodHiV9ErhGRYhEpEZFH+nl8tYjsFpEuEbm1z2PdIrLX/bHeV4EHgk8O19DZbXSZhiFaNi2ehtZOik42Wh2KUn5l0MQvInbgceBaYDZwl4jM7jOsHLgP+HM/T9FqjFno/lg3zHgDygeFp4gND+Yina07JMu0zq9Uvzw5418KlBhjyowxHcALwI29Bxhjjhpj8gGdI+8j3U7D5mIHa3W27pClxYWTPiGcHVrnV+ocnmSUNKCi1+eV7vs8FSYieSKyXURu6m+AiDzkHpPncDi8eOrxa0+5a7buZVrfH5ZlUxP47GgdxmidX6keniR+6ec+b36KMo0xucDdwP8RkennPZkxTxhjco0xuUlJOjsVXN08dp2tO2zLpsVT19zB4eomq0NRym94kvgrgYxen6cDVZ6+gDGmyv1vGbAZWORFfAFrc7GD3MkTdLbuMC2f6q7z6/INSp3lSeLfCWSJyFQRCQHuBDzqzhGRCSIS6r6dCKwEDg412EBxsqGNwhNndItFH8iIDyctLpytpZr4leoxaOI3xnQB3wA2AIXAS8aYAhF5VETWAYjIEhGpBG4DficiBe7DZwF5IrIP2AT81BijiX8QHx1y7a27NkfLPMMlIqzKSmRLSQ1duj6/UgAEeTLIGPMO8E6f+77f6/ZOXCWgvsdtBeYNM8aAs6nIQUpsGDMnRlsdyriwKiuJF3ZWkH+8gcWZ2hqrlPYJ+pmOLiefltSwZmYSIv1dV1feWjkjARH45FCN1aEo5Rc08fuZXcdO09TepfV9H4qLCGF+ehyfHNZWYaVAE7/f2VxcTbBdWDkj0epQxpXVWYnsqajnTFun1aEoZTlN/H5mU7Fr05WoUI8uvygPrcpKottp2KbdPUpp4vcnx+tbOXSqibVa5vG5RZlxRIbYtdyjFJr4/crmYlcb55qZ2sbpa8F2GxdPT+CTw3qBVylN/H5kc7GDtLhwZiRHWR3KuLQqK4ljtS0cq222OhSlLKWJ30+0d3WzpaSGtTnaxjlSVmW5LpjrWb8KdJr4/cTOI6dp6ehmTbbW90fK1MRI0uLCtc6vAp4mfj+xubiaELuNFTMSrA5l3BIRVmcnsrWkVpdvUAFNE7+f2FRczbJp8USEaBvnSFqVlURjexf7KuutDkUpy2ji9wMVdS2UOpp1tu4oWDE9AZvAx7p8gwpgmvj9QE8b51pt4xxxunyDUpr4/cKmYgeZ8RFMTYy0OpSAsDorkb0V9TS06vINKjBp4rdYW2c3W0truCwnWds4R8mq7CScBraVarlHBSa9kmixbWW1tHU6dbbuKFqYEUdUaBC/eP8Qu8vrmZIQyZRE119cE6PDsNn0F7Aa3zTxW2xzUTVhwTaWT9M2ztESbLfxjctm8OquSv6w9SgdXZ+3dq7KSuTZry7Vv77UuKaJ30LGGD4srmbl9ETCgu1WhxNQHr50Og9fOp1up+FEQytHa1p498AJnttRTkHVGeamxVodolIjRmv8Fip1NFNR18raHG3jtIrdJqRPiOCSrET+6eqZhNhtvLKr0uqwlBpRmvgttKmoZ1N1Tfz+IC4ihCtnT+TNvcfPKf8oNd5o4rfQpuJqZk6MJi0u3OpQlNsXL0rjdEsnm9xzK5QajzTxW6SxrZPPjtSxJke7efzJ6qwkEqNCeVXLPWoc08RvkS0lNXQ5DZfpMg1+Jchu46aFqXxYVE1tU7vV4Sg1IjTxW2RTkYPosCAWT55gdSiqjy9elE6X07B+X5XVoSg1IjTxW8AYw6bialZnJRFs1/8CfzMrJYY5qTG8unv45Z6tJTWcbu7wQVRK+Y5mHQsUVJ2hurFdu3n82BcXp3Pg+BmKTzYO+TkaWjq558kd/OL9Qz6MTKnh08RvgZ42zkuz9cKuv7pxYSpBNhnWWX/+8XqcBjYWnsIY48PolBoeTfwW2FRczYL0WJKiQ60ORQ0gISqUtTnJvLb7+JB369pX4drspaqhjYMnzvgyPKWGRRP/KKtr7mBPRb1uujIGfHFxOjVN7UPenH1vRQNJ0aGIwAcHdV6A8h+a+EfZx4ccGAOXaX3f712Wk8yEiGBeGUK5xxjDvsp6Vs1IZFFGHB8UnhqBCJUaGk38o+zDomoSo0KYp4uA+b2QIBs3Lkzj/YOnONnQ5tWxJ8+04WhsZ0FGHFfMnsj+4w1eP4dSI0UT/yjqdho+PuxgdXaSrvk+Rnx15VScTsOvPjzs1XE99f356bFcMWsiABuL9Kxf+QdN/KNoX2U99S2dWt8fQzITIrhraSYv7azgaE2zx8ftrWgg2C7MSokhKzmKzPgINhZqnV/5B038o+ijYgc2gVUzEq0ORXnh7y+bQbDd5lU//r6KemalxBAWbEdEuHxWMp+W1NDS0TWCkSrlGY8Sv4hcIyLFIlIiIo/08/hqEdktIl0icmufx+4VkcPuj3t9FfhYtPmQgwUZcUyIDLE6FOWF5JgwvrJyCuv3VXGwavC2TKfTsP94AwvS487ed+WsiXR0OYfcIaSULw2a+EXEDjwOXAvMBu4Skdl9hpUD9wF/7nNsPPADYBmwFPiBiATk4jR1zR3kV9azJlvLPGPR366eTkxYEP/xXvGgY8tqmmhq72JBxueJf8nUeKLDgtio3T3KD3hyxr8UKDHGlBljOoAXgBt7DzDGHDXG5AN9Z7pcDbxvjKkzxpwG3geu8UHcY84nh11tnJfqpupjUmxEMA+vmc6HRdXkHa274Ni9FQ0ALMz4vHMr2G5jzcxkNhZW0+3UWbzKWp4k/jSgotfnle77PDGcY8eVj4odxEeGMF/bOMesr6yYSnJ0KI/9teiCSzDsq6gnKjSIaYlR59x/xaxkaps72Ovu+FHKKp4k/v76Dj09ZfHoWBF5SETyRCTP4XB4+NRjh9Np+OiQg1VZidrGOYaFh9j5+8uz2Hn0NJuLB/4+3VdZz7y02PP+r9dkJ2O3iZZ7lOU8SfyVQEavz9MBTxcq9+hYY8wTxphcY0xuUtL4K4UUVJ2htrmDNVrmGfPuyM0gMz6Cn20oxtlPyaats5vCE2fOqe/3iI0IZumUeL+bxVvX3EGNbjoTUDxJ/DuBLBGZKiIhwJ3Aeg+ffwNwlYhMcF/Uvcp9X0DZ7N6/dVWWJv6xLiTIxj9elU3hiTO8lX/++U/hiTN0dptz6vu9XTF7IodONVFe2zLSoXrsn17ex8N/3GV1GGoUDZr4jTFdwDdwJexC4CVjTIGIPCoi6wBEZImIVAK3Ab8TkQL3sXXAj3H98tgJPOq+L6BsPuRgfnosiVG6Gud48IX5qcxJjeHnG4pp7+o+57H8SteF3f7O+MFV5wf86qz/WF0LeyrqdY5BAPGoj98Y844xJtsYM90Y82/u+75vjFnvvr3TGJNujIk0xiQYY+b0OvYpY8wM98fTI/Nl+K+Glk72lJ/WtffHEZtNeOTaHCpPt/Kn7eXnPLavop7k6FAmxYT1e+zkhEiykqPYUHByNEL1iKOxnW6nYW+5XnQOFDpzd4R9UuLAadD6/jizKiuJVVmJ/NeHh2lo7Tx7/97KehZkxCEy8EX8a+el8NnROqobrV+0ra2z+2z8ecdOWxyNGi2a+EfYR8UOYsKCzpnFqcaH716TQ31LJ7/9qBSAhtZOyhzNLBygzNPjhvkpGAMbDlh/1t/7ou7OQeYnqPFDE/8IMsbdxpmdRJBuqj7uzE2L5eZFaTz16RFONLSy313fn59+4bka2ROjmZEcxV/2nxiNMC/I0ehK/Glx4ewpr9fJZQFCs9EIKjzRSHVju9b3x7HvXJmNMfDL9w+xr9K9FHPa4H/dXTcvhR1HrC/39CT+a+dOoqm9i6KTukVkINDEP4I2H3K1ca7RxD9uZcRH8OWLJ/PKrkrW761iWmIksRHBgx53/Tz/KPdU9yT+eSkA5B3VOn8g0MQ/gj4qdjArJYbkATo81Pjw9bUziAwNovhU44BtnH1lT4xielKk5eUeR2M7Iq7yVEpsmF7gDRCa+EdIc3sXu45pG2cgmBAZwtfXzgBgwSD1/R4iwvXzU/nsSN3ZcosVHE3txEeEEGy3cdHkCew8UnfBdYjU+KCJf4TkHTtNl9OwYnqC1aGoUXDfiil864os1i30fA3C6+el4DTwVwt7+h2N7SRFuyYWLpkSz8kzbRyvb7UsHjU6NPGPkG2ltQTbhdwpAbn9QMAJC7bzrSuyifdik52z5Z5+ln4YLdW9En/P9+ouLfeMe5r4R8i2sloWpMcRERJkdSjKT4kI189LsbTcU9Mr8edMiiEqNEj7+QOAJv4R0NjWyYHjDVysZR41iOvmW1fuMcacU+qx24RFmXHa2RMANPGPgLyjp+l2GpZP08SvLmzmxGimJ0XyTv7od/ecae2io9tJUq/FA5dMiaf4VOM5y1B4q7m9i5t/s4UdZbW+CFONAE38I2BbWS0h7i4JpS6kp9yz40jtqJd7HE2uyWO9241zJ0/AGNhdPvSz/u1ltewpr+fZbceGHaMaGZr4R8C20loWZsYRFmy3OhQ1BlhV7qk+4/pF0/uMf2FmHHabsGsY5Z4tJa4z/Y1Fp2hu16We/ZEmfh9raO2koKqBi7XMozw0c2I00yzo7nG4F2jrqfEDRIQEMTc1ZlgXeLeW1pAQGUJbp5MPi6qHHafyPU38PrbzSB1Og9b3lcdEhHULUtlxpI4TDaPXQ99TWuqd+AEumhzP3op6OrqcXj9nTVM7RScb+crKKSRFh/IXC65dqMFp4vexbWW1hATZWJSpyzArz920MA1j4I09o3fW72hsJzTIRkzYuS3HS6ZMoL3LSUFVg9fPua3UVea5JCuJ6+elsKm4miYt9/gdTfw+tq20losyJ2h9X3llSmIkizPjeH1P5agtmdAzeavvpjEXuSdyDaWtc2tpDdFhQcxLi+X6+Sm0dznZ6EfbTCoXTfw+VN/SQeHJM9q/r4bk5sXpHDrVxMETo7M0cu8e/t6So8OYnBAxpDr/lpJalk9LwG4TLsqcwKSYMN7ap+Uef6OJ34d2HKnDaH1fDdEN81IItguv7z4+Kq/naGw/p6Ont6VT4vm0pIY8L5J/RV0L5XUtZ9enstmE6+al8PEhB2fahj4vQPmeJn4f2lZaS1iwjQUZnq3QqFRvEyJDWDMzmTf3VY3KTliOpv7P+AG+dWU2E2PCuOfJHXxY5Fmppqe+v3JG4tn7rp+fQke3kw8OarnHn2ji96HtZbXkTo4nNEjr+2poblmUhqOxnS0lNSP6Oh1dTuqaO0iO7n+viLS4cF5++GKykqN58NldvLqrctDn3FJaQ2JUKFnJUWfvW5wZR1pcOG9rd49f0cTvI7XuNjat76vhuGxWMjFhQby+Z2TLPbXN/bdy9pYYFcrzDy1n+bR4/vHlffz3x2UDjjXGsLW0lhXTE865WCwiXDdvEp8cdtDQouUef6GJ30d2HHHVQpdPi7c4EjWWhQbZuX5+Kn89cHJEZ70O1MPfV1RoEE/dt4Tr56Xwb+8U8pN3C/vtOiqpbsLR2M7KGeef+NwwP5XObsOGg9ZuM6k+p4nfR7aX1RIRYmd+uvbvq+G5eVEarZ3dvDeCidLTxA+uX0a/umsRX1qWye8+KuPVfi4+95SmVkxPPO+x+emxpE8I18lcfkQTv49sK60ld0o8wXZ9S9Xw5E6eQPqEcF4bwe6eai8SP7iWbH70xrksmxrPD948QHltyzmPbymtJSM+nIz4iPOOdW0zmcKWkhpON3cMP3g1bJqlfKC6sY3D1U26Po/yCZtNuHlRGltKaqg+0zYir9Fzxp8Y5fmOYXab8Is7FmKzCd96cQ9d3a4lHbqdhu1ltazs52y/xxfmp9LlNLx7QMs9/kATvw9sLHQtRLVmpm6srnzjpkVpOA2s3zcySzg4GtuJiwj2ugMtLS6c/33TXHaX1/P4plIADhxvoLGtixUzBk78c1JjmJ0Sw68/PKwrdvoBTfw+8F7BSTLiw8mZFG11KGqcmJ4UxYL0WJ7bUU5+Zb3Pn/9Ck7cGc+PCNG5amMqvPjzM7vLTbCl11fcv9BeviPDjm+Zy4kwb//neoSG9rvIdTfzD1NjWyZaSWq6ePem8NU+UGo6vr53ByYY21v16C+t+/Skv7aygtaPbJ899oclbnvjRjXOZFBPGt1/cy8bCamZOjB70+S6aPIEvLcvkD1uPsL/S+wXglO9o4h+mjw456Oh2ctWcSVaHosaZq+ZMYsf3LudH6+bQ2tHNP7+az9J//4CfvFs47Jm91Y1tJA8j8ceGB/OL2xdQXtfCrmOnWdFPG2d//unqHBKiQvmX1/PPXiNQo08T/zC9V3CKhMgQ3WZRjYiYsGDuXTGF9769mpf+9mIumZHI7z4q46/DuEjad5P1oVo2LYG/u3Q6AJdcoL7fW2x4MD/8whwOHD/DM7o1o2U08Q9DR5eTTUXVXDFrInablnnUyBERlk6N59d3L2ZyQgRPfjrwLNrBNLV30dbpHHbiB/jOldk8/ZUlrJ2Z7PEx182bxNqZSfzne8Ucrx+9jWfU5zTxD8O2sloa27u4as5Eq0NRAcJuE+5bMYXd5fXsGeKG6N5M3hpMkN3G2pnJ2Lw48RFxzQkwBn7w5oFR239AfU4T/zC8V3CSiBD7OasRKjXSbsvNIDo0iKe2HB3S8Wcnb0X1v0DbaMiIj+DbV2bxQWE1G0Z5k3nlYeIXkWtEpFhESkTkkX4eDxWRF92P7xCRKe77p4hIq4jsdX/81rfhW8fpNLx/8BRrZibpbltqVEWFBnHn0gze2X+CqiGUSnrO+JNjhn/GPxxfXTmV7IlR/GZzqaVxBKJBE7+I2IHHgWuB2cBdIjK7z7D7gdPGmBnAL4HHej1WaoxZ6P542EdxW25vZT3Vje1cNVu7edTou3fFFIwxPLPtqNfHni31DLGP31eC7DZumJ9KfmUDNU3tlsYSaDw5418KlBhjyowxHcALwI19xtwIPOO+/QpwuYzzpvb3Ck4RZBPW5nh+UUspX0mfEMG1c1N4fke51zNhHU3tBNuF2PDgEYrOcz2z3T857DCX42wAABIfSURBVLA4ksDiSeJPAyp6fV7pvq/fMcaYLqAB6GnsnSoie0TkIxFZ1d8LiMhDIpInInkOh/9/AxhjeK/gJBdPT/CLHx4VmL56yVTOtHXx2u7BN0nprfpMO4lRoV5dkB0pc1NjSYwKYXOx///cjyeeJP7+vjv6XoYfaMwJINMYswj4DvBnEYk5b6AxTxhjco0xuUlJ/r/eTamjibKaZq6ard08yjqLM+NYkBHHU1uO4vRiQpejqX1Yk7d8yWYTVmcl8fEhxwUnpRWdPMPPNxTppC8fCfJgTCWQ0evzdKDvylE9YypFJAiIBeqMq0+rHcAYs0tESoFsIG+4gVtpQ4Fr/9Artb6vLCQi3H/JVL75/B42FVdz+SzPTkQcje2kxVnX0dPXpTOTeG3PcfIr61mU2f9EyF++f4gNBaeIDA3ia2tm+OR173v6M7aW1BIVFkR0WBBRoa6POamxfH3tdBIsvgYykjw5498JZInIVBEJAe4E1vcZsx641337VuBDY4wRkST3xWFEZBqQBQx95omfeK/gJAsy4pgU6z8/PCowXTt3EimxYTz56RGPj/HFrF1fWp2VhE0YsNzjaGxnY2E1ESF2fvn+IQpPnBn2a5bXtrC52MHF0xO4du4kFmbEMSkmDKf7gvman2/mdx+V0t7lm7WR/M2gid9ds/8GsAEoBF4yxhSIyKMiss497EkgQURKcJV0elo+VwP5IrIP10Xfh40xdb7+IkbTiYZW9lU2cLVO2lJ+INhu494VU9haWuvRBu1d3U5qm4e+MudImBAZwoKMODYf6j/xv7HnOF1Ow9P3LSE2PJjvvLSPjq7hlXzeyncVLf73TXP5t5vn8X/vXMST9y3h5YdXsOFbq8idMoGfvFvElb/4mHf3nxh3k8w86uM3xrxjjMk2xkw3xvyb+77vG2PWu2+3GWNuM8bMMMYsNcaUue9/1RgzxxizwBiz2Bjz1sh9KaPj5TzXhbRrdFE25SfuXpbJjOQoHngmj62lF07+dc0dGOObWbu+tCY7mfzKemr7tHUaY3gxr4JFmXEsm5bAT26ZT+GJM/xq4+Fhvd7b+SdYlBnX745hM5KjeforS3n2q0sJC7bxd8/t5qE/7hpXyV9n7nqhvaubZ7cd49LsJKYlRVkdjlKAayG3Fx5aTkZ8OF/9w04+PTxw8v98y0X/KlOumZmEMfBJn9h3l9dTUt3EHbmuy4xXzp7IrRel85vNJUNesqLU0UThiTPcMD/1guNWZyfxzjdXcd+KKbx/8NTZ92480MTvhfV7q6hpaueBVVOtDkWpcyRGhfL8g8uZkhDJ/c/s5KMByiaOJt+t0+NL89JiSYgMYXNx9Tn3v7SzgogQOzcs+DxJf/8Ls5kUE8Y/vryPtk7va/Bv7zuBCFw/L2XQsUF2G9e5xx2sGv61BX+hid9Dxhie/PQIMydGe7wErVKjKSEqlD8/uJzpSVE8+Gwem4qqzxtzdrkGP0v8NpuwOjuJjw/XnG1NbW7v4u38Kq6fl0JU6OcNiDFhwfzs1gWUOZr52V+LvX6tt/OrWDI53uPmjJwU1856B31wUdlfaOL30NbSWopONnL/JVN1py3lt+IjQ/jzg8vInhjF3/5xF2/uPX7O459vsu5fiR9c5Z665g7yj7t25/pL/gmaO7q5Y0nGeWMvyUrkyxdP5qktR/jP94rp9LC/v/hkI4erm7hhweBn+z1iwoLJiA/XxB+Invz0CIlRIaxbeOG6oFJWi4sI4bn7l7MgI5Z/eGEvP1xfcLYLxtHYTnRoEOEh/rew4KqsJEQ4W+55Ma+CaUmRA25y9K/XzeLWi9L5rw9LuPW32zha0zzoa7y1rwqbwLVzPU/8ALNTYnzSRuovNPF7oNTRxIdF1Xxp2WRdiVONCbERwfz5weXcf8lU/rD1KHc+sY0TDa2uHn6LV+UcSHxkCAvS49hc7KCkuoldx05ze27GgH9hhwXb+Y/bFvD43Ys54mjiul99wkt5FQN23xhjeDu/iounJ3h9jWNWSgxHappp6fBuXSR/pYnfA099eoSQIBv3LJ9sdShKeSzYbuN/3TCbx+9eTPHJRm741afsraj3qx7+vtbMTGJfZT1PfFyK3SbcsrjvsmDnu35+Cn/91mrmp8fyz6/k87XndtPQ2nneuIKqMxytbRm0m6c/s1NiMAaKTjZ6faw/0sQ/iNPNHby6u5KbFqb6XSeEUp64fn4K6//+EuIjQzhe3+rX38drZiZjDLyUV8llOckke9h2mhoXznMPLOeRa3N4/+Apbv+t6y+c3t7KryLIJkOagzM71bXE2Hgp92jiH8SfPyunrdPJ/ZdMszoUpYZselIUb3x9JX+3Zjp3Lc20OpwBzU+LJT4yBOBs776n7Dbh4Uun88xXl3K8vpVbfrOVYvcZujGGt/edYOWMRCa4n98baXHhxIQFjZuWTk38F9DR5eSZrUdZlZXIzEnRVoej1LBEhgbx3Wty/HqrUJtNuHLWRNLiws+u1e+tlTMSeelvL6bbabj1t1vZXlbLnop6jte3csN87y7q9hARZqXEjJvOHk9W5wxYb+w5TnVjO4/dOt/qUJQKGD+6cQ5tnd0E2Yd+Xjo7NYbXvraC+57eyZef/Iy5aTGE2G1cNYylVmanxvDizgq6nQa7H+xlMBx6xj+AhpZOHvtrEQsy4rg0y//3CFBqvAgLthMX4X05pq/0CRG88vDFLMiIZXd5Pauzk4a1cdKslBhaOro5Vjt426i/0zP+ATy2oYjTLR08e/9Sv9ipSCnlvbiIEP54/zJ+s7mUa+cOb2HF2SmuC7wHT5wZ82t16Rl/P3YdO82fd5TzlZVTmZMaa3U4SqlhCAu2850rs5mVct7mf17JmhhFkE3GRWePJv4+urqdfO/1/aTEhvHtK7OtDkcp5SdCg+zMSI4aF509mvj7eHrLUYpONvKDL8w5Z2EopZSaPU46ezTx93K8vpVffnCIy3OSdYctpdR5ZqXEcOpM+3kbxow1mvh7+dH6ApzG8MN1c3QFTqXUeT6fwTu2l27QxO+2oeAk7x08xT9cnt3vdmxKKTXrbGdPg8WRDI8mflxdPN9+cS+zU2J0dy2l1IDiI0OYFBOmZ/xjXUFVA/c9/RnJ0aH84StLCB7GbEGl1Pg3OzVmzHf2BHSWK6lu4stPfkZ0aBB/emAZyTH+tQG1Usr/zE6JocTRNKT9fv1FwCb+iroW7vn9DkSEPz2wjPQJWtdXSg1uVkoM3U5DSXWT1aEMWUAm/pMNbdz9++20dnbzpweWjvnp10qp0dPT2TOWyz0BNUPpwPEGXthZzpt7qjDAcw8sI2fS8KZxK6UCy+T4CCJC7GN6Ite4T/xn2jpZv7eKF3aWc+D4GUKDbFw3L4UHV007+5tbKaU8ZbMJOZOiNfH7i4aWTgqqGjhQ1UBB1RkOHG+grKYZYyBnUjQ/WjeHmxamERsx9KVZlVJqdmoMb+6twhgzJid7jpvEX3m6hUse23T289TYMGanxnLD/FTW5iSzID12TP4HKaX8z5zUWP60vZzd5ae5aHK81eF4bdwk/rS4cP71uhxyJsUwJzWGhCj/3VBaKTW2XT8/hf/aeJh/eiWfd765irBgu9UheWXcdPWICA+tns7q7CRN+kqpERUTFszPb1tAmaOZn75bZHU4Xhs3iV8ppUbTyhmJ3LdiCn/YepQtJTVWh+MVTfxKKTVE370mh2lJkfyPl/fR0NppdTge08SvlFJDFB5i55e3L6S6sZ0frS+wOhyPaeJXSqlhWJARxzfWzuC1Pcd5d/8Jq8PxiEeJX0SuEZFiESkRkUf6eTxURF50P75DRKb0euxf3PcXi8jVvgtdKaX8wzcum8H89Fj+9fX9rN9XRUOLf5d9Bm3nFBE78DhwJVAJ7BSR9caYg72G3Q+cNsbMEJE7gceAO0RkNnAnMAdIBT4QkWxjzNhd1k4ppfoIttv4xe0Luef3O/jm83uw24SLJk/g8pxkLstJJiM+gtAgm9/MJRJjzIUHiFwM/NAYc7X7838BMMb8pNeYDe4x20QkCDgJJAGP9B7be9xAr5ebm2vy8vKG9UUppZQVup2GfZX1fFhYzcaiagp7LetgE4gMCSI8xE5kaBB2m9CTf3uy8KyUGB6/e/GQXltEdhljcj0Z68kErjSgotfnlcCygcYYY7pEpAFIcN+/vc+xaf0E/BDwEEBmZqYncSullN+x24TFmRNYnDmB/3H1TKrqW/nksIOapg5aOrpo6eimtaOb5o5unE53upfP/5mSEDkqcXqS+Pv726TvnwkDjfHkWIwxTwBPgOuM34OYlFLK76XGhXPHEv87mfXk4m4lkNHr83SgaqAx7lJPLFDn4bFKKaVGkSeJfyeQJSJTRSQE18Xa9X3GrAfudd++FfjQuIpX64E73V0/U4Es4DPfhK6UUmooBi31uGv23wA2AHbgKWNMgYg8CuQZY9YDTwJ/FJESXGf6d7qPLRCRl4CDQBfwde3oUUopaw3a1TPatKtHKaW8501Xj87cVUqpAKOJXymlAowmfqWUCjCa+JVSKsD43cVdEXEAx0bp5RIBf9xBQePyjsblPX+NTePyTu+4Jhtjkjw5yO8S/2gSkTxPr4KPJo3LOxqX9/w1No3LO0ONS0s9SikVYDTxK6VUgAn0xP+E1QEMQOPyjsblPX+NTePyzpDiCugav1JKBaJAP+NXSqmAo4lfKaUCTEAlfhG5TUQKRMQpIgO2QA22ufwIxBUvIu+LyGH3vxMGGNctInvdH32XxvZlPBf8+t3LbL/ofnyHiEwZqVi8jOs+EXH0eo8eGKW4nhKRahE5MMDjIiK/csedLyJD21vP93GtEZGGXu/X90chpgwR2SQihe6fxX/oZ8yov18exmXF+xUmIp+JyD53XD/qZ4z3P4/GmID5AGYBM4HNQO4AY+xAKTANCAH2AbNHOK6fAY+4bz8CPDbAuKZReI8G/fqBrwG/dd++E3jRT+K6D/i1Bd9Xq4HFwIEBHr8OeBfXjnTLgR1+Etca4O1Rfq9SgMXu29HAoX7+H0f9/fIwLiveLwGi3LeDgR3A8j5jvP55DKgzfmNMoTGmeJBhS4ESY0yZMaYDeAG4cYRDuxF4xn37GeCmEX69C/Hk6+8d7yvA5SLS3zabox2XJYwxH+Pah2IgNwLPGpftQJyIpPhBXKPOGHPCGLPbfbsRKOT8fbhH/f3yMK5R534PmtyfBrs/+nbkeP3zGFCJ30P9bS4/0t8AE40xJ8D1DQgkDzAuTETyRGS7iIzULwdPvv6zY4wxXUADkDBC8XgTF8AX3eWBV0Qko5/HrWDF95SnLnaXEd4VkTmj+cLuksQiXGexvVn6fl0gLrDg/RIRu4jsBaqB940xA75fnv48erLZ+pgiIh8Ak/p56HvGmDc9eYp+7ht2z+uF4vLiaTKNMVUiMg34UET2G2NKhxtbH558/SPyHg3Ck9d8C3jeGNMuIg/jOgu6bITj8oQV75cnduNa36VJRK4D3sC1PeqIE5Eo4FXgW8aYM30f7ueQUXm/BonLkvfLuHYtXCgiccDrIjLXGNP7uo3X79e4S/zGmCuG+RQjskH8heISkVMikmKMOeH+k7Z6gOeocv9bJiKbcZ2V+Drxe/L194ypFJEgIJaRLykMGpcxprbXp/8NPDbCMXlqRL6nhqt3YjPGvCMivxGRRGPMiC5GJiLBuJLrc8aY1/oZYsn7NVhcVr1fvV6z3v1zfw3QO/F7/fOopZ7zebK5vK/13qz+XuC8v0xEZIKIhLpvJwIrce1l7GuefP29470V+NC4ryyNoEHj6lMHXoerTusP1gNfdnerLAcaekp7VhKRST21YBFZiisf1F74qGG/puDao7vQGPOLAYaN+vvlSVwWvV9J7jN9RCQcuAIo6jPM+5/H0bxCbfUHcDOu347twClgg/v+VOCdXuOuw3VVvxRXiWik40oANgKH3f/Gu+/PBX7vvr0C2I+rm2U/cP8IxnPe1w88Cqxz3w4DXgZKgM+AaaP0/zdYXD8BCtzv0SYgZ5Tieh44AXS6v7/uBx4GHnY/LsDj7rj3M0BHmQVxfaPX+7UdWDEKMV2CqwyRD+x1f1xn9fvlYVxWvF/zgT3uuA4A3+/n+97rn0ddskEppQKMlnqUUirAaOJXSqkAo4lfKaUCjCZ+pZQKMJr4lVIqwGjiV0qpAKOJXymlAsz/B6l40sM2ARxKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_md[['pos_idx1','pred_any']].groupby('pos_idx1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.exp(np.log(preds).mean((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = 1 / (1 + np.exp(-(np.log(preds/(1-preds)).mean((0,1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13211, 0.00537, 0.04281, 0.03049, 0.04686, 0.05557])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1280228 , 0.00678272, 0.04317398, 0.03195811, 0.04593468,\n",
       "       0.05528003], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = np.array([a + '_' + b for a in test_md.SOPInstanceUID for b in all_ich])\n",
    "sub = pd.DataFrame({'ID': id_column, 'Label': predictions.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13210989216026986"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1281835436820984"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission_061.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13475628267250275"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = best_sub.Label.values.reshape((-1,6))\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(i, 'inconsistencies:', (vals[:,0] < vals[:,i]).sum())\n",
    "print('total', (vals[:,0] < vals[:,1:].max(1)).sum())\n",
    "\n",
    "max_vals = vals[:,1:].max(1)\n",
    "\n",
    "mask = vals[:,0] < max_vals\n",
    "\n",
    "mask_vals = 0.5*(vals[:,0] + max_vals)[mask]\n",
    "\n",
    "vals[mask,0] = mask_vals\n",
    "\n",
    "vals[mask,1:] = np.clip(vals[mask,1:],0,np.expand_dims(mask_vals,1))\n",
    "\n",
    "assert (vals[:,0] < vals[:,1:].max(1)).sum() == 0\n",
    "\n",
    "best_sub.Label = vals.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936759406170499"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944464662920349"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 20.8M/20.8M [00:05<00:00, 4.35MB/s]\n",
      "Successfully submitted to RSNA Intracranial Hemorrhage Detection"
     ]
    }
   ],
   "source": [
    "!~/.local/bin/kaggle competitions submit rsna-intracranial-hemorrhage-detection -f ~/sub.csv -m \"GCP, d161+d169+d201+s101, 8TTA, 3folds, ensemble, - sanity check\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/bin/kaggle\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/kaggle/cli.py\", line 51, in main\r\n",
      "    out = args.func(**command_args)\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/kaggle/api/kaggle_api_extended.py\", line 545, in competition_submit_cli\r\n",
      "    competition, quiet)\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/kaggle/api/kaggle_api_extended.py\", line 496, in competition_submit\r\n",
      "    content_length=os.path.getsize(file_name),\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/genericpath.py\", line 50, in getsize\r\n",
      "    return os.stat(filename).st_size\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:/StudioProjects/Hemorrhage/sub.csv'\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit rsna-intracranial-hemorrhage-detection -f C:/StudioProjects/Hemorrhage/sub.csv -m \"TPU, d161+d169+d201+s101, 32TTA, 3folds, mean/ensemble/mean \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
