{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 29\n",
    "CLOUD_SINGLE = True\n",
    "DATA_SMALL = False\n",
    "FOCAL_LOSS = 0\n",
    "WEIGHTED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_md' not in globals() or 'test_md' not in globals():\n",
    "    train_md, test_md = loadMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 8\n",
      "DataSet 6 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.251 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.684 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.887 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.492 time per batch: 0.167\n",
      "ver 20, iter 0, fold 0, val ll: 0.0652, cor: 0.8369, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.774 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.199 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.364 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.939 time per batch: 0.170\n",
      "ver 20, iter 1, fold 0, val ll: 0.0653, cor: 0.8367, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.355 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.519 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.645 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.213 time per batch: 0.166\n",
      "ver 20, iter 2, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.344 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.736 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.872 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.430 time per batch: 0.167\n",
      "ver 20, iter 3, fold 0, val ll: 0.0651, cor: 0.8372, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.551 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.750 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.862 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.307 time per batch: 0.167\n",
      "ver 20, iter 4, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.302 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.230 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.349 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.712 time per batch: 0.164\n",
      "ver 20, iter 5, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.102 time per batch: 0.182\n",
      "Batch 100 device: cuda time passed: 17.201 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.285 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.890 time per batch: 0.164\n",
      "ver 20, iter 6, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.418 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.334 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.479 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.093 time per batch: 0.165\n",
      "ver 20, iter 7, fold 0, val ll: 0.0653, cor: 0.8367, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.383 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.579 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.703 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.245 time per batch: 0.166\n",
      "ver 20, iter 8, fold 0, val ll: 0.0653, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.637 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.959 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 25.966 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.442 time per batch: 0.167\n",
      "ver 20, iter 9, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.430 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.502 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.472 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.034 time per batch: 0.165\n",
      "ver 20, iter 10, fold 0, val ll: 0.0653, cor: 0.8371, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.338 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.695 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.765 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.408 time per batch: 0.167\n",
      "ver 20, iter 11, fold 0, val ll: 0.0652, cor: 0.8369, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.432 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.517 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.683 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.226 time per batch: 0.166\n",
      "ver 20, iter 12, fold 0, val ll: 0.0654, cor: 0.8366, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.586 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.818 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.856 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.451 time per batch: 0.167\n",
      "ver 20, iter 13, fold 0, val ll: 0.0653, cor: 0.8366, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.274 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.561 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.636 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.249 time per batch: 0.166\n",
      "ver 20, iter 14, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.238 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.549 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.718 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.236 time per batch: 0.166\n",
      "ver 20, iter 15, fold 0, val ll: 0.0651, cor: 0.8372, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.260 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.638 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.714 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.160 time per batch: 0.166\n",
      "ver 20, iter 16, fold 0, val ll: 0.0652, cor: 0.8372, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.193 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.419 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.493 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.010 time per batch: 0.165\n",
      "ver 20, iter 17, fold 0, val ll: 0.0654, cor: 0.8363, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.180 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.568 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.479 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.926 time per batch: 0.165\n",
      "ver 20, iter 18, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.240 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.413 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.334 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 32.913 time per batch: 0.165\n",
      "ver 20, iter 19, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.441 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.397 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.486 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.925 time per batch: 0.165\n",
      "ver 20, iter 20, fold 0, val ll: 0.0653, cor: 0.8370, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.684 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.005 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 25.952 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.417 time per batch: 0.167\n",
      "ver 20, iter 21, fold 0, val ll: 0.0653, cor: 0.8366, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.294 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.585 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.570 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.949 time per batch: 0.165\n",
      "ver 20, iter 22, fold 0, val ll: 0.0652, cor: 0.8368, auc: 0.9875\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 9.196 time per batch: 0.184\n",
      "Batch 100 device: cuda time passed: 17.184 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.240 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.760 time per batch: 0.164\n",
      "ver 20, iter 23, fold 0, val ll: 0.0651, cor: 0.8373, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.508 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.648 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.758 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.134 time per batch: 0.166\n",
      "ver 20, iter 24, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.499 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.678 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.733 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.205 time per batch: 0.166\n",
      "ver 20, iter 25, fold 0, val ll: 0.0653, cor: 0.8370, auc: 0.9874\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.526 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.573 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.499 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.782 time per batch: 0.164\n",
      "ver 20, iter 26, fold 0, val ll: 0.0653, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.409 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.376 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.526 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.891 time per batch: 0.164\n",
      "ver 20, iter 27, fold 0, val ll: 0.0652, cor: 0.8371, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.272 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.223 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.454 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 32.992 time per batch: 0.165\n",
      "ver 20, iter 28, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.541 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.596 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.655 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.114 time per batch: 0.166\n",
      "ver 20, iter 29, fold 0, val ll: 0.0652, cor: 0.8370, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.300 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.218 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.224 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.796 time per batch: 0.164\n",
      "ver 20, iter 30, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9875\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 8.999 time per batch: 0.180\n",
      "Batch 100 device: cuda time passed: 16.921 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 24.872 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.632 time per batch: 0.163\n",
      "ver 20, iter 31, fold 0, val ll: 0.0654, cor: 0.8365, auc: 0.9874\n",
      "total running time 1218.9592831134796\n",
      "total time 1219.3914034366608\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 12\n",
      "DataSet 6 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.472 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.586 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.829 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.627 time per batch: 0.168\n",
      "ver 20, iter 0, fold 1, val ll: 0.0630, cor: 0.8385, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.399 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.682 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.873 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.625 time per batch: 0.168\n",
      "ver 20, iter 1, fold 1, val ll: 0.0632, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.411 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.526 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.673 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.697 time per batch: 0.168\n",
      "ver 20, iter 2, fold 1, val ll: 0.0632, cor: 0.8385, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.652 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.778 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.979 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.770 time per batch: 0.169\n",
      "ver 20, iter 3, fold 1, val ll: 0.0630, cor: 0.8389, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.441 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.605 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.733 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.719 time per batch: 0.169\n",
      "ver 20, iter 4, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.710 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.774 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.998 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.721 time per batch: 0.169\n",
      "ver 20, iter 5, fold 1, val ll: 0.0631, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.782 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 17.953 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.219 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.719 time per batch: 0.169\n",
      "ver 20, iter 6, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.445 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.798 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.014 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.930 time per batch: 0.170\n",
      "ver 20, iter 7, fold 1, val ll: 0.0629, cor: 0.8391, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.564 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.843 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.013 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.915 time per batch: 0.170\n",
      "ver 20, iter 8, fold 1, val ll: 0.0631, cor: 0.8385, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.536 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.793 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.952 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.873 time per batch: 0.169\n",
      "ver 20, iter 9, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.592 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.804 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.982 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.637 time per batch: 0.168\n",
      "ver 20, iter 10, fold 1, val ll: 0.0631, cor: 0.8383, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.511 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.663 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.716 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.278 time per batch: 0.166\n",
      "ver 20, iter 11, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.348 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.330 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.205 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.558 time per batch: 0.163\n",
      "ver 20, iter 12, fold 1, val ll: 0.0630, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.044 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 16.831 time per batch: 0.168\n",
      "Batch 150 device: cuda time passed: 24.853 time per batch: 0.166\n",
      "Batch 200 device: cuda time passed: 32.686 time per batch: 0.163\n",
      "ver 20, iter 13, fold 1, val ll: 0.0629, cor: 0.8387, auc: 0.9880\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 9.573 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.772 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.785 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.333 time per batch: 0.167\n",
      "ver 20, iter 14, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.414 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.624 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.622 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.411 time per batch: 0.167\n",
      "ver 20, iter 15, fold 1, val ll: 0.0629, cor: 0.8387, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.614 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.852 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 25.977 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.525 time per batch: 0.168\n",
      "ver 20, iter 16, fold 1, val ll: 0.0630, cor: 0.8387, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.289 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.579 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.473 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.211 time per batch: 0.166\n",
      "ver 20, iter 17, fold 1, val ll: 0.0630, cor: 0.8385, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.233 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.399 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.367 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.006 time per batch: 0.165\n",
      "ver 20, iter 18, fold 1, val ll: 0.0629, cor: 0.8390, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.297 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.196 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.168 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 33.141 time per batch: 0.166\n",
      "ver 20, iter 19, fold 1, val ll: 0.0631, cor: 0.8384, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.354 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.256 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.306 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.014 time per batch: 0.165\n",
      "ver 20, iter 20, fold 1, val ll: 0.0631, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.511 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.620 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.739 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.378 time per batch: 0.167\n",
      "ver 20, iter 21, fold 1, val ll: 0.0629, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.331 time per batch: 0.187\n",
      "Batch 100 device: cuda time passed: 17.721 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.804 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.593 time per batch: 0.168\n",
      "ver 20, iter 22, fold 1, val ll: 0.0630, cor: 0.8387, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.520 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.638 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.765 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.460 time per batch: 0.167\n",
      "ver 20, iter 23, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.283 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.253 time per batch: 0.173\n",
      "Batch 150 device: cuda time passed: 25.434 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.171 time per batch: 0.166\n",
      "ver 20, iter 24, fold 1, val ll: 0.0631, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.432 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.466 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.479 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.261 time per batch: 0.166\n",
      "ver 20, iter 25, fold 1, val ll: 0.0631, cor: 0.8388, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.474 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.557 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.792 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.380 time per batch: 0.167\n",
      "ver 20, iter 26, fold 1, val ll: 0.0628, cor: 0.8390, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.441 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.634 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.656 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.294 time per batch: 0.166\n",
      "ver 20, iter 27, fold 1, val ll: 0.0631, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.126 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.402 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.423 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.005 time per batch: 0.165\n",
      "ver 20, iter 28, fold 1, val ll: 0.0630, cor: 0.8388, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.244 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.208 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.175 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.990 time per batch: 0.165\n",
      "ver 20, iter 29, fold 1, val ll: 0.0631, cor: 0.8382, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.493 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.573 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.797 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.703 time per batch: 0.169\n",
      "ver 20, iter 30, fold 1, val ll: 0.0628, cor: 0.8389, auc: 0.9880\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.231 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.492 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.469 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.097 time per batch: 0.165\n",
      "ver 20, iter 31, fold 1, val ll: 0.0629, cor: 0.8391, auc: 0.9880\n",
      "total running time 1227.9004607200623\n",
      "total time 2447.71595287323\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 2\n",
      "DataSet 6 valid size 6496 fold 2\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f2.d6.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.034 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 16.871 time per batch: 0.169\n",
      "Batch 150 device: cuda time passed: 25.266 time per batch: 0.168\n",
      "Batch 200 device: cuda time passed: 32.781 time per batch: 0.164\n",
      "ver 20, iter 0, fold 2, val ll: 0.0617, cor: 0.8393, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.265 time per batch: 0.185\n",
      "Batch 100 device: cuda time passed: 17.517 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.429 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.098 time per batch: 0.165\n",
      "ver 20, iter 1, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.439 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.625 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.803 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.287 time per batch: 0.166\n",
      "ver 20, iter 2, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.421 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.544 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.551 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.322 time per batch: 0.167\n",
      "ver 20, iter 3, fold 2, val ll: 0.0616, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.528 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.523 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.685 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.238 time per batch: 0.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver 20, iter 4, fold 2, val ll: 0.0615, cor: 0.8392, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.556 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.616 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.900 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.558 time per batch: 0.168\n",
      "ver 20, iter 5, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.495 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.533 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.709 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.233 time per batch: 0.166\n",
      "ver 20, iter 6, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.564 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.797 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.088 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.611 time per batch: 0.168\n",
      "ver 20, iter 7, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.310 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.583 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.731 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.132 time per batch: 0.166\n",
      "ver 20, iter 8, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.639 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.851 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.260 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.847 time per batch: 0.169\n",
      "ver 20, iter 9, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.658 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.953 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.318 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.023 time per batch: 0.170\n",
      "ver 20, iter 10, fold 2, val ll: 0.0617, cor: 0.8393, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.627 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.802 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.785 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.192 time per batch: 0.166\n",
      "ver 20, iter 11, fold 2, val ll: 0.0617, cor: 0.8390, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.528 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.731 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.932 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.206 time per batch: 0.166\n",
      "ver 20, iter 12, fold 2, val ll: 0.0617, cor: 0.8392, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.541 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.846 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.977 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.694 time per batch: 0.168\n",
      "ver 20, iter 13, fold 2, val ll: 0.0616, cor: 0.8394, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.692 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.922 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.089 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.662 time per batch: 0.168\n",
      "ver 20, iter 14, fold 2, val ll: 0.0618, cor: 0.8387, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.701 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.007 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.176 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.645 time per batch: 0.168\n",
      "ver 20, iter 15, fold 2, val ll: 0.0616, cor: 0.8395, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.311 time per batch: 0.186\n",
      "Batch 100 device: cuda time passed: 17.462 time per batch: 0.175\n",
      "Batch 150 device: cuda time passed: 25.605 time per batch: 0.171\n",
      "Batch 200 device: cuda time passed: 33.285 time per batch: 0.166\n",
      "ver 20, iter 16, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.592 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.796 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.054 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.540 time per batch: 0.168\n",
      "ver 20, iter 17, fold 2, val ll: 0.0616, cor: 0.8394, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.762 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 17.975 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.201 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.661 time per batch: 0.168\n",
      "ver 20, iter 18, fold 2, val ll: 0.0618, cor: 0.8390, auc: 0.9888\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.731 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 17.970 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.170 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.667 time per batch: 0.168\n",
      "ver 20, iter 19, fold 2, val ll: 0.0614, cor: 0.8397, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.424 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.738 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.917 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.730 time per batch: 0.169\n",
      "ver 20, iter 20, fold 2, val ll: 0.0616, cor: 0.8396, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.904 time per batch: 0.198\n",
      "Batch 100 device: cuda time passed: 18.114 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.117 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.686 time per batch: 0.168\n",
      "ver 20, iter 21, fold 2, val ll: 0.0617, cor: 0.8391, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.538 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.840 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.961 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.769 time per batch: 0.169\n",
      "ver 20, iter 22, fold 2, val ll: 0.0615, cor: 0.8394, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.576 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 18.019 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.307 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.011 time per batch: 0.170\n",
      "ver 20, iter 23, fold 2, val ll: 0.0618, cor: 0.8390, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.476 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.960 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.229 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.853 time per batch: 0.169\n",
      "ver 20, iter 24, fold 2, val ll: 0.0616, cor: 0.8396, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.509 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.863 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.212 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.073 time per batch: 0.170\n",
      "ver 20, iter 25, fold 2, val ll: 0.0616, cor: 0.8394, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.684 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.038 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.284 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.998 time per batch: 0.170\n",
      "ver 20, iter 26, fold 2, val ll: 0.0616, cor: 0.8393, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.736 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.179 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.444 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.115 time per batch: 0.171\n",
      "ver 20, iter 27, fold 2, val ll: 0.0616, cor: 0.8395, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.703 time per batch: 0.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 device: cuda time passed: 18.071 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.339 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.948 time per batch: 0.170\n",
      "ver 20, iter 28, fold 2, val ll: 0.0616, cor: 0.8395, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.508 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.596 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.773 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.248 time per batch: 0.166\n",
      "ver 20, iter 29, fold 2, val ll: 0.0615, cor: 0.8395, auc: 0.9890\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.158 time per batch: 0.183\n",
      "Batch 100 device: cuda time passed: 17.364 time per batch: 0.174\n",
      "Batch 150 device: cuda time passed: 25.482 time per batch: 0.170\n",
      "Batch 200 device: cuda time passed: 33.060 time per batch: 0.165\n",
      "ver 20, iter 30, fold 2, val ll: 0.0615, cor: 0.8396, auc: 0.9889\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.074 time per batch: 0.181\n",
      "Batch 100 device: cuda time passed: 17.194 time per batch: 0.172\n",
      "Batch 150 device: cuda time passed: 25.425 time per batch: 0.169\n",
      "Batch 200 device: cuda time passed: 33.180 time per batch: 0.166\n",
      "ver 20, iter 31, fold 2, val ll: 0.0617, cor: 0.8394, auc: 0.9889\n",
      "total running time 1230.425933599472\n",
      "total time 3678.56298661232\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 8\n",
      "DataSet 7 valid size 6496 fold 0\n",
      "dataset valid: 6496 loader valid: 203\n",
      "loading model model.b10.f0.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.800 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 18.191 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.306 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.063 time per batch: 0.170\n",
      "ver 20, iter 0, fold 0, val ll: 0.0641, cor: 0.8415, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.975 time per batch: 0.199\n",
      "Batch 100 device: cuda time passed: 18.525 time per batch: 0.185\n",
      "Batch 150 device: cuda time passed: 26.775 time per batch: 0.179\n",
      "Batch 200 device: cuda time passed: 34.304 time per batch: 0.172\n",
      "ver 20, iter 1, fold 0, val ll: 0.0643, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.894 time per batch: 0.198\n",
      "Batch 100 device: cuda time passed: 18.210 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.467 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.336 time per batch: 0.172\n",
      "ver 20, iter 2, fold 0, val ll: 0.0642, cor: 0.8413, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.682 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.883 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.277 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.114 time per batch: 0.171\n",
      "ver 20, iter 3, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.680 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.014 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.248 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.090 time per batch: 0.170\n",
      "ver 20, iter 4, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.564 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.802 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.101 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 34.015 time per batch: 0.170\n",
      "ver 20, iter 5, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.622 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.821 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 26.109 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.918 time per batch: 0.170\n",
      "ver 20, iter 6, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.598 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.993 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.379 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.084 time per batch: 0.170\n",
      "ver 20, iter 7, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.732 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.102 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.585 time per batch: 0.177\n",
      "Batch 200 device: cuda time passed: 34.387 time per batch: 0.172\n",
      "ver 20, iter 8, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9877\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.689 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.015 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.254 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.118 time per batch: 0.171\n",
      "ver 20, iter 9, fold 0, val ll: 0.0643, cor: 0.8412, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.716 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.039 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.324 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.049 time per batch: 0.170\n",
      "ver 20, iter 10, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.718 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.196 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.347 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.970 time per batch: 0.170\n",
      "ver 20, iter 11, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.482 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.616 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.755 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.597 time per batch: 0.168\n",
      "ver 20, iter 12, fold 0, val ll: 0.0643, cor: 0.8408, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.575 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.747 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.956 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.840 time per batch: 0.169\n",
      "ver 20, iter 13, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.716 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.030 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.166 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.965 time per batch: 0.170\n",
      "ver 20, iter 14, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.563 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.794 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.982 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.846 time per batch: 0.169\n",
      "ver 20, iter 15, fold 0, val ll: 0.0642, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.454 time per batch: 0.189\n",
      "Batch 100 device: cuda time passed: 17.607 time per batch: 0.176\n",
      "Batch 150 device: cuda time passed: 25.773 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.512 time per batch: 0.168\n",
      "ver 20, iter 16, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.495 time per batch: 0.190\n",
      "Batch 100 device: cuda time passed: 17.842 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.975 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.724 time per batch: 0.169\n",
      "ver 20, iter 17, fold 0, val ll: 0.0641, cor: 0.8417, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.628 time per batch: 0.193\n",
      "Batch 100 device: cuda time passed: 17.903 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.128 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.688 time per batch: 0.168\n",
      "ver 20, iter 18, fold 0, val ll: 0.0643, cor: 0.8410, auc: 0.9878\n",
      "setFeats, augmentation -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50 device: cuda time passed: 9.682 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 17.865 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.045 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.835 time per batch: 0.169\n",
      "ver 20, iter 19, fold 0, val ll: 0.0643, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.536 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.871 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.092 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.896 time per batch: 0.169\n",
      "ver 20, iter 20, fold 0, val ll: 0.0642, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 11.001 time per batch: 0.220\n",
      "Batch 100 device: cuda time passed: 21.225 time per batch: 0.212\n",
      "Batch 150 device: cuda time passed: 31.302 time per batch: 0.209\n",
      "Batch 200 device: cuda time passed: 39.301 time per batch: 0.197\n",
      "ver 20, iter 21, fold 0, val ll: 0.0642, cor: 0.8412, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.747 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.031 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.391 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.143 time per batch: 0.171\n",
      "ver 20, iter 22, fold 0, val ll: 0.0644, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.588 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.957 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.221 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 33.979 time per batch: 0.170\n",
      "ver 20, iter 23, fold 0, val ll: 0.0642, cor: 0.8410, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.530 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.892 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.008 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.786 time per batch: 0.169\n",
      "ver 20, iter 24, fold 0, val ll: 0.0641, cor: 0.8413, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.809 time per batch: 0.196\n",
      "Batch 100 device: cuda time passed: 18.105 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.392 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.946 time per batch: 0.170\n",
      "ver 20, iter 25, fold 0, val ll: 0.0643, cor: 0.8409, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.610 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.969 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.231 time per batch: 0.175\n",
      "Batch 200 device: cuda time passed: 34.062 time per batch: 0.170\n",
      "ver 20, iter 26, fold 0, val ll: 0.0643, cor: 0.8412, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.603 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.993 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.352 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 33.977 time per batch: 0.170\n",
      "ver 20, iter 27, fold 0, val ll: 0.0642, cor: 0.8414, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.413 time per batch: 0.188\n",
      "Batch 100 device: cuda time passed: 17.670 time per batch: 0.177\n",
      "Batch 150 device: cuda time passed: 25.871 time per batch: 0.172\n",
      "Batch 200 device: cuda time passed: 33.612 time per batch: 0.168\n",
      "ver 20, iter 28, fold 0, val ll: 0.0641, cor: 0.8414, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.545 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 18.044 time per batch: 0.180\n",
      "Batch 150 device: cuda time passed: 26.073 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.876 time per batch: 0.169\n",
      "ver 20, iter 29, fold 0, val ll: 0.0642, cor: 0.8411, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.537 time per batch: 0.191\n",
      "Batch 100 device: cuda time passed: 17.802 time per batch: 0.178\n",
      "Batch 150 device: cuda time passed: 25.952 time per batch: 0.173\n",
      "Batch 200 device: cuda time passed: 33.729 time per batch: 0.169\n",
      "ver 20, iter 30, fold 0, val ll: 0.0644, cor: 0.8407, auc: 0.9878\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.579 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 17.852 time per batch: 0.179\n",
      "Batch 150 device: cuda time passed: 26.092 time per batch: 0.174\n",
      "Batch 200 device: cuda time passed: 33.973 time per batch: 0.170\n",
      "ver 20, iter 31, fold 0, val ll: 0.0641, cor: 0.8413, auc: 0.9879\n",
      "total running time 1369.0706129074097\n",
      "total time 5048.076225280762\n",
      "completed epochs: 10 iters starting now: 32\n",
      "adding dummy serieses 12\n",
      "DataSet 7 valid size 6560 fold 1\n",
      "dataset valid: 6560 loader valid: 205\n",
      "loading model model.b10.f1.d7.v20\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.763 time per batch: 0.195\n",
      "Batch 100 device: cuda time passed: 18.488 time per batch: 0.185\n",
      "Batch 150 device: cuda time passed: 27.071 time per batch: 0.180\n",
      "Batch 200 device: cuda time passed: 35.181 time per batch: 0.176\n",
      "ver 20, iter 0, fold 1, val ll: 0.0635, cor: 0.8379, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.705 time per batch: 0.194\n",
      "Batch 100 device: cuda time passed: 18.102 time per batch: 0.181\n",
      "Batch 150 device: cuda time passed: 26.400 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.394 time per batch: 0.172\n",
      "ver 20, iter 1, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.928 time per batch: 0.199\n",
      "Batch 100 device: cuda time passed: 18.463 time per batch: 0.185\n",
      "Batch 150 device: cuda time passed: 26.698 time per batch: 0.178\n",
      "Batch 200 device: cuda time passed: 34.803 time per batch: 0.174\n",
      "ver 20, iter 2, fold 1, val ll: 0.0634, cor: 0.8383, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.616 time per batch: 0.192\n",
      "Batch 100 device: cuda time passed: 18.181 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.339 time per batch: 0.176\n",
      "Batch 200 device: cuda time passed: 34.287 time per batch: 0.171\n",
      "ver 20, iter 3, fold 1, val ll: 0.0633, cor: 0.8386, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.846 time per batch: 0.197\n",
      "Batch 100 device: cuda time passed: 18.220 time per batch: 0.182\n",
      "Batch 150 device: cuda time passed: 26.636 time per batch: 0.178\n",
      "Batch 200 device: cuda time passed: 34.585 time per batch: 0.173\n",
      "ver 20, iter 4, fold 1, val ll: 0.0634, cor: 0.8384, auc: 0.9879\n",
      "setFeats, augmentation -1\n",
      "Batch 50 device: cuda time passed: 9.754 time per batch: 0.195\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for ds in range(6,10):\n",
    "    for fold in range(3):\n",
    "        predictions = oof_one(num_iter=32, bs=32, fold=fold, dataset=ds)\n",
    "        pickle.dump(predictions, open(PATH_DISK/'ensemble/oof_d{}_f{}_v{}'.format(ds, fold, VERSION),'wb'))\n",
    "        print('total time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.231111111111111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total running time 1201.68962931633\n",
    "#total time 15020.348212480545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between models\n",
    "# scores per slice\n",
    "# what is the best way to agg oof, model\\run levels\n",
    "# best aggregation theoretically\n",
    "# distribution of oof preds\n",
    "# score - what uniform p will get\n",
    "# 0.5 + np.sign(x-0.5) *2*(x-0.5)**2 - makes it less aggressive, is it a good transform above mean?\n",
    "# does scaling help for single runs, or is it aggregation artifact.\n",
    "\n",
    "# s101 problem.\n",
    "    # maybe 8 and 32 behave differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting runs aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbd70c0e8d0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(101)/100\n",
    "plt.plot(scalePreds(x, center=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "mean    [0.06429 0.06347 0.06388 0.06304] [0.03816 0.03822 0.0384  0.03748]\n",
      "gmean   [0.06444 0.06361 0.06411 0.06326] [0.03824 0.03834 0.03854 0.03766]\n",
      "q50     [0.06454 0.06372 0.06428 0.06335] [0.03833 0.03843 0.03866 0.03772]\n",
      "q25     [0.06518 0.06432 0.06533 0.06426] [0.03866 0.0388  0.03924 0.0383 ]\n",
      "q75     [0.0646  0.06367 0.06456 0.06314] [0.03832 0.03838 0.03889 0.03755]\n",
      "psig    [0.06443 0.06362 0.06407 0.06324] [0.03823 0.03836 0.03853 0.03765]\n",
      "fold 1\n",
      "mean    [0.06225 0.06248 0.06258 0.06124] [0.03745 0.0385  0.03817 0.03723]\n",
      "gmean   [0.06232 0.06259 0.06286 0.06144] [0.03755 0.03864 0.0384  0.03744]\n",
      "q50     [0.06246 0.06274 0.06298 0.06153] [0.03764 0.03872 0.03849 0.03745]\n",
      "q25     [0.06279 0.06314 0.06421 0.06238] [0.03804 0.03919 0.03941 0.03828]\n",
      "q75     [0.0627  0.06297 0.06296 0.06155] [0.03752 0.03861 0.03817 0.03711]\n",
      "psig    [0.06237 0.06263 0.06278 0.06143] [0.03756 0.03865 0.03834 0.03742]\n",
      "fold 2\n",
      "mean    [0.06078 0.05956 0.06078 0.05974] [0.03823 0.03747 0.0383  0.03753]\n",
      "gmean   [0.06092 0.05969 0.06094 0.05986] [0.03832 0.03755 0.03841 0.03759]\n",
      "q50     [0.06105 0.05981 0.06111 0.05995] [0.03841 0.03765 0.03857 0.03767]\n",
      "q25     [0.06159 0.0603  0.06181 0.06045] [0.03876 0.03796 0.03896 0.03795]\n",
      "q75     [0.06104 0.05986 0.0618  0.06027] [0.03837 0.0377  0.03894 0.03785]\n",
      "psig    [0.06093 0.05971 0.06093 0.05987] [0.03833 0.03757 0.03842 0.0376 ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5)\n",
    "\n",
    "for fold in range(3):\n",
    "    print('fold', fold)\n",
    "    data_fold = train_md.loc[train_md.fold == fold]\n",
    "    ww = data_fold.weights.values\n",
    "    ww = ww/ww.mean()\n",
    "\n",
    "    preds = np.stack([pickle.load(open(PATH_WORK/'oof_d{}_f{}_v{}'.format(ds, fold, VERSION),'rb')) \\\n",
    "        for ds in range(6,10)])\n",
    "\n",
    "    assert len(data_fold) == preds.shape[2]\n",
    "    \n",
    "    preds = np.clip(preds, 1e-15, 1-1e-15)\n",
    "    for afunc in afuncs_names:\n",
    "        apreds = applyAggFunc(preds, afunc)\n",
    "        res = ((- data_fold[all_ich].values * np.log(apreds) - (1 - data_fold[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean((1,2))\n",
    "        resw = (((- data_fold[all_ich].values * np.log(apreds) - (1 - data_fold[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean(2)*ww).mean(1)\n",
    "        \n",
    "        #roc = [roc_auc_score(data_fold[all_ich].values.reshape(-1), apreds[i].reshape(-1)) for i in range(4)]\n",
    "        print('{:7s} {} {}'.format(afunc,res,resw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = getPredsOOF(aug=32,datasets=range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_y = [\n",
    "           'model_Densenet201_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl',\n",
    "           'model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl',\n",
    "           'model_Densenet169_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl',\n",
    "           'model_se_resnext101_32x4d_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_{}.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding yuval_idx\n"
     ]
    }
   ],
   "source": [
    "preds_y = getYuvalOOF(train_md=train_md, names=names_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 674252, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14290754, 0.00339524, 0.0487164 , 0.03418155, 0.04797976,\n",
       "       0.0631835 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_y.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_y = preds_y[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = np.concatenate([preds_all, preds_y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32, 674252, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    [0.06233 0.06173 0.06221 0.06123 0.06155 0.06156 0.06217 0.06072]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (8, 1, 674252, 6) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b61b830f8a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mafunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mafuncs_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mapreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyAggFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n\u001b[1;32m      9\u001b[0m         * class_weights).mean((1,2))\n",
      "\u001b[0;32m<ipython-input-13-b12644745c16>\u001b[0m in \u001b[0;36mapplyAggFunc\u001b[0;34m(probs, func_name, axis, norm_axis)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gmean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q50'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (8, 1, 674252, 6) and data type float64"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5)\n",
    "\n",
    "ww = train_md.weights.values\n",
    "ww = ww/ww.mean()\n",
    "\n",
    "for afunc in afuncs_names:\n",
    "    apreds = applyAggFunc(preds_all, afunc)\n",
    "    res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean((1,2))\n",
    "    if False:\n",
    "        resw = (((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "            * class_weights).mean(2)*ww).mean(1)\n",
    "\n",
    "        print('{:7s} {} {}'.format(afunc,res,resw))\n",
    "    else:\n",
    "        print('{:7s} {}'.format(afunc,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06332, 0.06269, 0.06419, 0.06245, 0.06213, 0.06225, 0.06376,\n",
       "       0.06184])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06244, 0.06184, 0.06241, 0.06134, 0.0616 , 0.06162, 0.06231,\n",
       "       0.06083])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all.mean(1)) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all.mean(1),1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_afunc = 'mean'\n",
    "preds2 = applyAggFunc(preds_all, runs_afunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 674252, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial score 0.058888036483987334\n",
      "any too low inconsistencies\n",
      "1 class: 0.011859664255723379\n",
      "2 class: 0.03324907290782971\n",
      "3 class: 0.01985389341633395\n",
      "4 class: 0.05154873242867652\n",
      "5 class: 0.11456576950272301\n",
      "total 0.16696667311517058\n",
      "any too low corrected score 0.05886780423978061\n",
      "any too high inconsistencies\n",
      "total 0.1935819596196971\n",
      "any too high corrected score 0.05886198530963556\n"
     ]
    }
   ],
   "source": [
    "preds_all = predBounding(preds_all, target=train_md[all_ich].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predBounding(pp, target=None):\n",
    "    if target is not None:\n",
    "        ll = ((- target * np.log(pp.mean((0,1))) - (1 - target) * np.log(np.clip(1 - pp.mean((0,1)),1e-15,1-1e-15)))\n",
    "            * class_weights).mean()\n",
    "        print('initial score', ll)\n",
    "    \n",
    "    print('any too low inconsistencies')\n",
    "    for i in range(1,6):\n",
    "        print(i, 'class:', (pp[...,0] < pp[...,i]).mean())\n",
    "    print('total', (pp[...,0] < pp[...,1:].max(-1)).mean())\n",
    "    \n",
    "    max_vals = pp[...,1:].max(-1)\n",
    "    mask = pp[...,0] < max_vals\n",
    "    pp[mask,0] = max_vals[mask]\n",
    "    #mask_vals = 0.5*(preds_all[:,:,:,0] + max_vals)[mask]\n",
    "    #preds_all[mask,0] = mask_vals\n",
    "    #preds_all[mask] = np.clip(preds_all[mask],0,np.expand_dims(mask_vals,1))\n",
    "\n",
    "    assert (pp[...,0] < pp[...,1:].max(-1)).sum() == 0\n",
    "\n",
    "    if target is not None:\n",
    "        ll = ((- target * np.log(pp.mean((0,1))) - (1 - target) * np.log(np.clip(1 - pp.mean((0,1)),1e-15,1-1e-15)))\n",
    "            * class_weights).mean()\n",
    "        print('any too low corrected score', ll)\n",
    "    \n",
    "    print('any too high inconsistencies')\n",
    "    mask = pp[...,0] > pp[...,1:].sum(-1)\n",
    "    print('total', mask.mean())\n",
    "\n",
    "    mask_val = 0.5*(pp[mask,0] + pp[...,1:].sum(-1)[mask])\n",
    "    scaler = mask_val / pp[...,1:].sum(-1)[mask]\n",
    "    pp[mask,1:] = pp[mask,1:] * np.expand_dims(scaler,1)\n",
    "    pp[mask,0] = mask_val\n",
    "\n",
    "    if target is not None:\n",
    "        ll = ((- target * np.log(pp.mean((0,1))) - (1 - target) * np.log(np.clip(1 - pp.mean((0,1)),1e-15,1-1e-15)))\n",
    "            * class_weights).mean()\n",
    "        print('any too high corrected score', ll)\n",
    "    \n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between serieses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = train_md[['SeriesInstanceUID','PatientID']].groupby('PatientID').agg(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.sort_values('SeriesInstanceUID',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PatientID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_fa949caf</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_9d7de224</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_9d7dc280</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_33a89c47</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_afefd364</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SeriesInstanceUID\n",
       "PatientID                     \n",
       "ID_fa949caf                  3\n",
       "ID_9d7de224                  3\n",
       "ID_9d7dc280                  3\n",
       "ID_33a89c47                  3\n",
       "ID_afefd364                  3"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.loc[tt.SeriesInstanceUID == 3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = preds_all.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_md = pd.concat([train_md, pd.DataFrame(pp,columns=[s+'2' for s in all_ich])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_md = train_md.sort_values(['SeriesInstanceUID','pos_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of serieses 11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(30, 10))\n",
    "serieses = train_md.loc[train_md.PatientID == 'ID_5e035492'].SeriesInstanceUID.unique()\n",
    "print('total number of serieses', len(serieses))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i >= len(serieses): continue\n",
    "    ser = serieses[i]\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any'].values)\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any2'].values)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>img_id</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>Modality</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>ImagePositionPatient</th>\n",
       "      <th>ImageOrientationPatient</th>\n",
       "      <th>SamplesPerPixel</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>BitsAllocated</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>HighBit</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <th>RescaleSlope</th>\n",
       "      <th>PxlMin</th>\n",
       "      <th>PxlMax</th>\n",
       "      <th>PxlStd</th>\n",
       "      <th>PxlMean</th>\n",
       "      <th>ImageOrientationPatient_0</th>\n",
       "      <th>ImageOrientationPatient_1</th>\n",
       "      <th>ImageOrientationPatient_2</th>\n",
       "      <th>ImageOrientationPatient_3</th>\n",
       "      <th>ImageOrientationPatient_4</th>\n",
       "      <th>ImageOrientationPatient_5</th>\n",
       "      <th>ImagePositionPatient_0</th>\n",
       "      <th>ImagePositionPatient_1</th>\n",
       "      <th>ImagePositionPatient_2</th>\n",
       "      <th>PixelSpacing_0</th>\n",
       "      <th>PixelSpacing_1</th>\n",
       "      <th>WindowCenter_0</th>\n",
       "      <th>WindowCenter_1</th>\n",
       "      <th>WindowCenter_1_NAN</th>\n",
       "      <th>WindowWidth_0</th>\n",
       "      <th>WindowWidth_1</th>\n",
       "      <th>WindowWidth_0_le</th>\n",
       "      <th>WindowWidth_1_le</th>\n",
       "      <th>WindowCenter_1_le</th>\n",
       "      <th>BitType_le</th>\n",
       "      <th>ImageOrientationPatient_4_f</th>\n",
       "      <th>ImageOrientationPatient_4_enc_0</th>\n",
       "      <th>ImageOrientationPatient_4_enc_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ImageOrientationPatient_5_enc_1</th>\n",
       "      <th>ImagePositionPatient_0_f</th>\n",
       "      <th>ImagePositionPatient_0_enc_0</th>\n",
       "      <th>ImagePositionPatient_0_enc_1</th>\n",
       "      <th>ImagePositionPatient_0_f_r1</th>\n",
       "      <th>ImagePositionPatient_0_f_r05</th>\n",
       "      <th>ImagePositionPatient_1_f</th>\n",
       "      <th>ImagePositionPatient_1_enc_0</th>\n",
       "      <th>ImagePositionPatient_2_f</th>\n",
       "      <th>ImagePositionPatient_2_f_r05</th>\n",
       "      <th>PixelSpacing_1_f</th>\n",
       "      <th>PixelSpacing_1_enc_0</th>\n",
       "      <th>PixelSpacing_1_enc_1</th>\n",
       "      <th>WindowCenter_0_le</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>pos_min</th>\n",
       "      <th>pos_size</th>\n",
       "      <th>pos_idx1</th>\n",
       "      <th>pos_idx</th>\n",
       "      <th>pos_idx2</th>\n",
       "      <th>pos_inc1</th>\n",
       "      <th>pos_inc2</th>\n",
       "      <th>pos_inc1_grp_le</th>\n",
       "      <th>pos_inc2_grp_le</th>\n",
       "      <th>pos_inc1_r1</th>\n",
       "      <th>pos_inc1_r0001</th>\n",
       "      <th>pos_inc1_enc_0</th>\n",
       "      <th>pos_inc2_enc_0</th>\n",
       "      <th>pos_inc1_enc_1</th>\n",
       "      <th>pos_inc2_enc_1</th>\n",
       "      <th>pos_size_le</th>\n",
       "      <th>pos_range</th>\n",
       "      <th>pos_rel</th>\n",
       "      <th>pos_zeros</th>\n",
       "      <th>pos_inc_rng</th>\n",
       "      <th>pos_zeros_le</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>PxlMin_grp_le</th>\n",
       "      <th>weights</th>\n",
       "      <th>any2</th>\n",
       "      <th>epidural2</th>\n",
       "      <th>intraparenchymal2</th>\n",
       "      <th>intraventricular2</th>\n",
       "      <th>subarachnoid2</th>\n",
       "      <th>subdural2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183829</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b867760e2</td>\n",
       "      <td>ID_b867760e2</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '63.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>0.841333</td>\n",
       "      <td>-0.961477</td>\n",
       "      <td>0.754339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>63.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.147708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.152542</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084746</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106245</th>\n",
       "      <td>2.0</td>\n",
       "      <td>bc4054157</td>\n",
       "      <td>ID_bc4054157</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '68.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.302667</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>-0.981734</td>\n",
       "      <td>0.762372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>68.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.140544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.084746</td>\n",
       "      <td>1</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362507</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5d62cc5c7</td>\n",
       "      <td>ID_5d62cc5c7</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '73.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.310667</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>-1.000766</td>\n",
       "      <td>0.779547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>73.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.133381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.016949</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.757576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55311</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3ce444e82</td>\n",
       "      <td>ID_3ce444e82</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '78.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>-0.991928</td>\n",
       "      <td>0.843982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>78.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.126218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.949153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420941</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18b2ba4c8</td>\n",
       "      <td>ID_18b2ba4c8</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '83.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.314667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>-0.962363</td>\n",
       "      <td>0.910149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>83.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.119054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>4</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.515151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300366</th>\n",
       "      <td>2.0</td>\n",
       "      <td>396e28829</td>\n",
       "      <td>ID_396e28829</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '88.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>-0.933907</td>\n",
       "      <td>0.936926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>88.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.111891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.813559</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153659</th>\n",
       "      <td>2.0</td>\n",
       "      <td>acf76cddc</td>\n",
       "      <td>ID_acf76cddc</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '93.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>-0.867829</td>\n",
       "      <td>0.978963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>93.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.104728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.745763</td>\n",
       "      <td>6</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643991</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ca0f1bd1f</td>\n",
       "      <td>ID_ca0f1bd1f</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '98.9000244']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.306667</td>\n",
       "      <td>0.145333</td>\n",
       "      <td>-0.807630</td>\n",
       "      <td>1.034565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>98.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.097564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.677966</td>\n",
       "      <td>7</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.007825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99751</th>\n",
       "      <td>2.0</td>\n",
       "      <td>601be48cc</td>\n",
       "      <td>ID_601be48cc</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '103.900024']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>-0.818013</td>\n",
       "      <td>1.061267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>103.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.090401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.610169</td>\n",
       "      <td>8</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.032839</td>\n",
       "      <td>0.037040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387211</th>\n",
       "      <td>2.0</td>\n",
       "      <td>aa19146ca</td>\n",
       "      <td>ID_aa19146ca</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '108.900024']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>0.281333</td>\n",
       "      <td>-0.838944</td>\n",
       "      <td>1.060826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>108.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.542373</td>\n",
       "      <td>9</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.543668</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.322572</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.135512</td>\n",
       "      <td>0.124260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459452</th>\n",
       "      <td>2.0</td>\n",
       "      <td>942078d6e</td>\n",
       "      <td>ID_942078d6e</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '113.900024']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>-0.899123</td>\n",
       "      <td>1.030091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>113.900024</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.076074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.474576</td>\n",
       "      <td>10</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.499969</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.787878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.918656</td>\n",
       "      <td>0.024115</td>\n",
       "      <td>0.763064</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.315124</td>\n",
       "      <td>0.261145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451127</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1ecb66d35</td>\n",
       "      <td>ID_1ecb66d35</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '118.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.304000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>-0.978931</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>118.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.068911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.406780</td>\n",
       "      <td>11</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>1.499969</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.666668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.933054</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.762358</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.455088</td>\n",
       "      <td>0.252591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459214</th>\n",
       "      <td>2.0</td>\n",
       "      <td>874186cc5</td>\n",
       "      <td>ID_874186cc5</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '123.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>-0.041333</td>\n",
       "      <td>-0.988445</td>\n",
       "      <td>0.981606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>123.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.061748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.338983</td>\n",
       "      <td>12</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.920954</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.770226</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.563334</td>\n",
       "      <td>0.263610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118858</th>\n",
       "      <td>2.0</td>\n",
       "      <td>94ea99fbd</td>\n",
       "      <td>ID_94ea99fbd</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '128.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>-0.050667</td>\n",
       "      <td>-0.970255</td>\n",
       "      <td>0.993065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>128.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.054585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.271186</td>\n",
       "      <td>13</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.424243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.893019</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.717446</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.444525</td>\n",
       "      <td>0.180911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291418</th>\n",
       "      <td>2.0</td>\n",
       "      <td>656b6f494</td>\n",
       "      <td>ID_656b6f494</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '133.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.968606</td>\n",
       "      <td>1.002038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>133.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.047421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.203390</td>\n",
       "      <td>14</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.303031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.980438</td>\n",
       "      <td>0.009472</td>\n",
       "      <td>0.960037</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.337606</td>\n",
       "      <td>0.172147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473382</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ef16919b5</td>\n",
       "      <td>ID_ef16919b5</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '138.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.306667</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>-0.960171</td>\n",
       "      <td>1.014549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>138.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.040258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>15</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.181819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.988262</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.186669</td>\n",
       "      <td>0.121601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302721</th>\n",
       "      <td>2.0</td>\n",
       "      <td>f20709350</td>\n",
       "      <td>ID_f20709350</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '143.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.304000</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-0.940240</td>\n",
       "      <td>1.023711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>143.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.033095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.060607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.991860</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.135515</td>\n",
       "      <td>0.110268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401418</th>\n",
       "      <td>2.0</td>\n",
       "      <td>197a36d5d</td>\n",
       "      <td>ID_197a36d5d</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '148.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.936556</td>\n",
       "      <td>1.014516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>148.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.025931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.969767</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.967911</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.115135</td>\n",
       "      <td>0.092102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335737</th>\n",
       "      <td>2.0</td>\n",
       "      <td>fa093c6cb</td>\n",
       "      <td>ID_fa093c6cb</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '153.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>-0.022667</td>\n",
       "      <td>-0.954478</td>\n",
       "      <td>0.985129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>153.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.336236</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.302861</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.079112</td>\n",
       "      <td>0.059441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407299</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cdf49d705</td>\n",
       "      <td>ID_cdf49d705</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '158.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.313333</td>\n",
       "      <td>-0.065333</td>\n",
       "      <td>-0.973482</td>\n",
       "      <td>0.947405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>158.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.011605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.203390</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.281014</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.178869</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>0.101448</td>\n",
       "      <td>0.072873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463858</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ab11fbedf</td>\n",
       "      <td>ID_ab11fbedf</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '163.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-0.986472</td>\n",
       "      <td>0.906726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>163.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.004441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.271186</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.566976</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.428909</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.104829</td>\n",
       "      <td>0.094247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63088</th>\n",
       "      <td>2.0</td>\n",
       "      <td>acf54a89b</td>\n",
       "      <td>ID_acf54a89b</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '168.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-1.000733</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>168.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.338983</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.983561</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.975370</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.126935</td>\n",
       "      <td>0.121928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350252</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50dffd559</td>\n",
       "      <td>ID_50dffd559</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '173.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-1.017443</td>\n",
       "      <td>0.806401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>173.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.406780</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.985321</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.142108</td>\n",
       "      <td>0.139003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329738</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b13550aed</td>\n",
       "      <td>ID_b13550aed</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '178.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.314667</td>\n",
       "      <td>-0.274667</td>\n",
       "      <td>-1.039418</td>\n",
       "      <td>0.744862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>178.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.474576</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.787878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.986074</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.979739</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.142797</td>\n",
       "      <td>0.163557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212434</th>\n",
       "      <td>2.0</td>\n",
       "      <td>97048b0b5</td>\n",
       "      <td>ID_97048b0b5</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '183.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>-0.256000</td>\n",
       "      <td>-1.061740</td>\n",
       "      <td>0.673901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>183.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.542373</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.815646</td>\n",
       "      <td>0.013105</td>\n",
       "      <td>0.688247</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.161910</td>\n",
       "      <td>0.209642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210996</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b9799a238</td>\n",
       "      <td>ID_b9799a238</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '188.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309333</td>\n",
       "      <td>-0.349333</td>\n",
       "      <td>-1.082082</td>\n",
       "      <td>0.591044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>188.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.610169</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.405491</td>\n",
       "      <td>0.014217</td>\n",
       "      <td>0.102302</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.104954</td>\n",
       "      <td>0.227080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355909</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4f6986cea</td>\n",
       "      <td>ID_4f6986cea</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '193.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>-0.374667</td>\n",
       "      <td>-1.108516</td>\n",
       "      <td>0.498614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>193.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.677966</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.234505</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.061094</td>\n",
       "      <td>0.179025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517742</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64ea22498</td>\n",
       "      <td>ID_64ea22498</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '198.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.301333</td>\n",
       "      <td>-0.540000</td>\n",
       "      <td>-1.147880</td>\n",
       "      <td>0.399292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>198.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.745763</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.140069</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>0.122967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595062</th>\n",
       "      <td>2.0</td>\n",
       "      <td>051798ab9</td>\n",
       "      <td>ID_051798ab9</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '203.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>-0.645333</td>\n",
       "      <td>-1.202330</td>\n",
       "      <td>0.287098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>203.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.813559</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.044199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122981</th>\n",
       "      <td>2.0</td>\n",
       "      <td>58226ab52</td>\n",
       "      <td>ID_58226ab52</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '208.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>-0.532000</td>\n",
       "      <td>-1.296195</td>\n",
       "      <td>0.141956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>208.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.515151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520134</th>\n",
       "      <td>2.0</td>\n",
       "      <td>327587846</td>\n",
       "      <td>ID_327587846</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '213.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>-0.649333</td>\n",
       "      <td>-1.494685</td>\n",
       "      <td>-0.061172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>213.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.949153</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208401</th>\n",
       "      <td>2.0</td>\n",
       "      <td>36108c996</td>\n",
       "      <td>ID_36108c996</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '218.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.306667</td>\n",
       "      <td>-1.052000</td>\n",
       "      <td>-1.962864</td>\n",
       "      <td>-0.331970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>218.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.016949</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.757576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85848</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5873a24d6</td>\n",
       "      <td>ID_5873a24d6</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '223.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.305333</td>\n",
       "      <td>-1.556000</td>\n",
       "      <td>-2.590599</td>\n",
       "      <td>-0.575175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>223.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>32</td>\n",
       "      <td>-1.084746</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>1.878788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24414</th>\n",
       "      <td>2.0</td>\n",
       "      <td>a61bb8480</td>\n",
       "      <td>ID_a61bb8480</td>\n",
       "      <td>CT</td>\n",
       "      <td>ID_018b83e7</td>\n",
       "      <td>ID_ba1c7199ef</td>\n",
       "      <td>ID_91616854b0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['-122.73329', '45.9996796', '228.899963']</td>\n",
       "      <td>['1', '0', '0', '0', '1', '0']</td>\n",
       "      <td>1</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>['0.48828125', '0.48828125']</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>-1.546667</td>\n",
       "      <td>-2.807197</td>\n",
       "      <td>-0.682076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.73329</td>\n",
       "      <td>45.99968</td>\n",
       "      <td>228.899963</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.340446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.084746</td>\n",
       "      <td>33</td>\n",
       "      <td>-1.152542</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.599976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034987</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows  102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold     img_id SOPInstanceUID Modality    PatientID StudyInstanceUID  \\\n",
       "183829   2.0  b867760e2   ID_b867760e2       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "106245   2.0  bc4054157   ID_bc4054157       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "362507   2.0  5d62cc5c7   ID_5d62cc5c7       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "55311    2.0  3ce444e82   ID_3ce444e82       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "420941   2.0  18b2ba4c8   ID_18b2ba4c8       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "300366   2.0  396e28829   ID_396e28829       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "153659   2.0  acf76cddc   ID_acf76cddc       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "643991   2.0  ca0f1bd1f   ID_ca0f1bd1f       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "99751    2.0  601be48cc   ID_601be48cc       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "387211   2.0  aa19146ca   ID_aa19146ca       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "459452   2.0  942078d6e   ID_942078d6e       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "451127   2.0  1ecb66d35   ID_1ecb66d35       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "459214   2.0  874186cc5   ID_874186cc5       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "118858   2.0  94ea99fbd   ID_94ea99fbd       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "291418   2.0  656b6f494   ID_656b6f494       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "473382   2.0  ef16919b5   ID_ef16919b5       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "302721   2.0  f20709350   ID_f20709350       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "401418   2.0  197a36d5d   ID_197a36d5d       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "335737   2.0  fa093c6cb   ID_fa093c6cb       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "407299   2.0  cdf49d705   ID_cdf49d705       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "463858   2.0  ab11fbedf   ID_ab11fbedf       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "63088    2.0  acf54a89b   ID_acf54a89b       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "350252   2.0  50dffd559   ID_50dffd559       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "329738   2.0  b13550aed   ID_b13550aed       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "212434   2.0  97048b0b5   ID_97048b0b5       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "210996   2.0  b9799a238   ID_b9799a238       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "355909   2.0  4f6986cea   ID_4f6986cea       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "517742   2.0  64ea22498   ID_64ea22498       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "595062   2.0  051798ab9   ID_051798ab9       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "122981   2.0  58226ab52   ID_58226ab52       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "520134   2.0  327587846   ID_327587846       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "208401   2.0  36108c996   ID_36108c996       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "85848    2.0  5873a24d6   ID_5873a24d6       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "24414    2.0  a61bb8480   ID_a61bb8480       CT  ID_018b83e7    ID_ba1c7199ef   \n",
       "\n",
       "       SeriesInstanceUID  StudyID                        ImagePositionPatient  \\\n",
       "183829     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '63.9000244']   \n",
       "106245     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '68.9000244']   \n",
       "362507     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '73.9000244']   \n",
       "55311      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '78.9000244']   \n",
       "420941     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '83.9000244']   \n",
       "300366     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '88.9000244']   \n",
       "153659     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '93.9000244']   \n",
       "643991     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '98.9000244']   \n",
       "99751      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '103.900024']   \n",
       "387211     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '108.900024']   \n",
       "459452     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '113.900024']   \n",
       "451127     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '118.899963']   \n",
       "459214     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '123.899963']   \n",
       "118858     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '128.899963']   \n",
       "291418     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '133.899963']   \n",
       "473382     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '138.899963']   \n",
       "302721     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '143.899963']   \n",
       "401418     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '148.899963']   \n",
       "335737     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '153.899963']   \n",
       "407299     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '158.899963']   \n",
       "463858     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '163.899963']   \n",
       "63088      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '168.899963']   \n",
       "350252     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '173.899963']   \n",
       "329738     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '178.899963']   \n",
       "212434     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '183.899963']   \n",
       "210996     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '188.899963']   \n",
       "355909     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '193.899963']   \n",
       "517742     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '198.899963']   \n",
       "595062     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '203.899963']   \n",
       "122981     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '208.899963']   \n",
       "520134     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '213.899963']   \n",
       "208401     ID_91616854b0      NaN  ['-122.73329', '45.9996796', '218.899963']   \n",
       "85848      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '223.899963']   \n",
       "24414      ID_91616854b0      NaN  ['-122.73329', '45.9996796', '228.899963']   \n",
       "\n",
       "               ImageOrientationPatient  SamplesPerPixel  \\\n",
       "183829  ['1', '0', '0', '0', '1', '0']                1   \n",
       "106245  ['1', '0', '0', '0', '1', '0']                1   \n",
       "362507  ['1', '0', '0', '0', '1', '0']                1   \n",
       "55311   ['1', '0', '0', '0', '1', '0']                1   \n",
       "420941  ['1', '0', '0', '0', '1', '0']                1   \n",
       "300366  ['1', '0', '0', '0', '1', '0']                1   \n",
       "153659  ['1', '0', '0', '0', '1', '0']                1   \n",
       "643991  ['1', '0', '0', '0', '1', '0']                1   \n",
       "99751   ['1', '0', '0', '0', '1', '0']                1   \n",
       "387211  ['1', '0', '0', '0', '1', '0']                1   \n",
       "459452  ['1', '0', '0', '0', '1', '0']                1   \n",
       "451127  ['1', '0', '0', '0', '1', '0']                1   \n",
       "459214  ['1', '0', '0', '0', '1', '0']                1   \n",
       "118858  ['1', '0', '0', '0', '1', '0']                1   \n",
       "291418  ['1', '0', '0', '0', '1', '0']                1   \n",
       "473382  ['1', '0', '0', '0', '1', '0']                1   \n",
       "302721  ['1', '0', '0', '0', '1', '0']                1   \n",
       "401418  ['1', '0', '0', '0', '1', '0']                1   \n",
       "335737  ['1', '0', '0', '0', '1', '0']                1   \n",
       "407299  ['1', '0', '0', '0', '1', '0']                1   \n",
       "463858  ['1', '0', '0', '0', '1', '0']                1   \n",
       "63088   ['1', '0', '0', '0', '1', '0']                1   \n",
       "350252  ['1', '0', '0', '0', '1', '0']                1   \n",
       "329738  ['1', '0', '0', '0', '1', '0']                1   \n",
       "212434  ['1', '0', '0', '0', '1', '0']                1   \n",
       "210996  ['1', '0', '0', '0', '1', '0']                1   \n",
       "355909  ['1', '0', '0', '0', '1', '0']                1   \n",
       "517742  ['1', '0', '0', '0', '1', '0']                1   \n",
       "595062  ['1', '0', '0', '0', '1', '0']                1   \n",
       "122981  ['1', '0', '0', '0', '1', '0']                1   \n",
       "520134  ['1', '0', '0', '0', '1', '0']                1   \n",
       "208401  ['1', '0', '0', '0', '1', '0']                1   \n",
       "85848   ['1', '0', '0', '0', '1', '0']                1   \n",
       "24414   ['1', '0', '0', '0', '1', '0']                1   \n",
       "\n",
       "       PhotometricInterpretation  Rows  Columns                  PixelSpacing  \\\n",
       "183829               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "106245               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "362507               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "55311                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "420941               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "300366               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "153659               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "643991               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "99751                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "387211               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "459452               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "451127               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "459214               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "118858               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "291418               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "473382               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "302721               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "401418               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "335737               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "407299               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "463858               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "63088                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "350252               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "329738               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "212434               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "210996               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "355909               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "517742               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "595062               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "122981               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "520134               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "208401               MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "85848                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "24414                MONOCHROME2   512      512  ['0.48828125', '0.48828125']   \n",
       "\n",
       "        BitsAllocated  BitsStored  HighBit  PixelRepresentation  \\\n",
       "183829             16          12       11                    0   \n",
       "106245             16          12       11                    0   \n",
       "362507             16          12       11                    0   \n",
       "55311              16          12       11                    0   \n",
       "420941             16          12       11                    0   \n",
       "300366             16          12       11                    0   \n",
       "153659             16          12       11                    0   \n",
       "643991             16          12       11                    0   \n",
       "99751              16          12       11                    0   \n",
       "387211             16          12       11                    0   \n",
       "459452             16          12       11                    0   \n",
       "451127             16          12       11                    0   \n",
       "459214             16          12       11                    0   \n",
       "118858             16          12       11                    0   \n",
       "291418             16          12       11                    0   \n",
       "473382             16          12       11                    0   \n",
       "302721             16          12       11                    0   \n",
       "401418             16          12       11                    0   \n",
       "335737             16          12       11                    0   \n",
       "407299             16          12       11                    0   \n",
       "463858             16          12       11                    0   \n",
       "63088              16          12       11                    0   \n",
       "350252             16          12       11                    0   \n",
       "329738             16          12       11                    0   \n",
       "212434             16          12       11                    0   \n",
       "210996             16          12       11                    0   \n",
       "355909             16          12       11                    0   \n",
       "517742             16          12       11                    0   \n",
       "595062             16          12       11                    0   \n",
       "122981             16          12       11                    0   \n",
       "520134             16          12       11                    0   \n",
       "208401             16          12       11                    0   \n",
       "85848              16          12       11                    0   \n",
       "24414              16          12       11                    0   \n",
       "\n",
       "              WindowCenter         WindowWidth  RescaleIntercept  \\\n",
       "183829  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "106245  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "362507  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "55311   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "420941  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "300366  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "153659  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "643991  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "99751   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "387211  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "459452  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "451127  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "459214  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "118858  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "291418  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "473382  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "302721  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "401418  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "335737  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "407299  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "463858  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "63088   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "350252  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "329738  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "212434  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "210996  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "355909  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "517742  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "595062  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "122981  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "520134  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "208401  ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "85848   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "24414   ['00036', '00036']  ['00080', '00080']           -1024.0   \n",
       "\n",
       "        RescaleSlope    PxlMin    PxlMax    PxlStd   PxlMean  \\\n",
       "183829           1.0  1.301333  0.841333 -0.961477  0.754339   \n",
       "106245           1.0  1.302667  0.580000 -0.981734  0.762372   \n",
       "362507           1.0  1.310667  0.632000 -1.000766  0.779547   \n",
       "55311            1.0  1.316000  0.136000 -0.991928  0.843982   \n",
       "420941           1.0  1.314667  0.006667 -0.962363  0.910149   \n",
       "300366           1.0  1.312000 -0.048000 -0.933907  0.936926   \n",
       "153659           1.0  1.309333  0.018667 -0.867829  0.978963   \n",
       "643991           1.0  1.306667  0.145333 -0.807630  1.034565   \n",
       "99751            1.0  1.305333  0.060000 -0.818013  1.061267   \n",
       "387211           1.0  1.301333  0.281333 -0.838944  1.060826   \n",
       "459452           1.0  1.301333  0.028000 -0.899123  1.030091   \n",
       "451127           1.0  1.304000 -0.024000 -0.978931  0.988314   \n",
       "459214           1.0  1.308000 -0.041333 -0.988445  0.981606   \n",
       "118858           1.0  1.301333 -0.050667 -0.970255  0.993065   \n",
       "291418           1.0  1.301333 -0.066667 -0.968606  1.002038   \n",
       "473382           1.0  1.306667 -0.032000 -0.960171  1.014549   \n",
       "302721           1.0  1.304000 -0.012000 -0.940240  1.023711   \n",
       "401418           1.0  1.309333  0.000000 -0.936556  1.014516   \n",
       "335737           1.0  1.309333 -0.022667 -0.954478  0.985129   \n",
       "407299           1.0  1.313333 -0.065333 -0.973482  0.947405   \n",
       "463858           1.0  1.309333 -0.012000 -0.986472  0.906726   \n",
       "63088            1.0  1.308000 -0.133333 -1.000733  0.860140   \n",
       "350252           1.0  1.312000 -0.200000 -1.017443  0.806401   \n",
       "329738           1.0  1.314667 -0.274667 -1.039418  0.744862   \n",
       "212434           1.0  1.316000 -0.256000 -1.061740  0.673901   \n",
       "210996           1.0  1.309333 -0.349333 -1.082082  0.591044   \n",
       "355909           1.0  1.305333 -0.374667 -1.108516  0.498614   \n",
       "517742           1.0  1.301333 -0.540000 -1.147880  0.399292   \n",
       "595062           1.0  1.305333 -0.645333 -1.202330  0.287098   \n",
       "122981           1.0  1.316000 -0.532000 -1.296195  0.141956   \n",
       "520134           1.0  1.308000 -0.649333 -1.494685 -0.061172   \n",
       "208401           1.0  1.306667 -1.052000 -1.962864 -0.331970   \n",
       "85848            1.0  1.305333 -1.556000 -2.590599 -0.575175   \n",
       "24414            1.0  1.312000 -1.546667 -2.807197 -0.682076   \n",
       "\n",
       "        ImageOrientationPatient_0  ImageOrientationPatient_1  \\\n",
       "183829                        1.0                        0.0   \n",
       "106245                        1.0                        0.0   \n",
       "362507                        1.0                        0.0   \n",
       "55311                         1.0                        0.0   \n",
       "420941                        1.0                        0.0   \n",
       "300366                        1.0                        0.0   \n",
       "153659                        1.0                        0.0   \n",
       "643991                        1.0                        0.0   \n",
       "99751                         1.0                        0.0   \n",
       "387211                        1.0                        0.0   \n",
       "459452                        1.0                        0.0   \n",
       "451127                        1.0                        0.0   \n",
       "459214                        1.0                        0.0   \n",
       "118858                        1.0                        0.0   \n",
       "291418                        1.0                        0.0   \n",
       "473382                        1.0                        0.0   \n",
       "302721                        1.0                        0.0   \n",
       "401418                        1.0                        0.0   \n",
       "335737                        1.0                        0.0   \n",
       "407299                        1.0                        0.0   \n",
       "463858                        1.0                        0.0   \n",
       "63088                         1.0                        0.0   \n",
       "350252                        1.0                        0.0   \n",
       "329738                        1.0                        0.0   \n",
       "212434                        1.0                        0.0   \n",
       "210996                        1.0                        0.0   \n",
       "355909                        1.0                        0.0   \n",
       "517742                        1.0                        0.0   \n",
       "595062                        1.0                        0.0   \n",
       "122981                        1.0                        0.0   \n",
       "520134                        1.0                        0.0   \n",
       "208401                        1.0                        0.0   \n",
       "85848                         1.0                        0.0   \n",
       "24414                         1.0                        0.0   \n",
       "\n",
       "        ImageOrientationPatient_2  ImageOrientationPatient_3  \\\n",
       "183829                        0.0                        0.0   \n",
       "106245                        0.0                        0.0   \n",
       "362507                        0.0                        0.0   \n",
       "55311                         0.0                        0.0   \n",
       "420941                        0.0                        0.0   \n",
       "300366                        0.0                        0.0   \n",
       "153659                        0.0                        0.0   \n",
       "643991                        0.0                        0.0   \n",
       "99751                         0.0                        0.0   \n",
       "387211                        0.0                        0.0   \n",
       "459452                        0.0                        0.0   \n",
       "451127                        0.0                        0.0   \n",
       "459214                        0.0                        0.0   \n",
       "118858                        0.0                        0.0   \n",
       "291418                        0.0                        0.0   \n",
       "473382                        0.0                        0.0   \n",
       "302721                        0.0                        0.0   \n",
       "401418                        0.0                        0.0   \n",
       "335737                        0.0                        0.0   \n",
       "407299                        0.0                        0.0   \n",
       "463858                        0.0                        0.0   \n",
       "63088                         0.0                        0.0   \n",
       "350252                        0.0                        0.0   \n",
       "329738                        0.0                        0.0   \n",
       "212434                        0.0                        0.0   \n",
       "210996                        0.0                        0.0   \n",
       "355909                        0.0                        0.0   \n",
       "517742                        0.0                        0.0   \n",
       "595062                        0.0                        0.0   \n",
       "122981                        0.0                        0.0   \n",
       "520134                        0.0                        0.0   \n",
       "208401                        0.0                        0.0   \n",
       "85848                         0.0                        0.0   \n",
       "24414                         0.0                        0.0   \n",
       "\n",
       "        ImageOrientationPatient_4  ImageOrientationPatient_5  \\\n",
       "183829                        1.0                        0.0   \n",
       "106245                        1.0                        0.0   \n",
       "362507                        1.0                        0.0   \n",
       "55311                         1.0                        0.0   \n",
       "420941                        1.0                        0.0   \n",
       "300366                        1.0                        0.0   \n",
       "153659                        1.0                        0.0   \n",
       "643991                        1.0                        0.0   \n",
       "99751                         1.0                        0.0   \n",
       "387211                        1.0                        0.0   \n",
       "459452                        1.0                        0.0   \n",
       "451127                        1.0                        0.0   \n",
       "459214                        1.0                        0.0   \n",
       "118858                        1.0                        0.0   \n",
       "291418                        1.0                        0.0   \n",
       "473382                        1.0                        0.0   \n",
       "302721                        1.0                        0.0   \n",
       "401418                        1.0                        0.0   \n",
       "335737                        1.0                        0.0   \n",
       "407299                        1.0                        0.0   \n",
       "463858                        1.0                        0.0   \n",
       "63088                         1.0                        0.0   \n",
       "350252                        1.0                        0.0   \n",
       "329738                        1.0                        0.0   \n",
       "212434                        1.0                        0.0   \n",
       "210996                        1.0                        0.0   \n",
       "355909                        1.0                        0.0   \n",
       "517742                        1.0                        0.0   \n",
       "595062                        1.0                        0.0   \n",
       "122981                        1.0                        0.0   \n",
       "520134                        1.0                        0.0   \n",
       "208401                        1.0                        0.0   \n",
       "85848                         1.0                        0.0   \n",
       "24414                         1.0                        0.0   \n",
       "\n",
       "        ImagePositionPatient_0  ImagePositionPatient_1  \\\n",
       "183829              -122.73329                45.99968   \n",
       "106245              -122.73329                45.99968   \n",
       "362507              -122.73329                45.99968   \n",
       "55311               -122.73329                45.99968   \n",
       "420941              -122.73329                45.99968   \n",
       "300366              -122.73329                45.99968   \n",
       "153659              -122.73329                45.99968   \n",
       "643991              -122.73329                45.99968   \n",
       "99751               -122.73329                45.99968   \n",
       "387211              -122.73329                45.99968   \n",
       "459452              -122.73329                45.99968   \n",
       "451127              -122.73329                45.99968   \n",
       "459214              -122.73329                45.99968   \n",
       "118858              -122.73329                45.99968   \n",
       "291418              -122.73329                45.99968   \n",
       "473382              -122.73329                45.99968   \n",
       "302721              -122.73329                45.99968   \n",
       "401418              -122.73329                45.99968   \n",
       "335737              -122.73329                45.99968   \n",
       "407299              -122.73329                45.99968   \n",
       "463858              -122.73329                45.99968   \n",
       "63088               -122.73329                45.99968   \n",
       "350252              -122.73329                45.99968   \n",
       "329738              -122.73329                45.99968   \n",
       "212434              -122.73329                45.99968   \n",
       "210996              -122.73329                45.99968   \n",
       "355909              -122.73329                45.99968   \n",
       "517742              -122.73329                45.99968   \n",
       "595062              -122.73329                45.99968   \n",
       "122981              -122.73329                45.99968   \n",
       "520134              -122.73329                45.99968   \n",
       "208401              -122.73329                45.99968   \n",
       "85848               -122.73329                45.99968   \n",
       "24414               -122.73329                45.99968   \n",
       "\n",
       "        ImagePositionPatient_2  PixelSpacing_0  PixelSpacing_1  \\\n",
       "183829               63.900024        0.488281        0.488281   \n",
       "106245               68.900024        0.488281        0.488281   \n",
       "362507               73.900024        0.488281        0.488281   \n",
       "55311                78.900024        0.488281        0.488281   \n",
       "420941               83.900024        0.488281        0.488281   \n",
       "300366               88.900024        0.488281        0.488281   \n",
       "153659               93.900024        0.488281        0.488281   \n",
       "643991               98.900024        0.488281        0.488281   \n",
       "99751               103.900024        0.488281        0.488281   \n",
       "387211              108.900024        0.488281        0.488281   \n",
       "459452              113.900024        0.488281        0.488281   \n",
       "451127              118.899963        0.488281        0.488281   \n",
       "459214              123.899963        0.488281        0.488281   \n",
       "118858              128.899963        0.488281        0.488281   \n",
       "291418              133.899963        0.488281        0.488281   \n",
       "473382              138.899963        0.488281        0.488281   \n",
       "302721              143.899963        0.488281        0.488281   \n",
       "401418              148.899963        0.488281        0.488281   \n",
       "335737              153.899963        0.488281        0.488281   \n",
       "407299              158.899963        0.488281        0.488281   \n",
       "463858              163.899963        0.488281        0.488281   \n",
       "63088               168.899963        0.488281        0.488281   \n",
       "350252              173.899963        0.488281        0.488281   \n",
       "329738              178.899963        0.488281        0.488281   \n",
       "212434              183.899963        0.488281        0.488281   \n",
       "210996              188.899963        0.488281        0.488281   \n",
       "355909              193.899963        0.488281        0.488281   \n",
       "517742              198.899963        0.488281        0.488281   \n",
       "595062              203.899963        0.488281        0.488281   \n",
       "122981              208.899963        0.488281        0.488281   \n",
       "520134              213.899963        0.488281        0.488281   \n",
       "208401              218.899963        0.488281        0.488281   \n",
       "85848               223.899963        0.488281        0.488281   \n",
       "24414               228.899963        0.488281        0.488281   \n",
       "\n",
       "        WindowCenter_0  WindowCenter_1  WindowCenter_1_NAN  WindowWidth_0  \\\n",
       "183829            36.0            36.0               False           80.0   \n",
       "106245            36.0            36.0               False           80.0   \n",
       "362507            36.0            36.0               False           80.0   \n",
       "55311             36.0            36.0               False           80.0   \n",
       "420941            36.0            36.0               False           80.0   \n",
       "300366            36.0            36.0               False           80.0   \n",
       "153659            36.0            36.0               False           80.0   \n",
       "643991            36.0            36.0               False           80.0   \n",
       "99751             36.0            36.0               False           80.0   \n",
       "387211            36.0            36.0               False           80.0   \n",
       "459452            36.0            36.0               False           80.0   \n",
       "451127            36.0            36.0               False           80.0   \n",
       "459214            36.0            36.0               False           80.0   \n",
       "118858            36.0            36.0               False           80.0   \n",
       "291418            36.0            36.0               False           80.0   \n",
       "473382            36.0            36.0               False           80.0   \n",
       "302721            36.0            36.0               False           80.0   \n",
       "401418            36.0            36.0               False           80.0   \n",
       "335737            36.0            36.0               False           80.0   \n",
       "407299            36.0            36.0               False           80.0   \n",
       "463858            36.0            36.0               False           80.0   \n",
       "63088             36.0            36.0               False           80.0   \n",
       "350252            36.0            36.0               False           80.0   \n",
       "329738            36.0            36.0               False           80.0   \n",
       "212434            36.0            36.0               False           80.0   \n",
       "210996            36.0            36.0               False           80.0   \n",
       "355909            36.0            36.0               False           80.0   \n",
       "517742            36.0            36.0               False           80.0   \n",
       "595062            36.0            36.0               False           80.0   \n",
       "122981            36.0            36.0               False           80.0   \n",
       "520134            36.0            36.0               False           80.0   \n",
       "208401            36.0            36.0               False           80.0   \n",
       "85848             36.0            36.0               False           80.0   \n",
       "24414             36.0            36.0               False           80.0   \n",
       "\n",
       "        WindowWidth_1  WindowWidth_0_le  WindowWidth_1_le  WindowCenter_1_le  \\\n",
       "183829           80.0                 0                 0                  0   \n",
       "106245           80.0                 0                 0                  0   \n",
       "362507           80.0                 0                 0                  0   \n",
       "55311            80.0                 0                 0                  0   \n",
       "420941           80.0                 0                 0                  0   \n",
       "300366           80.0                 0                 0                  0   \n",
       "153659           80.0                 0                 0                  0   \n",
       "643991           80.0                 0                 0                  0   \n",
       "99751            80.0                 0                 0                  0   \n",
       "387211           80.0                 0                 0                  0   \n",
       "459452           80.0                 0                 0                  0   \n",
       "451127           80.0                 0                 0                  0   \n",
       "459214           80.0                 0                 0                  0   \n",
       "118858           80.0                 0                 0                  0   \n",
       "291418           80.0                 0                 0                  0   \n",
       "473382           80.0                 0                 0                  0   \n",
       "302721           80.0                 0                 0                  0   \n",
       "401418           80.0                 0                 0                  0   \n",
       "335737           80.0                 0                 0                  0   \n",
       "407299           80.0                 0                 0                  0   \n",
       "463858           80.0                 0                 0                  0   \n",
       "63088            80.0                 0                 0                  0   \n",
       "350252           80.0                 0                 0                  0   \n",
       "329738           80.0                 0                 0                  0   \n",
       "212434           80.0                 0                 0                  0   \n",
       "210996           80.0                 0                 0                  0   \n",
       "355909           80.0                 0                 0                  0   \n",
       "517742           80.0                 0                 0                  0   \n",
       "595062           80.0                 0                 0                  0   \n",
       "122981           80.0                 0                 0                  0   \n",
       "520134           80.0                 0                 0                  0   \n",
       "208401           80.0                 0                 0                  0   \n",
       "85848            80.0                 0                 0                  0   \n",
       "24414            80.0                 0                 0                  0   \n",
       "\n",
       "        BitType_le  ImageOrientationPatient_4_f  \\\n",
       "183829           1                    -1.333333   \n",
       "106245           1                    -1.333333   \n",
       "362507           1                    -1.333333   \n",
       "55311            1                    -1.333333   \n",
       "420941           1                    -1.333333   \n",
       "300366           1                    -1.333333   \n",
       "153659           1                    -1.333333   \n",
       "643991           1                    -1.333333   \n",
       "99751            1                    -1.333333   \n",
       "387211           1                    -1.333333   \n",
       "459452           1                    -1.333333   \n",
       "451127           1                    -1.333333   \n",
       "459214           1                    -1.333333   \n",
       "118858           1                    -1.333333   \n",
       "291418           1                    -1.333333   \n",
       "473382           1                    -1.333333   \n",
       "302721           1                    -1.333333   \n",
       "401418           1                    -1.333333   \n",
       "335737           1                    -1.333333   \n",
       "407299           1                    -1.333333   \n",
       "463858           1                    -1.333333   \n",
       "63088            1                    -1.333333   \n",
       "350252           1                    -1.333333   \n",
       "329738           1                    -1.333333   \n",
       "212434           1                    -1.333333   \n",
       "210996           1                    -1.333333   \n",
       "355909           1                    -1.333333   \n",
       "517742           1                    -1.333333   \n",
       "595062           1                    -1.333333   \n",
       "122981           1                    -1.333333   \n",
       "520134           1                    -1.333333   \n",
       "208401           1                    -1.333333   \n",
       "85848            1                    -1.333333   \n",
       "24414            1                    -1.333333   \n",
       "\n",
       "        ImageOrientationPatient_4_enc_0  ImageOrientationPatient_4_enc_1  ...  \\\n",
       "183829                              1.0                              0.0  ...   \n",
       "106245                              1.0                              0.0  ...   \n",
       "362507                              1.0                              0.0  ...   \n",
       "55311                               1.0                              0.0  ...   \n",
       "420941                              1.0                              0.0  ...   \n",
       "300366                              1.0                              0.0  ...   \n",
       "153659                              1.0                              0.0  ...   \n",
       "643991                              1.0                              0.0  ...   \n",
       "99751                               1.0                              0.0  ...   \n",
       "387211                              1.0                              0.0  ...   \n",
       "459452                              1.0                              0.0  ...   \n",
       "451127                              1.0                              0.0  ...   \n",
       "459214                              1.0                              0.0  ...   \n",
       "118858                              1.0                              0.0  ...   \n",
       "291418                              1.0                              0.0  ...   \n",
       "473382                              1.0                              0.0  ...   \n",
       "302721                              1.0                              0.0  ...   \n",
       "401418                              1.0                              0.0  ...   \n",
       "335737                              1.0                              0.0  ...   \n",
       "407299                              1.0                              0.0  ...   \n",
       "463858                              1.0                              0.0  ...   \n",
       "63088                               1.0                              0.0  ...   \n",
       "350252                              1.0                              0.0  ...   \n",
       "329738                              1.0                              0.0  ...   \n",
       "212434                              1.0                              0.0  ...   \n",
       "210996                              1.0                              0.0  ...   \n",
       "355909                              1.0                              0.0  ...   \n",
       "517742                              1.0                              0.0  ...   \n",
       "595062                              1.0                              0.0  ...   \n",
       "122981                              1.0                              0.0  ...   \n",
       "520134                              1.0                              0.0  ...   \n",
       "208401                              1.0                              0.0  ...   \n",
       "85848                               1.0                              0.0  ...   \n",
       "24414                               1.0                              0.0  ...   \n",
       "\n",
       "        ImageOrientationPatient_5_enc_1  ImagePositionPatient_0_f  \\\n",
       "183829                            False                  1.340446   \n",
       "106245                            False                  1.340446   \n",
       "362507                            False                  1.340446   \n",
       "55311                             False                  1.340446   \n",
       "420941                            False                  1.340446   \n",
       "300366                            False                  1.340446   \n",
       "153659                            False                  1.340446   \n",
       "643991                            False                  1.340446   \n",
       "99751                             False                  1.340446   \n",
       "387211                            False                  1.340446   \n",
       "459452                            False                  1.340446   \n",
       "451127                            False                  1.340446   \n",
       "459214                            False                  1.340446   \n",
       "118858                            False                  1.340446   \n",
       "291418                            False                  1.340446   \n",
       "473382                            False                  1.340446   \n",
       "302721                            False                  1.340446   \n",
       "401418                            False                  1.340446   \n",
       "335737                            False                  1.340446   \n",
       "407299                            False                  1.340446   \n",
       "463858                            False                  1.340446   \n",
       "63088                             False                  1.340446   \n",
       "350252                            False                  1.340446   \n",
       "329738                            False                  1.340446   \n",
       "212434                            False                  1.340446   \n",
       "210996                            False                  1.340446   \n",
       "355909                            False                  1.340446   \n",
       "517742                            False                  1.340446   \n",
       "595062                            False                  1.340446   \n",
       "122981                            False                  1.340446   \n",
       "520134                            False                  1.340446   \n",
       "208401                            False                  1.340446   \n",
       "85848                             False                  1.340446   \n",
       "24414                             False                  1.340446   \n",
       "\n",
       "        ImagePositionPatient_0_enc_0  ImagePositionPatient_0_enc_1  \\\n",
       "183829                           0.0                           0.0   \n",
       "106245                           0.0                           0.0   \n",
       "362507                           0.0                           0.0   \n",
       "55311                            0.0                           0.0   \n",
       "420941                           0.0                           0.0   \n",
       "300366                           0.0                           0.0   \n",
       "153659                           0.0                           0.0   \n",
       "643991                           0.0                           0.0   \n",
       "99751                            0.0                           0.0   \n",
       "387211                           0.0                           0.0   \n",
       "459452                           0.0                           0.0   \n",
       "451127                           0.0                           0.0   \n",
       "459214                           0.0                           0.0   \n",
       "118858                           0.0                           0.0   \n",
       "291418                           0.0                           0.0   \n",
       "473382                           0.0                           0.0   \n",
       "302721                           0.0                           0.0   \n",
       "401418                           0.0                           0.0   \n",
       "335737                           0.0                           0.0   \n",
       "407299                           0.0                           0.0   \n",
       "463858                           0.0                           0.0   \n",
       "63088                            0.0                           0.0   \n",
       "350252                           0.0                           0.0   \n",
       "329738                           0.0                           0.0   \n",
       "212434                           0.0                           0.0   \n",
       "210996                           0.0                           0.0   \n",
       "355909                           0.0                           0.0   \n",
       "517742                           0.0                           0.0   \n",
       "595062                           0.0                           0.0   \n",
       "122981                           0.0                           0.0   \n",
       "520134                           0.0                           0.0   \n",
       "208401                           0.0                           0.0   \n",
       "85848                            0.0                           0.0   \n",
       "24414                            0.0                           0.0   \n",
       "\n",
       "        ImagePositionPatient_0_f_r1  ImagePositionPatient_0_f_r05  \\\n",
       "183829                          0.0                           0.0   \n",
       "106245                          0.0                           0.0   \n",
       "362507                          0.0                           0.0   \n",
       "55311                           0.0                           0.0   \n",
       "420941                          0.0                           0.0   \n",
       "300366                          0.0                           0.0   \n",
       "153659                          0.0                           0.0   \n",
       "643991                          0.0                           0.0   \n",
       "99751                           0.0                           0.0   \n",
       "387211                          0.0                           0.0   \n",
       "459452                          0.0                           0.0   \n",
       "451127                          0.0                           0.0   \n",
       "459214                          0.0                           0.0   \n",
       "118858                          0.0                           0.0   \n",
       "291418                          0.0                           0.0   \n",
       "473382                          0.0                           0.0   \n",
       "302721                          0.0                           0.0   \n",
       "401418                          0.0                           0.0   \n",
       "335737                          0.0                           0.0   \n",
       "407299                          0.0                           0.0   \n",
       "463858                          0.0                           0.0   \n",
       "63088                           0.0                           0.0   \n",
       "350252                          0.0                           0.0   \n",
       "329738                          0.0                           0.0   \n",
       "212434                          0.0                           0.0   \n",
       "210996                          0.0                           0.0   \n",
       "355909                          0.0                           0.0   \n",
       "517742                          0.0                           0.0   \n",
       "595062                          0.0                           0.0   \n",
       "122981                          0.0                           0.0   \n",
       "520134                          0.0                           0.0   \n",
       "208401                          0.0                           0.0   \n",
       "85848                           0.0                           0.0   \n",
       "24414                           0.0                           0.0   \n",
       "\n",
       "        ImagePositionPatient_1_f  ImagePositionPatient_1_enc_0  \\\n",
       "183829                  1.479996                           1.0   \n",
       "106245                  1.479996                           1.0   \n",
       "362507                  1.479996                           1.0   \n",
       "55311                   1.479996                           1.0   \n",
       "420941                  1.479996                           1.0   \n",
       "300366                  1.479996                           1.0   \n",
       "153659                  1.479996                           1.0   \n",
       "643991                  1.479996                           1.0   \n",
       "99751                   1.479996                           1.0   \n",
       "387211                  1.479996                           1.0   \n",
       "459452                  1.479996                           1.0   \n",
       "451127                  1.479996                           1.0   \n",
       "459214                  1.479996                           1.0   \n",
       "118858                  1.479996                           1.0   \n",
       "291418                  1.479996                           1.0   \n",
       "473382                  1.479996                           1.0   \n",
       "302721                  1.479996                           1.0   \n",
       "401418                  1.479996                           1.0   \n",
       "335737                  1.479996                           1.0   \n",
       "407299                  1.479996                           1.0   \n",
       "463858                  1.479996                           1.0   \n",
       "63088                   1.479996                           1.0   \n",
       "350252                  1.479996                           1.0   \n",
       "329738                  1.479996                           1.0   \n",
       "212434                  1.479996                           1.0   \n",
       "210996                  1.479996                           1.0   \n",
       "355909                  1.479996                           1.0   \n",
       "517742                  1.479996                           1.0   \n",
       "595062                  1.479996                           1.0   \n",
       "122981                  1.479996                           1.0   \n",
       "520134                  1.479996                           1.0   \n",
       "208401                  1.479996                           1.0   \n",
       "85848                   1.479996                           1.0   \n",
       "24414                   1.479996                           1.0   \n",
       "\n",
       "        ImagePositionPatient_2_f  ImagePositionPatient_2_f_r05  \\\n",
       "183829                 -0.147708                           0.0   \n",
       "106245                 -0.140544                           0.0   \n",
       "362507                 -0.133381                           0.0   \n",
       "55311                  -0.126218                           0.0   \n",
       "420941                 -0.119054                           0.0   \n",
       "300366                 -0.111891                           0.0   \n",
       "153659                 -0.104728                           0.0   \n",
       "643991                 -0.097564                           0.0   \n",
       "99751                  -0.090401                           0.0   \n",
       "387211                 -0.083238                           0.0   \n",
       "459452                 -0.076074                           0.0   \n",
       "451127                 -0.068911                           0.0   \n",
       "459214                 -0.061748                           0.0   \n",
       "118858                 -0.054585                           0.0   \n",
       "291418                 -0.047421                           0.0   \n",
       "473382                 -0.040258                           0.0   \n",
       "302721                 -0.033095                           0.0   \n",
       "401418                 -0.025931                           0.0   \n",
       "335737                 -0.018768                           0.0   \n",
       "407299                 -0.011605                           0.0   \n",
       "463858                 -0.004441                           0.0   \n",
       "63088                   0.002722                           0.0   \n",
       "350252                  0.009885                           0.0   \n",
       "329738                  0.017049                           0.0   \n",
       "212434                  0.024212                           0.0   \n",
       "210996                  0.031375                           0.0   \n",
       "355909                  0.038539                           0.0   \n",
       "517742                  0.045702                           0.0   \n",
       "595062                  0.052865                           0.0   \n",
       "122981                  0.060029                           0.0   \n",
       "520134                  0.067192                           0.0   \n",
       "208401                  0.074355                           0.0   \n",
       "85848                   0.081519                           0.0   \n",
       "24414                   0.088682                           0.0   \n",
       "\n",
       "        PixelSpacing_1_f  PixelSpacing_1_enc_0  PixelSpacing_1_enc_1  \\\n",
       "183829             -0.48                   1.0                 False   \n",
       "106245             -0.48                   1.0                 False   \n",
       "362507             -0.48                   1.0                 False   \n",
       "55311              -0.48                   1.0                 False   \n",
       "420941             -0.48                   1.0                 False   \n",
       "300366             -0.48                   1.0                 False   \n",
       "153659             -0.48                   1.0                 False   \n",
       "643991             -0.48                   1.0                 False   \n",
       "99751              -0.48                   1.0                 False   \n",
       "387211             -0.48                   1.0                 False   \n",
       "459452             -0.48                   1.0                 False   \n",
       "451127             -0.48                   1.0                 False   \n",
       "459214             -0.48                   1.0                 False   \n",
       "118858             -0.48                   1.0                 False   \n",
       "291418             -0.48                   1.0                 False   \n",
       "473382             -0.48                   1.0                 False   \n",
       "302721             -0.48                   1.0                 False   \n",
       "401418             -0.48                   1.0                 False   \n",
       "335737             -0.48                   1.0                 False   \n",
       "407299             -0.48                   1.0                 False   \n",
       "463858             -0.48                   1.0                 False   \n",
       "63088              -0.48                   1.0                 False   \n",
       "350252             -0.48                   1.0                 False   \n",
       "329738             -0.48                   1.0                 False   \n",
       "212434             -0.48                   1.0                 False   \n",
       "210996             -0.48                   1.0                 False   \n",
       "355909             -0.48                   1.0                 False   \n",
       "517742             -0.48                   1.0                 False   \n",
       "595062             -0.48                   1.0                 False   \n",
       "122981             -0.48                   1.0                 False   \n",
       "520134             -0.48                   1.0                 False   \n",
       "208401             -0.48                   1.0                 False   \n",
       "85848              -0.48                   1.0                 False   \n",
       "24414              -0.48                   1.0                 False   \n",
       "\n",
       "        WindowCenter_0_le  pos_max  pos_min  pos_size  pos_idx1  pos_idx  \\\n",
       "183829                  1   0.9156   0.2556      -0.1 -1.152542        0   \n",
       "106245                  1   0.9156   0.2556      -0.1 -1.084746        1   \n",
       "362507                  1   0.9156   0.2556      -0.1 -1.016949        2   \n",
       "55311                   1   0.9156   0.2556      -0.1 -0.949153        3   \n",
       "420941                  1   0.9156   0.2556      -0.1 -0.881356        4   \n",
       "300366                  1   0.9156   0.2556      -0.1 -0.813559        5   \n",
       "153659                  1   0.9156   0.2556      -0.1 -0.745763        6   \n",
       "643991                  1   0.9156   0.2556      -0.1 -0.677966        7   \n",
       "99751                   1   0.9156   0.2556      -0.1 -0.610169        8   \n",
       "387211                  1   0.9156   0.2556      -0.1 -0.542373        9   \n",
       "459452                  1   0.9156   0.2556      -0.1 -0.474576       10   \n",
       "451127                  1   0.9156   0.2556      -0.1 -0.406780       11   \n",
       "459214                  1   0.9156   0.2556      -0.1 -0.338983       12   \n",
       "118858                  1   0.9156   0.2556      -0.1 -0.271186       13   \n",
       "291418                  1   0.9156   0.2556      -0.1 -0.203390       14   \n",
       "473382                  1   0.9156   0.2556      -0.1 -0.135593       15   \n",
       "302721                  1   0.9156   0.2556      -0.1 -0.067797       16   \n",
       "401418                  1   0.9156   0.2556      -0.1  0.000000       17   \n",
       "335737                  1   0.9156   0.2556      -0.1  0.067797       18   \n",
       "407299                  1   0.9156   0.2556      -0.1  0.135593       19   \n",
       "463858                  1   0.9156   0.2556      -0.1  0.203390       20   \n",
       "63088                   1   0.9156   0.2556      -0.1  0.271186       21   \n",
       "350252                  1   0.9156   0.2556      -0.1  0.338983       22   \n",
       "329738                  1   0.9156   0.2556      -0.1  0.406780       23   \n",
       "212434                  1   0.9156   0.2556      -0.1  0.474576       24   \n",
       "210996                  1   0.9156   0.2556      -0.1  0.542373       25   \n",
       "355909                  1   0.9156   0.2556      -0.1  0.610169       26   \n",
       "517742                  1   0.9156   0.2556      -0.1  0.677966       27   \n",
       "595062                  1   0.9156   0.2556      -0.1  0.745763       28   \n",
       "122981                  1   0.9156   0.2556      -0.1  0.813559       29   \n",
       "520134                  1   0.9156   0.2556      -0.1  0.881356       30   \n",
       "208401                  1   0.9156   0.2556      -0.1  0.949153       31   \n",
       "85848                   1   0.9156   0.2556      -0.1  1.016949       32   \n",
       "24414                   1   0.9156   0.2556      -0.1  1.084746       33   \n",
       "\n",
       "        pos_idx2  pos_inc1  pos_inc2  pos_inc1_grp_le  pos_inc2_grp_le  \\\n",
       "183829  1.084746 -1.500000  1.500000                0                3   \n",
       "106245  1.016949  1.500000 -1.500000                3                3   \n",
       "362507  0.949153 -1.500000 -1.500000                3                3   \n",
       "55311   0.881356 -1.500000 -1.500000                3                3   \n",
       "420941  0.813559 -1.500000 -1.500000                3                3   \n",
       "300366  0.745763 -1.500000 -1.500000                3                3   \n",
       "153659  0.677966 -1.500000 -1.500000                3                3   \n",
       "643991  0.610169 -1.500000  1.500000                3                3   \n",
       "99751   0.542373  1.500000 -1.500000                3                3   \n",
       "387211  0.474576 -1.500000 -1.500000                3                3   \n",
       "459452  0.406780 -1.500000  1.499969                3                3   \n",
       "451127  0.338983  1.499969 -1.500000                3                3   \n",
       "459214  0.271186 -1.500000  1.500000                3                3   \n",
       "118858  0.203390  1.500000 -1.500000                3                3   \n",
       "291418  0.135593 -1.500000 -1.500000                3                3   \n",
       "473382  0.067797 -1.500000 -1.500000                3                3   \n",
       "302721  0.000000 -1.500000 -1.500000                3                3   \n",
       "401418 -0.067797 -1.500000 -1.500000                3                3   \n",
       "335737 -0.135593 -1.500000 -1.500000                3                3   \n",
       "407299 -0.203390 -1.500000 -1.500000                3                3   \n",
       "463858 -0.271186 -1.500000 -1.500000                3                3   \n",
       "63088  -0.338983 -1.500000 -1.500000                3                3   \n",
       "350252 -0.406780 -1.500000 -1.500000                3                3   \n",
       "329738 -0.474576 -1.500000 -1.500000                3                3   \n",
       "212434 -0.542373 -1.500000 -1.500000                3                3   \n",
       "210996 -0.610169 -1.500000 -1.500000                3                3   \n",
       "355909 -0.677966 -1.500000 -1.500000                3                3   \n",
       "517742 -0.745763 -1.500000 -1.500000                3                3   \n",
       "595062 -0.813559 -1.500000 -1.500000                3                3   \n",
       "122981 -0.881356 -1.500000 -1.500000                3                3   \n",
       "520134 -0.949153 -1.500000 -1.500000                3                3   \n",
       "208401 -1.016949 -1.500000 -1.500000                3                3   \n",
       "85848  -1.084746 -1.500000 -1.500000                3                3   \n",
       "24414  -1.152542 -1.500000 -1.500000                3                0   \n",
       "\n",
       "        pos_inc1_r1  pos_inc1_r0001  pos_inc1_enc_0  pos_inc2_enc_0  \\\n",
       "183829          1.0             1.0             1.0             0.0   \n",
       "106245          1.0             1.0             0.0             0.0   \n",
       "362507          1.0             1.0             0.0             0.0   \n",
       "55311           1.0             1.0             0.0             0.0   \n",
       "420941          1.0             1.0             0.0             0.0   \n",
       "300366          1.0             1.0             0.0             0.0   \n",
       "153659          1.0             1.0             0.0             0.0   \n",
       "643991          1.0             1.0             0.0             0.0   \n",
       "99751           0.0             0.0             0.0             0.0   \n",
       "387211          1.0             1.0             0.0             0.0   \n",
       "459452          1.0             1.0             0.0             0.0   \n",
       "451127          0.0             0.0             0.0             0.0   \n",
       "459214          1.0             1.0             0.0             0.0   \n",
       "118858          1.0             1.0             0.0             0.0   \n",
       "291418          1.0             1.0             0.0             0.0   \n",
       "473382          1.0             1.0             0.0             0.0   \n",
       "302721          1.0             1.0             0.0             0.0   \n",
       "401418          1.0             1.0             0.0             0.0   \n",
       "335737          1.0             1.0             0.0             0.0   \n",
       "407299          1.0             1.0             0.0             0.0   \n",
       "463858          1.0             1.0             0.0             0.0   \n",
       "63088           1.0             1.0             0.0             0.0   \n",
       "350252          1.0             1.0             0.0             0.0   \n",
       "329738          1.0             1.0             0.0             0.0   \n",
       "212434          1.0             1.0             0.0             0.0   \n",
       "210996          1.0             1.0             0.0             0.0   \n",
       "355909          1.0             1.0             0.0             0.0   \n",
       "517742          1.0             1.0             0.0             0.0   \n",
       "595062          1.0             1.0             0.0             0.0   \n",
       "122981          1.0             1.0             0.0             0.0   \n",
       "520134          1.0             1.0             0.0             0.0   \n",
       "208401          1.0             1.0             0.0             0.0   \n",
       "85848           1.0             1.0             0.0             0.0   \n",
       "24414           1.0             1.0             0.0             1.0   \n",
       "\n",
       "        pos_inc1_enc_1  pos_inc2_enc_1  pos_size_le  pos_range   pos_rel  \\\n",
       "183829             0.0             0.0            4  -0.000002 -2.000000   \n",
       "106245             0.0             1.0            4  -0.000002 -1.878788   \n",
       "362507             1.0             1.0            4  -0.000002 -1.757576   \n",
       "55311              1.0             1.0            4  -0.000002 -1.636364   \n",
       "420941             1.0             1.0            4  -0.000002 -1.515151   \n",
       "300366             1.0             1.0            4  -0.000002 -1.393939   \n",
       "153659             1.0             1.0            4  -0.000002 -1.272727   \n",
       "643991             1.0             0.0            4  -0.000002 -1.151515   \n",
       "99751              0.0             1.0            4  -0.000002 -1.030303   \n",
       "387211             1.0             1.0            4  -0.000002 -0.909091   \n",
       "459452             1.0             0.0            4  -0.000002 -0.787878   \n",
       "451127             0.0             1.0            4  -0.000002 -0.666668   \n",
       "459214             1.0             0.0            4  -0.000002 -0.545455   \n",
       "118858             0.0             1.0            4  -0.000002 -0.424243   \n",
       "291418             1.0             1.0            4  -0.000002 -0.303031   \n",
       "473382             1.0             1.0            4  -0.000002 -0.181819   \n",
       "302721             1.0             1.0            4  -0.000002 -0.060607   \n",
       "401418             1.0             1.0            4  -0.000002  0.060605   \n",
       "335737             1.0             1.0            4  -0.000002  0.181818   \n",
       "407299             1.0             1.0            4  -0.000002  0.303030   \n",
       "463858             1.0             1.0            4  -0.000002  0.424242   \n",
       "63088              1.0             1.0            4  -0.000002  0.545454   \n",
       "350252             1.0             1.0            4  -0.000002  0.666666   \n",
       "329738             1.0             1.0            4  -0.000002  0.787878   \n",
       "212434             1.0             1.0            4  -0.000002  0.909091   \n",
       "210996             1.0             1.0            4  -0.000002  1.030303   \n",
       "355909             1.0             1.0            4  -0.000002  1.151515   \n",
       "517742             1.0             1.0            4  -0.000002  1.272727   \n",
       "595062             1.0             1.0            4  -0.000002  1.393939   \n",
       "122981             1.0             1.0            4  -0.000002  1.515151   \n",
       "520134             1.0             1.0            4  -0.000002  1.636364   \n",
       "208401             1.0             1.0            4  -0.000002  1.757576   \n",
       "85848              1.0             1.0            4  -0.000002  1.878788   \n",
       "24414              1.0             0.0            4  -0.000002  2.000000   \n",
       "\n",
       "        pos_zeros  pos_inc_rng  pos_zeros_le  any  epidural  intraparenchymal  \\\n",
       "183829        0.0    -0.599976             0    0         0                 0   \n",
       "106245        0.0    -0.599976             0    0         0                 0   \n",
       "362507        0.0    -0.599976             0    0         0                 0   \n",
       "55311         0.0    -0.599976             0    0         0                 0   \n",
       "420941        0.0    -0.599976             0    0         0                 0   \n",
       "300366        0.0    -0.599976             0    0         0                 0   \n",
       "153659        0.0    -0.599976             0    0         0                 0   \n",
       "643991        0.0    -0.599976             0    0         0                 0   \n",
       "99751         0.0    -0.599976             0    1         0                 0   \n",
       "387211        0.0    -0.599976             0    1         0                 1   \n",
       "459452        0.0    -0.599976             0    1         0                 1   \n",
       "451127        0.0    -0.599976             0    1         0                 1   \n",
       "459214        0.0    -0.599976             0    1         0                 1   \n",
       "118858        0.0    -0.599976             0    1         0                 1   \n",
       "291418        0.0    -0.599976             0    1         0                 1   \n",
       "473382        0.0    -0.599976             0    1         0                 1   \n",
       "302721        0.0    -0.599976             0    1         0                 1   \n",
       "401418        0.0    -0.599976             0    1         0                 1   \n",
       "335737        0.0    -0.599976             0    1         0                 0   \n",
       "407299        0.0    -0.599976             0    1         0                 1   \n",
       "463858        0.0    -0.599976             0    1         0                 1   \n",
       "63088         0.0    -0.599976             0    1         0                 1   \n",
       "350252        0.0    -0.599976             0    1         0                 1   \n",
       "329738        0.0    -0.599976             0    1         0                 1   \n",
       "212434        0.0    -0.599976             0    1         0                 1   \n",
       "210996        0.0    -0.599976             0    1         0                 1   \n",
       "355909        0.0    -0.599976             0    1         0                 0   \n",
       "517742        0.0    -0.599976             0    1         0                 0   \n",
       "595062        0.0    -0.599976             0    0         0                 0   \n",
       "122981        0.0    -0.599976             0    0         0                 0   \n",
       "520134        0.0    -0.599976             0    0         0                 0   \n",
       "208401        0.0    -0.599976             0    0         0                 0   \n",
       "85848         0.0    -0.599976             0    0         0                 0   \n",
       "24414         0.0    -0.599976             0    0         0                 0   \n",
       "\n",
       "        intraventricular  subarachnoid  subdural  PxlMin_grp_le   weights  \\\n",
       "183829                 0             0         0              2  0.034987   \n",
       "106245                 0             0         0              2  0.034987   \n",
       "362507                 0             0         0              2  0.034987   \n",
       "55311                  0             0         0              2  0.034987   \n",
       "420941                 0             0         0              2  0.034987   \n",
       "300366                 0             0         0              2  0.034987   \n",
       "153659                 0             0         0              2  0.034987   \n",
       "643991                 0             0         0              2  0.034987   \n",
       "99751                  0             1         0              2  0.034987   \n",
       "387211                 0             1         0              2  0.034987   \n",
       "459452                 0             1         0              2  0.034987   \n",
       "451127                 0             1         0              2  0.034987   \n",
       "459214                 0             1         0              2  0.034987   \n",
       "118858                 0             1         0              2  0.034987   \n",
       "291418                 0             1         0              2  0.034987   \n",
       "473382                 0             1         0              2  0.034987   \n",
       "302721                 0             1         0              2  0.034987   \n",
       "401418                 0             1         0              2  0.034987   \n",
       "335737                 0             1         0              2  0.034987   \n",
       "407299                 0             1         0              2  0.034987   \n",
       "463858                 0             1         0              2  0.034987   \n",
       "63088                  0             1         0              2  0.034987   \n",
       "350252                 0             1         0              2  0.034987   \n",
       "329738                 0             1         0              2  0.034987   \n",
       "212434                 0             1         0              2  0.034987   \n",
       "210996                 0             1         0              2  0.034987   \n",
       "355909                 0             1         0              2  0.034987   \n",
       "517742                 0             1         0              2  0.034987   \n",
       "595062                 0             0         0              2  0.034987   \n",
       "122981                 0             0         0              2  0.034987   \n",
       "520134                 0             0         0              2  0.034987   \n",
       "208401                 0             0         0              2  0.034987   \n",
       "85848                  0             0         0              2  0.034987   \n",
       "24414                  0             0         0              2  0.034987   \n",
       "\n",
       "            any2  epidural2  intraparenchymal2  intraventricular2  \\\n",
       "183829  0.000839   0.000099           0.000168           0.000138   \n",
       "106245  0.000584   0.000054           0.000185           0.000118   \n",
       "362507  0.001178   0.000100           0.000323           0.000155   \n",
       "55311   0.001729   0.000112           0.000339           0.000157   \n",
       "420941  0.001685   0.000111           0.000288           0.000189   \n",
       "300366  0.001612   0.000125           0.000305           0.000177   \n",
       "153659  0.003401   0.000254           0.000714           0.000404   \n",
       "643991  0.013303   0.000935           0.002368           0.001195   \n",
       "99751   0.099510   0.003812           0.032196           0.003922   \n",
       "387211  0.543668   0.009774           0.322572           0.005362   \n",
       "459452  0.918656   0.024115           0.763064           0.006704   \n",
       "451127  0.933054   0.019543           0.762358           0.005252   \n",
       "459214  0.920954   0.020513           0.770226           0.007980   \n",
       "118858  0.893019   0.011949           0.717446           0.006604   \n",
       "291418  0.980438   0.009472           0.960037           0.007377   \n",
       "473382  0.992883   0.005158           0.988262           0.006374   \n",
       "302721  0.991860   0.004986           0.989301           0.008418   \n",
       "401418  0.969767   0.005849           0.967911           0.014270   \n",
       "335737  0.336236   0.005383           0.302861           0.005350   \n",
       "407299  0.281014   0.007053           0.178869           0.006009   \n",
       "463858  0.566976   0.006558           0.428909           0.005297   \n",
       "63088   0.983561   0.005313           0.975370           0.006219   \n",
       "350252  0.991035   0.004644           0.985321           0.003356   \n",
       "329738  0.986074   0.005986           0.979739           0.004869   \n",
       "212434  0.815646   0.013105           0.688247           0.003345   \n",
       "210996  0.405491   0.014217           0.102302           0.001918   \n",
       "355909  0.234505   0.008246           0.016757           0.001161   \n",
       "517742  0.140069   0.004162           0.005150           0.000746   \n",
       "595062  0.061963   0.001527           0.002038           0.000626   \n",
       "122981  0.008272   0.000297           0.000405           0.000291   \n",
       "520134  0.000764   0.000073           0.000112           0.000127   \n",
       "208401  0.000222   0.000034           0.000052           0.000097   \n",
       "85848   0.000032   0.000015           0.000042           0.000029   \n",
       "24414   0.000074   0.000035           0.000052           0.000050   \n",
       "\n",
       "        subarachnoid2  subdural2  \n",
       "183829       0.000511   0.000372  \n",
       "106245       0.000284   0.000325  \n",
       "362507       0.000567   0.000675  \n",
       "55311        0.000622   0.001050  \n",
       "420941       0.000711   0.001004  \n",
       "300366       0.000802   0.001155  \n",
       "153659       0.001726   0.002313  \n",
       "643991       0.005325   0.007825  \n",
       "99751        0.032839   0.037040  \n",
       "387211       0.135512   0.124260  \n",
       "459452       0.315124   0.261145  \n",
       "451127       0.455088   0.252591  \n",
       "459214       0.563334   0.263610  \n",
       "118858       0.444525   0.180911  \n",
       "291418       0.337606   0.172147  \n",
       "473382       0.186669   0.121601  \n",
       "302721       0.135515   0.110268  \n",
       "401418       0.115135   0.092102  \n",
       "335737       0.079112   0.059441  \n",
       "407299       0.101448   0.072873  \n",
       "463858       0.104829   0.094247  \n",
       "63088        0.126935   0.121928  \n",
       "350252       0.142108   0.139003  \n",
       "329738       0.142797   0.163557  \n",
       "212434       0.161910   0.209642  \n",
       "210996       0.104954   0.227080  \n",
       "355909       0.061094   0.179025  \n",
       "517742       0.030422   0.122967  \n",
       "595062       0.012903   0.044199  \n",
       "122981       0.001939   0.005390  \n",
       "520134       0.000305   0.000570  \n",
       "208401       0.000101   0.000146  \n",
       "85848        0.000035   0.000051  \n",
       "24414        0.000076   0.000071  \n",
       "\n",
       "[34 rows x 102 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_md.loc[train_md.SeriesInstanceUID == 'ID_91616854b0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = train_md[['SeriesInstanceUID','PatientID']].groupby('PatientID').agg(lambda x: x.nunique())\n",
    "\n",
    "tt = tt.sort_values('SeriesInstanceUID',ascending=False)\n",
    "\n",
    "tt.loc[tt.SeriesInstanceUID == 6].head()\n",
    "\n",
    "pp = preds_all.mean((0,1))\n",
    "\n",
    "train_md = pd.concat([train_md, pd.DataFrame(pp,columns=[s+'2' for s in all_ich])],axis=1)\n",
    "\n",
    "train_md = train_md.sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(30, 10))\n",
    "serieses = train_md.loc[train_md.PatientID == 'ID_f41d724c'].SeriesInstanceUID.unique()\n",
    "print('total number of serieses', len(serieses))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i >= len(serieses): continue\n",
    "    ser = serieses[i]\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any'].values)\n",
    "    a = ax.plot(train_md.loc[train_md.SeriesInstanceUID == ser,'any2'].values)\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title(ser)\n",
    "\n",
    "train_md.loc[train_md.SeriesInstanceUID == 'ID_5752d1b055']\n",
    "\n",
    "\n",
    "\n",
    "sums1 = train_md[['SeriesInstanceUID'] + [s+'2' for s in all_ich]].groupby('SeriesInstanceUID').mean()\n",
    "\n",
    "sums2 = train_md[['PatientID'] + [s+'2' for s in all_ich]].groupby('PatientID').mean()\n",
    "\n",
    "train_md = train_md.join(sums1, on = 'SeriesInstanceUID',rsuffix='_s')\n",
    "\n",
    "train_md = train_md.join(sums2, on = 'PatientID',rsuffix='_p')\n",
    "\n",
    "train_md.head()\n",
    "\n",
    "lls = np.zeros(6)\n",
    "for i,col in enumerate(all_ich):\n",
    "    ll = log_loss(train_md[col], train_md[col+'2'])\n",
    "    lls[i] = ll\n",
    "    print('{:20s}{}'.format(col, ll))\n",
    "print('total',(lls*class_weights).mean())\n",
    "\n",
    "lls = np.zeros(6)\n",
    "for i,col in enumerate(all_ich):\n",
    "    ll = log_loss(train_md[col], train_md[col+'2']*(train_md[col+'2_p']/train_md[col+'2_s'])**0.01)\n",
    "    lls[i] = ll\n",
    "    print('{:20s}{}'.format(col, ll))\n",
    "print('total',(lls*class_weights).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting models aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    0.058905\n",
      "gmean   0.059180\n",
      "q50     0.059230\n",
      "q25     0.060806\n",
      "q75     0.059752\n",
      "psig    0.059120\n"
     ]
    }
   ],
   "source": [
    "for afunc in afuncs_names:\n",
    "    #print(afunc)\n",
    "    apreds = applyAggFunc(preds2, afunc, axis=0)\n",
    "    res = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()\n",
    "    \n",
    "    if False:\n",
    "        best_score = res\n",
    "        best_k = 0\n",
    "        for k in range(1,50):\n",
    "            apreds2 = scalePreds(apreds, 1.0 + 0.01 * k)\n",
    "            apreds2 = np.clip(apreds2, 1e-15, 1-1e-15)\n",
    "\n",
    "            res2 = ((- train_md[all_ich].values * np.log(apreds2) - (1 - train_md[all_ich].values) * np.log(1 - apreds2))\\\n",
    "                    * class_weights).mean()\n",
    "\n",
    "            if res2 > best_score: break\n",
    "            best_score = res2\n",
    "            best_k = k\n",
    "\n",
    "        print('{:7s} {:5f}   {:2f} {:5f}'.format(afunc,res,1+0.01*best_k,best_score))\n",
    "    else:\n",
    "        print('{:7s} {:5f}'.format(afunc,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0589051240716035"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*(np.concatenate([np.ones(4)/8,np.ones(4)/8]))[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05925450523588664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*(np.concatenate([np.zeros(4),np.ones(4)/4]))[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058978989694675375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apreds = (preds2*(np.concatenate([np.ones(4)/16,3*np.ones(4)/16]))[:,None,None]).sum(0)\n",
    "((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "        * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_afunc = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 674252, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06268, 0.06259, 0.06242, 0.06195])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- train_md[all_ich].values * np.log(preds_all) \n",
    "  - (1 - train_md[all_ich].values) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    best_score = res\n",
    "    best_k = 0\n",
    "    for k in range(1,50):\n",
    "        apreds = scalePreds(preds_all, 1.0 + 0.01 * k)\n",
    "        apreds = np.clip(apreds, 1e-15, 1-1e-15)\n",
    "\n",
    "        res2 = ((- train_md[all_ich].values * np.log(apreds) - (1 - train_md[all_ich].values) * np.log(1 - apreds))\\\n",
    "                * class_weights).mean()\n",
    "\n",
    "        if res2 > best_score: break\n",
    "        best_score = res2\n",
    "        best_k = k\n",
    "\n",
    "    print('{{:5f}   {:2f} {:5f}'.format(res,1+0.01*best_k,best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models behavior per groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WindowCenter_1_le     0 248151   2157 [0.03754 0.03719 0.03679 0.03699 0.03656 0.03676 0.037   0.03685]\n",
      "WindowCenter_1_le     2  10377     34 [0.11828 0.11642 0.11726 0.11536 0.11701 0.11623 0.11605 0.11333]\n",
      "WindowCenter_1_le     3 341674  75369 [0.06474 0.06439 0.06526 0.06359 0.06427 0.06427 0.06513 0.06314]\n",
      "WindowCenter_1_le     1  70894    985 [0.12907 0.12632 0.12904 0.12675 0.12683 0.12644 0.12791 0.12472]\n",
      "WindowCenter_1_le     4   3156      0 [0.09075 0.09554 0.09205 0.08595 0.09443 0.09397 0.09533 0.0886 ]\n",
      "BitType_le            1 323550   3088 [0.05799 0.0573  0.05758 0.05716 0.05684 0.05697 0.05747 0.05667]\n",
      "BitType_le            0 338723  75369 [0.06411 0.06378 0.0646  0.06293 0.06364 0.06366 0.06451 0.06249]\n",
      "BitType_le            2   2252     60 [0.12818 0.12513 0.12613 0.12392 0.13314 0.12856 0.12732 0.12169]\n",
      "BitType_le            4   6776     28 [0.13693 0.12889 0.12844 0.12693 0.1308  0.12802 0.1291  0.12263]\n",
      "BitType_le            3   2951      0 [0.13769 0.13434 0.14018 0.13928 0.13676 0.1339  0.13665 0.13799]\n",
      "WindowCenter_0_le     1 248151   2157 [0.03754 0.03719 0.03679 0.03699 0.03656 0.03676 0.037   0.03685]\n",
      "WindowCenter_0_le     4  10343     34 [0.11838 0.11662 0.1173  0.11543 0.11717 0.1164  0.11612 0.11339]\n",
      "WindowCenter_0_le     2 151196   2148 [0.1232  0.12122 0.12367 0.12085 0.12164 0.1212  0.12283 0.1196 ]\n",
      "WindowCenter_0_le     0 213404  69272 [0.0356  0.03576 0.03592 0.03505 0.03564 0.03574 0.03624 0.03493]\n",
      "WindowCenter_0_le     3  43648   4934 [0.10603 0.10517 0.10645 0.10424 0.10382 0.10419 0.10524 0.10254]\n",
      "WindowCenter_0_le     6   3553      0 [0.0863  0.0899  0.08581 0.08013 0.09024 0.08986 0.08956 0.08275]\n",
      "WindowCenter_0_le     5   3957      0 [0.10166 0.09817 0.1068  0.10114 0.10183 0.10133 0.10354 0.09903]\n",
      "pos_inc1_grp_le       3 589641  59576 [0.06549 0.0647  0.06535 0.06444 0.06446 0.06446 0.0652  0.06381]\n",
      "pos_inc1_grp_le       0  25148   3724 [0.03066 0.0299  0.03029 0.02929 0.0314  0.03124 0.0302  0.03054]\n",
      "pos_inc1_grp_le       1  51896  14995 [0.03733 0.0386  0.03823 0.0359  0.03773 0.03778 0.03873 0.03615]\n",
      "pos_inc1_grp_le       2   7567    250 [0.10276 0.1043  0.10583 0.1005  0.10306 0.10447 0.10491 0.09895]\n",
      "pos_inc2_grp_le       3 589642  59576 [0.06603 0.06522 0.06589 0.06498 0.065   0.06497 0.06574 0.06432]\n",
      "pos_inc2_grp_le       0  25147   3724 [0.02662 0.02652 0.02648 0.0254  0.02713 0.02825 0.02621 0.02695]\n",
      "pos_inc2_grp_le       1  51896  14995 [0.03446 0.03574 0.03538 0.0331  0.03514 0.03503 0.03596 0.0334 ]\n",
      "pos_inc2_grp_le       2   7567    250 [0.09397 0.09426 0.09629 0.09117 0.09305 0.09377 0.09503 0.08997]\n",
      "pos_size_le          10 113357   7349 [0.05377 0.05336 0.05314 0.05246 0.05343 0.05339 0.05352 0.05258]\n",
      "pos_size_le           2  78912   9072 [0.05846 0.05841 0.05939 0.05796 0.05839 0.05835 0.05889 0.05762]\n",
      "pos_size_le           3  52218   9884 [0.07602 0.07416 0.07576 0.07413 0.07514 0.07404 0.07571 0.07283]\n",
      "pos_size_le           0 156544  21824 [0.07402 0.07334 0.07436 0.07271 0.07319 0.07324 0.07407 0.07191]\n",
      "pos_size_le           7  30393    231 [0.03408 0.03338 0.03309 0.03375 0.0328  0.0327  0.03287 0.03406]\n",
      "pos_size_le           8  25270   1596 [0.05737 0.05755 0.05649 0.05675 0.05463 0.05686 0.05649 0.05595]\n",
      "pos_size_le           4  51508    884 [0.07359 0.07292 0.07389 0.07346 0.07286 0.07248 0.07423 0.07224]\n",
      "pos_size_le           5  33180    930 [0.10807 0.10402 0.1057  0.10399 0.10576 0.10473 0.10443 0.10306]\n",
      "pos_size_le           1  79040  21840 [0.04457 0.04484 0.04527 0.04399 0.04376 0.04414 0.04515 0.04386]\n",
      "pos_size_le           6  32270    315 [0.04138 0.04146 0.04155 0.0416  0.04014 0.04106 0.04192 0.04143]\n",
      "pos_size_le           9  21560   4620 [0.05172 0.05214 0.0515  0.04966 0.0509  0.0513  0.05153 0.04895]\n",
      "pos_zeros_le          0 669377  77188 [0.06225 0.06165 0.0622  0.06117 0.06139 0.06138 0.06208 0.06062]\n",
      "pos_zeros_le          3   2665    917 [0.10061 0.09651 0.10214 0.09344 0.10265 0.10859 0.10435 0.09879]\n",
      "pos_zeros_le          2   1132    332 [0.08937 0.08674 0.08746 0.08854 0.08971 0.09384 0.09184 0.09408]\n",
      "pos_zeros_le          1   1078    108 [0.05822 0.0633  0.06831 0.06056 0.06124 0.0629  0.07016 0.06182]\n",
      "WindowWidth_0_le      0 541489  72448 [0.05015 0.04967 0.04991 0.04935 0.04941 0.04948 0.04997 0.04893]\n",
      "WindowWidth_0_le      1  63927    921 [0.1146  0.11291 0.11504 0.11176 0.11392 0.11343 0.11464 0.11147]\n",
      "WindowWidth_0_le      2  30067   4308 [0.09336 0.0928  0.09517 0.09161 0.093   0.09253 0.09452 0.0912 ]\n",
      "WindowWidth_0_le      3  31237    762 [0.13246 0.13112 0.13263 0.13015 0.12933 0.12951 0.13091 0.12774]\n",
      "WindowWidth_0_le      5   5389     90 [0.08139 0.08339 0.08448 0.08302 0.07962 0.08062 0.08526 0.0805 ]\n",
      "WindowWidth_0_le      4   2143     16 [0.1088  0.11343 0.11194 0.1049  0.10881 0.11158 0.10959 0.10588]\n",
      "WindowWidth_1_le      0 329597   3176 [0.05977 0.05886 0.05917 0.05877 0.05852 0.05856 0.05905 0.05817]\n",
      "WindowWidth_1_le      1 341674  75369 [0.06474 0.06439 0.06526 0.06359 0.06427 0.06427 0.06513 0.06314]\n",
      "WindowWidth_1_le      2   2981      0 [0.09309 0.09853 0.09519 0.08769 0.0968  0.09617 0.09789 0.08997]\n",
      "PxlMin_grp_le         2 363504   3934 [0.06615 0.06525 0.06563 0.065   0.06477 0.06482 0.0654  0.06427]\n",
      "PxlMin_grp_le         1  83433   1095 [0.11636 0.11505 0.11728 0.11371 0.11551 0.11513 0.11678 0.11312]\n",
      "PxlMin_grp_le         0 227315  73516 [0.03671 0.03685 0.03712 0.03627 0.03676 0.03687 0.03737 0.03614]\n"
     ]
    }
   ],
   "source": [
    "for col in cols_le:\n",
    "    for i in train_md[col].unique():\n",
    "        res = ((- train_md[all_ich].values * np.log(preds_all.mean(1)) - (1 - train_md[all_ich].values) \\\n",
    "                * np.log(1 - preds_all.mean(1))) * class_weights)[:,(train_md[col] == i)].mean((1,2))\n",
    "        sz = (train_md[col] == i).sum()\n",
    "        sz_test = (test_md[col] == i).sum()\n",
    "        print('{:20s} {:2d} {:6d} {:6d} {}'.format(col,i,sz,sz_test,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PxlMin_grp_le         2 any                  363504   3934 [0.10395 0.10279 0.10281 0.10252 0.10261 0.103   0.10377 0.10255]\n",
      "PxlMin_grp_le         1 any                   83433   1095 [0.18196 0.17981 0.1821  0.17766 0.18249 0.18235 0.1828  0.17839]\n",
      "PxlMin_grp_le         0 any                  227315  73516 [0.06435 0.06464 0.06487 0.06336 0.06476 0.06512 0.06577 0.06412]\n",
      "PxlMin_grp_le         2 epidural             363504   3934 [0.01702 0.01776 0.01722 0.01757 0.01783 0.01777 0.01732 0.01544]\n",
      "PxlMin_grp_le         1 epidural              83433   1095 [0.02218 0.02326 0.02527 0.0242  0.02376 0.02341 0.0243  0.02053]\n",
      "PxlMin_grp_le         0 epidural             227315  73516 [0.01231 0.01366 0.01299 0.01279 0.01327 0.01387 0.01382 0.01163]\n",
      "PxlMin_grp_le         2 intraparenchymal     363504   3934 [0.04702 0.04555 0.04753 0.04491 0.04441 0.04455 0.04546 0.04434]\n",
      "PxlMin_grp_le         1 intraparenchymal      83433   1095 [0.0879  0.08405 0.08973 0.0842  0.08421 0.08298 0.08739 0.08412]\n",
      "PxlMin_grp_le         0 intraparenchymal     227315  73516 [0.02321 0.02288 0.02356 0.02277 0.0228  0.02267 0.02333 0.02231]\n",
      "PxlMin_grp_le         2 intraventricular     363504   3934 [0.02567 0.02499 0.02586 0.02512 0.02466 0.02434 0.02522 0.02479]\n",
      "PxlMin_grp_le         1 intraventricular      83433   1095 [0.06925 0.06802 0.07146 0.06848 0.06773 0.06774 0.0709  0.06827]\n",
      "PxlMin_grp_le         0 intraventricular     227315  73516 [0.01181 0.01142 0.01221 0.01157 0.01126 0.01112 0.01189 0.01133]\n",
      "PxlMin_grp_le         2 subarachnoid         363504   3934 [0.07405 0.07273 0.07322 0.07215 0.07155 0.07154 0.07247 0.07117]\n",
      "PxlMin_grp_le         1 subarachnoid          83433   1095 [0.12831 0.12705 0.12803 0.12445 0.1257  0.12666 0.12691 0.12493]\n",
      "PxlMin_grp_le         0 subarachnoid         227315  73516 [0.03469 0.03427 0.03478 0.03424 0.03469 0.03403 0.03445 0.03414]\n",
      "PxlMin_grp_le         2 subdural             363504   3934 [0.09141 0.09011 0.08999 0.09023 0.0897  0.08951 0.08976 0.08907]\n",
      "PxlMin_grp_le         1 subdural              83433   1095 [0.14299 0.14334 0.1423  0.13929 0.14222 0.14041 0.1424  0.13723]\n",
      "PxlMin_grp_le         0 subdural             227315  73516 [0.04624 0.04648 0.04659 0.04578 0.04577 0.04613 0.04656 0.04529]\n"
     ]
    }
   ],
   "source": [
    "col = 'PxlMin_grp_le'\n",
    "for k in range(6):\n",
    "    for i in train_md[col].unique():\n",
    "        res = (- train_md[all_ich[k]].values * np.log(preds_all.mean(1)[:,:,k]) - (1 - train_md[all_ich[k]].values) \\\n",
    "                * np.log(1 - preds_all.mean(1)[:,:,k]))[:,(train_md[col] == i)].mean(1)\n",
    "        sz = (train_md[col] == i).sum()\n",
    "        sz_test = (test_md[col] == i).sum()\n",
    "        print('{:20s} {:2d} {:20s} {:6d} {:6d} {}'.format(col,i,all_ich[k],sz,sz_test,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>any</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PxlMin_grp_le</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>212492</td>\n",
       "      <td>14823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>56254</td>\n",
       "      <td>27179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>308403</td>\n",
       "      <td>55101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "any                 0      1\n",
       "PxlMin_grp_le               \n",
       "0              212492  14823\n",
       "1               56254  27179\n",
       "2              308403  55101"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab([train_md['PxlMin_grp_le']], [train_md[all_ich[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (8, 32, 674252, 6) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6c3b567b7cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m--> 217\u001b[0;31m                keepdims=keepdims)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (8, 32, 674252, 6) and data type float64"
     ]
    }
   ],
   "source": [
    "stds = preds_all.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00663, 0.00082, 0.00371, 0.00237, 0.00463, 0.00465],\n",
       "       [0.00653, 0.00076, 0.00331, 0.00226, 0.00419, 0.00432],\n",
       "       [0.01035, 0.00107, 0.00553, 0.00373, 0.00675, 0.00676],\n",
       "       [0.00783, 0.00065, 0.00383, 0.00267, 0.00484, 0.00487],\n",
       "       [0.00585, 0.00061, 0.00281, 0.00171, 0.00363, 0.0036 ],\n",
       "       [0.00608, 0.00067, 0.00278, 0.00178, 0.00325, 0.00362],\n",
       "       [0.01031, 0.00072, 0.00515, 0.00293, 0.00594, 0.00608],\n",
       "       [0.0078 , 0.00073, 0.00368, 0.00236, 0.00467, 0.00449]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds.mean((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 674252, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0721  0.69844 0.04717 0.87074 0.90913 0.38538 0.47888 0.49287]\n",
      "[0.65942 0.14143 0.80356 0.20604 0.03734 0.7852  0.74105 0.29836]\n",
      "[0.93923 0.87878 0.88173 0.10275 0.9006  0.17714 0.87711 0.22097]\n",
      "[0.92357 0.05838 0.82988 0.1811  0.91063 0.91305 0.1835  0.28412]\n",
      "[0.23838 0.77077 0.26534 0.11955 0.63966 0.28781 0.76715 0.17522]\n",
      "[0.75192 0.22898 0.87654 0.65612 0.38861 0.84263 0.21847 0.60288]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    idx = stds[0,:,i].argmax()\n",
    "    print(preds_all[0,:,idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89607 0.12613 0.89643 0.10395 0.8919  0.10412 0.12296 0.10019]\n",
      "[0.29146 0.09448 0.08381 0.29124 0.25786 0.27932 0.26    0.17203]\n",
      "[0.9805  0.96471 0.96605 0.97915 0.96169 0.12889 0.20027 0.15312]\n",
      "[0.88048 0.84696 0.0523  0.05313 0.06338 0.23104 0.20848 0.92539]\n",
      "[0.79051 0.40486 0.24571 0.92017 0.90041 0.22817 0.2481  0.90389]\n",
      "[0.14481 0.74231 0.74153 0.14874 0.15549 0.66152 0.74362 0.17278]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    idx = stds[3,:,i].argmax()\n",
    "    print(preds_all[3,:,idx,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14491, 0.00945, 0.03508, 0.02361, 0.05398, 0.06132],\n",
       "       [0.14669, 0.01034, 0.03552, 0.02403, 0.05463, 0.06025],\n",
       "       [0.14752, 0.00944, 0.03492, 0.02384, 0.05311, 0.06174],\n",
       "       [0.14552, 0.01318, 0.03636, 0.02443, 0.05468, 0.06079]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean(1, keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean(1, keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05472, 0.05524, 0.05509, 0.05582])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean(1, keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean(1, keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6043 , 0.60165, 0.59441, 0.6038 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds_all.mean((1,2), keepdims=True) * np.log(preds_all) \n",
    "  - (1 - preds_all.mean((1,2), keepdims=True)) * np.log(np.clip(1 - preds_all,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.741 time per batch: 0.174\n",
      "B20 -> time passed: 2.345 time per batch: 0.117\n",
      "B30 -> time passed: 3.156 time per batch: 0.105\n",
      "B40 -> time passed: 3.970 time per batch: 0.099\n",
      "B50 -> time passed: 5.343 time per batch: 0.107\n",
      "B60 -> time passed: 6.099 time per batch: 0.102\n",
      "B70 -> time passed: 6.560 time per batch: 0.094\n",
      "test processing time: 13.635547637939453\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.534 time per batch: 0.153\n",
      "B20 -> time passed: 2.287 time per batch: 0.114\n",
      "B30 -> time passed: 3.085 time per batch: 0.103\n",
      "B40 -> time passed: 3.859 time per batch: 0.096\n",
      "B50 -> time passed: 5.238 time per batch: 0.105\n",
      "B60 -> time passed: 5.965 time per batch: 0.099\n",
      "B70 -> time passed: 6.472 time per batch: 0.092\n",
      "test processing time: 9.228058815002441\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.508 time per batch: 0.151\n",
      "B20 -> time passed: 2.330 time per batch: 0.116\n",
      "B30 -> time passed: 3.141 time per batch: 0.105\n",
      "B40 -> time passed: 3.973 time per batch: 0.099\n",
      "B50 -> time passed: 5.464 time per batch: 0.109\n",
      "B60 -> time passed: 6.168 time per batch: 0.103\n",
      "B70 -> time passed: 6.601 time per batch: 0.094\n",
      "test processing time: 9.379076957702637\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.489 time per batch: 0.149\n",
      "B20 -> time passed: 2.255 time per batch: 0.113\n",
      "B30 -> time passed: 3.026 time per batch: 0.101\n",
      "B40 -> time passed: 3.837 time per batch: 0.096\n",
      "B50 -> time passed: 5.265 time per batch: 0.105\n",
      "B60 -> time passed: 5.992 time per batch: 0.100\n",
      "B70 -> time passed: 6.456 time per batch: 0.092\n",
      "test processing time: 9.206547737121582\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.586 time per batch: 0.159\n",
      "B20 -> time passed: 2.415 time per batch: 0.121\n",
      "B30 -> time passed: 3.250 time per batch: 0.108\n",
      "B40 -> time passed: 4.056 time per batch: 0.101\n",
      "B50 -> time passed: 5.493 time per batch: 0.110\n",
      "B60 -> time passed: 6.187 time per batch: 0.103\n",
      "B70 -> time passed: 6.621 time per batch: 0.095\n",
      "test processing time: 9.362603425979614\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.493 time per batch: 0.149\n",
      "B20 -> time passed: 2.287 time per batch: 0.114\n",
      "B30 -> time passed: 3.084 time per batch: 0.103\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.265 time per batch: 0.105\n",
      "B60 -> time passed: 6.006 time per batch: 0.100\n",
      "B70 -> time passed: 6.518 time per batch: 0.093\n",
      "test processing time: 9.238621950149536\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.518 time per batch: 0.152\n",
      "B20 -> time passed: 2.318 time per batch: 0.116\n",
      "B30 -> time passed: 3.119 time per batch: 0.104\n",
      "B40 -> time passed: 3.914 time per batch: 0.098\n",
      "B50 -> time passed: 5.288 time per batch: 0.106\n",
      "B60 -> time passed: 6.031 time per batch: 0.101\n",
      "B70 -> time passed: 6.541 time per batch: 0.093\n",
      "test processing time: 9.242868900299072\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.524 time per batch: 0.152\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.109 time per batch: 0.104\n",
      "B40 -> time passed: 3.916 time per batch: 0.098\n",
      "B50 -> time passed: 5.258 time per batch: 0.105\n",
      "B60 -> time passed: 6.079 time per batch: 0.101\n",
      "B70 -> time passed: 6.533 time per batch: 0.093\n",
      "test processing time: 9.27852201461792\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.306 time per batch: 0.115\n",
      "B30 -> time passed: 3.102 time per batch: 0.103\n",
      "B40 -> time passed: 3.939 time per batch: 0.098\n",
      "B50 -> time passed: 5.392 time per batch: 0.108\n",
      "B60 -> time passed: 6.093 time per batch: 0.102\n",
      "B70 -> time passed: 6.529 time per batch: 0.093\n",
      "test processing time: 9.257392883300781\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.564 time per batch: 0.156\n",
      "B20 -> time passed: 2.332 time per batch: 0.117\n",
      "B30 -> time passed: 3.159 time per batch: 0.105\n",
      "B40 -> time passed: 3.972 time per batch: 0.099\n",
      "B50 -> time passed: 5.220 time per batch: 0.104\n",
      "B60 -> time passed: 6.115 time per batch: 0.102\n",
      "B70 -> time passed: 6.559 time per batch: 0.094\n",
      "test processing time: 9.220059394836426\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.307 time per batch: 0.115\n",
      "B30 -> time passed: 3.067 time per batch: 0.102\n",
      "B40 -> time passed: 3.846 time per batch: 0.096\n",
      "B50 -> time passed: 5.172 time per batch: 0.103\n",
      "B60 -> time passed: 6.006 time per batch: 0.100\n",
      "B70 -> time passed: 6.549 time per batch: 0.094\n",
      "test processing time: 9.223680257797241\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.588 time per batch: 0.159\n",
      "B20 -> time passed: 2.351 time per batch: 0.118\n",
      "B30 -> time passed: 3.161 time per batch: 0.105\n",
      "B40 -> time passed: 3.977 time per batch: 0.099\n",
      "B50 -> time passed: 5.410 time per batch: 0.108\n",
      "B60 -> time passed: 6.137 time per batch: 0.102\n",
      "B70 -> time passed: 6.581 time per batch: 0.094\n",
      "test processing time: 9.279882192611694\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.531 time per batch: 0.153\n",
      "B20 -> time passed: 2.274 time per batch: 0.114\n",
      "B30 -> time passed: 3.070 time per batch: 0.102\n",
      "B40 -> time passed: 3.885 time per batch: 0.097\n",
      "B50 -> time passed: 5.299 time per batch: 0.106\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.495 time per batch: 0.093\n",
      "test processing time: 9.222498893737793\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.527 time per batch: 0.153\n",
      "B20 -> time passed: 2.309 time per batch: 0.115\n",
      "B30 -> time passed: 3.095 time per batch: 0.103\n",
      "B40 -> time passed: 3.857 time per batch: 0.096\n",
      "B50 -> time passed: 5.223 time per batch: 0.104\n",
      "B60 -> time passed: 6.047 time per batch: 0.101\n",
      "B70 -> time passed: 6.540 time per batch: 0.093\n",
      "test processing time: 9.229142427444458\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.513 time per batch: 0.151\n",
      "B20 -> time passed: 2.301 time per batch: 0.115\n",
      "B30 -> time passed: 3.094 time per batch: 0.103\n",
      "B40 -> time passed: 3.835 time per batch: 0.096\n",
      "B50 -> time passed: 5.098 time per batch: 0.102\n",
      "B60 -> time passed: 5.985 time per batch: 0.100\n",
      "B70 -> time passed: 6.503 time per batch: 0.093\n",
      "test processing time: 9.1771981716156\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.310 time per batch: 0.116\n",
      "B30 -> time passed: 3.101 time per batch: 0.103\n",
      "B40 -> time passed: 3.892 time per batch: 0.097\n",
      "B50 -> time passed: 5.282 time per batch: 0.106\n",
      "B60 -> time passed: 5.986 time per batch: 0.100\n",
      "B70 -> time passed: 6.457 time per batch: 0.092\n",
      "test processing time: 9.130589008331299\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.296 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.876 time per batch: 0.097\n",
      "B50 -> time passed: 5.278 time per batch: 0.106\n",
      "B60 -> time passed: 6.002 time per batch: 0.100\n",
      "B70 -> time passed: 6.506 time per batch: 0.093\n",
      "test processing time: 9.21247410774231\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.504 time per batch: 0.150\n",
      "B20 -> time passed: 2.269 time per batch: 0.113\n",
      "B30 -> time passed: 3.038 time per batch: 0.101\n",
      "B40 -> time passed: 3.815 time per batch: 0.095\n",
      "B50 -> time passed: 5.160 time per batch: 0.103\n",
      "B60 -> time passed: 5.982 time per batch: 0.100\n",
      "B70 -> time passed: 6.488 time per batch: 0.093\n",
      "test processing time: 9.211161851882935\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.507 time per batch: 0.151\n",
      "B20 -> time passed: 2.292 time per batch: 0.115\n",
      "B30 -> time passed: 3.098 time per batch: 0.103\n",
      "B40 -> time passed: 3.905 time per batch: 0.098\n",
      "B50 -> time passed: 5.339 time per batch: 0.107\n",
      "B60 -> time passed: 6.094 time per batch: 0.102\n",
      "B70 -> time passed: 6.586 time per batch: 0.094\n",
      "test processing time: 9.260430812835693\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.524 time per batch: 0.152\n",
      "B20 -> time passed: 2.291 time per batch: 0.115\n",
      "B30 -> time passed: 3.086 time per batch: 0.103\n",
      "B40 -> time passed: 3.900 time per batch: 0.098\n",
      "B50 -> time passed: 5.317 time per batch: 0.106\n",
      "B60 -> time passed: 6.100 time per batch: 0.102\n",
      "B70 -> time passed: 6.550 time per batch: 0.094\n",
      "test processing time: 9.281440019607544\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.281 time per batch: 0.114\n",
      "B30 -> time passed: 3.063 time per batch: 0.102\n",
      "B40 -> time passed: 3.862 time per batch: 0.097\n",
      "B50 -> time passed: 5.227 time per batch: 0.105\n",
      "B60 -> time passed: 5.972 time per batch: 0.100\n",
      "B70 -> time passed: 6.426 time per batch: 0.092\n",
      "test processing time: 9.13616943359375\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.270 time per batch: 0.113\n",
      "B30 -> time passed: 3.063 time per batch: 0.102\n",
      "B40 -> time passed: 3.871 time per batch: 0.097\n",
      "B50 -> time passed: 5.233 time per batch: 0.105\n",
      "B60 -> time passed: 6.027 time per batch: 0.100\n",
      "B70 -> time passed: 6.538 time per batch: 0.093\n",
      "test processing time: 9.230047941207886\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.539 time per batch: 0.154\n",
      "B20 -> time passed: 2.356 time per batch: 0.118\n",
      "B30 -> time passed: 3.166 time per batch: 0.106\n",
      "B40 -> time passed: 3.987 time per batch: 0.100\n",
      "B50 -> time passed: 5.425 time per batch: 0.109\n",
      "B60 -> time passed: 6.140 time per batch: 0.102\n",
      "B70 -> time passed: 6.588 time per batch: 0.094\n",
      "test processing time: 9.274323225021362\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.544 time per batch: 0.154\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.131 time per batch: 0.104\n",
      "B40 -> time passed: 3.950 time per batch: 0.099\n",
      "B50 -> time passed: 5.359 time per batch: 0.107\n",
      "B60 -> time passed: 6.133 time per batch: 0.102\n",
      "B70 -> time passed: 6.552 time per batch: 0.094\n",
      "test processing time: 9.28483533859253\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.328 time per batch: 0.116\n",
      "B30 -> time passed: 3.120 time per batch: 0.104\n",
      "B40 -> time passed: 3.932 time per batch: 0.098\n",
      "B50 -> time passed: 5.351 time per batch: 0.107\n",
      "B60 -> time passed: 6.191 time per batch: 0.103\n",
      "B70 -> time passed: 6.640 time per batch: 0.095\n",
      "test processing time: 9.398405313491821\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.527 time per batch: 0.153\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.119 time per batch: 0.104\n",
      "B40 -> time passed: 3.917 time per batch: 0.098\n",
      "B50 -> time passed: 5.228 time per batch: 0.105\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.509 time per batch: 0.093\n",
      "test processing time: 9.244327306747437\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.499 time per batch: 0.150\n",
      "B20 -> time passed: 2.271 time per batch: 0.114\n",
      "B30 -> time passed: 3.049 time per batch: 0.102\n",
      "B40 -> time passed: 3.857 time per batch: 0.096\n",
      "B50 -> time passed: 5.219 time per batch: 0.104\n",
      "B60 -> time passed: 6.020 time per batch: 0.100\n",
      "B70 -> time passed: 6.545 time per batch: 0.093\n",
      "test processing time: 9.245455741882324\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.150\n",
      "B20 -> time passed: 2.298 time per batch: 0.115\n",
      "B30 -> time passed: 3.061 time per batch: 0.102\n",
      "B40 -> time passed: 3.842 time per batch: 0.096\n",
      "B50 -> time passed: 5.193 time per batch: 0.104\n",
      "B60 -> time passed: 5.969 time per batch: 0.099\n",
      "B70 -> time passed: 6.529 time per batch: 0.093\n",
      "test processing time: 9.238971948623657\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.486 time per batch: 0.149\n",
      "B20 -> time passed: 2.292 time per batch: 0.115\n",
      "B30 -> time passed: 3.076 time per batch: 0.103\n",
      "B40 -> time passed: 3.867 time per batch: 0.097\n",
      "B50 -> time passed: 5.178 time per batch: 0.104\n",
      "B60 -> time passed: 5.989 time per batch: 0.100\n",
      "B70 -> time passed: 6.465 time per batch: 0.092\n",
      "test processing time: 9.244385719299316\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.463 time per batch: 0.146\n",
      "B20 -> time passed: 2.268 time per batch: 0.113\n",
      "B30 -> time passed: 3.058 time per batch: 0.102\n",
      "B40 -> time passed: 3.808 time per batch: 0.095\n",
      "B50 -> time passed: 5.081 time per batch: 0.102\n",
      "B60 -> time passed: 6.023 time per batch: 0.100\n",
      "B70 -> time passed: 6.539 time per batch: 0.093\n",
      "test processing time: 9.297285318374634\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.557 time per batch: 0.156\n",
      "B20 -> time passed: 2.356 time per batch: 0.118\n",
      "B30 -> time passed: 3.168 time per batch: 0.106\n",
      "B40 -> time passed: 4.006 time per batch: 0.100\n",
      "B50 -> time passed: 5.253 time per batch: 0.105\n",
      "B60 -> time passed: 6.127 time per batch: 0.102\n",
      "B70 -> time passed: 6.576 time per batch: 0.094\n",
      "test processing time: 9.299047946929932\n",
      "completed epochs: 16\n",
      "loading model model.b16.f0.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 0\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.531 time per batch: 0.153\n",
      "B20 -> time passed: 2.292 time per batch: 0.115\n",
      "B30 -> time passed: 3.083 time per batch: 0.103\n",
      "B40 -> time passed: 3.868 time per batch: 0.097\n",
      "B50 -> time passed: 5.304 time per batch: 0.106\n",
      "B60 -> time passed: 6.106 time per batch: 0.102\n",
      "B70 -> time passed: 6.545 time per batch: 0.094\n",
      "test processing time: 9.240044832229614\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.534 time per batch: 0.153\n",
      "B20 -> time passed: 2.320 time per batch: 0.116\n",
      "B30 -> time passed: 3.129 time per batch: 0.104\n",
      "B40 -> time passed: 3.959 time per batch: 0.099\n",
      "B50 -> time passed: 5.436 time per batch: 0.109\n",
      "B60 -> time passed: 6.157 time per batch: 0.103\n",
      "B70 -> time passed: 6.673 time per batch: 0.095\n",
      "test processing time: 13.653184413909912\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.603 time per batch: 0.160\n",
      "B20 -> time passed: 2.463 time per batch: 0.123\n",
      "B30 -> time passed: 3.228 time per batch: 0.108\n",
      "B40 -> time passed: 4.006 time per batch: 0.100\n",
      "B50 -> time passed: 5.465 time per batch: 0.109\n",
      "B60 -> time passed: 6.143 time per batch: 0.102\n",
      "B70 -> time passed: 6.598 time per batch: 0.094\n",
      "test processing time: 9.34171175956726\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.453 time per batch: 0.145\n",
      "B20 -> time passed: 2.288 time per batch: 0.114\n",
      "B30 -> time passed: 3.107 time per batch: 0.104\n",
      "B40 -> time passed: 3.834 time per batch: 0.096\n",
      "B50 -> time passed: 5.128 time per batch: 0.103\n",
      "B60 -> time passed: 6.001 time per batch: 0.100\n",
      "B70 -> time passed: 6.493 time per batch: 0.093\n",
      "test processing time: 9.23952841758728\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.549 time per batch: 0.155\n",
      "B20 -> time passed: 2.334 time per batch: 0.117\n",
      "B30 -> time passed: 3.115 time per batch: 0.104\n",
      "B40 -> time passed: 3.926 time per batch: 0.098\n",
      "B50 -> time passed: 5.224 time per batch: 0.104\n",
      "B60 -> time passed: 6.080 time per batch: 0.101\n",
      "B70 -> time passed: 6.605 time per batch: 0.094\n",
      "test processing time: 9.33094048500061\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.542 time per batch: 0.154\n",
      "B20 -> time passed: 2.298 time per batch: 0.115\n",
      "B30 -> time passed: 3.111 time per batch: 0.104\n",
      "B40 -> time passed: 3.894 time per batch: 0.097\n",
      "B50 -> time passed: 5.275 time per batch: 0.106\n",
      "B60 -> time passed: 6.022 time per batch: 0.100\n",
      "B70 -> time passed: 6.607 time per batch: 0.094\n",
      "test processing time: 9.309144020080566\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.504 time per batch: 0.150\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.093 time per batch: 0.103\n",
      "B40 -> time passed: 3.889 time per batch: 0.097\n",
      "B50 -> time passed: 5.229 time per batch: 0.105\n",
      "B60 -> time passed: 5.990 time per batch: 0.100\n",
      "B70 -> time passed: 6.546 time per batch: 0.094\n",
      "test processing time: 9.306957960128784\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.560 time per batch: 0.156\n",
      "B20 -> time passed: 2.415 time per batch: 0.121\n",
      "B30 -> time passed: 3.213 time per batch: 0.107\n",
      "B40 -> time passed: 4.026 time per batch: 0.101\n",
      "B50 -> time passed: 5.425 time per batch: 0.109\n",
      "B60 -> time passed: 6.158 time per batch: 0.103\n",
      "B70 -> time passed: 6.622 time per batch: 0.095\n",
      "test processing time: 9.381970167160034\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.293 time per batch: 0.115\n",
      "B30 -> time passed: 3.094 time per batch: 0.103\n",
      "B40 -> time passed: 3.881 time per batch: 0.097\n",
      "B50 -> time passed: 5.277 time per batch: 0.106\n",
      "B60 -> time passed: 6.060 time per batch: 0.101\n",
      "B70 -> time passed: 6.563 time per batch: 0.094\n",
      "test processing time: 9.270122766494751\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.535 time per batch: 0.153\n",
      "B20 -> time passed: 2.303 time per batch: 0.115\n",
      "B30 -> time passed: 3.148 time per batch: 0.105\n",
      "B40 -> time passed: 3.990 time per batch: 0.100\n",
      "B50 -> time passed: 5.403 time per batch: 0.108\n",
      "B60 -> time passed: 6.132 time per batch: 0.102\n",
      "B70 -> time passed: 6.556 time per batch: 0.094\n",
      "test processing time: 9.274120092391968\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.504 time per batch: 0.150\n",
      "B20 -> time passed: 2.301 time per batch: 0.115\n",
      "B30 -> time passed: 3.108 time per batch: 0.104\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.140 time per batch: 0.103\n",
      "B60 -> time passed: 6.036 time per batch: 0.101\n",
      "B70 -> time passed: 6.514 time per batch: 0.093\n",
      "test processing time: 9.26406455039978\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.464 time per batch: 0.123\n",
      "B30 -> time passed: 3.281 time per batch: 0.109\n",
      "B40 -> time passed: 4.080 time per batch: 0.102\n",
      "B50 -> time passed: 5.483 time per batch: 0.110\n",
      "B60 -> time passed: 6.219 time per batch: 0.104\n",
      "B70 -> time passed: 6.670 time per batch: 0.095\n",
      "test processing time: 9.430973291397095\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.534 time per batch: 0.153\n",
      "B20 -> time passed: 2.309 time per batch: 0.115\n",
      "B30 -> time passed: 3.105 time per batch: 0.104\n",
      "B40 -> time passed: 3.914 time per batch: 0.098\n",
      "B50 -> time passed: 5.293 time per batch: 0.106\n",
      "B60 -> time passed: 6.126 time per batch: 0.102\n",
      "B70 -> time passed: 6.595 time per batch: 0.094\n",
      "test processing time: 9.311425685882568\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.541 time per batch: 0.154\n",
      "B20 -> time passed: 2.380 time per batch: 0.119\n",
      "B30 -> time passed: 3.209 time per batch: 0.107\n",
      "B40 -> time passed: 4.041 time per batch: 0.101\n",
      "B50 -> time passed: 5.505 time per batch: 0.110\n",
      "B60 -> time passed: 6.197 time per batch: 0.103\n",
      "B70 -> time passed: 6.639 time per batch: 0.095\n",
      "test processing time: 9.337935209274292\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.516 time per batch: 0.152\n",
      "B20 -> time passed: 2.296 time per batch: 0.115\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.877 time per batch: 0.097\n",
      "B50 -> time passed: 5.272 time per batch: 0.105\n",
      "B60 -> time passed: 6.010 time per batch: 0.100\n",
      "B70 -> time passed: 6.569 time per batch: 0.094\n",
      "test processing time: 9.298280000686646\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.319 time per batch: 0.116\n",
      "B30 -> time passed: 3.100 time per batch: 0.103\n",
      "B40 -> time passed: 3.884 time per batch: 0.097\n",
      "B50 -> time passed: 5.229 time per batch: 0.105\n",
      "B60 -> time passed: 6.071 time per batch: 0.101\n",
      "B70 -> time passed: 6.576 time per batch: 0.094\n",
      "test processing time: 9.28855586051941\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.463 time per batch: 0.146\n",
      "B20 -> time passed: 2.237 time per batch: 0.112\n",
      "B30 -> time passed: 3.000 time per batch: 0.100\n",
      "B40 -> time passed: 3.773 time per batch: 0.094\n",
      "B50 -> time passed: 5.088 time per batch: 0.102\n",
      "B60 -> time passed: 6.001 time per batch: 0.100\n",
      "B70 -> time passed: 6.499 time per batch: 0.093\n",
      "test processing time: 9.27782392501831\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.298 time per batch: 0.115\n",
      "B30 -> time passed: 3.102 time per batch: 0.103\n",
      "B40 -> time passed: 3.871 time per batch: 0.097\n",
      "B50 -> time passed: 5.283 time per batch: 0.106\n",
      "B60 -> time passed: 6.077 time per batch: 0.101\n",
      "B70 -> time passed: 6.591 time per batch: 0.094\n",
      "test processing time: 9.330050468444824\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.570 time per batch: 0.157\n",
      "B20 -> time passed: 2.355 time per batch: 0.118\n",
      "B30 -> time passed: 3.179 time per batch: 0.106\n",
      "B40 -> time passed: 3.925 time per batch: 0.098\n",
      "B50 -> time passed: 5.292 time per batch: 0.106\n",
      "B60 -> time passed: 6.096 time per batch: 0.102\n",
      "B70 -> time passed: 6.550 time per batch: 0.094\n",
      "test processing time: 9.243154764175415\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.537 time per batch: 0.154\n",
      "B20 -> time passed: 2.317 time per batch: 0.116\n",
      "B30 -> time passed: 3.044 time per batch: 0.101\n",
      "B40 -> time passed: 3.881 time per batch: 0.097\n",
      "B50 -> time passed: 5.287 time per batch: 0.106\n",
      "B60 -> time passed: 6.142 time per batch: 0.102\n",
      "B70 -> time passed: 6.623 time per batch: 0.095\n",
      "test processing time: 9.349373579025269\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.478 time per batch: 0.148\n",
      "B20 -> time passed: 2.283 time per batch: 0.114\n",
      "B30 -> time passed: 3.098 time per batch: 0.103\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.094 time per batch: 0.102\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.567 time per batch: 0.094\n",
      "test processing time: 9.31458330154419\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.552 time per batch: 0.155\n",
      "B20 -> time passed: 2.353 time per batch: 0.118\n",
      "B30 -> time passed: 3.207 time per batch: 0.107\n",
      "B40 -> time passed: 4.049 time per batch: 0.101\n",
      "B50 -> time passed: 5.443 time per batch: 0.109\n",
      "B60 -> time passed: 6.231 time per batch: 0.104\n",
      "B70 -> time passed: 6.716 time per batch: 0.096\n",
      "test processing time: 9.427820682525635\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.510 time per batch: 0.151\n",
      "B20 -> time passed: 2.283 time per batch: 0.114\n",
      "B30 -> time passed: 3.093 time per batch: 0.103\n",
      "B40 -> time passed: 3.902 time per batch: 0.098\n",
      "B50 -> time passed: 5.168 time per batch: 0.103\n",
      "B60 -> time passed: 6.082 time per batch: 0.101\n",
      "B70 -> time passed: 6.542 time per batch: 0.093\n",
      "test processing time: 9.334532976150513\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.525 time per batch: 0.153\n",
      "B20 -> time passed: 2.301 time per batch: 0.115\n",
      "B30 -> time passed: 3.068 time per batch: 0.102\n",
      "B40 -> time passed: 3.880 time per batch: 0.097\n",
      "B50 -> time passed: 5.268 time per batch: 0.105\n",
      "B60 -> time passed: 6.044 time per batch: 0.101\n",
      "B70 -> time passed: 6.508 time per batch: 0.093\n",
      "test processing time: 9.207856178283691\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.573 time per batch: 0.157\n",
      "B20 -> time passed: 2.357 time per batch: 0.118\n",
      "B30 -> time passed: 3.171 time per batch: 0.106\n",
      "B40 -> time passed: 3.954 time per batch: 0.099\n",
      "B50 -> time passed: 5.370 time per batch: 0.107\n",
      "B60 -> time passed: 6.139 time per batch: 0.102\n",
      "B70 -> time passed: 6.615 time per batch: 0.095\n",
      "test processing time: 9.32008147239685\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.484 time per batch: 0.148\n",
      "B20 -> time passed: 2.287 time per batch: 0.114\n",
      "B30 -> time passed: 3.069 time per batch: 0.102\n",
      "B40 -> time passed: 3.862 time per batch: 0.097\n",
      "B50 -> time passed: 5.135 time per batch: 0.103\n",
      "B60 -> time passed: 6.026 time per batch: 0.100\n",
      "B70 -> time passed: 6.490 time per batch: 0.093\n",
      "test processing time: 9.228575229644775\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.546 time per batch: 0.155\n",
      "B20 -> time passed: 2.348 time per batch: 0.117\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.913 time per batch: 0.098\n",
      "B50 -> time passed: 5.301 time per batch: 0.106\n",
      "B60 -> time passed: 6.113 time per batch: 0.102\n",
      "B70 -> time passed: 6.564 time per batch: 0.094\n",
      "test processing time: 9.30621337890625\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.151\n",
      "B20 -> time passed: 2.290 time per batch: 0.114\n",
      "B30 -> time passed: 3.070 time per batch: 0.102\n",
      "B40 -> time passed: 3.862 time per batch: 0.097\n",
      "B50 -> time passed: 5.201 time per batch: 0.104\n",
      "B60 -> time passed: 6.130 time per batch: 0.102\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 9.317590475082397\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.316 time per batch: 0.116\n",
      "B30 -> time passed: 3.088 time per batch: 0.103\n",
      "B40 -> time passed: 3.878 time per batch: 0.097\n",
      "B50 -> time passed: 5.148 time per batch: 0.103\n",
      "B60 -> time passed: 6.084 time per batch: 0.101\n",
      "B70 -> time passed: 6.576 time per batch: 0.094\n",
      "test processing time: 9.304396867752075\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.572 time per batch: 0.157\n",
      "B20 -> time passed: 2.411 time per batch: 0.121\n",
      "B30 -> time passed: 3.275 time per batch: 0.109\n",
      "B40 -> time passed: 4.139 time per batch: 0.103\n",
      "B50 -> time passed: 5.573 time per batch: 0.111\n",
      "B60 -> time passed: 6.341 time per batch: 0.106\n",
      "B70 -> time passed: 6.720 time per batch: 0.096\n",
      "test processing time: 9.411621570587158\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.238 time per batch: 0.112\n",
      "B30 -> time passed: 3.061 time per batch: 0.102\n",
      "B40 -> time passed: 3.853 time per batch: 0.096\n",
      "B50 -> time passed: 5.329 time per batch: 0.107\n",
      "B60 -> time passed: 6.015 time per batch: 0.100\n",
      "B70 -> time passed: 6.497 time per batch: 0.093\n",
      "test processing time: 9.2828848361969\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.315 time per batch: 0.116\n",
      "B30 -> time passed: 3.142 time per batch: 0.105\n",
      "B40 -> time passed: 3.952 time per batch: 0.099\n",
      "B50 -> time passed: 5.176 time per batch: 0.104\n",
      "B60 -> time passed: 6.159 time per batch: 0.103\n",
      "B70 -> time passed: 6.642 time per batch: 0.095\n",
      "test processing time: 9.383066177368164\n",
      "completed epochs: 16\n",
      "loading model model.b16.f1.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 1\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.342 time per batch: 0.117\n",
      "B30 -> time passed: 3.163 time per batch: 0.105\n",
      "B40 -> time passed: 3.914 time per batch: 0.098\n",
      "B50 -> time passed: 5.202 time per batch: 0.104\n",
      "B60 -> time passed: 6.106 time per batch: 0.102\n",
      "B70 -> time passed: 6.563 time per batch: 0.094\n",
      "test processing time: 9.329248905181885\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.511 time per batch: 0.151\n",
      "B20 -> time passed: 2.302 time per batch: 0.115\n",
      "B30 -> time passed: 3.064 time per batch: 0.102\n",
      "B40 -> time passed: 3.830 time per batch: 0.096\n",
      "B50 -> time passed: 5.120 time per batch: 0.102\n",
      "B60 -> time passed: 5.991 time per batch: 0.100\n",
      "B70 -> time passed: 6.556 time per batch: 0.094\n",
      "test processing time: 13.635977029800415\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.527 time per batch: 0.153\n",
      "B20 -> time passed: 2.286 time per batch: 0.114\n",
      "B30 -> time passed: 3.093 time per batch: 0.103\n",
      "B40 -> time passed: 3.890 time per batch: 0.097\n",
      "B50 -> time passed: 5.225 time per batch: 0.104\n",
      "B60 -> time passed: 5.984 time per batch: 0.100\n",
      "B70 -> time passed: 6.567 time per batch: 0.094\n",
      "test processing time: 9.337101221084595\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.498 time per batch: 0.150\n",
      "B20 -> time passed: 2.266 time per batch: 0.113\n",
      "B30 -> time passed: 3.065 time per batch: 0.102\n",
      "B40 -> time passed: 3.846 time per batch: 0.096\n",
      "B50 -> time passed: 5.225 time per batch: 0.104\n",
      "B60 -> time passed: 5.998 time per batch: 0.100\n",
      "B70 -> time passed: 6.464 time per batch: 0.092\n",
      "test processing time: 9.245311498641968\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.521 time per batch: 0.152\n",
      "B20 -> time passed: 2.314 time per batch: 0.116\n",
      "B30 -> time passed: 3.122 time per batch: 0.104\n",
      "B40 -> time passed: 3.940 time per batch: 0.098\n",
      "B50 -> time passed: 5.311 time per batch: 0.106\n",
      "B60 -> time passed: 6.025 time per batch: 0.100\n",
      "B70 -> time passed: 6.553 time per batch: 0.094\n",
      "test processing time: 9.318505764007568\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.541 time per batch: 0.154\n",
      "B20 -> time passed: 2.367 time per batch: 0.118\n",
      "B30 -> time passed: 3.207 time per batch: 0.107\n",
      "B40 -> time passed: 3.968 time per batch: 0.099\n",
      "B50 -> time passed: 5.443 time per batch: 0.109\n",
      "B60 -> time passed: 6.130 time per batch: 0.102\n",
      "B70 -> time passed: 6.559 time per batch: 0.094\n",
      "test processing time: 9.291889905929565\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.499 time per batch: 0.150\n",
      "B20 -> time passed: 2.261 time per batch: 0.113\n",
      "B30 -> time passed: 3.040 time per batch: 0.101\n",
      "B40 -> time passed: 3.820 time per batch: 0.095\n",
      "B50 -> time passed: 5.169 time per batch: 0.103\n",
      "B60 -> time passed: 5.938 time per batch: 0.099\n",
      "B70 -> time passed: 6.491 time per batch: 0.093\n",
      "test processing time: 9.26548957824707\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.518 time per batch: 0.152\n",
      "B20 -> time passed: 2.305 time per batch: 0.115\n",
      "B30 -> time passed: 3.095 time per batch: 0.103\n",
      "B40 -> time passed: 3.900 time per batch: 0.098\n",
      "B50 -> time passed: 5.277 time per batch: 0.106\n",
      "B60 -> time passed: 6.080 time per batch: 0.101\n",
      "B70 -> time passed: 6.552 time per batch: 0.094\n",
      "test processing time: 9.288116455078125\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.454 time per batch: 0.145\n",
      "B20 -> time passed: 2.264 time per batch: 0.113\n",
      "B30 -> time passed: 3.063 time per batch: 0.102\n",
      "B40 -> time passed: 3.859 time per batch: 0.096\n",
      "B50 -> time passed: 5.136 time per batch: 0.103\n",
      "B60 -> time passed: 6.018 time per batch: 0.100\n",
      "B70 -> time passed: 6.539 time per batch: 0.093\n",
      "test processing time: 9.310360431671143\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.533 time per batch: 0.153\n",
      "B20 -> time passed: 2.375 time per batch: 0.119\n",
      "B30 -> time passed: 3.164 time per batch: 0.105\n",
      "B40 -> time passed: 3.943 time per batch: 0.099\n",
      "B50 -> time passed: 5.178 time per batch: 0.104\n",
      "B60 -> time passed: 6.061 time per batch: 0.101\n",
      "B70 -> time passed: 6.567 time per batch: 0.094\n",
      "test processing time: 9.249794960021973\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.497 time per batch: 0.150\n",
      "B20 -> time passed: 2.291 time per batch: 0.115\n",
      "B30 -> time passed: 3.091 time per batch: 0.103\n",
      "B40 -> time passed: 3.876 time per batch: 0.097\n",
      "B50 -> time passed: 5.138 time per batch: 0.103\n",
      "B60 -> time passed: 6.068 time per batch: 0.101\n",
      "B70 -> time passed: 6.572 time per batch: 0.094\n",
      "test processing time: 9.28425145149231\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.536 time per batch: 0.154\n",
      "B20 -> time passed: 2.291 time per batch: 0.115\n",
      "B30 -> time passed: 3.064 time per batch: 0.102\n",
      "B40 -> time passed: 3.886 time per batch: 0.097\n",
      "B50 -> time passed: 5.120 time per batch: 0.102\n",
      "B60 -> time passed: 6.143 time per batch: 0.102\n",
      "B70 -> time passed: 6.624 time per batch: 0.095\n",
      "test processing time: 9.360982656478882\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.465 time per batch: 0.147\n",
      "B20 -> time passed: 2.256 time per batch: 0.113\n",
      "B30 -> time passed: 3.075 time per batch: 0.102\n",
      "B40 -> time passed: 3.867 time per batch: 0.097\n",
      "B50 -> time passed: 5.290 time per batch: 0.106\n",
      "B60 -> time passed: 6.055 time per batch: 0.101\n",
      "B70 -> time passed: 6.527 time per batch: 0.093\n",
      "test processing time: 9.26304841041565\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.549 time per batch: 0.155\n",
      "B20 -> time passed: 2.380 time per batch: 0.119\n",
      "B30 -> time passed: 3.183 time per batch: 0.106\n",
      "B40 -> time passed: 3.980 time per batch: 0.100\n",
      "B50 -> time passed: 5.315 time per batch: 0.106\n",
      "B60 -> time passed: 6.029 time per batch: 0.100\n",
      "B70 -> time passed: 6.482 time per batch: 0.093\n",
      "test processing time: 9.174805164337158\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.529 time per batch: 0.153\n",
      "B20 -> time passed: 2.288 time per batch: 0.114\n",
      "B30 -> time passed: 3.061 time per batch: 0.102\n",
      "B40 -> time passed: 3.853 time per batch: 0.096\n",
      "B50 -> time passed: 5.115 time per batch: 0.102\n",
      "B60 -> time passed: 6.013 time per batch: 0.100\n",
      "B70 -> time passed: 6.523 time per batch: 0.093\n",
      "test processing time: 9.215315103530884\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.485 time per batch: 0.149\n",
      "B20 -> time passed: 2.284 time per batch: 0.114\n",
      "B30 -> time passed: 3.091 time per batch: 0.103\n",
      "B40 -> time passed: 3.857 time per batch: 0.096\n",
      "B50 -> time passed: 5.116 time per batch: 0.102\n",
      "B60 -> time passed: 6.060 time per batch: 0.101\n",
      "B70 -> time passed: 6.507 time per batch: 0.093\n",
      "test processing time: 9.218997240066528\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.462 time per batch: 0.146\n",
      "B20 -> time passed: 2.253 time per batch: 0.113\n",
      "B30 -> time passed: 3.029 time per batch: 0.101\n",
      "B40 -> time passed: 3.823 time per batch: 0.096\n",
      "B50 -> time passed: 5.033 time per batch: 0.101\n",
      "B60 -> time passed: 5.973 time per batch: 0.100\n",
      "B70 -> time passed: 6.445 time per batch: 0.092\n",
      "test processing time: 9.204635381698608\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.498 time per batch: 0.150\n",
      "B20 -> time passed: 2.277 time per batch: 0.114\n",
      "B30 -> time passed: 3.084 time per batch: 0.103\n",
      "B40 -> time passed: 3.909 time per batch: 0.098\n",
      "B50 -> time passed: 5.243 time per batch: 0.105\n",
      "B60 -> time passed: 6.011 time per batch: 0.100\n",
      "B70 -> time passed: 6.544 time per batch: 0.093\n",
      "test processing time: 9.262245178222656\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.499 time per batch: 0.150\n",
      "B20 -> time passed: 2.268 time per batch: 0.113\n",
      "B30 -> time passed: 3.040 time per batch: 0.101\n",
      "B40 -> time passed: 3.835 time per batch: 0.096\n",
      "B50 -> time passed: 5.103 time per batch: 0.102\n",
      "B60 -> time passed: 5.969 time per batch: 0.099\n",
      "B70 -> time passed: 6.465 time per batch: 0.092\n",
      "test processing time: 9.230512619018555\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.522 time per batch: 0.152\n",
      "B20 -> time passed: 2.295 time per batch: 0.115\n",
      "B30 -> time passed: 3.103 time per batch: 0.103\n",
      "B40 -> time passed: 3.916 time per batch: 0.098\n",
      "B50 -> time passed: 5.072 time per batch: 0.101\n",
      "B60 -> time passed: 6.099 time per batch: 0.102\n",
      "B70 -> time passed: 6.578 time per batch: 0.094\n",
      "test processing time: 9.261183261871338\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.505 time per batch: 0.150\n",
      "B20 -> time passed: 2.313 time per batch: 0.116\n",
      "B30 -> time passed: 3.094 time per batch: 0.103\n",
      "B40 -> time passed: 3.864 time per batch: 0.097\n",
      "B50 -> time passed: 5.241 time per batch: 0.105\n",
      "B60 -> time passed: 6.085 time per batch: 0.101\n",
      "B70 -> time passed: 6.561 time per batch: 0.094\n",
      "test processing time: 9.306511640548706\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.556 time per batch: 0.156\n",
      "B20 -> time passed: 2.392 time per batch: 0.120\n",
      "B30 -> time passed: 3.189 time per batch: 0.106\n",
      "B40 -> time passed: 3.903 time per batch: 0.098\n",
      "B50 -> time passed: 5.344 time per batch: 0.107\n",
      "B60 -> time passed: 6.074 time per batch: 0.101\n",
      "B70 -> time passed: 6.552 time per batch: 0.094\n",
      "test processing time: 9.30801796913147\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.520 time per batch: 0.152\n",
      "B20 -> time passed: 2.363 time per batch: 0.118\n",
      "B30 -> time passed: 3.164 time per batch: 0.105\n",
      "B40 -> time passed: 3.995 time per batch: 0.100\n",
      "B50 -> time passed: 5.222 time per batch: 0.104\n",
      "B60 -> time passed: 6.215 time per batch: 0.104\n",
      "B70 -> time passed: 6.616 time per batch: 0.095\n",
      "test processing time: 9.422072649002075\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.561 time per batch: 0.156\n",
      "B20 -> time passed: 2.392 time per batch: 0.120\n",
      "B30 -> time passed: 3.177 time per batch: 0.106\n",
      "B40 -> time passed: 3.980 time per batch: 0.100\n",
      "B50 -> time passed: 5.486 time per batch: 0.110\n",
      "B60 -> time passed: 6.176 time per batch: 0.103\n",
      "B70 -> time passed: 6.646 time per batch: 0.095\n",
      "test processing time: 9.407198667526245\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.544 time per batch: 0.154\n",
      "B20 -> time passed: 2.325 time per batch: 0.116\n",
      "B30 -> time passed: 3.102 time per batch: 0.103\n",
      "B40 -> time passed: 3.907 time per batch: 0.098\n",
      "B50 -> time passed: 5.230 time per batch: 0.105\n",
      "B60 -> time passed: 6.029 time per batch: 0.100\n",
      "B70 -> time passed: 6.515 time per batch: 0.093\n",
      "test processing time: 9.229886293411255\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.471 time per batch: 0.147\n",
      "B20 -> time passed: 2.249 time per batch: 0.112\n",
      "B30 -> time passed: 3.042 time per batch: 0.101\n",
      "B40 -> time passed: 3.824 time per batch: 0.096\n",
      "B50 -> time passed: 5.316 time per batch: 0.106\n",
      "B60 -> time passed: 6.074 time per batch: 0.101\n",
      "B70 -> time passed: 6.538 time per batch: 0.093\n",
      "test processing time: 9.290018320083618\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.473 time per batch: 0.147\n",
      "B20 -> time passed: 2.290 time per batch: 0.114\n",
      "B30 -> time passed: 3.169 time per batch: 0.106\n",
      "B40 -> time passed: 4.006 time per batch: 0.100\n",
      "B50 -> time passed: 5.190 time per batch: 0.104\n",
      "B60 -> time passed: 6.225 time per batch: 0.104\n",
      "B70 -> time passed: 6.679 time per batch: 0.095\n",
      "test processing time: 9.50119161605835\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.470 time per batch: 0.147\n",
      "B20 -> time passed: 2.254 time per batch: 0.113\n",
      "B30 -> time passed: 3.087 time per batch: 0.103\n",
      "B40 -> time passed: 3.901 time per batch: 0.098\n",
      "B50 -> time passed: 5.105 time per batch: 0.102\n",
      "B60 -> time passed: 6.122 time per batch: 0.102\n",
      "B70 -> time passed: 6.575 time per batch: 0.094\n",
      "test processing time: 9.352869987487793\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.514 time per batch: 0.151\n",
      "B20 -> time passed: 2.328 time per batch: 0.116\n",
      "B30 -> time passed: 3.155 time per batch: 0.105\n",
      "B40 -> time passed: 3.882 time per batch: 0.097\n",
      "B50 -> time passed: 5.380 time per batch: 0.108\n",
      "B60 -> time passed: 6.080 time per batch: 0.101\n",
      "B70 -> time passed: 6.524 time per batch: 0.093\n",
      "test processing time: 9.24760127067566\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.469 time per batch: 0.147\n",
      "B20 -> time passed: 2.272 time per batch: 0.114\n",
      "B30 -> time passed: 3.034 time per batch: 0.101\n",
      "B40 -> time passed: 3.844 time per batch: 0.096\n",
      "B50 -> time passed: 5.154 time per batch: 0.103\n",
      "B60 -> time passed: 5.909 time per batch: 0.098\n",
      "B70 -> time passed: 6.390 time per batch: 0.091\n",
      "test processing time: 9.20726203918457\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.454 time per batch: 0.145\n",
      "B20 -> time passed: 2.241 time per batch: 0.112\n",
      "B30 -> time passed: 3.009 time per batch: 0.100\n",
      "B40 -> time passed: 3.924 time per batch: 0.098\n",
      "B50 -> time passed: 5.149 time per batch: 0.103\n",
      "B60 -> time passed: 5.956 time per batch: 0.099\n",
      "B70 -> time passed: 6.458 time per batch: 0.092\n",
      "test processing time: 9.242924451828003\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.464 time per batch: 0.146\n",
      "B20 -> time passed: 2.267 time per batch: 0.113\n",
      "B30 -> time passed: 3.028 time per batch: 0.101\n",
      "B40 -> time passed: 3.824 time per batch: 0.096\n",
      "B50 -> time passed: 5.091 time per batch: 0.102\n",
      "B60 -> time passed: 5.971 time per batch: 0.100\n",
      "B70 -> time passed: 6.501 time per batch: 0.093\n",
      "test processing time: 9.266935586929321\n",
      "completed epochs: 16\n",
      "loading model model.b16.f2.d9.v29\n",
      "adding dummy serieses 26\n",
      "DataSet 9 test size 2240 fold 2\n",
      "dataset test: 2240 loader test: 70\n",
      "setFeats, augmentation -1\n",
      "B10 -> time passed: 1.526 time per batch: 0.153\n",
      "B20 -> time passed: 2.301 time per batch: 0.115\n",
      "B30 -> time passed: 3.121 time per batch: 0.104\n",
      "B40 -> time passed: 3.941 time per batch: 0.099\n",
      "B50 -> time passed: 5.376 time per batch: 0.108\n",
      "B60 -> time passed: 6.171 time per batch: 0.103\n",
      "B70 -> time passed: 6.579 time per batch: 0.094\n",
      "test processing time: 9.354855060577393\n",
      "total time 906.5262689590454\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "\n",
    "for ds in range(9,10):\n",
    "    preds = []\n",
    "    for fold in range(3):\n",
    "        preds2 = []\n",
    "        for anum in range(32):\n",
    "            predictions = inference_one(fold = fold, anum = anum, bs=bs, dataset=ds)\n",
    "            preds2.append(predictions)\n",
    "        preds.append(np.stack(preds2))\n",
    "    preds = np.stack(preds)\n",
    "    print('total time', time.time() - stg)\n",
    "    \n",
    "    pickle.dump(preds, open(PATH_WORK/'preds_d{}_v{}'.format(ds, VERSION),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total time 883.3684198856354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.86666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "883*4/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 78545, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13662565, 0.00536638, 0.0433894 , 0.02999757, 0.04678237,\n",
       "       0.05763499], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/zahar_chikishev/running/oof_d6_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d6_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d6_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f0_v20 [Content-Type=application/octet-stream]...\n",
      "- [4 files][164.5 MiB/164.5 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d7_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d8_f2_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f0_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f1_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/oof_d9_f2_v20 [Content-Type=application/octet-stream]...\n",
      "| [12 files][493.8 MiB/493.8 MiB]   35.9 MiB/s                                  \n",
      "Operation completed over 12 objects/493.8 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/zahar_chikishev/running/oof* gs://rsna-hemorrhage/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/zahar_chikishev/running/preds_d6_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d7_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d8_v20 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/zahar_chikishev/running/preds_d9_v20 [Content-Type=application/octet-stream]...\n",
      "\\ [4 files][172.6 MiB/172.6 MiB]                                                \n",
      "Operation completed over 4 objects/172.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/zahar_chikishev/running/preds* gs://rsna-hemorrhage/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/results/* C:\\StudioProjects\\Hemorrhage\\running\\ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/yuvals/model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/yuvals/model_*_version_classifier_splits_fullhead_resmodel_type_OOF_pred_split_* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://rsna-hemorrhage/yuvals/model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://rsna-hemorrhage/yuvals/OOF_validation_image_ids.pkl .\n",
    "!gsutil cp gs://rsna-hemorrhage/yuvals/ensemble_test_image_ids.pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /home/zahar_chikishev/running/*v53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/preds_se_resnext101_32x4d_v53\r\n",
      "/home/zahar_chikishev/running/stats.f0.v53\r\n",
      "/home/zahar_chikishev/running/stats.f1.v53\r\n",
      "/home/zahar_chikishev/running/stats.f2.v53\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/*v53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/oof_Densenet161_f0_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet161_f1_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet161_f2_v72\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f0_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f1_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet169_f2_v73\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f0_v74\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f1_v74\r\n",
      "/home/zahar_chikishev/running/oof_Densenet201_f2_v74\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f0_v75\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f1_v75\r\n",
      "/home/zahar_chikishev/running/oof_se_resnext101_32x4d_f2_v75\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/oof*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahar_chikishev/running/preds_Densenet161_v72\r\n",
      "/home/zahar_chikishev/running/preds_Densenet169_v73\r\n",
      "/home/zahar_chikishev/running/preds_Densenet201_v74\r\n",
      "/home/zahar_chikishev/running/preds_se_resnext101_32x4d_v75\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/zahar_chikishev/running/preds*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = getPredsOOF(aug=8,datasets=range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32, 674252, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model 0 fold 0 target 0\n",
      "starting model 0 fold 0 target 1\n",
      "starting model 0 fold 0 target 2\n",
      "starting model 0 fold 0 target 3\n",
      "starting model 0 fold 0 target 4\n",
      "starting model 0 fold 0 target 5\n",
      "starting model 1 fold 0 target 0\n",
      "starting model 1 fold 0 target 1\n",
      "starting model 1 fold 0 target 2\n",
      "starting model 1 fold 0 target 3\n",
      "starting model 1 fold 0 target 4\n",
      "starting model 1 fold 0 target 5\n",
      "starting model 2 fold 0 target 0\n",
      "starting model 2 fold 0 target 1\n",
      "starting model 2 fold 0 target 2\n",
      "starting model 2 fold 0 target 3\n",
      "starting model 2 fold 0 target 4\n",
      "starting model 2 fold 0 target 5\n",
      "starting model 3 fold 0 target 0\n",
      "starting model 3 fold 0 target 1\n",
      "starting model 3 fold 0 target 2\n",
      "starting model 3 fold 0 target 3\n",
      "starting model 3 fold 0 target 4\n",
      "starting model 3 fold 0 target 5\n",
      "starting model 4 fold 0 target 0\n",
      "starting model 4 fold 0 target 1\n",
      "starting model 4 fold 0 target 2\n",
      "starting model 4 fold 0 target 3\n",
      "starting model 4 fold 0 target 4\n",
      "starting model 4 fold 0 target 5\n",
      "starting model 5 fold 0 target 0\n",
      "starting model 5 fold 0 target 1\n",
      "starting model 5 fold 0 target 2\n",
      "starting model 5 fold 0 target 3\n",
      "starting model 5 fold 0 target 4\n",
      "starting model 5 fold 0 target 5\n",
      "starting model 6 fold 0 target 0\n",
      "starting model 6 fold 0 target 1\n",
      "starting model 6 fold 0 target 2\n",
      "starting model 6 fold 0 target 3\n",
      "starting model 6 fold 0 target 4\n",
      "starting model 6 fold 0 target 5\n",
      "starting model 7 fold 0 target 0\n",
      "starting model 7 fold 0 target 1\n",
      "starting model 7 fold 0 target 2\n",
      "starting model 7 fold 0 target 3\n",
      "starting model 7 fold 0 target 4\n",
      "starting model 7 fold 0 target 5\n",
      "starting model 0 fold 1 target 0\n",
      "starting model 0 fold 1 target 1\n",
      "starting model 0 fold 1 target 2\n",
      "starting model 0 fold 1 target 3\n",
      "starting model 0 fold 1 target 4\n",
      "starting model 0 fold 1 target 5\n",
      "starting model 1 fold 1 target 0\n",
      "starting model 1 fold 1 target 1\n",
      "starting model 1 fold 1 target 2\n",
      "starting model 1 fold 1 target 3\n",
      "starting model 1 fold 1 target 4\n",
      "starting model 1 fold 1 target 5\n",
      "starting model 2 fold 1 target 0\n",
      "starting model 2 fold 1 target 1\n",
      "starting model 2 fold 1 target 2\n",
      "starting model 2 fold 1 target 3\n",
      "starting model 2 fold 1 target 4\n",
      "starting model 2 fold 1 target 5\n",
      "starting model 3 fold 1 target 0\n",
      "starting model 3 fold 1 target 1\n",
      "starting model 3 fold 1 target 2\n",
      "starting model 3 fold 1 target 3\n",
      "starting model 3 fold 1 target 4\n",
      "starting model 3 fold 1 target 5\n",
      "starting model 4 fold 1 target 0\n",
      "starting model 4 fold 1 target 1\n",
      "starting model 4 fold 1 target 2\n",
      "starting model 4 fold 1 target 3\n",
      "starting model 4 fold 1 target 4\n",
      "starting model 4 fold 1 target 5\n",
      "starting model 5 fold 1 target 0\n",
      "starting model 5 fold 1 target 1\n",
      "starting model 5 fold 1 target 2\n",
      "starting model 5 fold 1 target 3\n",
      "starting model 5 fold 1 target 4\n",
      "starting model 5 fold 1 target 5\n",
      "starting model 6 fold 1 target 0\n",
      "starting model 6 fold 1 target 1\n",
      "starting model 6 fold 1 target 2\n",
      "starting model 6 fold 1 target 3\n",
      "starting model 6 fold 1 target 4\n",
      "starting model 6 fold 1 target 5\n",
      "starting model 7 fold 1 target 0\n",
      "starting model 7 fold 1 target 1\n",
      "starting model 7 fold 1 target 2\n",
      "starting model 7 fold 1 target 3\n",
      "starting model 7 fold 1 target 4\n",
      "starting model 7 fold 1 target 5\n",
      "starting model 0 fold 2 target 0\n",
      "starting model 0 fold 2 target 1\n",
      "starting model 0 fold 2 target 2\n",
      "starting model 0 fold 2 target 3\n",
      "starting model 0 fold 2 target 4\n",
      "starting model 0 fold 2 target 5\n",
      "starting model 1 fold 2 target 0\n",
      "starting model 1 fold 2 target 1\n",
      "starting model 1 fold 2 target 2\n",
      "starting model 1 fold 2 target 3\n",
      "starting model 1 fold 2 target 4\n",
      "starting model 1 fold 2 target 5\n",
      "starting model 2 fold 2 target 0\n",
      "starting model 2 fold 2 target 1\n",
      "starting model 2 fold 2 target 2\n",
      "starting model 2 fold 2 target 3\n",
      "starting model 2 fold 2 target 4\n",
      "starting model 2 fold 2 target 5\n",
      "starting model 3 fold 2 target 0\n",
      "starting model 3 fold 2 target 1\n",
      "starting model 3 fold 2 target 2\n",
      "starting model 3 fold 2 target 3\n",
      "starting model 3 fold 2 target 4\n",
      "starting model 3 fold 2 target 5\n",
      "starting model 4 fold 2 target 0\n",
      "starting model 4 fold 2 target 1\n",
      "starting model 4 fold 2 target 2\n",
      "starting model 4 fold 2 target 3\n",
      "starting model 4 fold 2 target 4\n",
      "starting model 4 fold 2 target 5\n",
      "starting model 5 fold 2 target 0\n",
      "starting model 5 fold 2 target 1\n",
      "starting model 5 fold 2 target 2\n",
      "starting model 5 fold 2 target 3\n",
      "starting model 5 fold 2 target 4\n",
      "starting model 5 fold 2 target 5\n",
      "starting model 6 fold 2 target 0\n",
      "starting model 6 fold 2 target 1\n",
      "starting model 6 fold 2 target 2\n",
      "starting model 6 fold 2 target 3\n",
      "starting model 6 fold 2 target 4\n",
      "starting model 6 fold 2 target 5\n",
      "starting model 7 fold 2 target 0\n",
      "starting model 7 fold 2 target 1\n",
      "starting model 7 fold 2 target 2\n",
      "starting model 7 fold 2 target 3\n",
      "starting model 7 fold 2 target 4\n",
      "starting model 7 fold 2 target 5\n",
      "total running time 37.21793270111084\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for fold in range(3):\n",
    "    for ds_idx in range(len(preds_all)):\n",
    "        for target in range(6):\n",
    "            train_ensemble(train_md, preds_all, fold=fold, target=target, ds_idx=ds_idx, \n",
    "                           first_step=True, skip_first=True)\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total running time 578.6535203456879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.06172 ensemble ll 0.06133\n",
      "valid original ll 0.06172 ensemble ll 0.06154\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx != -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.06180 ensemble ll 0.06140\n",
      "valid original ll 0.06180 ensemble ll 0.06162\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx != -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0 target 0\n",
      "obj  0.09505849853965692\n",
      "obj  0.09918208444059423\n",
      "obj  0.09917166581599661\n",
      "obj  0.0991624383465325\n",
      "obj  0.09915674972073371\n",
      "obj  0.09912212885958238\n",
      "obj  0.09910981173006794\n",
      "obj  0.09889245178546928\n",
      "obj  0.09645445001098746\n",
      "obj  0.09640950070186724\n",
      "obj  0.09636595303170802\n",
      "obj  0.0963273966135857\n",
      "obj  0.09628863388143438\n",
      "obj  0.09624948474948827\n",
      "obj  0.09621309957593742\n",
      "obj  0.09618081281413036\n",
      "obj  0.09615409117491973\n",
      "obj  0.09613501200630495\n",
      "obj  0.09611679256046779\n",
      "obj  0.09609346001177674\n",
      "obj  0.09607304752830283\n",
      "obj  0.09605632365236\n",
      "obj  0.09604278295873692\n",
      "obj  0.0960305332567309\n",
      "obj  0.09602033858171219\n",
      "obj  0.09601182020771828\n",
      "obj  0.0960054039722957\n",
      "obj  0.09600019142895776\n",
      "obj  0.09599511085994882\n",
      "obj  0.09599146144968833\n",
      "obj  0.09598925350824185\n",
      "obj  0.09596885153130054\n",
      "obj  0.09594739489551073\n",
      "obj  0.09592428872292628\n",
      "obj  0.09590640660344679\n",
      "obj  0.09588875980388578\n",
      "obj  0.09586998834351895\n",
      "obj  0.0958485385829003\n",
      "obj  0.095823804374683\n",
      "obj  0.09580984591091782\n",
      "obj  0.09579607620225751\n",
      "obj  0.0957824670968154\n",
      "obj  0.09576908634744723\n",
      "obj  0.09575667551776089\n",
      "obj  0.09574044553853633\n",
      "obj  0.09572466456420388\n",
      "obj  0.09570761680386729\n",
      "obj  0.09569120168929936\n",
      "obj  0.09567140745757843\n",
      "obj  0.09564975900504119\n",
      "obj  0.09562689239611677\n",
      "obj  0.09560425180178905\n",
      "obj  0.09558449796367731\n",
      "obj  0.09556768339932112\n",
      "obj  0.095551393855818\n",
      "obj  0.09553272275825007\n",
      "obj  0.09551265503786845\n",
      "obj  0.09549142329763435\n",
      "obj  0.09547205086794794\n",
      "obj  0.09545208792468832\n",
      "obj  0.09543245742376721\n",
      "obj  0.09541278535928395\n",
      "obj  0.09539346438162764\n",
      "obj  0.09537490271819991\n",
      "obj  0.09535767248594039\n",
      "obj  0.09534091171488038\n",
      "obj  0.09532528626366255\n",
      "obj  0.09530508458214482\n",
      "obj  0.09528340120928967\n",
      "obj  0.09525988165528505\n",
      "obj  0.09523852532370349\n",
      "obj  0.09521605103486845\n",
      "obj  0.09519748597331341\n",
      "obj  0.09518069367257712\n",
      "obj  0.09516117834848539\n",
      "obj  0.09514406954531618\n",
      "obj  0.0951294701687113\n",
      "obj  0.09511655563643312\n",
      "obj  0.0951030225491998\n",
      "obj  0.09508964822776433\n",
      "obj  0.09507694372888756\n",
      "obj  0.09505993621789954\n",
      "obj  0.09504440064592333\n",
      "obj  0.09503007422549022\n",
      "obj  0.0950175165628692\n",
      "obj  0.09500655182079332\n",
      "obj  0.09499672369168825\n",
      "obj  0.09498557682654868\n",
      "obj  0.09497471041921492\n",
      "obj  0.09496533434770864\n",
      "obj  0.0949569525774456\n",
      "obj  0.09494529680899622\n",
      "obj  0.09493455035230544\n",
      "obj  0.09492552368600403\n",
      "obj  0.09491761534368606\n",
      "obj  0.09490827721426331\n",
      "obj  0.09489774939026108\n",
      "obj  0.09488867427892565\n",
      "obj  0.0948799081998475\n",
      "obj  0.09487089506843412\n",
      "obj  0.09486095276848683\n",
      "obj  0.09485229572765266\n",
      "obj  0.09484506110359564\n",
      "obj  0.09483879846807423\n",
      "obj  0.09483326285201438\n",
      "obj  0.09482752971340717\n",
      "obj  0.09481991345108687\n",
      "obj  0.09481126853764482\n",
      "obj  0.09480244310672034\n",
      "obj  0.09479321723297278\n",
      "obj  0.09478322892906203\n",
      "obj  0.0947712781831175\n",
      "obj  0.09475002140135777\n",
      "obj  0.09471013570980465\n",
      "obj  0.09469365850533654\n",
      "obj  0.0946917552774049\n",
      "obj  0.09469123344813268\n",
      "obj  0.09469092020506195\n",
      "obj  0.09469089005512021\n",
      "obj  0.09469046276461796\n",
      "obj  0.09469042256065961\n",
      "obj  0.094690422559243\n",
      "obj  0.09469042255869453\n",
      "v20 d-1 f0 t0: original ll 0.0962 auc 0.9871, ensemble ll 0.0964 auc 0.9871\n",
      "running time 50.912203788757324\n",
      "starting fold 0 target 1\n",
      "obj  0.014075210985955924\n",
      "obj  0.014158556220545728\n",
      "obj  0.01415306023432727\n",
      "obj  0.014184097145269078\n",
      "obj  0.014518891550107918\n",
      "obj  0.014468572368663212\n",
      "obj  0.014521376829060045\n",
      "obj  0.014680975758498142\n",
      "obj  0.014539080510479366\n",
      "obj  0.014301053952346562\n",
      "obj  0.014290205698714437\n",
      "obj  0.014278536097508062\n",
      "obj  0.014148197466698466\n",
      "obj  0.014139300890860124\n",
      "obj  0.014131280308038327\n",
      "obj  0.014124018699479358\n",
      "obj  0.014117422345118442\n",
      "obj  0.014111413075344012\n",
      "obj  0.014105925060507705\n",
      "obj  0.01410090182411397\n",
      "obj  0.014096293318907247\n",
      "obj  0.014092056260839996\n",
      "obj  0.014086245492808992\n",
      "obj  0.014080875106968397\n",
      "obj  0.014076250455178033\n",
      "obj  0.014072175248582713\n",
      "obj  0.014067463236967632\n",
      "obj  0.014061903053883324\n",
      "obj  0.01405714534006839\n",
      "obj  0.014053095054367673\n",
      "obj  0.01404955755733184\n",
      "obj  0.014046411512566961\n",
      "obj  0.014043577058318102\n",
      "obj  0.014040997782373858\n",
      "obj  0.014038631746198854\n",
      "obj  0.014036446625743196\n",
      "obj  0.014033957103464396\n",
      "obj  0.014028398267806469\n",
      "obj  0.013980825119144077\n",
      "obj  0.013963100701862857\n",
      "obj  0.013933800191750173\n",
      "obj  0.013887224206275322\n",
      "obj  0.013831972220984376\n",
      "obj  0.013812237712872509\n",
      "obj  0.013806131017982242\n",
      "obj  0.013803576224596827\n",
      "obj  0.013783945175028003\n",
      "obj  0.013763439312885468\n",
      "obj  0.013756459554597417\n",
      "obj  0.013756247682370262\n",
      "obj  0.01375616130085957\n",
      "obj  0.013756121843397511\n",
      "obj  0.013756068072161771\n",
      "obj  0.013755936545460519\n",
      "obj  0.013755934535036977\n",
      "obj  0.013755933659076737\n",
      "v20 d-1 f0 t1: original ll 0.0155 auc 0.9782, ensemble ll 0.0155 auc 0.9778\n",
      "running time 23.54450249671936\n",
      "starting fold 0 target 2\n",
      "obj  0.03918687467805548\n",
      "obj  0.03995582683563147\n",
      "obj  0.03995140152179508\n",
      "obj  0.03994882315763924\n",
      "obj  0.03995088036261975\n",
      "obj  0.03989989409977279\n",
      "obj  0.039910130323024325\n",
      "obj  0.039852622961355944\n",
      "obj  0.0391404401637099\n",
      "obj  0.0390643032002066\n",
      "obj  0.039043933151165826\n",
      "obj  0.03902606550751277\n",
      "obj  0.0390110474514835\n",
      "obj  0.03899635662048828\n",
      "obj  0.0389845117522356\n",
      "obj  0.03897628423550015\n",
      "obj  0.03897075317985068\n",
      "obj  0.03896696384103961\n",
      "obj  0.03896416394655591\n",
      "obj  0.03896191686463763\n",
      "obj  0.038959366613634756\n",
      "obj  0.038954257666612375\n",
      "obj  0.03894953509659316\n",
      "obj  0.03894574067559165\n",
      "obj  0.03894434794527603\n",
      "obj  0.038939950496625304\n",
      "obj  0.038935789441999144\n",
      "obj  0.03893407940592046\n",
      "obj  0.03893288078251633\n",
      "obj  0.038932038691155864\n",
      "obj  0.038929281363222774\n",
      "obj  0.03892713970902496\n",
      "obj  0.038925412499619554\n",
      "obj  0.03892421789444223\n",
      "obj  0.03892315060989883\n",
      "obj  0.038921079766190504\n",
      "obj  0.038919675124162265\n",
      "obj  0.0389186087243667\n",
      "obj  0.038917759827063164\n",
      "obj  0.038917067888997695\n",
      "obj  0.038916498535714814\n",
      "obj  0.03891471803299155\n",
      "obj  0.0389131876819644\n",
      "obj  0.038912051646425375\n",
      "obj  0.038911156459924795\n",
      "obj  0.03891042925942365\n",
      "obj  0.03890911063704582\n",
      "obj  0.038907021447202345\n",
      "obj  0.0389053823697646\n",
      "obj  0.038904057511521345\n",
      "obj  0.03890296177489165\n",
      "obj  0.038902046816447954\n",
      "obj  0.03890128087042098\n",
      "obj  0.03890064027178047\n",
      "obj  0.03890010721641272\n",
      "obj  0.03889966807128476\n",
      "obj  0.038899312406538676\n",
      "obj  0.03889903011822824\n",
      "obj  0.03889881214069636\n",
      "obj  0.038898653140383405\n",
      "obj  0.03889854675437829\n",
      "obj  0.03889848774806924\n",
      "obj  0.0388984729069297\n",
      "obj  0.03889849819128834\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855953809132\n",
      "obj  0.03889855933790453\n",
      "obj  0.03889855933790453\n",
      "obj  0.03889852513498917\n",
      "obj  0.03889856111736237\n",
      "obj  0.03889856111736236\n",
      "obj  0.03889854219372149\n",
      "obj  0.03889854219372149\n",
      "obj  0.03889853344449871\n",
      "obj  0.03889853344449871\n",
      "obj  0.03889852923461893\n",
      "obj  0.03889852923461893\n",
      "obj  0.03889852717100259\n",
      "obj  0.03889852717100259\n",
      "obj  0.03889852614954297\n",
      "obj  0.03889852614954297\n",
      "obj  0.038898525641402545\n",
      "obj  0.038898525641402545\n",
      "obj  0.03889852538797993\n",
      "obj  0.03889852538797993\n",
      "obj  0.038898525261430575\n",
      "obj  0.03889852526143058\n",
      "obj  0.03889852519819637\n",
      "obj  0.03889852519819637\n",
      "obj  0.03889852516658941\n",
      "obj  0.03889852516658941\n",
      "obj  0.03889852515078845\n",
      "obj  0.03889852514288861\n",
      "obj  0.0388985251428886\n",
      "obj  0.038898525138938836\n",
      "obj  0.038898525138938836\n",
      "obj  0.038898525136964006\n",
      "obj  0.038898525136964006\n",
      "obj  0.038898525135976594\n",
      "obj  0.038898525135976594\n",
      "obj  0.03889852513548288\n",
      "obj  0.038898525135482885\n",
      "obj  0.038898525135236034\n",
      "obj  0.038898525135236034\n",
      "obj  0.0388985251351126\n",
      "obj  0.0388985251351126\n",
      "obj  0.03889852513505089\n",
      "obj  0.03889852513505089\n",
      "obj  0.03889852513498917\n",
      "obj  0.038898596419162455\n",
      "obj  0.038898596419162455\n",
      "obj  0.03889859401190345\n",
      "obj  0.03889859401190345\n",
      "obj  0.03889855602620522\n",
      "obj  0.03889855602620522\n",
      "obj  0.03889853974116861\n",
      "obj  0.03889853974116861\n",
      "obj  0.038898532238402304\n",
      "obj  0.038898532238402304\n",
      "obj  0.03889852863663695\n",
      "obj  0.03889852863663694\n",
      "obj  0.0388985268732808\n",
      "obj  0.0388985268732808\n",
      "obj  0.03889852600099972\n",
      "obj  0.03889852600099972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.03889852556721037\n",
      "obj  0.03889852556721037\n",
      "obj  0.03889852535090372\n",
      "obj  0.03889852535090372\n",
      "obj  0.03889852524289743\n",
      "obj  0.038898525242897435\n",
      "obj  0.038898525188931034\n",
      "obj  0.038898525188931034\n",
      "obj  0.03889852516195705\n",
      "obj  0.03889852516195705\n",
      "obj  0.03889852514847236\n",
      "obj  0.038898525148472356\n",
      "obj  0.03889852514173057\n",
      "obj  0.03889852514173057\n",
      "obj  0.038898525138359834\n",
      "obj  0.038898525138359834\n",
      "obj  0.03889852513667451\n",
      "obj  0.03889852513583182\n",
      "obj  0.03889852513583182\n",
      "obj  0.0388985251354105\n",
      "obj  0.0388985251354105\n",
      "obj  0.03889852513519985\n",
      "obj  0.03889852513519985\n",
      "obj  0.0388985251350945\n",
      "obj  0.0388985251350945\n",
      "obj  0.038898525135041856\n",
      "obj  0.03889852513504185\n",
      "obj  0.03889852513498917\n",
      "obj  0.03889859494985436\n",
      "obj  0.03889859494985437\n",
      "obj  0.03889859231801107\n",
      "obj  0.03889859231801106\n",
      "obj  0.03889855521243488\n",
      "obj  0.03889855521243488\n",
      "obj  0.03889853934306171\n",
      "obj  0.03889853934306171\n",
      "obj  0.03889853204124085\n",
      "obj  0.03889853204124085\n",
      "obj  0.03889852853853112\n",
      "obj  0.0388985285385311\n",
      "obj  0.03889852682434686\n",
      "obj  0.03889852682434686\n",
      "obj  0.03889852597656252\n",
      "obj  0.03889852597656252\n",
      "obj  0.03889852555499921\n",
      "obj  0.0388985255549992\n",
      "obj  0.03889852534479999\n",
      "obj  0.0388985253448\n",
      "obj  0.03889852523984602\n",
      "obj  0.03889852523984603\n",
      "obj  0.038898525187405476\n",
      "obj  0.038898525187405476\n",
      "obj  0.03889852516119428\n",
      "obj  0.03889852516119428\n",
      "obj  0.038898525148090966\n",
      "obj  0.038898525148090966\n",
      "obj  0.038898525141539894\n",
      "obj  0.03889852514153989\n",
      "obj  0.03889852513826448\n",
      "obj  0.038898525138264486\n",
      "obj  0.038898525136626824\n",
      "obj  0.038898525136626824\n",
      "obj  0.03889852513580799\n",
      "obj  0.03889852513580799\n",
      "obj  0.038898525135398584\n",
      "obj  0.038898525135398584\n",
      "obj  0.038898525135193894\n",
      "obj  0.038898525135193894\n",
      "obj  0.038898525135091525\n",
      "obj  0.03889852513509152\n",
      "obj  0.03889852513504036\n",
      "obj  0.03889852513504036\n",
      "obj  0.03889852513498917\n",
      "obj  0.03889859465616795\n",
      "obj  0.03889859465616795\n",
      "obj  0.03889859198135059\n",
      "obj  0.03889859198135059\n",
      "obj  0.03889855505061492\n",
      "obj  0.03889855505061492\n",
      "obj  0.03889853926387451\n",
      "obj  0.03889853926387451\n",
      "obj  0.03889853200201835\n",
      "obj  0.03889853200201836\n",
      "obj  0.038898528519012994\n",
      "obj  0.03889852851901301\n",
      "obj  0.03889852681461114\n",
      "obj  0.03889852681461114\n",
      "obj  0.03889852597170048\n",
      "obj  0.03889852597170048\n",
      "obj  0.038898525552569646\n",
      "obj  0.038898525552569646\n",
      "obj  0.03889852534358557\n",
      "obj  0.03889852534358557\n",
      "obj  0.038898525239238924\n",
      "obj  0.038898525239238924\n",
      "obj  0.03889852518710192\n",
      "obj  0.03889852518710192\n",
      "obj  0.038898525161042516\n",
      "obj  0.038898525161042516\n",
      "obj  0.03889852514801508\n",
      "obj  0.03889852514801509\n",
      "obj  0.03889852514150196\n",
      "obj  0.038898525141501966\n",
      "obj  0.038898525138245515\n",
      "obj  0.038898525138245515\n",
      "obj  0.038898525136617325\n",
      "obj  0.038898525136617325\n",
      "obj  0.038898525135803254\n",
      "obj  0.038898525135803254\n",
      "obj  0.038898525135396204\n",
      "obj  0.038898525135396204\n",
      "obj  0.038898525135192694\n",
      "obj  0.038898525135192694\n",
      "obj  0.03889852513509094\n",
      "obj  0.03889852513504006\n",
      "obj  0.03889852513504006\n",
      "obj  0.03889852513498917\n",
      "obj  0.0388985945974374\n",
      "obj  0.03889859459743741\n",
      "obj  0.03889859191410216\n",
      "obj  0.03889859191410215\n",
      "obj  0.038898555018287796\n",
      "obj  0.038898555018287796\n",
      "obj  0.038898539248054205\n",
      "obj  0.03889853924805419\n",
      "obj  0.03889853199418212\n",
      "obj  0.038898531994182126\n",
      "obj  0.038898528515113426\n",
      "obj  0.038898528515113426\n",
      "obj  0.038898526812666\n",
      "obj  0.03889852681266599\n",
      "obj  0.038898525970729105\n",
      "obj  0.038898525970729105\n",
      "obj  0.03889852555208424\n",
      "obj  0.03889852555208424\n",
      "obj  0.038898525343342955\n",
      "obj  0.038898525343342955\n",
      "obj  0.03889852523911762\n",
      "obj  0.03889852523911762\n",
      "obj  0.03889852518704129\n",
      "obj  0.03889852518704129\n",
      "obj  0.03889852516101221\n",
      "obj  0.03889852516101221\n",
      "obj  0.03889852514799993\n",
      "obj  0.03889852514799993\n",
      "obj  0.03889852514149436\n",
      "obj  0.03889852514149436\n",
      "obj  0.03889852513824172\n",
      "obj  0.03889852513824172\n",
      "obj  0.03889852513661545\n",
      "obj  0.03889852513661545\n",
      "obj  0.03889852513580232\n",
      "obj  0.03889852513580232\n",
      "obj  0.038898525135395746\n",
      "obj  0.038898525135395746\n",
      "obj  0.03889852513519246\n",
      "obj  0.03889852513519246\n",
      "obj  0.03889852513509082\n",
      "obj  0.03889852513509082\n",
      "obj  0.038898525135039996\n",
      "obj  0.03889852513504\n",
      "v20 d-1 f0 t2: original ll 0.0426 auc 0.9927, ensemble ll 0.0427 auc 0.9927\n",
      "running time 35.160927295684814\n",
      "starting fold 0 target 3\n",
      "obj  0.02367841576293622\n",
      "obj  0.02440374756705673\n",
      "obj  0.02439896137962826\n",
      "obj  0.024396061643364143\n",
      "obj  0.024397991647132546\n",
      "obj  0.02435833165600985\n",
      "obj  0.02436627491598206\n",
      "obj  0.02430543628638337\n",
      "obj  0.023611737142949132\n",
      "obj  0.023584664732725424\n",
      "obj  0.023581581974293733\n",
      "obj  0.023576798345901383\n",
      "obj  0.023564190083777047\n",
      "obj  0.023540945954199703\n",
      "obj  0.023534397862662947\n",
      "obj  0.023531018458880226\n",
      "obj  0.023529331239575145\n",
      "obj  0.023525469864510894\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495146842768\n",
      "obj  0.023525495146842774\n",
      "obj  0.023525495137019126\n",
      "obj  0.023525495137019126\n",
      "obj  0.02352542092387438\n",
      "obj  0.023525491165055607\n",
      "obj  0.0235254911650556\n",
      "obj  0.023525441364680048\n",
      "obj  0.023525441364680048\n",
      "obj  0.023525427439273428\n",
      "obj  0.023525427439273428\n",
      "obj  0.023525423257027004\n",
      "obj  0.023525423257027004\n",
      "obj  0.02352542186019694\n",
      "obj  0.02352542186019694\n",
      "obj  0.023525421334844455\n",
      "obj  0.023525421334844452\n",
      "obj  0.023525421115060282\n",
      "obj  0.02352542133443129\n",
      "obj  0.023525421334431303\n",
      "obj  0.023525421221173674\n",
      "obj  0.023525421221173674\n",
      "obj  0.023525421167223927\n",
      "obj  0.023525421167223927\n",
      "obj  0.023525421140918844\n",
      "obj  0.023525421140918854\n",
      "obj  0.02352542112793375\n",
      "obj  0.023525421127933755\n",
      "obj  0.023525421121483057\n",
      "obj  0.023525421121483057\n",
      "obj  0.02352542111826817\n",
      "obj  0.02352542111826818\n",
      "obj  0.023525421116663368\n",
      "obj  0.023525421116663368\n",
      "obj  0.02352542111586161\n",
      "obj  0.02352542111586161\n",
      "obj  0.02352542111546089\n",
      "obj  0.02352542111546089\n",
      "obj  0.023525421115260573\n",
      "obj  0.023525421115260573\n",
      "obj  0.023525421115160424\n",
      "obj  0.023525421115160424\n",
      "obj  0.023525421115110363\n",
      "obj  0.023525421115110363\n",
      "obj  0.023525421115085317\n",
      "obj  0.023525421115085317\n",
      "obj  0.02352542111507281\n",
      "obj  0.02352542111507281\n",
      "obj  0.023525421115066558\n",
      "obj  0.023525421115066558\n",
      "obj  0.023525421115060282\n",
      "obj  0.023525648751591785\n",
      "obj  0.023525648751591785\n",
      "obj  0.023525555699787922\n",
      "obj  0.023525555699787922\n",
      "obj  0.023525459211600857\n",
      "obj  0.023525459211600857\n",
      "obj  0.023525432809024905\n",
      "obj  0.023525432809024905\n",
      "obj  0.02352542511194263\n",
      "obj  0.02352542511194263\n",
      "obj  0.02352542265423748\n",
      "obj  0.02352542265423748\n",
      "obj  0.023525421769978114\n",
      "obj  0.023525421769978117\n",
      "obj  0.02352542141401014\n",
      "obj  0.02352542141401014\n",
      "obj  0.023525421257407496\n",
      "obj  0.023525421257407496\n",
      "obj  0.023525421184451886\n",
      "obj  0.023525421184451896\n",
      "obj  0.023525421149310593\n",
      "obj  0.023525421149310593\n",
      "obj  0.023525421132074054\n",
      "obj  0.023525421132074054\n",
      "obj  0.023525421123539326\n",
      "obj  0.02352542112353933\n",
      "obj  0.023525421119292855\n",
      "obj  0.023525421119292855\n",
      "obj  0.02352542111717482\n",
      "obj  0.02352542111717482\n",
      "obj  0.023525421116117117\n",
      "obj  0.023525421116117124\n",
      "obj  0.023525421115588595\n",
      "obj  0.023525421115588595\n",
      "obj  0.023525421115324414\n",
      "obj  0.023525421115324414\n",
      "obj  0.023525421115192346\n",
      "obj  0.023525421115192346\n",
      "obj  0.023525421115126302\n",
      "obj  0.023525421115126302\n",
      "obj  0.0235254211150933\n",
      "obj  0.0235254211150933\n",
      "obj  0.02352542111507679\n",
      "obj  0.023525421115076793\n",
      "obj  0.023525421115068543\n",
      "obj  0.023525421115068543\n",
      "obj  0.023525421115064418\n",
      "obj  0.023525421115064418\n",
      "obj  0.023525421115060282\n",
      "obj  0.023525648125500797\n",
      "obj  0.023525648125500797\n",
      "obj  0.023525555458964467\n",
      "obj  0.023525555458964467\n",
      "obj  0.023525459089497998\n",
      "obj  0.023525459089497998\n",
      "obj  0.023525432747506965\n",
      "obj  0.023525432747506965\n",
      "obj  0.023525425081071027\n",
      "obj  0.023525425081071027\n",
      "obj  0.023525422638782247\n",
      "obj  0.023525422638782247\n",
      "obj  0.02352542176224814\n",
      "obj  0.02352542176224814\n",
      "obj  0.023525421410143507\n",
      "obj  0.02352542141014351\n",
      "obj  0.023525421255473758\n",
      "obj  0.023525421255473758\n",
      "obj  0.023525421183484926\n",
      "obj  0.023525421183484926\n",
      "obj  0.023525421148827073\n",
      "obj  0.023525421148827073\n",
      "obj  0.023525421131832293\n",
      "obj  0.023525421131832293\n",
      "obj  0.02352542112341845\n",
      "obj  0.023525421123418447\n",
      "obj  0.023525421119232413\n",
      "obj  0.023525421119232413\n",
      "obj  0.02352542111714461\n",
      "obj  0.02352542111714461\n",
      "obj  0.023525421116102008\n",
      "obj  0.02352542111610201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.02352542111558104\n",
      "obj  0.02352542111558104\n",
      "obj  0.02352542111532064\n",
      "obj  0.023525421115320636\n",
      "obj  0.023525421115190456\n",
      "obj  0.023525421115190456\n",
      "obj  0.023525421115125372\n",
      "obj  0.023525421115125372\n",
      "obj  0.023525421115092836\n",
      "obj  0.023525421115092836\n",
      "obj  0.023525421115076554\n",
      "obj  0.023525421115076554\n",
      "obj  0.02352542111506842\n",
      "obj  0.02352542111506842\n",
      "obj  0.02352542111506435\n",
      "obj  0.02352542111506436\n",
      "obj  0.023525421115060282\n",
      "obj  0.023525648001794842\n",
      "obj  0.023525648001794842\n",
      "obj  0.023525555410331547\n",
      "obj  0.02352555541033154\n",
      "obj  0.023525459064937235\n",
      "obj  0.023525459064937235\n",
      "obj  0.023525432735156743\n",
      "obj  0.023525432735156743\n",
      "obj  0.02352542507487938\n",
      "obj  0.02352542507487938\n",
      "obj  0.02352542263568402\n",
      "obj  0.02352542263568402\n",
      "obj  0.02352542176069894\n",
      "obj  0.02352542176069894\n",
      "obj  0.023525421409368665\n",
      "obj  0.023525421409368665\n",
      "obj  0.023525421255086283\n",
      "obj  0.023525421255086283\n",
      "obj  0.023525421183291182\n",
      "obj  0.023525421183291182\n",
      "obj  0.023525421148730203\n",
      "obj  0.023525421148730203\n",
      "obj  0.023525421131783856\n",
      "obj  0.023525421131783856\n",
      "obj  0.023525421123394223\n",
      "obj  0.023525421123394223\n",
      "obj  0.023525421119220298\n",
      "obj  0.023525421119220298\n",
      "obj  0.02352542111713855\n",
      "obj  0.023525421116098986\n",
      "obj  0.02352542111609899\n",
      "obj  0.023525421115579526\n",
      "obj  0.023525421115579526\n",
      "obj  0.023525421115319873\n",
      "obj  0.023525421115319873\n",
      "obj  0.023525421115190084\n",
      "obj  0.023525421115190084\n",
      "obj  0.023525421115125178\n",
      "obj  0.023525421115125178\n",
      "obj  0.02352542111509273\n",
      "obj  0.023525421115092735\n",
      "obj  0.023525421115076512\n",
      "obj  0.023525421115076512\n",
      "obj  0.023525421115068397\n",
      "obj  0.023525421115068397\n",
      "obj  0.02352542111506434\n",
      "obj  0.02352542111506434\n",
      "v20 d-1 f0 t3: original ll 0.0257 auc 0.9964, ensemble ll 0.0264 auc 0.9964\n",
      "running time 15.699487447738647\n",
      "starting fold 0 target 4\n",
      "obj  0.06296278612083933\n",
      "obj  0.06379218416415877\n",
      "obj  0.06378994326117474\n",
      "obj  0.06378755377007568\n",
      "obj  0.06378762570916878\n",
      "obj  0.0637605788133759\n",
      "obj  0.06376026205185756\n",
      "obj  0.06369836901270365\n",
      "obj  0.06320687584679596\n",
      "obj  0.06319031862402814\n",
      "obj  0.06317496574453474\n",
      "obj  0.06313871333019871\n",
      "obj  0.06310740844982106\n",
      "obj  0.0630967336089957\n",
      "obj  0.06308798323090561\n",
      "obj  0.06308086647602762\n",
      "obj  0.06307514631301102\n",
      "obj  0.0630586780616591\n",
      "obj  0.06305488525372765\n",
      "obj  0.06305241677834729\n",
      "obj  0.06303131972596503\n",
      "obj  0.06302944158086252\n",
      "obj  0.06302837293670431\n",
      "obj  0.06302621403736561\n",
      "obj  0.06301398904088278\n",
      "obj  0.06301283484872046\n",
      "obj  0.06301258706367618\n",
      "obj  0.06300631329297308\n",
      "obj  0.06300595389852658\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300627809265966\n",
      "obj  0.06300609241650551\n",
      "obj  0.06300609241650552\n",
      "obj  0.0630059972270964\n",
      "obj  0.0630059972270964\n",
      "obj  0.06300596875750365\n",
      "obj  0.0630059595812226\n",
      "obj  0.06300596872026752\n",
      "obj  0.06300596872026752\n",
      "obj  0.0630059637211522\n",
      "obj  0.0630059637211522\n",
      "obj  0.0630059615430658\n",
      "obj  0.06300596154306581\n",
      "obj  0.06300596053502193\n",
      "obj  0.06300596053502193\n",
      "obj  0.06300596005133012\n",
      "obj  0.06300596005133012\n",
      "obj  0.06300595981457686\n",
      "obj  0.06300595981457686\n",
      "obj  0.06300595969747468\n",
      "obj  0.06300595969747469\n",
      "obj  0.06300595963924237\n",
      "obj  0.06300595963924237\n",
      "obj  0.0630059596102059\n",
      "obj  0.0630059596102059\n",
      "obj  0.0630059595957076\n",
      "obj  0.06300595959570762\n",
      "obj  0.06300595958846343\n",
      "obj  0.06300595958846343\n",
      "obj  0.0630059595848426\n",
      "obj  0.06300595958484262\n",
      "obj  0.0630059595830325\n",
      "obj  0.06300595958212753\n",
      "obj  0.06300595958212751\n",
      "obj  0.06300595958167506\n",
      "obj  0.06300595958167507\n",
      "obj  0.06300595958144882\n",
      "obj  0.0630059595813357\n",
      "obj  0.0630059595813357\n",
      "obj  0.06300595958127914\n",
      "obj  0.06300595958127914\n",
      "obj  0.06300595958125088\n",
      "obj  0.06300595958125088\n",
      "obj  0.0630059595812226\n",
      "obj  0.06300630063501536\n",
      "obj  0.06300630063501536\n",
      "obj  0.06300625388449116\n",
      "obj  0.06300625388449116\n",
      "obj  0.06300605429783702\n",
      "obj  0.06300605429783702\n",
      "obj  0.06300599297673017\n",
      "obj  0.06300599297673015\n",
      "obj  0.0630059726612718\n",
      "obj  0.0630059726612718\n",
      "obj  0.06300596519949199\n",
      "obj  0.063005965199492\n",
      "obj  0.06300596215765138\n",
      "obj  0.06300596081097046\n",
      "obj  0.06300596081097046\n",
      "obj  0.06300596018144317\n",
      "obj  0.06300596018144318\n",
      "obj  0.06300595987766497\n",
      "obj  0.06300595987766498\n",
      "obj  0.06300595972852621\n",
      "obj  0.06300595972852621\n",
      "obj  0.06300595965464494\n",
      "obj  0.06300595965464494\n",
      "obj  0.06300595961787638\n",
      "obj  0.06300595961787638\n",
      "obj  0.06300595959953514\n",
      "obj  0.06300595959953514\n",
      "obj  0.06300595959037529\n",
      "obj  0.06300595959037529\n",
      "obj  0.06300595958579804\n",
      "obj  0.06300595958579804\n",
      "obj  0.06300595958351012\n",
      "obj  0.06300595958351012\n",
      "obj  0.06300595958236628\n",
      "obj  0.06300595958236628\n",
      "obj  0.06300595958179445\n",
      "obj  0.06300595958179445\n",
      "obj  0.06300595958150852\n",
      "obj  0.06300595958150852\n",
      "obj  0.06300595958136555\n",
      "obj  0.06300595958136557\n",
      "obj  0.06300595958129405\n",
      "obj  0.06300595958129405\n",
      "obj  0.06300595958125832\n",
      "obj  0.06300595958125833\n",
      "obj  0.06300595958124046\n",
      "obj  0.06300595958124046\n",
      "obj  0.0630059595812226\n",
      "obj  0.06300402391820976\n",
      "obj  0.06300380769710473\n",
      "obj  0.06299918597897977\n",
      "obj  0.06299705896666864\n",
      "obj  0.06298653821055826\n",
      "obj  0.06294492821395674\n",
      "obj  0.06292844195243921\n",
      "obj  0.06290910779571106\n",
      "obj  0.06288874751928042\n",
      "obj  0.06288162996569534\n",
      "obj  0.06288026841135648\n",
      "obj  0.06287610424742011\n",
      "obj  0.06284330078589177\n",
      "obj  0.06283691055102264\n",
      "obj  0.0628367299492197\n",
      "obj  0.06283661581034117\n",
      "obj  0.06283655078541356\n",
      "obj  0.06283654398435393\n",
      "v20 d-1 f0 t4: original ll 0.0651 auc 0.9817, ensemble ll 0.0649 auc 0.9818\n",
      "running time 23.900542736053467\n",
      "starting fold 0 target 5\n",
      "obj  0.07722920618345883\n",
      "obj  0.07880854554517194\n",
      "obj  0.07880166678733833\n",
      "obj  0.07879567557681627\n",
      "obj  0.07878722910550251\n",
      "obj  0.07884275011086744\n",
      "obj  0.07880420881460816\n",
      "obj  0.07869187680584228\n",
      "obj  0.07832255722304636\n",
      "obj  0.07825863665976292\n",
      "obj  0.07819664515364837\n",
      "obj  0.0781350421715941\n",
      "obj  0.07806791962714292\n",
      "obj  0.07798959239200955\n",
      "obj  0.07792031528965634\n",
      "obj  0.07785656866594536\n",
      "obj  0.07779116371761272\n",
      "obj  0.07773345382656191\n",
      "obj  0.07768491946455644\n",
      "obj  0.07764822273509629\n",
      "obj  0.07761881573070237\n",
      "obj  0.07759668196935518\n",
      "obj  0.07758035471086142\n",
      "obj  0.07756815260198024\n",
      "obj  0.07755888487904268\n",
      "obj  0.07755103395106855\n",
      "obj  0.07753860292902186\n",
      "obj  0.07753287934824749\n",
      "obj  0.07752800800197722\n",
      "obj  0.07751597112706297\n",
      "obj  0.07751266005370658\n",
      "obj  0.07750934806825145\n",
      "obj  0.07750640548317818\n",
      "obj  0.07749586725142993\n",
      "obj  0.07748798394956463\n",
      "obj  0.07748070980536415\n",
      "obj  0.07747470401705843\n",
      "obj  0.07746764215182403\n",
      "obj  0.07745928412140661\n",
      "obj  0.0774498518284684\n",
      "obj  0.0774414739718658\n",
      "obj  0.07743427187991062\n",
      "obj  0.07742789831629401\n",
      "obj  0.07742214066913429\n",
      "obj  0.07741686291909336\n",
      "obj  0.07741197159988304\n",
      "obj  0.07740740323407092\n",
      "obj  0.07740310796273517\n",
      "obj  0.07739904877654881\n",
      "obj  0.0773951963188442\n",
      "obj  0.07739152920728547\n",
      "obj  0.07738802683419795\n",
      "obj  0.07738440831289076\n",
      "obj  0.07737932188153462\n",
      "obj  0.07737290380478754\n",
      "obj  0.0773668407602688\n",
      "obj  0.07736048588179081\n",
      "obj  0.07735264026485467\n",
      "obj  0.07734547992291911\n",
      "obj  0.07733927547058023\n",
      "obj  0.07733257601613519\n",
      "obj  0.07731841442975407\n",
      "obj  0.07727196929383176\n",
      "obj  0.07721642438594183\n",
      "obj  0.07719736523795483\n",
      "obj  0.07719391197495158\n",
      "obj  0.07717473039329664\n",
      "obj  0.07697730731251883\n",
      "obj  0.07697172497705149\n",
      "obj  0.07697169820137437\n",
      "obj  0.07697169624578296\n",
      "obj  0.0769716458705707\n",
      "v20 d-1 f0 t5: original ll 0.0808 auc 0.9791, ensemble ll 0.0809 auc 0.9791\n",
      "running time 31.352774381637573\n",
      "starting fold 1 target 0\n",
      "obj  0.09461062279871378\n",
      "obj  0.0986843057887551\n",
      "obj  0.0986754789246689\n",
      "obj  0.09866717285216485\n",
      "obj  0.09865797567524098\n",
      "obj  0.09865160647734555\n",
      "obj  0.09862662476255658\n",
      "obj  0.098389465705754\n",
      "obj  0.09594285413634833\n",
      "obj  0.09590734841090685\n",
      "obj  0.0958716720407405\n",
      "obj  0.09583860002358556\n",
      "obj  0.09580540601110804\n",
      "obj  0.09577581643523676\n",
      "obj  0.09574442993566316\n",
      "obj  0.09571789787330241\n",
      "obj  0.09569475960507826\n",
      "obj  0.09567478772710693\n",
      "obj  0.09565922897851062\n",
      "obj  0.09564529511929809\n",
      "obj  0.0956340581167793\n",
      "obj  0.09562510704888456\n",
      "obj  0.09561686638212447\n",
      "obj  0.09560919732865064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.09560171937967199\n",
      "obj  0.0955903740470844\n",
      "obj  0.0955764574601639\n",
      "obj  0.09556117477549776\n",
      "obj  0.09554591286041314\n",
      "obj  0.09552914837932056\n",
      "obj  0.09551377894098735\n",
      "obj  0.09549833458112066\n",
      "obj  0.09548425712907288\n",
      "obj  0.09547226481077542\n",
      "obj  0.09546058927135\n",
      "obj  0.09544730381696538\n",
      "obj  0.09543414061591003\n",
      "obj  0.0954159828066395\n",
      "obj  0.09539728793082136\n",
      "obj  0.09537930742341927\n",
      "obj  0.09536078103845566\n",
      "obj  0.09534327839896502\n",
      "obj  0.0953254697872216\n",
      "obj  0.09530928169073659\n",
      "obj  0.09529128450722252\n",
      "obj  0.09527402183334685\n",
      "obj  0.09525526847970782\n",
      "obj  0.09523434831902984\n",
      "obj  0.09521375427675459\n",
      "obj  0.09519470792648167\n",
      "obj  0.09517872892965268\n",
      "obj  0.09516299301702467\n",
      "obj  0.09514620749427057\n",
      "obj  0.09512694689632903\n",
      "obj  0.09510819374651072\n",
      "obj  0.09508838953719526\n",
      "obj  0.09507078443939901\n",
      "obj  0.09505167280408827\n",
      "obj  0.09503272119529409\n",
      "obj  0.09501187273427195\n",
      "obj  0.09499066992126201\n",
      "obj  0.09496963764060158\n",
      "obj  0.09495051970733163\n",
      "obj  0.09492914168268576\n",
      "obj  0.09490824032645659\n",
      "obj  0.09488868103367952\n",
      "obj  0.09487111471259037\n",
      "obj  0.09485449292263871\n",
      "obj  0.09483763499072319\n",
      "obj  0.0948187799462432\n",
      "obj  0.09479880764287506\n",
      "obj  0.09477887292952467\n",
      "obj  0.09476155951140491\n",
      "obj  0.09474691704701978\n",
      "obj  0.09473271474469902\n",
      "obj  0.09471957966031326\n",
      "obj  0.09470806498515552\n",
      "obj  0.09469779459502116\n",
      "obj  0.09468806716948158\n",
      "obj  0.09467615231368824\n",
      "obj  0.09466330759310747\n",
      "obj  0.0946498845519625\n",
      "obj  0.09463750026204629\n",
      "obj  0.09462290686088283\n",
      "obj  0.09452224604557811\n",
      "obj  0.09450484580262948\n",
      "obj  0.09449138755395975\n",
      "obj  0.09448125777280597\n",
      "obj  0.09447130068366749\n",
      "obj  0.0944496542200751\n",
      "obj  0.09441881700365728\n",
      "obj  0.09440030084270087\n",
      "obj  0.09439673510574564\n",
      "obj  0.09439618511826428\n",
      "obj  0.09439505276976357\n",
      "obj  0.09439396555290605\n",
      "obj  0.09439396171182572\n",
      "obj  0.09439396161910758\n",
      "obj  0.09439396161704726\n",
      "obj  0.09439396161692709\n",
      "obj  0.0943939616169133\n",
      "v20 d-1 f1 t0: original ll 0.0971 auc 0.9868, ensemble ll 0.0969 auc 0.9869\n",
      "running time 43.7419011592865\n",
      "starting fold 1 target 1\n",
      "obj  0.015357502699849762\n",
      "obj  0.015278582384106794\n",
      "obj  0.015279757256526538\n",
      "obj  0.015285461228105776\n",
      "obj  0.015300528764454596\n",
      "obj  0.01531725491812975\n",
      "obj  0.015335056471453138\n",
      "obj  0.015394349590857755\n",
      "obj  0.015400941409788243\n",
      "obj  0.015108712872062613\n",
      "obj  0.015017066074791236\n",
      "obj  0.014971423799835145\n",
      "obj  0.014958941387287775\n",
      "obj  0.014952099129162675\n",
      "obj  0.014945212036534393\n",
      "obj  0.014943473531366613\n",
      "obj  0.014943062312566896\n",
      "obj  0.014942815195501225\n",
      "obj  0.014942760135748927\n",
      "obj  0.014942758539091775\n",
      "obj  0.014942739498347827\n",
      "v20 d-1 f1 t1: original ll 0.0129 auc 0.9659, ensemble ll 0.0131 auc 0.9667\n",
      "running time 9.560332298278809\n",
      "starting fold 1 target 2\n",
      "obj  0.04013301422538455\n",
      "obj  0.041559904653384015\n",
      "obj  0.04155505313014329\n",
      "obj  0.04155116526605666\n",
      "obj  0.04154911558060573\n",
      "obj  0.04152351183002103\n",
      "obj  0.04152044385552439\n",
      "obj  0.04142317613984308\n",
      "obj  0.04030883235336671\n",
      "obj  0.04027544165522133\n",
      "obj  0.04024844519363962\n",
      "obj  0.04022883769065668\n",
      "obj  0.040227452035526565\n",
      "obj  0.04022699072452291\n",
      "obj  0.04021118675439028\n",
      "obj  0.040211652095582834\n",
      "obj  0.04021165209558284\n",
      "obj  0.040211652095582834\n",
      "obj  0.04021165209558284\n",
      "obj  0.040211652095582834\n",
      "obj  0.04021165209558284\n",
      "obj  0.040211652095582834\n",
      "obj  0.04021165209558284\n",
      "obj  0.040211652095582834\n",
      "obj  0.04021165209558284\n",
      "obj  0.040211652095582834\n",
      "obj  0.04021165209558284\n",
      "obj  0.04021164479421005\n",
      "obj  0.04021164479421004\n",
      "obj  0.040211327211784324\n",
      "obj  0.040211644793119054\n",
      "obj  0.040211644793119054\n",
      "obj  0.040211464954325225\n",
      "obj  0.04021146495432523\n",
      "obj  0.04021139066529247\n",
      "obj  0.04021139066529247\n",
      "obj  0.04021135755932712\n",
      "obj  0.04021134204035977\n",
      "obj  0.04021134204035977\n",
      "obj  0.04021133453898919\n",
      "obj  0.04021133453898919\n",
      "obj  0.04021133085311967\n",
      "obj  0.04021133085311967\n",
      "obj  0.04021132902702212\n",
      "obj  0.040211328118047444\n",
      "obj  0.04021132811804745\n",
      "obj  0.04021132766457686\n",
      "obj  0.04021132766457686\n",
      "obj  0.04021132743809583\n",
      "obj  0.04021132743809583\n",
      "obj  0.04021132732491887\n",
      "obj  0.040211327324918875\n",
      "obj  0.04021132726834629\n",
      "obj  0.040211327268346295\n",
      "obj  0.040211327240063995\n",
      "obj  0.040211327240063995\n",
      "obj  0.040211327225923806\n",
      "obj  0.040211327218853975\n",
      "obj  0.040211327218853975\n",
      "obj  0.04021132721531912\n",
      "obj  0.04021132721531912\n",
      "obj  0.04021132721355172\n",
      "obj  0.04021132721355172\n",
      "obj  0.04021132721266799\n",
      "obj  0.040211327212668\n",
      "obj  0.040211327212226165\n",
      "obj  0.040211327212226165\n",
      "obj  0.04021132721200525\n",
      "obj  0.04021132721200523\n",
      "obj  0.04021132721189478\n",
      "obj  0.04021132721189478\n",
      "obj  0.040211327211784324\n",
      "obj  0.04021191197218562\n",
      "obj  0.04021191197218562\n",
      "obj  0.04021190331529938\n",
      "obj  0.04021190331529938\n",
      "obj  0.04021155173373143\n",
      "obj  0.04021155173373142\n",
      "obj  0.0402114228766464\n",
      "obj  0.0402114228766464\n",
      "obj  0.0402113707817943\n",
      "obj  0.0402113707817943\n",
      "obj  0.040211347916142136\n",
      "obj  0.04021134791614214\n",
      "obj  0.04021133729330176\n",
      "obj  0.04021133729330176\n",
      "obj  0.04021133218419781\n",
      "obj  0.04021133218419781\n",
      "obj  0.04021132968055627\n",
      "obj  0.04021132968055628\n",
      "obj  0.04021132844192593\n",
      "obj  0.04021132844192593\n",
      "obj  0.04021132782579359\n",
      "obj  0.04021132782579359\n",
      "obj  0.04021132751852351\n",
      "obj  0.04021132751852352\n",
      "obj  0.04021132736508756\n",
      "obj  0.04021132736508756\n",
      "obj  0.04021132728841932\n",
      "obj  0.040211327288419335\n",
      "obj  0.04021132725009767\n",
      "obj  0.04021132725009768\n",
      "obj  0.04021132723093996\n",
      "obj  0.04021132723093996\n",
      "obj  0.04021132722136188\n",
      "obj  0.04021132722136188\n",
      "obj  0.04021132721657302\n",
      "obj  0.04021132721657303\n",
      "obj  0.04021132721417865\n",
      "obj  0.04021132721417865\n",
      "obj  0.040211327212981464\n",
      "obj  0.04021132721298148\n",
      "obj  0.040211327212382894\n",
      "obj  0.040211327212382894\n",
      "obj  0.040211327212083606\n",
      "obj  0.04021132721208361\n",
      "obj  0.04021132721193396\n",
      "obj  0.04021132721193396\n",
      "obj  0.04021132721185912\n",
      "obj  0.040211327211784324\n",
      "obj  0.04021188706229107\n",
      "obj  0.04021188706229107\n",
      "obj  0.04021188287348339\n",
      "obj  0.04021188287348339\n",
      "obj  0.0402115416304607\n",
      "obj  0.0402115416304607\n",
      "obj  0.04021141785867289\n",
      "obj  0.040211417858672896\n",
      "obj  0.040211368281842186\n",
      "obj  0.040211368281842186\n",
      "obj  0.04021134666849669\n",
      "obj  0.04021134666849669\n",
      "obj  0.04021133667007732\n",
      "obj  0.04021133667007732\n",
      "obj  0.04021133187273665\n",
      "obj  0.04021133187273666\n",
      "obj  0.04021132952486732\n",
      "obj  0.040211329524867334\n",
      "obj  0.04021132836409097\n",
      "obj  0.04021132836409097\n",
      "obj  0.0402113277868785\n",
      "obj  0.0402113277868785\n",
      "obj  0.040211327499066564\n",
      "obj  0.040211327499066564\n",
      "obj  0.04021132735535921\n",
      "obj  0.04021132728355521\n",
      "obj  0.04021132728355521\n",
      "obj  0.040211327247665615\n",
      "obj  0.040211327247665615\n",
      "obj  0.040211327229723946\n",
      "obj  0.040211327229723946\n",
      "obj  0.04021132722075387\n",
      "obj  0.04021132722075387\n",
      "obj  0.040211327216269015\n",
      "obj  0.04021132721402664\n",
      "obj  0.04021132721402665\n",
      "obj  0.040211327212905476\n",
      "obj  0.040211327212905476\n",
      "obj  0.040211327212344904\n",
      "obj  0.040211327212344904\n",
      "obj  0.040211327212064614\n",
      "obj  0.0402113272120646\n",
      "obj  0.04021132721192447\n",
      "obj  0.04021132721192448\n",
      "obj  0.04021132721185437\n",
      "obj  0.04021132721185438\n",
      "obj  0.040211327211784324\n",
      "obj  0.04021188204566175\n",
      "obj  0.040211882045661757\n",
      "obj  0.040211878766425874\n",
      "obj  0.040211878766425894\n",
      "obj  0.04021153960185062\n",
      "obj  0.04021153960185062\n",
      "obj  0.040211416851474245\n",
      "obj  0.040211416851474245\n",
      "obj  0.040211367780146993\n",
      "obj  0.040211367780146993\n",
      "obj  0.04021134641814049\n",
      "obj  0.04021134641814048\n",
      "obj  0.04021133654502514\n",
      "obj  0.040211336545025136\n",
      "obj  0.04021133181024234\n",
      "obj  0.040211331810242355\n",
      "obj  0.04021132949362891\n",
      "obj  0.04021132949362891\n",
      "obj  0.04021132834847377\n",
      "obj  0.04021132834847377\n",
      "obj  0.04021132777907039\n",
      "obj  0.04021132777907039\n",
      "obj  0.04021132749516263\n",
      "obj  0.04021132749516263\n",
      "obj  0.040211327353407295\n",
      "obj  0.04021132728257925\n",
      "obj  0.040211327282579236\n",
      "obj  0.040211327247177645\n",
      "obj  0.040211327247177645\n",
      "obj  0.04021132722947994\n",
      "obj  0.04021132722947996\n",
      "obj  0.04021132722063188\n",
      "obj  0.04021132722063188\n",
      "obj  0.04021132721620802\n",
      "obj  0.040211327216208015\n",
      "obj  0.04021132721399616\n",
      "obj  0.04021132721399616\n",
      "obj  0.04021132721289024\n",
      "obj  0.04021132721289024\n",
      "obj  0.04021132721233727\n",
      "obj  0.04021132721233727\n",
      "obj  0.04021132721206079\n",
      "obj  0.04021132721206079\n",
      "obj  0.040211327211922554\n",
      "obj  0.04021132721192253\n",
      "obj  0.04021132721185344\n",
      "obj  0.040211327211784324\n",
      "obj  0.04021188104091256\n",
      "obj  0.040211881040912556\n",
      "obj  0.04021187794427853\n",
      "obj  0.040211877944278544\n",
      "obj  0.04021153919581644\n",
      "obj  0.04021153919581644\n",
      "obj  0.04021141664989339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.04021141664989339\n",
      "obj  0.0402113676797413\n",
      "obj  0.0402113676797413\n",
      "obj  0.040211346368036915\n",
      "obj  0.04021134636803693\n",
      "obj  0.040211336519998815\n",
      "obj  0.040211336519998815\n",
      "obj  0.040211331797735624\n",
      "obj  0.04021133179773563\n",
      "obj  0.04021132948737732\n",
      "obj  0.04021132948737731\n",
      "obj  0.040211328345348386\n",
      "obj  0.040211328345348386\n",
      "obj  0.04021132777750779\n",
      "obj  0.04021132777750779\n",
      "obj  0.040211327494381374\n",
      "obj  0.04021132749438137\n",
      "obj  0.04021132735301665\n",
      "obj  0.040211327353016656\n",
      "obj  0.04021132728238394\n",
      "obj  0.04021132728238395\n",
      "obj  0.04021132724707999\n",
      "obj  0.04021132724708\n",
      "obj  0.04021132722943111\n",
      "obj  0.04021132722943111\n",
      "obj  0.04021132722060745\n",
      "obj  0.04021132722060744\n",
      "obj  0.04021132721619582\n",
      "obj  0.04021132721619583\n",
      "obj  0.040211327213990046\n",
      "obj  0.040211327213990046\n",
      "obj  0.040211327212887164\n",
      "obj  0.040211327212887164\n",
      "obj  0.04021132721233574\n",
      "obj  0.04021132721233574\n",
      "obj  0.04021132721206003\n",
      "obj  0.04021132721206003\n",
      "obj  0.04021132721192218\n",
      "obj  0.04021132721192218\n",
      "obj  0.04021132721185324\n",
      "obj  0.04021132721185324\n",
      "obj  0.040211327211784324\n",
      "obj  0.04021188083990549\n",
      "obj  0.040211880839905484\n",
      "obj  0.04021187777981973\n",
      "obj  0.04021187777981972\n",
      "obj  0.04021153911459716\n",
      "obj  0.04021153911459716\n",
      "obj  0.04021141660957159\n",
      "obj  0.04021141660957159\n",
      "obj  0.040211367659657514\n",
      "obj  0.040211367659657514\n",
      "obj  0.040211346358014925\n",
      "obj  0.040211346358014925\n",
      "obj  0.0402113365149929\n",
      "obj  0.0402113365149929\n",
      "obj  0.040211331795233944\n",
      "obj  0.040211331795233944\n",
      "obj  0.04021132948612684\n",
      "obj  0.04021132834472321\n",
      "obj  0.04021132834472321\n",
      "obj  0.04021132777719522\n",
      "obj  0.04021132777719523\n",
      "obj  0.040211327494225076\n",
      "obj  0.04021132749422507\n",
      "obj  0.04021132735293852\n",
      "obj  0.04021132735293852\n",
      "obj  0.04021132728234487\n",
      "obj  0.04021132728234486\n",
      "obj  0.040211327247060454\n",
      "obj  0.040211327247060454\n",
      "obj  0.04021132722942136\n",
      "obj  0.04021132722942136\n",
      "obj  0.04021132722060257\n",
      "obj  0.04021132722060257\n",
      "obj  0.04021132721619338\n",
      "obj  0.0402113272161934\n",
      "obj  0.04021132721398884\n",
      "obj  0.04021132721398884\n",
      "obj  0.04021132721288658\n",
      "obj  0.04021132721233544\n",
      "obj  0.04021132721233544\n",
      "obj  0.04021132721205987\n",
      "obj  0.04021132721205987\n",
      "obj  0.04021132721192212\n",
      "obj  0.04021132721192212\n",
      "obj  0.0402113272118532\n",
      "obj  0.0402113272118532\n",
      "v20 d-1 f1 t2: original ll 0.0407 auc 0.9927, ensemble ll 0.0412 auc 0.9927\n",
      "running time 18.062718152999878\n",
      "starting fold 1 target 3\n",
      "obj  0.024848393455658972\n",
      "obj  0.025673112125740475\n",
      "obj  0.02567002068662006\n",
      "obj  0.025668118677571326\n",
      "obj  0.025672743313521016\n",
      "obj  0.0256222698257212\n",
      "obj  0.025632502182928202\n",
      "obj  0.025590271181606148\n",
      "obj  0.024935844671350283\n",
      "obj  0.024929960867745335\n",
      "obj  0.024924147261829895\n",
      "obj  0.024917854394289524\n",
      "obj  0.024912689496151528\n",
      "obj  0.02490891898609911\n",
      "obj  0.02490613734842663\n",
      "obj  0.02490413077260264\n",
      "obj  0.024902765255225376\n",
      "obj  0.024901949293112423\n",
      "obj  0.02490161421387953\n",
      "obj  0.024901706008954947\n",
      "obj  0.024902181889341846\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490300777668703\n",
      "obj  0.02490299423032713\n",
      "obj  0.02490299423032713\n",
      "obj  0.02490254424711132\n",
      "obj  0.024902544247111323\n",
      "obj  0.024902352011351485\n",
      "obj  0.024902352011351485\n",
      "obj  0.02490226417406322\n",
      "obj  0.024902351891422012\n",
      "obj  0.024902351891422016\n",
      "obj  0.024902307334450098\n",
      "obj  0.024902307334450098\n",
      "obj  0.02490228557847921\n",
      "obj  0.024902285578479205\n",
      "obj  0.024902274831616868\n",
      "obj  0.024902274831616864\n",
      "obj  0.024902269492132655\n",
      "obj  0.024902269492132655\n",
      "obj  0.024902266830420856\n",
      "obj  0.024902266830420856\n",
      "obj  0.024902265501572735\n",
      "obj  0.024902265501572738\n",
      "obj  0.024902264837650654\n",
      "obj  0.024902264837650647\n",
      "obj  0.024902264505815102\n",
      "obj  0.024902264505815102\n",
      "obj  0.0249022643399287\n",
      "obj  0.0249022643399287\n",
      "obj  0.024902264256993344\n",
      "obj  0.024902264215527624\n",
      "obj  0.024902264215527624\n",
      "obj  0.024902264194795257\n",
      "obj  0.024902264194795267\n",
      "obj  0.024902264184429198\n",
      "obj  0.0249022641844292\n",
      "obj  0.024902264179246195\n",
      "obj  0.024902264179246195\n",
      "obj  0.024902264176654705\n",
      "obj  0.024902264176654712\n",
      "obj  0.02490226417535896\n",
      "obj  0.02490226417471109\n",
      "obj  0.024902264174711093\n",
      "obj  0.024902264174387144\n",
      "obj  0.024902264174387144\n",
      "obj  0.02490226417422518\n",
      "obj  0.02490226417422518\n",
      "obj  0.02490226417406322\n",
      "obj  0.024903140341448176\n",
      "obj  0.024903140341448183\n",
      "obj  0.024903017754356865\n",
      "obj  0.024903017754356865\n",
      "obj  0.024902607242864583\n",
      "obj  0.024902607242864583\n",
      "obj  0.02490242720564452\n",
      "obj  0.02490242720564452\n",
      "obj  0.02490234355678342\n",
      "obj  0.02490234355678342\n",
      "obj  0.024902303326540295\n",
      "obj  0.024902303326540295\n",
      "obj  0.024902283613571545\n",
      "obj  0.024902283613571545\n",
      "obj  0.024902273859732666\n",
      "obj  0.024902273859732673\n",
      "obj  0.024902269008632835\n",
      "obj  0.024902269008632832\n",
      "obj  0.024902266589281595\n",
      "obj  0.024902266589281595\n",
      "obj  0.024902265381155787\n",
      "obj  0.02490226538115579\n",
      "obj  0.02490226477748033\n",
      "obj  0.024902264475739493\n",
      "obj  0.02490226447573949\n",
      "obj  0.024902264324893286\n",
      "obj  0.024902264324893286\n",
      "obj  0.024902264249476218\n",
      "obj  0.024902264249476218\n",
      "obj  0.024902264211769217\n",
      "obj  0.024902264211769217\n",
      "obj  0.024902264192916104\n",
      "obj  0.024902264192916104\n",
      "obj  0.024902264183489623\n",
      "obj  0.024902264183489623\n",
      "obj  0.02490226417877641\n",
      "obj  0.02490226417877641\n",
      "obj  0.024902264176419803\n",
      "obj  0.024902264176419806\n",
      "obj  0.024902264175241516\n",
      "obj  0.02490226417524152\n",
      "obj  0.02490226417465237\n",
      "obj  0.024902264174652366\n",
      "obj  0.024902264174357796\n",
      "obj  0.024902264174357792\n",
      "obj  0.024902264174210497\n",
      "obj  0.024902264174210504\n",
      "obj  0.02490226417406322\n",
      "obj  0.024903142905851376\n",
      "obj  0.02490314290585138\n",
      "obj  0.024903023885226045\n",
      "obj  0.024903023885226052\n",
      "obj  0.02490261016374407\n",
      "obj  0.02490261016374407\n",
      "obj  0.024902428629761053\n",
      "obj  0.024902428629761053\n",
      "obj  0.024902344259772693\n",
      "obj  0.024902344259772693\n",
      "obj  0.02490230367574227\n",
      "obj  0.024902303675742272\n",
      "obj  0.02490228378760477\n",
      "obj  0.02490228378760477\n",
      "obj  0.02490227394660107\n",
      "obj  0.024902273946601078\n",
      "obj  0.02490226905203154\n",
      "obj  0.02490226905203154\n",
      "obj  0.024902266610972064\n",
      "obj  0.024902266610972064\n",
      "obj  0.024902265391998808\n",
      "obj  0.024902265391998808\n",
      "obj  0.02490226478290129\n",
      "obj  0.024902264782901293\n",
      "obj  0.024902264478449825\n",
      "obj  0.024902264478449825\n",
      "obj  0.02490226432624842\n",
      "obj  0.02490226432624842\n",
      "obj  0.024902264250153787\n",
      "obj  0.024902264250153787\n",
      "obj  0.024902264212108\n",
      "obj  0.024902264212108\n",
      "obj  0.02490226419308548\n",
      "obj  0.024902264193085485\n",
      "obj  0.024902264183574323\n",
      "obj  0.024902264183574323\n",
      "obj  0.024902264178818755\n",
      "obj  0.024902264178818755\n",
      "obj  0.024902264176440987\n",
      "obj  0.024902264176440987\n",
      "obj  0.024902264175252105\n",
      "obj  0.024902264175252105\n",
      "obj  0.024902264174657653\n",
      "obj  0.024902264174657653\n",
      "obj  0.02490226417436044\n",
      "obj  0.024902264174211833\n",
      "obj  0.024902264174211833\n",
      "obj  0.02490226417406322\n",
      "obj  0.024903143445522448\n",
      "obj  0.02490314344552245\n",
      "obj  0.02490302510501525\n",
      "obj  0.02490302510501525\n",
      "obj  0.024902610745444573\n",
      "obj  0.024902610745444573\n",
      "obj  0.024902428913528164\n",
      "obj  0.024902428913528164\n",
      "obj  0.024902344399887557\n",
      "obj  0.024902344399887557\n",
      "obj  0.024902303745352756\n",
      "obj  0.024902303745352756\n",
      "obj  0.024902283822299292\n",
      "obj  0.02490228382229929\n",
      "obj  0.024902273963919454\n",
      "obj  0.024902273963919454\n",
      "obj  0.02490226906068381\n",
      "obj  0.02490226906068381\n",
      "obj  0.024902266615296483\n",
      "obj  0.024902266615296483\n",
      "obj  0.024902265394160565\n",
      "obj  0.024902265394160565\n",
      "obj  0.024902264783982067\n",
      "obj  0.024902264783982064\n",
      "obj  0.024902264478990185\n",
      "obj  0.024902264478990195\n",
      "obj  0.02490226432651859\n",
      "obj  0.024902264326518594\n",
      "obj  0.02490226425028887\n",
      "obj  0.02490226425028887\n",
      "obj  0.024902264212175545\n",
      "obj  0.02490226421217554\n",
      "obj  0.02490226419311925\n",
      "obj  0.02490226419311925\n",
      "obj  0.024902264183591205\n",
      "obj  0.024902264183591205\n",
      "obj  0.02490226417882721\n",
      "obj  0.024902264178827203\n",
      "obj  0.024902264176445216\n",
      "obj  0.024902264176445216\n",
      "obj  0.024902264175254214\n",
      "obj  0.02490226417465872\n",
      "obj  0.02490226417465872\n",
      "obj  0.02490226417436097\n",
      "obj  0.02490226417436097\n",
      "obj  0.024902264174212083\n",
      "obj  0.024902264174212083\n",
      "obj  0.02490226417406322\n",
      "obj  0.024903143554540996\n",
      "obj  0.024903143554540996\n",
      "obj  0.02490302534871006\n",
      "obj  0.02490302534871006\n",
      "obj  0.024902610861682294\n",
      "obj  0.024902610861682294\n",
      "obj  0.024902428970237762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.024902428970237762\n",
      "obj  0.024902344427890456\n",
      "obj  0.024902344427890456\n",
      "obj  0.02490230375926528\n",
      "obj  0.024902303759265283\n",
      "obj  0.024902283829233526\n",
      "obj  0.024902283829233523\n",
      "obj  0.024902273967380834\n",
      "obj  0.024902273967380834\n",
      "obj  0.024902269062413128\n",
      "obj  0.024902269062413135\n",
      "obj  0.02490226661616078\n",
      "obj  0.02490226661616078\n",
      "obj  0.024902265394592636\n",
      "obj  0.024902265394592636\n",
      "obj  0.024902264784198085\n",
      "obj  0.024902264784198085\n",
      "obj  0.02490226447909819\n",
      "obj  0.02490226447909819\n",
      "obj  0.024902264326572582\n",
      "obj  0.024902264326572592\n",
      "obj  0.024902264250315883\n",
      "obj  0.024902264212189044\n",
      "obj  0.024902264212189044\n",
      "obj  0.02490226419312601\n",
      "obj  0.024902264193126016\n",
      "obj  0.02490226418359458\n",
      "obj  0.02490226418359458\n",
      "obj  0.024902264178828893\n",
      "obj  0.024902264178828896\n",
      "obj  0.02490226417644605\n",
      "obj  0.024902264176446053\n",
      "obj  0.02490226417525464\n",
      "obj  0.024902264175254644\n",
      "obj  0.024902264174658923\n",
      "obj  0.024902264174658923\n",
      "obj  0.024902264174361078\n",
      "obj  0.024902264174361078\n",
      "obj  0.024902264174212145\n",
      "obj  0.024902264174212145\n",
      "obj  0.02490226417406322\n",
      "obj  0.024903143576388172\n",
      "obj  0.024903143576388176\n",
      "obj  0.02490302539743845\n",
      "obj  0.024903025397438446\n",
      "obj  0.02490261088492574\n",
      "obj  0.02490261088492574\n",
      "obj  0.024902428981577913\n",
      "obj  0.024902428981577917\n",
      "obj  0.024902344433490233\n",
      "obj  0.024902344433490233\n",
      "obj  0.024902303762047405\n",
      "obj  0.024902303762047405\n",
      "obj  0.024902283830620188\n",
      "obj  0.024902283830620188\n",
      "obj  0.02490227396807302\n",
      "obj  0.024902273968073017\n",
      "obj  0.024902269062758928\n",
      "obj  0.024902269062758928\n",
      "obj  0.024902266616333633\n",
      "obj  0.024902266616333633\n",
      "obj  0.024902265394679043\n",
      "obj  0.024902265394679043\n",
      "obj  0.024902264784241273\n",
      "obj  0.024902264784241273\n",
      "obj  0.02490226447911979\n",
      "obj  0.02490226447911979\n",
      "obj  0.024902264326583382\n",
      "obj  0.024902264250321274\n",
      "obj  0.02490226425032127\n",
      "obj  0.024902264212191733\n",
      "obj  0.02490226421219173\n",
      "obj  0.02490226419312735\n",
      "obj  0.024902264193127348\n",
      "obj  0.024902264183595254\n",
      "obj  0.024902264183595257\n",
      "obj  0.02490226417882923\n",
      "obj  0.02490226417882923\n",
      "obj  0.024902264176446223\n",
      "obj  0.024902264176446223\n",
      "obj  0.024902264175254714\n",
      "obj  0.024902264175254714\n",
      "obj  0.024902264174658968\n",
      "obj  0.024902264174658968\n",
      "obj  0.024902264174361092\n",
      "obj  0.024902264174361092\n",
      "obj  0.024902264174212152\n",
      "obj  0.024902264174212152\n",
      "v20 d-1 f1 t3: original ll 0.0234 auc 0.9971, ensemble ll 0.0233 auc 0.9971\n",
      "running time 20.63153910636902\n",
      "starting fold 1 target 4\n",
      "obj  0.06402387550332801\n",
      "obj  0.06437503148762977\n",
      "obj  0.06437371867668507\n",
      "obj  0.06437275070408735\n",
      "obj  0.06436542013208767\n",
      "obj  0.06444417229991486\n",
      "obj  0.06440209414521951\n",
      "obj  0.06435595032327229\n",
      "obj  0.0644823737948335\n",
      "obj  0.06419697613188112\n",
      "obj  0.06413122342561942\n",
      "obj  0.06404218312042669\n",
      "obj  0.06399667230258069\n",
      "obj  0.06394766457162926\n",
      "obj  0.06392123878719298\n",
      "obj  0.06391418675299898\n",
      "obj  0.06390978161736087\n",
      "obj  0.06390703170031341\n",
      "obj  0.06389972291111826\n",
      "obj  0.06389947946931837\n",
      "obj  0.0638996305928642\n",
      "obj  0.06389791730829225\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389832789044765\n",
      "obj  0.06389814466508542\n",
      "obj  0.06389814466508542\n",
      "obj  0.06389801325067064\n",
      "obj  0.06389801325067064\n",
      "obj  0.06389796085875844\n",
      "obj  0.06389796085875844\n",
      "obj  0.06389793797914255\n",
      "obj  0.06389793797914256\n",
      "obj  0.06389792736761057\n",
      "obj  0.06389792736761057\n",
      "obj  0.06389792226892313\n",
      "obj  0.06389792226892313\n",
      "obj  0.06389791977135027\n",
      "obj  0.06389791977135027\n",
      "obj  0.06389791853550673\n",
      "obj  0.06389791853550673\n",
      "obj  0.06389791792082068\n",
      "obj  0.06389791792082068\n",
      "obj  0.0638979176142866\n",
      "obj  0.0638979176142866\n",
      "obj  0.06389791746122181\n",
      "obj  0.06389791746122181\n",
      "obj  0.06389791738473995\n",
      "obj  0.06389791738473995\n",
      "obj  0.06389791734651169\n",
      "obj  0.06389791734651169\n",
      "obj  0.06389791732740069\n",
      "obj  0.06389791732740069\n",
      "obj  0.06389791731784597\n",
      "obj  0.06389791731784597\n",
      "obj  0.06389791731306882\n",
      "obj  0.06389791731306882\n",
      "obj  0.06389791731068031\n",
      "obj  0.06389791731068031\n",
      "obj  0.06389791730948605\n",
      "obj  0.06389791730948606\n",
      "obj  0.06389791730888894\n",
      "obj  0.06389791730948605\n",
      "obj  0.06389791730948605\n",
      "obj  0.0638979173091875\n",
      "obj  0.0638979173091875\n",
      "obj  0.06389791730903821\n",
      "obj  0.06389791730903822\n",
      "obj  0.0638979173089636\n",
      "obj  0.06389791730896359\n",
      "obj  0.06389791730888894\n",
      "obj  0.06389829973196336\n",
      "obj  0.06389829973196336\n",
      "obj  0.06389821591796997\n",
      "obj  0.06389821591796997\n",
      "obj  0.06389803923713716\n",
      "obj  0.06389803923713716\n",
      "obj  0.06389797144511916\n",
      "obj  0.06389797144511916\n",
      "obj  0.06389794267286068\n",
      "obj  0.06389794267286068\n",
      "obj  0.06389792956481369\n",
      "obj  0.06389792956481369\n",
      "obj  0.0638979233303328\n",
      "obj  0.06389792029298083\n",
      "obj  0.06389792029298083\n",
      "obj  0.06389791879427732\n",
      "obj  0.06389791879427732\n",
      "obj  0.0638979180499187\n",
      "obj  0.0638979180499187\n",
      "obj  0.06389791767898771\n",
      "obj  0.06389791767898771\n",
      "obj  0.0638979174938343\n",
      "obj  0.0638979174938343\n",
      "obj  0.0638979174013356\n",
      "obj  0.0638979174013356\n",
      "obj  0.06389791735510575\n",
      "obj  0.06389791735510575\n",
      "obj  0.06389791733199572\n",
      "obj  0.06389791733199572\n",
      "obj  0.06389791732044194\n",
      "obj  0.06389791732044194\n",
      "obj  0.06389791731466536\n",
      "obj  0.06389791731466536\n",
      "obj  0.06389791731177713\n",
      "obj  0.06389791731177713\n",
      "obj  0.06389791731033301\n",
      "obj  0.06389791731033301\n",
      "obj  0.06389791730961097\n",
      "obj  0.06389791730924994\n",
      "obj  0.06389791730924994\n",
      "obj  0.06389791730906942\n",
      "obj  0.06389791730897919\n",
      "obj  0.06389791730897919\n",
      "obj  0.06389791730888894\n",
      "obj  0.0638982945919265\n",
      "obj  0.0638982945919265\n",
      "obj  0.06389820762152296\n",
      "obj  0.06389820762152296\n",
      "obj  0.06389803605243514\n",
      "obj  0.06389803605243514\n",
      "obj  0.06389797009401056\n",
      "obj  0.06389797009401056\n",
      "obj  0.06389794205734967\n",
      "obj  0.06389794205734967\n",
      "obj  0.06389792927206941\n",
      "obj  0.0638979292720694\n",
      "obj  0.0638979231877135\n",
      "obj  0.0638979231877135\n",
      "obj  0.0638979202226094\n",
      "obj  0.0638979202226094\n",
      "obj  0.06389791875932616\n",
      "obj  0.06389791875932617\n",
      "obj  0.0638979180325018\n",
      "obj  0.0638979180325018\n",
      "obj  0.06389791767029394\n",
      "obj  0.06389791767029394\n",
      "obj  0.06389791748949104\n",
      "obj  0.06389791748949106\n",
      "obj  0.0638979173991649\n",
      "obj  0.0638979173991649\n",
      "obj  0.06389791735402066\n",
      "obj  0.06389791735402066\n",
      "obj  0.06389791733145322\n",
      "obj  0.06389791733145321\n",
      "obj  0.0638979173201707\n",
      "obj  0.0638979173201707\n",
      "obj  0.06389791731452973\n",
      "obj  0.06389791731452973\n",
      "obj  0.0638979173117093\n",
      "obj  0.06389791731029915\n",
      "obj  0.06389791731029915\n",
      "obj  0.06389791730959402\n",
      "obj  0.06389791730959402\n",
      "obj  0.06389791730924146\n",
      "obj  0.06389791730924146\n",
      "obj  0.0638979173090652\n",
      "obj  0.06389791730897706\n",
      "obj  0.06389791730897706\n",
      "obj  0.06389791730888894\n",
      "obj  0.0638982935835599\n",
      "obj  0.0638982935835599\n",
      "obj  0.06389820602160232\n",
      "obj  0.06389820602160232\n",
      "obj  0.06389803543657296\n",
      "obj  0.06389803543657296\n",
      "obj  0.06389796983217395\n",
      "obj  0.06389796983217395\n",
      "obj  0.06389794193790348\n",
      "obj  0.06389794193790348\n",
      "obj  0.06389792921521441\n",
      "obj  0.06389792921521441\n",
      "obj  0.06389792316000308\n",
      "obj  0.06389792316000306\n",
      "obj  0.06389792020893342\n",
      "obj  0.063897918752533\n",
      "obj  0.063897918752533\n",
      "obj  0.06389791802911643\n",
      "obj  0.06389791802911643\n",
      "obj  0.06389791766860402\n",
      "obj  0.06389791766860402\n",
      "obj  0.06389791748864683\n",
      "obj  0.06389791748864683\n",
      "obj  0.06389791739874297\n",
      "obj  0.06389791735380972\n",
      "obj  0.06389791735380972\n",
      "obj  0.06389791733134777\n",
      "obj  0.06389791733134777\n",
      "obj  0.06389791732011799\n",
      "obj  0.06389791732011799\n",
      "obj  0.06389791731450337\n",
      "obj  0.06389791731450335\n",
      "obj  0.06389791731169613\n",
      "obj  0.06389791731169613\n",
      "obj  0.06389791731029254\n",
      "obj  0.06389791731029254\n",
      "obj  0.06389791730959071\n",
      "obj  0.0638979173095907\n",
      "obj  0.06389791730923985\n",
      "obj  0.06389791730923985\n",
      "obj  0.06389791730906438\n",
      "obj  0.06389791730897666\n",
      "obj  0.06389791730897666\n",
      "obj  0.06389791730888894\n",
      "obj  0.06389829338267206\n",
      "obj  0.06389829338267206\n",
      "obj  0.06389820570394927\n",
      "obj  0.06389820570394927\n",
      "obj  0.06389803531422958\n",
      "obj  0.06389803531422958\n",
      "obj  0.06389796978013697\n",
      "obj  0.06389796978013697\n",
      "obj  0.06389794191415844\n",
      "obj  0.06389794191415844\n",
      "obj  0.06389792920391027\n",
      "obj  0.06389792920391027\n",
      "obj  0.0638979231544931\n",
      "obj  0.0638979231544931\n",
      "obj  0.06389792020621397\n",
      "obj  0.06389792020621395\n",
      "obj  0.06389791875118213\n",
      "obj  0.06389791875118213\n",
      "obj  0.0638979180284432\n",
      "obj  0.06389791802844319\n",
      "obj  0.06389791766826797\n",
      "obj  0.06389791766826798\n",
      "obj  0.06389791748847892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.06389791748847892\n",
      "obj  0.06389791739865908\n",
      "obj  0.06389791739865908\n",
      "obj  0.06389791735376778\n",
      "obj  0.06389791735376778\n",
      "obj  0.06389791733132678\n",
      "obj  0.06389791733132678\n",
      "obj  0.06389791732010748\n",
      "obj  0.06389791732010748\n",
      "obj  0.0638979173144981\n",
      "obj  0.0638979173144981\n",
      "obj  0.06389791731169349\n",
      "obj  0.06389791731169349\n",
      "obj  0.0638979173102912\n",
      "obj  0.0638979173102912\n",
      "obj  0.06389791730959009\n",
      "obj  0.06389791730959009\n",
      "obj  0.0638979173092395\n",
      "obj  0.0638979173092395\n",
      "obj  0.06389791730906422\n",
      "obj  0.06389791730906422\n",
      "obj  0.06389791730897658\n",
      "obj  0.06389791730897658\n",
      "v20 d-1 f1 t4: original ll 0.0629 auc 0.9813, ensemble ll 0.0632 auc 0.9814\n",
      "running time 18.890931367874146\n",
      "starting fold 1 target 5\n",
      "obj  0.07785001073677729\n",
      "obj  0.07895869589378952\n",
      "obj  0.07895395248820763\n",
      "obj  0.07895011987210629\n",
      "obj  0.07894852809320889\n",
      "obj  0.07891924076734637\n",
      "obj  0.07891559424520375\n",
      "obj  0.07881448558564373\n",
      "obj  0.0783462478267586\n",
      "obj  0.07824117562346809\n",
      "obj  0.07819047826297\n",
      "obj  0.07814339888232476\n",
      "obj  0.07807239982108785\n",
      "obj  0.07803657924627741\n",
      "obj  0.07800915432044823\n",
      "obj  0.077987454147277\n",
      "obj  0.0779695086651887\n",
      "obj  0.07795568068603108\n",
      "obj  0.07793827675952368\n",
      "obj  0.07791512288734781\n",
      "obj  0.07791385673267102\n",
      "obj  0.07791324787461194\n",
      "obj  0.07791281270397304\n",
      "obj  0.07791024037338548\n",
      "obj  0.07790702289232813\n",
      "obj  0.07790342195317822\n",
      "obj  0.07789858081480451\n",
      "obj  0.07789369537043699\n",
      "obj  0.07788953250517036\n",
      "obj  0.07788583618998658\n",
      "obj  0.07788247470652179\n",
      "obj  0.07787937233143341\n",
      "obj  0.07787647901626094\n",
      "obj  0.0778737603113246\n",
      "obj  0.0778711918817759\n",
      "obj  0.07786845229189293\n",
      "obj  0.07786452384843902\n",
      "obj  0.07786120954923395\n",
      "obj  0.07785749221058438\n",
      "obj  0.07785329521028672\n",
      "obj  0.07784978381909997\n",
      "obj  0.0778466922391592\n",
      "obj  0.07784388522907437\n",
      "obj  0.07784103086417035\n",
      "obj  0.077835720089818\n",
      "obj  0.07783056657776313\n",
      "obj  0.07782441562652624\n",
      "obj  0.07781846329880107\n",
      "obj  0.07781130531199804\n",
      "obj  0.07780454607078538\n",
      "obj  0.07779891537187224\n",
      "obj  0.07779409805014599\n",
      "obj  0.07778987118654386\n",
      "obj  0.07778421092029282\n",
      "obj  0.0777697152693807\n",
      "obj  0.07772303575037626\n",
      "obj  0.07769924273264495\n",
      "obj  0.07769340160553795\n",
      "obj  0.07768814391880868\n",
      "obj  0.07767837040812904\n",
      "obj  0.07762496260505569\n",
      "obj  0.07762387221801043\n",
      "obj  0.07762362533453054\n",
      "obj  0.07762290148004904\n",
      "obj  0.07762275738407248\n",
      "obj  0.07762274536814029\n",
      "v20 d-1 f1 t5: original ll 0.0795 auc 0.9793, ensemble ll 0.0795 auc 0.9792\n",
      "running time 27.76715636253357\n",
      "starting fold 2 target 0\n",
      "obj  0.09668796198357936\n",
      "obj  0.1000892423353546\n",
      "obj  0.10007859390767683\n",
      "obj  0.10006991818010867\n",
      "obj  0.10006207733096455\n",
      "obj  0.10004870466962973\n",
      "obj  0.10002584447579158\n",
      "obj  0.0998129643487115\n",
      "obj  0.09809242867697499\n",
      "obj  0.09802836982405361\n",
      "obj  0.09796751751892359\n",
      "obj  0.0979006188666299\n",
      "obj  0.09784445907276035\n",
      "obj  0.0977975166295358\n",
      "obj  0.09775491269265969\n",
      "obj  0.09771992158990274\n",
      "obj  0.09768977608112195\n",
      "obj  0.09766117375179854\n",
      "obj  0.09763171518902372\n",
      "obj  0.09760499726765456\n",
      "obj  0.09758569431991454\n",
      "obj  0.09757218803001069\n",
      "obj  0.09756065770419121\n",
      "obj  0.09754829277515951\n",
      "obj  0.09753318683177457\n",
      "obj  0.09751762387013156\n",
      "obj  0.09750064894864413\n",
      "obj  0.0974850785415242\n",
      "obj  0.09747084498672616\n",
      "obj  0.09745110347944674\n",
      "obj  0.097430675632596\n",
      "obj  0.0974069686228437\n",
      "obj  0.09738557626961851\n",
      "obj  0.09736677108280656\n",
      "obj  0.09734794329201805\n",
      "obj  0.09732772526263732\n",
      "obj  0.09730715051662871\n",
      "obj  0.09728861793555689\n",
      "obj  0.09727223266905333\n",
      "obj  0.09725363568148694\n",
      "obj  0.0972371999619385\n",
      "obj  0.09721980396501347\n",
      "obj  0.09720269896951\n",
      "obj  0.09718605053679688\n",
      "obj  0.09717021300586956\n",
      "obj  0.09715683237079814\n",
      "obj  0.09714492432333634\n",
      "obj  0.09713302827911145\n",
      "obj  0.09712156318648783\n",
      "obj  0.09711112145162558\n",
      "obj  0.09710061758071782\n",
      "obj  0.0970896166297804\n",
      "obj  0.09707965238937268\n",
      "obj  0.09706621572781708\n",
      "obj  0.09705144770423614\n",
      "obj  0.09703800627185886\n",
      "obj  0.09702684109858783\n",
      "obj  0.09701294815730288\n",
      "obj  0.09700000467835915\n",
      "obj  0.09698734993410184\n",
      "obj  0.0969738131807518\n",
      "obj  0.09696105227174345\n",
      "obj  0.0969493685787339\n",
      "obj  0.09693795759991115\n",
      "obj  0.0969254155284037\n",
      "obj  0.0969137394245621\n",
      "obj  0.09690378913299812\n",
      "obj  0.09689400986401413\n",
      "obj  0.09688379465510293\n",
      "obj  0.09687511198427319\n",
      "obj  0.09686447823242791\n",
      "obj  0.09685427629813564\n",
      "obj  0.09684590952104993\n",
      "obj  0.0968387438526785\n",
      "obj  0.09683244018099305\n",
      "obj  0.0968238801609131\n",
      "obj  0.09681667419170145\n",
      "obj  0.09681060379604721\n",
      "obj  0.09680530824313409\n",
      "obj  0.09680060855118293\n",
      "obj  0.09679524102969955\n",
      "obj  0.09678917005425179\n",
      "obj  0.09678226256780402\n",
      "obj  0.09677527113310001\n",
      "obj  0.09676905848572688\n",
      "obj  0.09676299870115757\n",
      "obj  0.0967569745714553\n",
      "obj  0.09674955331626225\n",
      "obj  0.09674078895203693\n",
      "obj  0.09673200382599276\n",
      "obj  0.09672440355770932\n",
      "obj  0.09671710233661182\n",
      "obj  0.09671110895591635\n",
      "obj  0.09670584917253709\n",
      "obj  0.09670032024458311\n",
      "obj  0.0966959680758923\n",
      "obj  0.0966920413916337\n",
      "obj  0.09668594722297619\n",
      "obj  0.096678130145638\n",
      "obj  0.09667165104128718\n",
      "obj  0.09666557774042207\n",
      "obj  0.0966587011949306\n",
      "obj  0.09665095901630144\n",
      "obj  0.09659997778835376\n",
      "obj  0.09658880342158477\n",
      "obj  0.09657091898051533\n",
      "obj  0.0965637144628812\n",
      "obj  0.09655053663426628\n",
      "obj  0.09648485801937799\n",
      "obj  0.0964818526930002\n",
      "obj  0.09648108538864775\n",
      "obj  0.09648071506006374\n",
      "obj  0.09648065238696767\n",
      "obj  0.096480643909913\n",
      "obj  0.09648064346510238\n",
      "v20 d-1 f2 t0: original ll 0.0930 auc 0.9884, ensemble ll 0.0928 auc 0.9885\n",
      "running time 47.890265703201294\n",
      "starting fold 2 target 1\n",
      "obj  0.014220614441326069\n",
      "obj  0.014254120333584348\n",
      "obj  0.014258309058958583\n",
      "obj  0.014272527078476866\n",
      "obj  0.014453242619376404\n",
      "obj  0.0143561225467803\n",
      "obj  0.014368625021344915\n",
      "obj  0.014456349355305516\n",
      "obj  0.014371191954441745\n",
      "obj  0.014157102055774112\n",
      "obj  0.014096626836242646\n",
      "obj  0.014058911184484782\n",
      "obj  0.014025230951968138\n",
      "obj  0.014006923310363127\n",
      "obj  0.01399021063080025\n",
      "obj  0.013987916540075017\n",
      "obj  0.013987121771429157\n",
      "obj  0.013985079402490351\n",
      "obj  0.013982170365947028\n",
      "obj  0.013982033944452023\n",
      "obj  0.013982031272086106\n",
      "obj  0.013981984294149334\n",
      "obj  0.013981970774507768\n",
      "obj  0.013981970752392929\n",
      "obj  0.013981966680291339\n",
      "obj  0.013981966171470593\n",
      "v20 d-1 f2 t1: original ll 0.0152 auc 0.9722, ensemble ll 0.0149 auc 0.9745\n",
      "running time 11.387333154678345\n",
      "starting fold 2 target 2\n",
      "obj  0.04165829347069\n",
      "obj  0.04326035181868271\n",
      "obj  0.04325447943716165\n",
      "obj  0.04325016429338094\n",
      "obj  0.04324831311442195\n",
      "obj  0.043226670234890345\n",
      "obj  0.0432216958558675\n",
      "obj  0.04313109820131491\n",
      "obj  0.04201678474875598\n",
      "obj  0.04201404912498749\n",
      "obj  0.042011067681203204\n",
      "obj  0.042009189530789734\n",
      "obj  0.04197817397598954\n",
      "obj  0.041978183878310274\n",
      "obj  0.04196002752194178\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.04196124678053379\n",
      "obj  0.041961171366284446\n",
      "obj  0.041961171366284446\n",
      "obj  0.041960496388444374\n",
      "obj  0.041960496388444374\n",
      "obj  0.041960233132757194\n",
      "obj  0.04196023313275719\n",
      "obj  0.041960122640021046\n",
      "obj  0.041960122640021046\n",
      "obj  0.041960073089107736\n",
      "obj  0.04196007308910772\n",
      "obj  0.04196004979680654\n",
      "obj  0.04196004979680654\n",
      "obj  0.04196003853045322\n",
      "obj  0.04196003853045323\n",
      "obj  0.04196003299397014\n",
      "obj  0.04196003299397015\n",
      "obj  0.04196003024990186\n",
      "obj  0.041960030249901886\n",
      "obj  0.041960028883912065\n",
      "obj  0.04196002888391207\n",
      "obj  0.041960028202430506\n",
      "obj  0.04196002820243049\n",
      "obj  0.04196002786206832\n",
      "obj  0.04196002786206832\n",
      "obj  0.041960027691981885\n",
      "obj  0.041960027691981906\n",
      "obj  0.04196002760696237\n",
      "obj  0.04196002760696239\n",
      "obj  0.041960027564458546\n",
      "obj  0.041960027564458546\n",
      "obj  0.041960027543208066\n",
      "obj  0.041960027543208094\n",
      "obj  0.04196002753258323\n",
      "obj  0.04196002753258323\n",
      "obj  0.041960027527270884\n",
      "obj  0.041960027524614744\n",
      "obj  0.041960027524614744\n",
      "obj  0.04196002752328668\n",
      "obj  0.04196002752461475\n",
      "obj  0.04196002752461476\n",
      "obj  0.04196002752395074\n",
      "obj  0.04196002752395074\n",
      "obj  0.04196002752361871\n",
      "obj  0.041960027523618715\n",
      "obj  0.041960027523452695\n",
      "obj  0.0419600275234527\n",
      "obj  0.04196002752328668\n",
      "obj  0.04196110709567874\n",
      "obj  0.04196110709567874\n",
      "obj  0.04196100691350428\n",
      "obj  0.04196100691350428\n",
      "obj  0.041960421737976504\n",
      "obj  0.041960421737976504\n",
      "obj  0.04196019800585807\n",
      "obj  0.04196019800585807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.0419601056758099\n",
      "obj  0.0419601056758099\n",
      "obj  0.041960064765094666\n",
      "obj  0.04196006476509466\n",
      "obj  0.041960045675979954\n",
      "obj  0.04196004567597997\n",
      "obj  0.041960036480945935\n",
      "obj  0.041960031972505724\n",
      "obj  0.041960031972505724\n",
      "obj  0.041960029740480666\n",
      "obj  0.04196002863002754\n",
      "obj  0.04196002863002755\n",
      "obj  0.041960028076192826\n",
      "obj  0.041960027799623656\n",
      "obj  0.041960027799623656\n",
      "obj  0.04196002766142614\n",
      "obj  0.04196002766142612\n",
      "obj  0.04196002759234916\n",
      "obj  0.04196002759234916\n",
      "obj  0.04196002755781612\n",
      "obj  0.04196002755781611\n",
      "obj  0.041960027540550934\n",
      "obj  0.041960027540550934\n",
      "obj  0.041960027531918694\n",
      "obj  0.04196002753191872\n",
      "obj  0.04196002752760267\n",
      "obj  0.041960027525444685\n",
      "obj  0.04196002752544468\n",
      "obj  0.041960027524365694\n",
      "obj  0.041960027524365694\n",
      "obj  0.04196002752382619\n",
      "obj  0.04196002752382616\n",
      "obj  0.04196002752355645\n",
      "obj  0.04196002752355645\n",
      "obj  0.04196002752342156\n",
      "obj  0.04196002752342153\n",
      "obj  0.04196002752328668\n",
      "obj  0.041961079948559424\n",
      "obj  0.04196107994855944\n",
      "obj  0.04196097662627792\n",
      "obj  0.0419609766262779\n",
      "obj  0.041960407857108924\n",
      "obj  0.041960407857108924\n",
      "obj  0.041960191431158284\n",
      "obj  0.0419601914311583\n",
      "obj  0.04196010248793103\n",
      "obj  0.041960063197251055\n",
      "obj  0.041960063197251055\n",
      "obj  0.0419600448987778\n",
      "obj  0.041960044898777825\n",
      "obj  0.041960036094042495\n",
      "obj  0.041960036094042495\n",
      "obj  0.04196003177948946\n",
      "obj  0.04196002964407976\n",
      "obj  0.04196002858185394\n",
      "obj  0.041960028581853964\n",
      "obj  0.04196002805211272\n",
      "obj  0.04196002805211272\n",
      "obj  0.041960027787585265\n",
      "obj  0.041960027787585265\n",
      "obj  0.04196002765540738\n",
      "obj  0.041960027655407364\n",
      "obj  0.04196002758933987\n",
      "obj  0.04196002758933987\n",
      "obj  0.041960027556311494\n",
      "obj  0.04196002755631151\n",
      "obj  0.04196002753979864\n",
      "obj  0.041960027539798626\n",
      "obj  0.04196002753154256\n",
      "obj  0.04196002753154256\n",
      "obj  0.04196002752741458\n",
      "obj  0.041960027527414595\n",
      "obj  0.04196002752535065\n",
      "obj  0.041960027525350656\n",
      "obj  0.04196002752431865\n",
      "obj  0.04196002752431864\n",
      "obj  0.04196002752380269\n",
      "obj  0.04196002752380268\n",
      "obj  0.04196002752354468\n",
      "obj  0.041960027523544684\n",
      "obj  0.04196002752341568\n",
      "obj  0.04196002752341569\n",
      "obj  0.04196002752328668\n",
      "obj  0.041961074548952884\n",
      "obj  0.041961074548952884\n",
      "obj  0.04196097066411964\n",
      "obj  0.04196097066411964\n",
      "obj  0.04196040511899377\n",
      "obj  0.04196040511899378\n",
      "obj  0.04196019013244389\n",
      "obj  0.04196019013244389\n",
      "obj  0.04196010185769881\n",
      "obj  0.04196010185769881\n",
      "obj  0.041960062887151275\n",
      "obj  0.041960044745019534\n",
      "obj  0.041960044745019534\n",
      "obj  0.04196003601748962\n",
      "obj  0.041960031741296755\n",
      "obj  0.041960031741296776\n",
      "obj  0.04196002962500399\n",
      "obj  0.041960029625004\n",
      "obj  0.041960028572321215\n",
      "obj  0.041960028572321215\n",
      "obj  0.04196002804734762\n",
      "obj  0.04196002804734764\n",
      "obj  0.04196002778520308\n",
      "obj  0.04196002765421634\n",
      "obj  0.04196002765421634\n",
      "obj  0.04196002758874437\n",
      "obj  0.04196002758874439\n",
      "obj  0.04196002755601376\n",
      "obj  0.04196002755601376\n",
      "obj  0.041960027539649766\n",
      "obj  0.04196002753964977\n",
      "obj  0.04196002753146812\n",
      "obj  0.04196002753146813\n",
      "obj  0.04196002752737739\n",
      "obj  0.04196002752737738\n",
      "obj  0.04196002752533204\n",
      "obj  0.041960027525332046\n",
      "obj  0.04196002752430936\n",
      "obj  0.04196002752430936\n",
      "obj  0.04196002752379803\n",
      "obj  0.041960027523542366\n",
      "obj  0.041960027523542366\n",
      "obj  0.04196002752341453\n",
      "obj  0.041960027523414545\n",
      "obj  0.04196002752328668\n",
      "obj  0.04196107347020963\n",
      "obj  0.041961073470209644\n",
      "obj  0.04196096947543202\n",
      "obj  0.04196096947543204\n",
      "obj  0.04196040457286271\n",
      "obj  0.04196040457286271\n",
      "obj  0.041960189873335864\n",
      "obj  0.04196018987333585\n",
      "obj  0.04196010173193932\n",
      "obj  0.04196010173193932\n",
      "obj  0.04196006282526675\n",
      "obj  0.04196006282526675\n",
      "obj  0.041960044714333566\n",
      "obj  0.041960044714333566\n",
      "obj  0.04196003600221135\n",
      "obj  0.04196003600221135\n",
      "obj  0.041960031733674207\n",
      "obj  0.04196003173367422\n",
      "obj  0.04196002962119681\n",
      "obj  0.04196002857041865\n",
      "obj  0.04196002857041865\n",
      "obj  0.04196002804639662\n",
      "obj  0.04196002804639661\n",
      "obj  0.0419600277847276\n",
      "obj  0.041960027784727585\n",
      "obj  0.04196002765397863\n",
      "obj  0.04196002765397862\n",
      "obj  0.04196002758862553\n",
      "obj  0.041960027588625534\n",
      "obj  0.041960027555954335\n",
      "obj  0.04196002755595435\n",
      "obj  0.041960027539620054\n",
      "obj  0.04196002753145327\n",
      "obj  0.04196002753145325\n",
      "obj  0.04196002752736996\n",
      "obj  0.041960027527369964\n",
      "obj  0.041960027525328306\n",
      "obj  0.041960027525328306\n",
      "obj  0.0419600275243075\n",
      "obj  0.04196002752430749\n",
      "obj  0.0419600275237971\n",
      "obj  0.04196002752379708\n",
      "obj  0.04196002752354189\n",
      "obj  0.04196002752354191\n",
      "obj  0.04196002752341429\n",
      "obj  0.041960027523414274\n",
      "obj  0.04196002752328668\n",
      "obj  0.04196107325450799\n",
      "obj  0.04196107325450797\n",
      "obj  0.041960969237843745\n",
      "obj  0.041960969237843745\n",
      "obj  0.04196040446369594\n",
      "obj  0.041960404463695956\n",
      "obj  0.04196018982153957\n",
      "obj  0.04196018982153957\n",
      "obj  0.041960101706798855\n",
      "obj  0.04196010170679888\n",
      "obj  0.04196006281289522\n",
      "obj  0.041960062812895244\n",
      "obj  0.04196004470819895\n",
      "obj  0.04196004470819897\n",
      "obj  0.041960035999157\n",
      "obj  0.041960035999157\n",
      "obj  0.04196003173215034\n",
      "obj  0.04196003173215037\n",
      "obj  0.041960029620435726\n",
      "obj  0.04196002857003829\n",
      "obj  0.04196002857003829\n",
      "obj  0.04196002804620649\n",
      "obj  0.04196002804620648\n",
      "obj  0.04196002778463255\n",
      "obj  0.04196002778463258\n",
      "obj  0.04196002765393113\n",
      "obj  0.041960027588601775\n",
      "obj  0.04196002758860178\n",
      "obj  0.04196002755594246\n",
      "obj  0.041960027555942477\n",
      "obj  0.041960027539614114\n",
      "obj  0.04196002753961412\n",
      "obj  0.041960027531450284\n",
      "obj  0.04196002752736846\n",
      "obj  0.04196002752736846\n",
      "obj  0.04196002752532757\n",
      "obj  0.04196002752532758\n",
      "obj  0.04196002752430713\n",
      "obj  0.04196002752430713\n",
      "obj  0.04196002752379692\n",
      "obj  0.041960027523541804\n",
      "obj  0.041960027523541776\n",
      "obj  0.04196002752341425\n",
      "obj  0.04196002752341425\n",
      "v20 d-1 f2 t2: original ll 0.0377 auc 0.9933, ensemble ll 0.0377 auc 0.9933\n",
      "running time 17.282289266586304\n",
      "starting fold 2 target 3\n",
      "obj  0.024552257883799167\n",
      "obj  0.025529498991234825\n",
      "obj  0.025527380811779566\n",
      "obj  0.025526178053118614\n",
      "obj  0.025529835531931236\n",
      "obj  0.025483874640850532\n",
      "obj  0.02549589688326527\n",
      "obj  0.02546172613717032\n",
      "obj  0.02470819653183398\n",
      "obj  0.024696848166390676\n",
      "obj  0.024683505389066628\n",
      "obj  0.024672600807619224\n",
      "obj  0.0246641159500107\n",
      "obj  0.02465733881220541\n",
      "obj  0.02464965952775935\n",
      "obj  0.02464286855718424\n",
      "obj  0.024636948288275225\n",
      "obj  0.024632505283755816\n",
      "obj  0.024629139539526328\n",
      "obj  0.024626616743227147\n",
      "obj  0.02462379174560127\n",
      "obj  0.02462052205890733\n",
      "obj  0.02461642514952318\n",
      "obj  0.024614050694220475\n",
      "obj  0.0246129296172535\n",
      "obj  0.02461118113753202\n",
      "obj  0.0246104877251026\n",
      "obj  0.0246105509480216\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.024611073011505398\n",
      "obj  0.02461104151707524\n",
      "obj  0.024611041517075247\n",
      "obj  0.024610734541093214\n",
      "obj  0.024610734541093214\n",
      "obj  0.024610626811674117\n",
      "obj  0.024610626811674117\n",
      "obj  0.024610584845490165\n",
      "obj  0.024610584845490162\n",
      "obj  0.02461056688803165\n",
      "obj  0.02461056688803164\n",
      "obj  0.02461055866540338\n",
      "obj  0.024610558665403376\n",
      "obj  0.024610554743427535\n",
      "obj  0.02461055474342753\n",
      "obj  0.024610552829887066\n",
      "obj  0.024610552829887066\n",
      "obj  0.02461055188499291\n",
      "obj  0.02461055141551665\n",
      "obj  0.02461055141551665\n",
      "obj  0.024610551181521435\n",
      "obj  0.024610551181521435\n",
      "obj  0.024610551064709593\n",
      "obj  0.024610551064709593\n",
      "obj  0.0246105510063501\n",
      "obj  0.0246105510063501\n",
      "obj  0.024610550977181987\n",
      "obj  0.024610550977181983\n",
      "obj  0.02461055096260082\n",
      "obj  0.02461055096260082\n",
      "obj  0.024610550955310968\n",
      "obj  0.024610550955310964\n",
      "obj  0.02461055095166622\n",
      "obj  0.024610550951666213\n",
      "obj  0.02461055094984389\n",
      "obj  0.024610550949843883\n",
      "obj  0.024610550948932743\n",
      "obj  0.02461055094893274\n",
      "obj  0.02461055094847717\n",
      "obj  0.024610550948477163\n",
      "obj  0.024610550948249377\n",
      "obj  0.02461055094824938\n",
      "obj  0.024610550948135492\n",
      "obj  0.024610550948135492\n",
      "obj  0.02461055094807853\n",
      "obj  0.02461055094807853\n",
      "obj  0.0246105509480216\n",
      "obj  0.02461109458947299\n",
      "obj  0.02461109458947299\n",
      "obj  0.024610812423592927\n",
      "obj  0.024610812423592927\n",
      "obj  0.024610657445353908\n",
      "obj  0.024610657445353908\n",
      "obj  0.024610598032338355\n",
      "obj  0.024610598032338355\n",
      "obj  0.024610572942164895\n",
      "obj  0.024610572942164895\n",
      "obj  0.02461056155817881\n",
      "obj  0.02461056155817881\n",
      "obj  0.024610556156130056\n",
      "obj  0.024610556156130056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.024610553527802836\n",
      "obj  0.024610553527802836\n",
      "obj  0.02461055223184015\n",
      "obj  0.024610552231840135\n",
      "obj  0.024610551588412372\n",
      "obj  0.024610551588412372\n",
      "obj  0.024610551267837302\n",
      "obj  0.024610551267837302\n",
      "obj  0.02461055110783452\n",
      "obj  0.024610551107834524\n",
      "obj  0.024610551027904326\n",
      "obj  0.024610551027904326\n",
      "obj  0.024610550987957024\n",
      "obj  0.024610550987957024\n",
      "obj  0.024610550967987824\n",
      "obj  0.024610550967987824\n",
      "obj  0.024610550958004337\n",
      "obj  0.024610550958004327\n",
      "obj  0.02461055095301286\n",
      "obj  0.02461055095301286\n",
      "obj  0.024610550950517212\n",
      "obj  0.024610550950517212\n",
      "obj  0.024610550949269394\n",
      "obj  0.024610550949269394\n",
      "obj  0.024610550948645494\n",
      "obj  0.024610550948645494\n",
      "obj  0.02461055094833355\n",
      "obj  0.02461055094833355\n",
      "obj  0.024610550948177563\n",
      "obj  0.02461055094817756\n",
      "obj  0.024610550948099583\n",
      "obj  0.02461055094809958\n",
      "obj  0.02461055094806058\n",
      "obj  0.02461055094806058\n",
      "obj  0.0246105509480216\n",
      "obj  0.024611098968849717\n",
      "obj  0.02461109896884971\n",
      "obj  0.0246108158668462\n",
      "obj  0.0246108158668462\n",
      "obj  0.024610659126302774\n",
      "obj  0.024610659126302774\n",
      "obj  0.024610598862596235\n",
      "obj  0.024610598862596235\n",
      "obj  0.024610573354740595\n",
      "obj  0.02461057335474059\n",
      "obj  0.024610561763824954\n",
      "obj  0.024610561763824954\n",
      "obj  0.02461055625879267\n",
      "obj  0.02461055625879267\n",
      "obj  0.024610553579094026\n",
      "obj  0.02461055357909402\n",
      "obj  0.024610552257475708\n",
      "obj  0.024610552257475708\n",
      "obj  0.024610551601227642\n",
      "obj  0.024610551601227645\n",
      "obj  0.024610551274244306\n",
      "obj  0.024610551274244306\n",
      "obj  0.024610551111037864\n",
      "obj  0.024610551111037864\n",
      "obj  0.024610551029505958\n",
      "obj  0.024610551029505958\n",
      "obj  0.02461055098875782\n",
      "obj  0.02461055096838823\n",
      "obj  0.02461055095820454\n",
      "obj  0.02461055095820453\n",
      "obj  0.024610550953112983\n",
      "obj  0.02461055095311298\n",
      "obj  0.024610550950567255\n",
      "obj  0.024610550950567255\n",
      "obj  0.024610550949294423\n",
      "obj  0.024610550948658\n",
      "obj  0.024610550948658005\n",
      "obj  0.024610550948339794\n",
      "obj  0.024610550948339787\n",
      "obj  0.024610550948180702\n",
      "obj  0.024610550948180692\n",
      "obj  0.024610550948101145\n",
      "obj  0.02461055094810114\n",
      "obj  0.024610550948061378\n",
      "obj  0.024610550948061378\n",
      "obj  0.0246105509480216\n",
      "obj  0.024611099847411638\n",
      "obj  0.024611099847411638\n",
      "obj  0.024610816555962194\n",
      "obj  0.024610816555962194\n",
      "obj  0.02461065946276821\n",
      "obj  0.024610659462768206\n",
      "obj  0.02461059902879703\n",
      "obj  0.02461059902879704\n",
      "obj  0.024610573437333284\n",
      "obj  0.024610573437333284\n",
      "obj  0.02461056180499367\n",
      "obj  0.02461056180499367\n",
      "obj  0.024610556279345122\n",
      "obj  0.02461055358936227\n",
      "obj  0.024610553589362275\n",
      "obj  0.024610552262607825\n",
      "obj  0.024610552262607825\n",
      "obj  0.024610551603793215\n",
      "obj  0.02461055160379322\n",
      "obj  0.024610551275526964\n",
      "obj  0.024610551275526957\n",
      "obj  0.02461055111167916\n",
      "obj  0.02461055111167916\n",
      "obj  0.024610551029826594\n",
      "obj  0.02461055102982659\n",
      "obj  0.024610550988918158\n",
      "obj  0.024610550968468384\n",
      "obj  0.024610550968468384\n",
      "obj  0.02461055095824461\n",
      "obj  0.02461055095824461\n",
      "obj  0.024610550953133015\n",
      "obj  0.024610550953133015\n",
      "obj  0.02461055095057729\n",
      "obj  0.02461055095057729\n",
      "obj  0.024610550949299436\n",
      "obj  0.024610550949299436\n",
      "obj  0.024610550948660503\n",
      "obj  0.0246105509486605\n",
      "obj  0.02461055094834105\n",
      "obj  0.024610550948341053\n",
      "obj  0.02461055094818133\n",
      "obj  0.024610550948181324\n",
      "obj  0.024610550948101453\n",
      "obj  0.024610550948101453\n",
      "obj  0.02461055094806152\n",
      "obj  0.02461055094806151\n",
      "obj  0.0246105509480216\n",
      "obj  0.024611100023232593\n",
      "obj  0.024611100023232586\n",
      "obj  0.024610816693803647\n",
      "obj  0.024610816693803647\n",
      "obj  0.024610659530072153\n",
      "obj  0.024610659530072153\n",
      "obj  0.024610599062043086\n",
      "obj  0.024610599062043086\n",
      "obj  0.02461057345385487\n",
      "obj  0.024610573453854874\n",
      "obj  0.024610561813228966\n",
      "obj  0.024610561813228966\n",
      "obj  0.0246105562834564\n",
      "obj  0.0246105562834564\n",
      "obj  0.024610553591416316\n",
      "obj  0.02461055359141631\n",
      "obj  0.024610552263634455\n",
      "obj  0.024610552263634455\n",
      "obj  0.024610551604306415\n",
      "obj  0.024610551604306405\n",
      "obj  0.02461055127578354\n",
      "obj  0.024610551275783533\n",
      "obj  0.02461055111180745\n",
      "obj  0.024610551111807447\n",
      "obj  0.024610551029890737\n",
      "obj  0.024610551029890737\n",
      "obj  0.02461055098895022\n",
      "obj  0.024610550988950215\n",
      "obj  0.024610550968484426\n",
      "obj  0.024610550968484416\n",
      "obj  0.024610550958252635\n",
      "obj  0.024610550958252632\n",
      "obj  0.024610550953137016\n",
      "obj  0.02461055095313701\n",
      "obj  0.024610550950579284\n",
      "obj  0.02461055095057928\n",
      "obj  0.02461055094930043\n",
      "obj  0.02461055094930043\n",
      "obj  0.024610550948661013\n",
      "obj  0.02461055094834131\n",
      "obj  0.02461055094818144\n",
      "obj  0.02461055094810152\n",
      "obj  0.024610550948101516\n",
      "obj  0.024610550948061558\n",
      "v20 d-1 f2 t3: original ll 0.0240 auc 0.9970, ensemble ll 0.0239 auc 0.9970\n",
      "running time 20.76252055168152\n",
      "starting fold 2 target 4\n",
      "obj  0.06400315370669656\n",
      "obj  0.06448078307459675\n",
      "obj  0.06448012977210445\n",
      "obj  0.06448064469900218\n",
      "obj  0.06448668341090237\n",
      "obj  0.06442477090758647\n",
      "obj  0.06444341946963289\n",
      "obj  0.06441586890396207\n",
      "obj  0.06410442917619945\n",
      "obj  0.06407326723472258\n",
      "obj  0.06404712354454735\n",
      "obj  0.06402438920316224\n",
      "obj  0.06400035500371662\n",
      "obj  0.06397622804571138\n",
      "obj  0.06395844670531428\n",
      "obj  0.06394514237129965\n",
      "obj  0.06393516693544306\n",
      "obj  0.06392747246903197\n",
      "obj  0.06392181255220986\n",
      "obj  0.06391770965143699\n",
      "obj  0.06391478164637038\n",
      "obj  0.06391272752230923\n",
      "obj  0.06391131943457104\n",
      "obj  0.06391040149335579\n",
      "obj  0.06390936618166256\n",
      "obj  0.06390912294233539\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.0639094360262952\n",
      "obj  0.06390942833454727\n",
      "obj  0.06390942833454727\n",
      "obj  0.06390921894847285\n",
      "obj  0.06390921894847285\n",
      "obj  0.06390915677142499\n",
      "obj  0.06390921851936224\n",
      "obj  0.06390921851936224\n",
      "obj  0.06390918411374212\n",
      "obj  0.06390918411374212\n",
      "obj  0.06390916956007334\n",
      "obj  0.06390916956007331\n",
      "obj  0.06390916294556663\n",
      "obj  0.0639091695459919\n",
      "obj  0.06390916619059846\n",
      "obj  0.06390916619059846\n",
      "obj  0.06390916455433687\n",
      "obj  0.06390916455433687\n",
      "obj  0.06390916374651524\n",
      "obj  0.06390916374651524\n",
      "obj  0.06390916334518176\n",
      "obj  0.06390916334518176\n",
      "obj  0.06390916314515942\n",
      "obj  0.06390916314515942\n",
      "obj  0.06390916304530929\n",
      "obj  0.06390916304530929\n",
      "obj  0.06390916299542454\n",
      "obj  0.06390916299542454\n",
      "obj  0.0639091629704922\n",
      "obj  0.06390916297049219\n",
      "obj  0.06390916295802856\n",
      "obj  0.06390916295802856\n",
      "obj  0.0639091629517974\n",
      "obj  0.0639091629517974\n",
      "obj  0.06390916294868196\n",
      "obj  0.06390916294712426\n",
      "obj  0.06390916294712427\n",
      "obj  0.06390916294634544\n",
      "obj  0.06390916294595601\n",
      "obj  0.06390916294576131\n",
      "obj  0.06390916294576131\n",
      "obj  0.06390916294566397\n",
      "obj  0.06390916294561529\n",
      "obj  0.0639091629456153\n",
      "obj  0.06390916294559096\n",
      "obj  0.06390916294559096\n",
      "obj  0.06390916294556663\n",
      "obj  0.06390954576900731\n",
      "obj  0.06390954576900731\n",
      "obj  0.06390930122686249\n",
      "obj  0.06390930122686249\n",
      "obj  0.06390921880710218\n",
      "obj  0.06390921880710218\n",
      "obj  0.06390918755112575\n",
      "obj  0.06390917441894824\n",
      "obj  0.06390917441894824\n",
      "obj  0.06390916847391462\n",
      "obj  0.06390916847391463\n",
      "obj  0.06390916565790825\n",
      "obj  0.06390916565790825\n",
      "obj  0.06390916428879552\n",
      "obj  0.06390916428879552\n",
      "obj  0.0639091636139455\n",
      "obj  0.0639091636139455\n",
      "obj  0.06390916327894715\n",
      "obj  0.06390916327894715\n",
      "obj  0.06390916311205466\n",
      "obj  0.06390916302876007\n",
      "obj  0.0639091629871507\n",
      "obj  0.0639091629871507\n",
      "obj  0.06390916296635549\n",
      "obj  0.06390916295596026\n",
      "obj  0.06390916295596026\n",
      "obj  0.06390916295076324\n",
      "obj  0.06390916295076324\n",
      "obj  0.0639091629481649\n",
      "obj  0.06390916294686574\n",
      "obj  0.06390916294621617\n",
      "obj  0.0639091629462162\n",
      "obj  0.06390916294589138\n",
      "obj  0.06390916294589138\n",
      "obj  0.063909162945729\n",
      "obj  0.063909162945729\n",
      "obj  0.0639091629456478\n",
      "obj  0.06390916294560722\n",
      "obj  0.06390916294560721\n",
      "obj  0.06390916294558689\n",
      "obj  0.06390916294556663\n",
      "obj  0.06390954154953903\n",
      "obj  0.06390954154953903\n",
      "obj  0.06390929886700679\n",
      "obj  0.06390929886700679\n",
      "obj  0.06390921756523771\n",
      "obj  0.06390921756523771\n",
      "obj  0.06390918691468934\n",
      "obj  0.06390918691468934\n",
      "obj  0.06390917409692601\n",
      "obj  0.06390917409692601\n",
      "obj  0.0639091683119376\n",
      "obj  0.06390916831193762\n",
      "obj  0.06390916557669339\n",
      "obj  0.06390916557669339\n",
      "obj  0.06390916424812779\n",
      "obj  0.06390916424812779\n",
      "obj  0.06390916359359657\n",
      "obj  0.06390916359359655\n",
      "obj  0.06390916326876893\n",
      "obj  0.06390916326876893\n",
      "obj  0.06390916310696461\n",
      "obj  0.06390916310696461\n",
      "obj  0.06390916302621479\n",
      "obj  0.06390916302621479\n",
      "obj  0.063909162985878\n",
      "obj  0.063909162985878\n",
      "obj  0.06390916296571915\n",
      "obj  0.06390916296571915\n",
      "obj  0.06390916295564207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj  0.06390916295564208\n",
      "obj  0.06390916295060414\n",
      "obj  0.06390916295060414\n",
      "obj  0.06390916294808534\n",
      "obj  0.06390916294682594\n",
      "obj  0.06390916294682596\n",
      "obj  0.0639091629461963\n",
      "obj  0.0639091629461963\n",
      "obj  0.06390916294588143\n",
      "obj  0.06390916294572403\n",
      "obj  0.06390916294564536\n",
      "obj  0.06390916294564536\n",
      "obj  0.06390916294560599\n",
      "obj  0.06390916294560599\n",
      "obj  0.0639091629455863\n",
      "obj  0.0639091629455863\n",
      "obj  0.06390916294556663\n",
      "obj  0.06390954070639028\n",
      "obj  0.06390954070639028\n",
      "obj  0.0639092983945412\n",
      "obj  0.0639092983945412\n",
      "obj  0.06390921731640056\n",
      "obj  0.06390921731640056\n",
      "obj  0.06390918678711548\n",
      "obj  0.06390918678711548\n",
      "obj  0.06390917403236476\n",
      "obj  0.06390917403236476\n",
      "obj  0.06390916827946036\n",
      "obj  0.06390916827946036\n",
      "obj  0.06390916556040865\n",
      "obj  0.06390916556040865\n",
      "obj  0.06390916423997316\n",
      "obj  0.06390916423997317\n",
      "obj  0.06390916358951616\n",
      "obj  0.06390916358951616\n",
      "obj  0.06390916326672794\n",
      "obj  0.06390916326672794\n",
      "obj  0.06390916310594394\n",
      "obj  0.06390916310594394\n",
      "obj  0.06390916302570442\n",
      "obj  0.06390916302570443\n",
      "obj  0.0639091629856228\n",
      "obj  0.0639091629856228\n",
      "obj  0.06390916296559151\n",
      "obj  0.0639091629555783\n",
      "obj  0.06390916295557829\n",
      "obj  0.06390916295057225\n",
      "obj  0.06390916295057225\n",
      "obj  0.0639091629480694\n",
      "obj  0.0639091629480694\n",
      "obj  0.06390916294681796\n",
      "obj  0.06390916294681796\n",
      "obj  0.06390916294619228\n",
      "obj  0.06390916294619228\n",
      "obj  0.06390916294587946\n",
      "obj  0.06390916294587946\n",
      "obj  0.06390916294572305\n",
      "obj  0.06390916294572305\n",
      "obj  0.0639091629456448\n",
      "obj  0.0639091629456448\n",
      "obj  0.06390916294560574\n",
      "obj  0.06390916294560574\n",
      "obj  0.0639091629455862\n",
      "obj  0.0639091629455862\n",
      "obj  0.06390916294556663\n",
      "obj  0.06390954053779133\n",
      "obj  0.06390954053779133\n",
      "obj  0.06390929830002881\n",
      "obj  0.06390929830002881\n",
      "obj  0.06390921726661478\n",
      "obj  0.06390921726661478\n",
      "obj  0.06390918676158937\n",
      "obj  0.06390918676158937\n",
      "obj  0.06390917401944629\n",
      "obj  0.06390917401944629\n",
      "obj  0.06390916827296168\n",
      "obj  0.06390916827296168\n",
      "obj  0.06390916555715007\n",
      "obj  0.06390916555715007\n",
      "obj  0.06390916423834139\n",
      "obj  0.06390916423834139\n",
      "obj  0.06390916358869965\n",
      "obj  0.06390916358869965\n",
      "obj  0.06390916326631953\n",
      "obj  0.06390916326631953\n",
      "obj  0.06390916310573971\n",
      "obj  0.0639091630256023\n",
      "obj  0.0639091630256023\n",
      "obj  0.06390916298557175\n",
      "obj  0.06390916298557175\n",
      "obj  0.063909162965566\n",
      "obj  0.063909162965566\n",
      "obj  0.06390916295556551\n",
      "obj  0.06390916295556551\n",
      "obj  0.06390916295056587\n",
      "obj  0.06390916295056587\n",
      "obj  0.0639091629480662\n",
      "obj  0.0639091629468164\n",
      "obj  0.0639091629468164\n",
      "obj  0.0639091629461915\n",
      "obj  0.0639091629461915\n",
      "obj  0.06390916294587906\n",
      "obj  0.06390916294587905\n",
      "obj  0.06390916294572281\n",
      "obj  0.06390916294572282\n",
      "obj  0.06390916294564472\n",
      "obj  0.06390916294564472\n",
      "obj  0.06390916294560567\n",
      "obj  0.06390916294560567\n",
      "obj  0.06390916294558617\n",
      "obj  0.06390916294558617\n",
      "v20 d-1 f2 t4: original ll 0.0630 auc 0.9828, ensemble ll 0.0631 auc 0.9828\n",
      "running time 20.702837705612183\n",
      "starting fold 2 target 5\n",
      "obj  0.08015944011159046\n",
      "obj  0.08114536174448106\n",
      "obj  0.08114049369937125\n",
      "obj  0.08113654166459588\n",
      "obj  0.08113356269652935\n",
      "obj  0.0811202641635094\n",
      "obj  0.08111531447341021\n",
      "obj  0.08102197728576771\n",
      "obj  0.08063986604615275\n",
      "obj  0.08059148584873262\n",
      "obj  0.08041724474117194\n",
      "obj  0.08024700377362116\n",
      "obj  0.0801684299706664\n",
      "obj  0.08014401456799677\n",
      "obj  0.08014136982031173\n",
      "obj  0.08013900921617131\n",
      "obj  0.0801363658188802\n",
      "obj  0.08013618002643602\n",
      "obj  0.08013584869902599\n",
      "obj  0.08013488766085607\n",
      "obj  0.08013430790907965\n",
      "obj  0.080133789531722\n",
      "obj  0.08013187140400992\n",
      "obj  0.08013033119482438\n",
      "obj  0.08012903870495955\n",
      "obj  0.08012788240187227\n",
      "obj  0.08012681462169323\n",
      "obj  0.08012581188539712\n",
      "obj  0.0801233902911796\n",
      "obj  0.0801200264797817\n",
      "obj  0.08011735165814095\n",
      "obj  0.08011521478987556\n",
      "obj  0.08011339895002617\n",
      "obj  0.08011021709818597\n",
      "obj  0.08010758079325167\n",
      "obj  0.08010538874782676\n",
      "obj  0.08010347946578396\n",
      "obj  0.08010177232436473\n",
      "obj  0.08010022285371983\n",
      "obj  0.08009880078798036\n",
      "obj  0.08009620030061494\n",
      "obj  0.08009367108783291\n",
      "obj  0.08009156296443674\n",
      "obj  0.0800897254517283\n",
      "obj  0.08008808249865308\n",
      "obj  0.08008658894384423\n",
      "obj  0.08008518799853279\n",
      "obj  0.08008224888529406\n",
      "obj  0.0800798968527006\n",
      "obj  0.0800779509570995\n",
      "obj  0.08007626405914961\n",
      "obj  0.08007403652377225\n",
      "obj  0.08007104202097029\n",
      "obj  0.08006861843904728\n",
      "obj  0.0800665944132473\n",
      "obj  0.0800648393470431\n",
      "obj  0.08006263626454532\n",
      "obj  0.08005931544611558\n",
      "obj  0.08003819705543787\n",
      "obj  0.08003641241738287\n",
      "obj  0.08003490232148344\n",
      "obj  0.08003358968346097\n",
      "obj  0.08003162457489536\n",
      "obj  0.08002795449453173\n",
      "obj  0.08002138950442296\n",
      "obj  0.08001021540161316\n",
      "obj  0.08000796890243858\n",
      "obj  0.08000772688616821\n",
      "obj  0.07999739170888565\n",
      "obj  0.07998194528342202\n",
      "obj  0.07998187677421992\n",
      "obj  0.0799818694458225\n",
      "obj  0.07998186941374825\n",
      "obj  0.07998186941209702\n",
      "obj  0.07998186941151604\n",
      "obj  0.07998186941149422\n",
      "obj  0.07998186941149246\n",
      "v20 d-1 f2 t5: original ll 0.0749 auc 0.9822, ensemble ll 0.0748 auc 0.9823\n",
      "running time 32.21351218223572\n",
      "total running time 469.5972030162811\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "for fold in range(3):\n",
    "    for target in range(6):\n",
    "        train_ensemble(train_md, preds_all, fold=fold, target=target, ds_idx=-1, first_step=False)\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total running time 353.5499176979065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.05889 ensemble ll 0.05878\n",
      "valid original ll 0.05889 ensemble ll 0.05891\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx == -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.05888 ensemble ll 0.05879\n",
      "valid original ll 0.05897 ensemble ll 0.05903\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx == -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train original ll 0.05891 ensemble ll 0.05887\n",
      "valid original ll 0.05900 ensemble ll 0.05908\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(PATH_DISK/'ensemble'/'stats.v{}'.format(VERSION))\n",
    "\n",
    "agg = stats.loc[stats.ds_idx == -1].groupby('target').mean().sort_index()\n",
    "print('train original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.train_loss * class_weights).mean(), (agg.train_loss_ens * class_weights).mean()))\n",
    "print('valid original ll {:.5f} ensemble ll {:.5f}'\n",
    "      .format((agg.valid_loss * class_weights).mean(), (agg.valid_loss_ens * class_weights).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.1051 0.4512 0.4401 0.3512 0.0611 0.5971] 2.005774795470866\n",
      "0 [0.0912 0.2706 0.102  0.1998 0.099  0.0239 0.0161 0.2029] 1.0054459577647874\n",
      "1 [0.0852 0.5294 0.139  0.4292 0.3318 0.4856] 2.0001469111881636\n",
      "1 [2.8353e-01 1.1771e-02 6.9776e-07 8.3137e-07 8.1208e-02 9.5143e-02\n",
      " 7.1965e-02 4.6638e-01] 1.0099984380702238\n",
      "2 [0.3666 0.3011 0.3285 0.587  0.3419 0.0775] 2.00249748846708\n",
      "2 [0.044  0.1292 0.0378 0.0965 0.206  0.2044 0.0411 0.2483] 1.0072474715332207\n",
      "3 [0.527  0.3224 0.1478 0.2761 0.6425 0.074 ] 1.9896982601009017\n",
      "3 [0.0376 0.1832 0.0204 0.1586 0.1783 0.2333 0.0577 0.1379] 1.007066477992875\n",
      "4 [0.2905 0.323  0.3876 0.4178 0.2741 0.302 ] 1.9949661935342407\n",
      "4 [0.0096 0.1292 0.1144 0.1041 0.1763 0.1598 0.0155 0.2976] 1.006524941150742\n",
      "5 [0.0334 0.4708 0.4853 0.4062 0.1629 0.448 ] 2.0065815320339198\n",
      "5 [0.0416 0.1423 0.0984 0.084  0.1792 0.05   0.0414 0.3711] 1.008025205543532\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "for target in range(6):\n",
    "    res1 = np.zeros((3*len(preds_all), 6))\n",
    "    res2 = np.zeros((3, len(preds_all)))\n",
    "    for fold in range(3):\n",
    "        for ds_idx in range(len(preds_all)):\n",
    "            model = pickle.load(open(PATH_DISK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                     .format(ds_idx,fold,target,VERSION),'rb'))\n",
    "            res1[fold*len(preds_all) + ds_idx] = model.x\n",
    "            #print(ds_idx,fold,target,model.x)\n",
    "        model = pickle.load(open(PATH_DISK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                 .format(-1,fold,target,VERSION),'rb'))\n",
    "        res2[fold] = model.x\n",
    "        #print(fold,target,model.x)\n",
    "    print(target, res1.mean(0), res1.mean(0).sum())\n",
    "    print(target, res2.mean(0), res2.mean(0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuval_test = pickle.load(open(PATH_DISK/'ensemble/ensemble_test_image_ids.pkl','rb'))\n",
    "assert len(yuval_test) == len(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del test_md['yuval_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(len(yuval_test)), columns=['yuval_idx'])\n",
    "df.index = yuval_test\n",
    "test_md = test_md.join(df, on = 'img_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_y = [\n",
    "           'model_Densenet201_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           'model_Densenet161_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           'model_Densenet169_3_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           'model_se_resnext101_32x4d_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_y = [\n",
    "           'model_se_resnext101_32x4d_version_classifier_splits_fullhead_resmodel_type_test_pred_ensamble_split_{}.pkl',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = np.stack([torch.sigmoid(torch.stack([torch.stack(pickle.load(\n",
    "    open(PATH_DISK/'ensemble'/name.format(fold),'rb'))) for fold in range(3)])).numpy() for name in names_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = preds_y[:,:,:,test_md.yuval_idx]\n",
    "#preds_y = preds_y[:,:,:8]\n",
    "preds_y = preds_y[:,:,:,:,np.array([5,0,1,2,3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = np.stack([pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(ds, VERSION),'rb')) for ds in range(6,10)])\n",
    "preds = np.concatenate([preds, preds_y.mean(0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(9, VERSION),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.concatenate([preds, preds_y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 32, 78545, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any too low inconsistencies\n",
      "1 class: 0.0010847682856960977\n",
      "2 class: 0.010471173637193116\n",
      "3 class: 0.006220027797228765\n",
      "4 class: 0.023541175971311563\n",
      "5 class: 0.08800667610923674\n",
      "total 0.12245773388927791\n",
      "any too high inconsistencies\n",
      "total 0.16194166825811107\n"
     ]
    }
   ],
   "source": [
    "preds = predBounding(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total running time 6.308442115783691\n"
     ]
    }
   ],
   "source": [
    "stg = time.time()\n",
    "\n",
    "test_preds_trgt = []\n",
    "for target in range(6):\n",
    "    \n",
    "    test_preds_folds = []\n",
    "    for fold in range(3):\n",
    "        \n",
    "        test_preds = []\n",
    "        for ds_idx in range(len(preds)):\n",
    "            model = pickle.load(open(PATH_DISK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                     .format(ds_idx,fold,target,VERSION),'rb'))\n",
    "            X,y,ll_train,auc_train =  getFirstStepX(None, preds[:,fold], TH=model.prior, \n",
    "                                                    powerLow=model.powerLow, powerHigh=model.powerHigh, \n",
    "                                                    fold=fold, target=target, ds_idx=ds_idx, mode='test')\n",
    "            test_preds.append((X*np.expand_dims(model.x, axis=1)).sum(0))\n",
    "        \n",
    "        X = np.stack(test_preds)\n",
    "        model = pickle.load(open(PATH_DISK/'ensemble'/'model.d{}.f{}.t{}.v{}'\n",
    "                                 .format(-1,fold,target,VERSION),'rb'))\n",
    "        test_preds_folds.append((X*np.expand_dims(model.x, axis=1)).sum(0))\n",
    "    \n",
    "    X = np.stack(test_preds_folds).mean(0)\n",
    "    test_preds_trgt.append(X)\n",
    "\n",
    "predictions = np.stack(test_preds_trgt,axis=1)\n",
    "\n",
    "print('total running time', time.time() - stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.9951, 0.9952, 0.9924, 0.9968, 0.9938, 0.9943, 0.9912],\n",
       "       [0.9951, 1.    , 0.9951, 0.9929, 0.9938, 0.9971, 0.9943, 0.9916],\n",
       "       [0.9952, 0.9951, 1.    , 0.9927, 0.9935, 0.9938, 0.9964, 0.9913],\n",
       "       [0.9924, 0.9929, 0.9927, 1.    , 0.9913, 0.9921, 0.9917, 0.998 ],\n",
       "       [0.9968, 0.9938, 0.9935, 0.9913, 1.    , 0.9956, 0.9964, 0.9922],\n",
       "       [0.9938, 0.9971, 0.9938, 0.9921, 0.9956, 1.    , 0.9957, 0.9928],\n",
       "       [0.9943, 0.9943, 0.9964, 0.9917, 0.9964, 0.9957, 1.    , 0.9922],\n",
       "       [0.9912, 0.9916, 0.9913, 0.998 , 0.9922, 0.9928, 0.9922, 1.    ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(preds.mean((1,2))[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78545, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_d{}_v{}'.format(9, 20),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0.5* (pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 51),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 52),'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 51),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 52),'rb')) +\n",
    "         pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 53),'rb'))) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet161', 72),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet169', 73),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('Densenet201', 74),'rb')),\n",
    "                  pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 78),'rb'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00797, 0.00125, 0.0039 , 0.0026 , 0.00511, 0.00504],\n",
       "       [0.00727, 0.00117, 0.00363, 0.00238, 0.00469, 0.00434],\n",
       "       [0.00687, 0.00118, 0.00313, 0.00217, 0.00415, 0.00443],\n",
       "       [0.00905, 0.00102, 0.00443, 0.00315, 0.00575, 0.00509]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.std(2).mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15249, 0.01507, 0.03719, 0.02508, 0.05596, 0.06206],\n",
       "       [0.14765, 0.01445, 0.03652, 0.02455, 0.05567, 0.05837],\n",
       "       [0.14786, 0.01586, 0.0346 , 0.02439, 0.05371, 0.06038],\n",
       "       [0.1466 , 0.01732, 0.03613, 0.02529, 0.05583, 0.05959]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds.mean((1,2), keepdims=True) * np.log(np.clip(preds,1e-15,1-1e-15)) \n",
    "  - (1 - preds.mean((1,2), keepdims=True)) * np.log(np.clip(1 - preds,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54027, 0.54585, 0.53983, 0.54938])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- preds.mean((1,2,3), keepdims=True) * np.log(np.clip(preds,1e-15,1-1e-15)) \n",
    "  - (1 - preds.mean((1,2,3), keepdims=True)) * np.log(np.clip(1 - preds,1e-15,1-1e-15)))\n",
    " * class_weights).mean((1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pickle.load(open(PATH_WORK/'preds_{}_v{}'.format('se_resnext101_32x4d', 75),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 78545, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.quantile(preds,q=0.5,axis=(1)).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scalePreds(predictions, 1.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md['pred_any'] = predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f01ca4257d0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_md[['pos_idx1','pred_any']].groupby('pos_idx1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.exp(np.log(preds).mean((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = 1 / (1 + np.exp(-(np.log(preds/(1-preds)).mean((0,1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13450962, 0.00509856, 0.04342182, 0.02973641, 0.04710878,\n",
       "       0.05719417], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13278, 0.00531, 0.04268, 0.03012, 0.04659, 0.05525])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1280228 , 0.00678272, 0.04317398, 0.03195811, 0.04593468,\n",
       "       0.05528003], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.137883,0.004889,0.045248,0.031052,0.045235,0.0594456,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = np.array([a + '_' + b for a in test_md.SOPInstanceUID for b in all_ich])\n",
    "sub = pd.DataFrame({'ID': id_column, 'Label': predictions.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1345096230506897"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1281835436820984"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission_061.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13475628267250275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9469207879216331, pvalue=0.0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.spearmanr(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "                   best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9569675239389986, pvalue=0.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.spearmanr(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "                   best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934800299351926"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944464662920349"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 16.8M/16.8M [00:04<00:00, 4.31MB/s]\n",
      "Successfully submitted to RSNA Intracranial Hemorrhage Detection"
     ]
    }
   ],
   "source": [
    "!~/.local/bin/kaggle competitions submit rsna-intracranial-hemorrhage-detection -f ~/sub.csv -m \"GCP, s101+(avg of y), 32TTA, 3folds, mean, bounding, weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit rsna-intracranial-hemorrhage-detection -f C:/StudioProjects/Hemorrhage/sub.csv -m \"GCP, d161+d169+d201+s101+yd161, 8TTA, ensemble, bounds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
