{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD = True\n",
    "\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from matplotlib import patches, patheffects\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import pdb\n",
    "\n",
    "import scipy as sp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "if not CLOUD:\n",
    "    torch.cuda.current_device()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as M\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = Path('C:/StudioProjects/Hemorrhage')\n",
    "PATH_WORK = Path('C:/StudioProjects/Hemorrhage/running')\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import seaborn as sn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "all_ich = ['any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural']\n",
    "class_weights = 6.0*np.array([2,1,1,1,1,1])/7.0\n",
    "\n",
    "if CLOUD:\n",
    "    import torch_xla\n",
    "    import torch_xla_py.data_parallel as dp\n",
    "    import torch_xla_py.utils as xu\n",
    "    import torch_xla_py.xla_model as xm\n",
    "\n",
    "\n",
    "#sys.path.insert(0, \"C:\\\\fastai\")\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.tabular import *\n",
    "from fastprogress import *\n",
    "\n",
    "VERSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2351\n",
    "\n",
    "def setSeeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "setSeeds(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate torch-xla-nightly\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;$10.0.101.2:8470\"\n",
    "#git init\n",
    "#git remote add origin https://github.com/nosound2/RSNA-Hemorrhage\n",
    "#git pull origin master\n",
    "#git config remote.origin.push HEAD\n",
    "#gcloud config set compute/zone europe-west4-a\n",
    "#gcloud auth login\n",
    "#gcloud config set project endless-empire-239015\n",
    "#pip install kaggle\n",
    "#mkdir .kaggle\n",
    "#gsutil cp gs://recursion-double-strand/kaggle-keys/kaggle.json ~/.kaggle\n",
    "#chmod 600 /home/zahar_chikishev/.kaggle/kaggle.json\n",
    "#kaggle competitions download rsna-intracranial-hemorrhage-detection -f stage_1_train.csv\n",
    "#kaggle kernels output xhlulu/rsna-generate-metadata-csvs -p .\n",
    "#gsutil cp gs://rsna-hemorrhage/yuvals/* .\n",
    "\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;$10.0.101.2:8470\"; conda activate pytorch-nightly; jupyter notebook\n",
    "\n",
    "# 35.204.242.164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat, cols_float = pickle.load(open(PATH_WORK/'covs','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_WORK/'yuvals_indexes_file.pkl'\n",
    "all_idx, train_ids, val_ids = pickle.load(open(filename,'rb'))\n",
    "\n",
    "train_md = pd.read_csv(PATH_WORK/'train_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "train_md['img_id'] = train_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = train_md.loc[train_md.img_id.isin(all_idx[train_ids])]\n",
    "val_data = train_md.loc[train_md.img_id.isin(all_idx[val_ids])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trn_data.SeriesInstanceUID.unique()) + len(val_data.SeriesInstanceUID.unique()) \\\n",
    "    == len(train_md.SeriesInstanceUID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trn_data.PatientID.unique()) + len(val_data.PatientID.unique()) \\\n",
    "    >= len(train_md.PatientID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_df = pd.DataFrame(all_idx, columns = ['img_id'])\n",
    "ids_df = ids_df.join(train_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "assert len(ids_df.SeriesInstanceUID.unique()) == 19530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md = pd.read_csv(PATH_WORK/'test_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "test_md['img_id'] = test_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_WORK/'yuvals_test_indexes.pkl'\n",
    "test_ids = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_df = pd.DataFrame(test_ids, columns = ['img_id'])\n",
    "test_ids_df = test_ids_df.join(test_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "assert len(test_ids_df.SeriesInstanceUID.unique()) == 2214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BitsStored</th>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.494393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PixelRepresentation</th>\n",
       "      <td>0.039672</td>\n",
       "      <td>0.489732</td>\n",
       "      <td>0.491567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>0.023441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowCenter_1_NAN</th>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.494393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_0</th>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>0.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_1</th>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_3</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_4</th>\n",
       "      <td>0.948793</td>\n",
       "      <td>0.973095</td>\n",
       "      <td>0.972877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_5</th>\n",
       "      <td>-0.285991</td>\n",
       "      <td>-0.154848</td>\n",
       "      <td>-0.156091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImagePositionPatient_0</th>\n",
       "      <td>-125.024699</td>\n",
       "      <td>-122.681411</td>\n",
       "      <td>-122.742795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImagePositionPatient_1</th>\n",
       "      <td>-113.426820</td>\n",
       "      <td>-59.968123</td>\n",
       "      <td>-60.116496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImagePositionPatient_2</th>\n",
       "      <td>106.356928</td>\n",
       "      <td>174.080145</td>\n",
       "      <td>174.857098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PixelSpacing_0</th>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.478824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PixelSpacing_1</th>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.478824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowCenter_0</th>\n",
       "      <td>30.759692</td>\n",
       "      <td>36.087277</td>\n",
       "      <td>35.437203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowCenter_1</th>\n",
       "      <td>37.988691</td>\n",
       "      <td>38.023234</td>\n",
       "      <td>37.974277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_max</th>\n",
       "      <td>192.955649</td>\n",
       "      <td>259.120051</td>\n",
       "      <td>259.991850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_min</th>\n",
       "      <td>31.319018</td>\n",
       "      <td>93.610421</td>\n",
       "      <td>94.324693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_size</th>\n",
       "      <td>36.440754</td>\n",
       "      <td>35.257130</td>\n",
       "      <td>35.150762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_idx</th>\n",
       "      <td>17.720377</td>\n",
       "      <td>17.128472</td>\n",
       "      <td>17.075381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_inc</th>\n",
       "      <td>4.522789</td>\n",
       "      <td>4.745734</td>\n",
       "      <td>4.763764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_range</th>\n",
       "      <td>161.636632</td>\n",
       "      <td>165.509630</td>\n",
       "      <td>165.667157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_rel</th>\n",
       "      <td>0.463977</td>\n",
       "      <td>0.485689</td>\n",
       "      <td>0.485599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_zeros</th>\n",
       "      <td>0.157375</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>0.020392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_inc_rng</th>\n",
       "      <td>1.915072</td>\n",
       "      <td>1.374015</td>\n",
       "      <td>1.376714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0           1           2\n",
       "BitsStored                   0.040435    0.493129    0.494393\n",
       "PixelRepresentation          0.039672    0.489732    0.491567\n",
       "RescaleIntercept             0.001884    0.025994    0.023441\n",
       "WindowCenter_1_NAN           0.040435    0.493129    0.494393\n",
       "ImageOrientationPatient_0    0.999491    0.999703    0.999969\n",
       "ImageOrientationPatient_1   -0.000509    0.000072    0.000118\n",
       "ImageOrientationPatient_2    0.000000    0.000015   -0.000118\n",
       "ImageOrientationPatient_3    0.000495   -0.000066   -0.000132\n",
       "ImageOrientationPatient_4    0.948793    0.973095    0.972877\n",
       "ImageOrientationPatient_5   -0.285991   -0.154848   -0.156091\n",
       "ImagePositionPatient_0    -125.024699 -122.681411 -122.742795\n",
       "ImagePositionPatient_1    -113.426820  -59.968123  -60.116496\n",
       "ImagePositionPatient_2     106.356928  174.080145  174.857098\n",
       "PixelSpacing_0               0.487562    0.478761    0.478824\n",
       "PixelSpacing_1               0.487562    0.478761    0.478824\n",
       "WindowCenter_0              30.759692   36.087277   35.437203\n",
       "WindowCenter_1              37.988691   38.023234   37.974277\n",
       "pos_max                    192.955649  259.120051  259.991850\n",
       "pos_min                     31.319018   93.610421   94.324693\n",
       "pos_size                    36.440754   35.257130   35.150762\n",
       "pos_idx                     17.720377   17.128472   17.075381\n",
       "pos_inc                      4.522789    4.745734    4.763764\n",
       "pos_range                  161.636632  165.509630  165.667157\n",
       "pos_rel                      0.463977    0.485689    0.485599\n",
       "pos_zeros                    0.157375    0.065163    0.020392\n",
       "pos_inc_rng                  1.915072    1.374015    1.376714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([test_md[cols_cat + cols_float].mean(0),\n",
    "           trn_data[cols_cat + cols_float].mean(0),\n",
    "           val_data[cols_cat + cols_float].mean(0)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['pos_size','pos_idx','pos_inc','pos_rel','pos_zeros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = cols_cat + cols_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = PATH_WORK/'yuvals_model_Densenet161_3_vehrsion_basic_classifier_type_features_train_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/train/{}'.format(series_id),'wb'))\n",
    "\n",
    "\n",
    "    filename = PATH_WORK/'yuvals_model_Densenet161_3_vehrsion_basic_classifier_type_features_test_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(test_ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(test_ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/test/{}'.format(series_id),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = PATH_WORK/'features/densenet161_v3/train/ID_000a935543'\n",
    "#feats1 = pickle.load(open(path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_black = '006d4432e'\n",
    "\n",
    "path = PATH_WORK/'features/densenet161_v3/train/ID_992b567eb6'\n",
    "black_feats = pickle.load(open(path,'rb'))[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA_DataSet(D.Dataset):\n",
    "    def __init__(self, metadata, ids_df, mode='train'):\n",
    "        \n",
    "        super(RSNA_DataSet, self).__init__()\n",
    "        \n",
    "        #self.records = df.to_records(index=False)\n",
    "        self.mode = mode\n",
    "        self.series = metadata.SeriesInstanceUID.unique()\n",
    "        self.metadata = metadata\n",
    "        self.ids_df = ids_df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        series_id = self.series[index]\n",
    "        df = self.metadata.loc[self.metadata.SeriesInstanceUID == series_id].reset_index(drop=True)\n",
    "        \n",
    "        folder = 'test' if self.mode == 'test' else 'train'\n",
    "        path = PATH_WORK/'features/densenet161_v3/{}/{}'.format(folder,series_id)\n",
    "        feats = pickle.load(open(path,'rb'))\n",
    "        ids_df_sub = self.ids_df.loc[self.ids_df.SeriesInstanceUID.values == series_id]\n",
    "        \n",
    "        if feats.shape[0] > len(df):\n",
    "            mask_dup = ~ids_df_sub.img_id.duplicated().values\n",
    "            ids_df_sub = ids_df_sub.loc[mask_dup]\n",
    "            feats = feats[torch.BoolTensor(mask_dup)]\n",
    "        \n",
    "        assert feats.shape[0] == len(df)\n",
    "        assert len(ids_df_sub) == len(df)\n",
    "        assert np.all(ids_df_sub.img_id.isin(df.img_id).values)\n",
    "        order = np.argsort(ids_df_sub.pos_idx.values)\n",
    "        assert np.all(ids_df_sub.img_id.values[order] == df.img_id.values)\n",
    "        feats = feats[torch.LongTensor(order)]\n",
    "        \n",
    "        feats = torch.cat([feats, torch.Tensor(df[meta_cols].values)], dim=1)\n",
    "        offset = np.random.randint(0, 61 - feats.shape[0])\n",
    "        if offset > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.head(1)[meta_cols].values).squeeze()])\n",
    "            feats = torch.cat([dummy_row.repeat(offset,1), feats], dim=0)\n",
    "        if (60 - len(df) - offset) > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.tail(1)[meta_cols].values).squeeze()])\n",
    "            feats = torch.cat([feats, dummy_row.repeat(60 - len(df) - offset,1)], dim=0)\n",
    "        assert feats.shape[0] == 60\n",
    "        \n",
    "        target = torch.cat([torch.Tensor(df[all_ich].values), \n",
    "                            torch.zeros((60 - len(df), len(all_ich)))], dim=0)\n",
    "        feats = feats.transpose(1,0)\n",
    "        \n",
    "        return feats, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.series) if not DATA_SMALL else int(0.01*len(self.series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(Module):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "\n",
    "class BCEWithLogitsLoss(_Loss):\n",
    "    __constants__ = ['weight', 'pos_weight', 'reduction']\n",
    "\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None):\n",
    "        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.register_buffer('pos_weight', pos_weight)\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        #((torch.log(1+torch.exp(input)) - target*input)*self.weight).mean()\n",
    "        return F.binary_cross_entropy_with_logits(input.squeeze(), target,\n",
    "                                                  self.weight,\n",
    "                                                  pos_weight=self.pos_weight,\n",
    "                                                  reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatProduct(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(FeatProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = F.linear(x, self.weight)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, n_cont:int, out_sz:int, layers:Collection[int], ps:Collection[float]=None,\n",
    "                 emb_drop:float=0., use_bn:bool=True, bn_final:bool=False, feat_sz=2208, fc_drop_p=0.3):\n",
    "        super().__init__()\n",
    "        ps = ifnone(ps, [0]*len(layers))\n",
    "        ps = listify(ps, layers)\n",
    "        self.bn_cont = nn.BatchNorm1d(feat_sz + n_cont)\n",
    "        self.n_cont = n_cont\n",
    "        sizes = self.get_sizes(layers, out_sz)\n",
    "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.feat_product = FeatProduct(feat_sz + n_cont, 20)\n",
    "        self.fc_drop = nn.Dropout(p=fc_drop_p)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def get_sizes(self, layers, out_sz):\n",
    "        return [1200] + layers + [out_sz]\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = self.bn_cont(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.fc_drop(x)\n",
    "        x = self.feat_product(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x = self.layers(x)\n",
    "        x = x.reshape(x.shape[0],60,6)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentBatch(fold=0):\n",
    "    sel_batch = None\n",
    "    for filename in os.listdir(PATH_WORK/'models'):\n",
    "        splits = filename.split('.')\n",
    "        if int(splits[2][1]) != fold: continue\n",
    "        if int(splits[3][1:]) != VERSION: continue\n",
    "        if sel_batch is None:\n",
    "            sel_batch = int(splits[1][1:])\n",
    "        else:\n",
    "            sel_batch = max(sel_batch, int(splits[1][1:]))\n",
    "    return sel_batch\n",
    "\n",
    "def modelFileName(fold=0, batch = 1, return_last = False, return_next = False):\n",
    "    sel_batch = batch\n",
    "    if return_last or return_next:\n",
    "        sel_batch = getCurrentBatch(fold)\n",
    "        if return_last and sel_batch is None:\n",
    "            return None\n",
    "        if return_next:\n",
    "            if sel_batch is None: sel_batch = 1\n",
    "            else: sel_batch += 1\n",
    "    \n",
    "    return 'model.b{}.f{}.v{}'.format(sel_batch, fold, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_progress():\n",
    "    fastprogress.NO_BAR = True\n",
    "    master_bar, progress_bar = force_console_behavior()\n",
    "    basic_train.master_bar, basic_train.progress_bar = master_bar, progress_bar\n",
    "    \n",
    "def enable_progress():\n",
    "    basic_train.master_bar, basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixup\n",
    "# position randomization\n",
    "# one-cycle\n",
    "# fill empty with all black features, and meta of the last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(weight=None, load_model=True, epochs=1, bs=100):\n",
    "    \n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch, 'starting now:', epochs)\n",
    "    \n",
    "    setSeeds(SEED + cur_epoch)\n",
    "    \n",
    "    #sampler = None\n",
    "    #if False:\n",
    "    #    ww = torch.DoubleTensor(wt)\n",
    "    #    sampler = torch.utils.data.sampler.WeightedRandomSampler(ww, len(ww), replacement=True)\n",
    "    \n",
    "    trn_ds = RSNA_DataSet(trn_data, ids_df, mode='train')\n",
    "    val_ds = RSNA_DataSet(val_data, ids_df, mode='valid')\n",
    "    tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test')\n",
    "    df = DataBunch.create(train_ds=trn_ds, valid_ds=val_ds, test_ds=tst_ds, bs=bs, num_workers=0)\n",
    "    \n",
    "    tab_model = TabularModel(n_cont = len(meta_cols), out_sz=360, \\\n",
    "                             layers=[500,200], ps=[0.5,0.5], bn_final=True)\n",
    "    loss_func = BCEWithLogitsLoss(weight = torch.Tensor(class_weights).cuda())\n",
    "    model = Learner(df, tab_model, path=PATH_WORK, loss_func=loss_func)#.mixup()\n",
    "    \n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if load_model:\n",
    "        if model_file_name is not None:\n",
    "            print('loading model', model_file_name)\n",
    "            model.load(PATH_WORK/'models'/model_file_name)\n",
    "        else:\n",
    "            print('starting from scratch')\n",
    "    \n",
    "    for i in range(cur_epoch+1, cur_epoch+epochs+1):\n",
    "        st = time.time()\n",
    "        model.fit(1, 1e-1, wd=5e-3)\n",
    "        train_time = time.time()-st\n",
    "        \n",
    "        model_file_name = modelFileName(return_next=True)\n",
    "        if not DATA_SMALL:\n",
    "            model.save(PATH_WORK/'models'/model_file_name)\n",
    "\n",
    "        st = time.time()\n",
    "        disable_progress()\n",
    "        predictions = np.array(model.get_preds(ds_type=DatasetType.Valid)[0])\n",
    "        enable_progress()\n",
    "        \n",
    "        loc_data = val_data.copy()\n",
    "        if DATA_SMALL:\n",
    "            val_sz = int(0.01*len(val_data.SeriesInstanceUID.unique()))\n",
    "            val_series = val_data.SeriesInstanceUID.unique()[:val_sz]\n",
    "            loc_data = loc_data.loc[val_data.SeriesInstanceUID.isin(val_series)]\n",
    "\n",
    "        val_results = np.zeros((len(loc_data),6))\n",
    "        for k, series in enumerate(loc_data.SeriesInstanceUID.unique()):\n",
    "            mask = loc_data.SeriesInstanceUID == series\n",
    "            val_results[mask] = predictions[k,:mask.sum()]\n",
    "\n",
    "        #ll = log_loss(loc_data.loc[:,all_ich].reshape(-1), val_results.reshape(-1), eps=1e-6)\n",
    "        lls = [log_loss(loc_data[all_ich[k]].values, val_results[:,k], eps=1e-8, labels=[0,1]) for k in range(6)]\n",
    "        ll = (class_weights * np.array(lls)).mean()\n",
    "        cor = np.corrcoef(loc_data.loc[:,all_ich].values.reshape(-1), val_results.reshape(-1))[0,1]\n",
    "\n",
    "        print('epoch {}, val ll: {:.4f}, cor: {:.4f}'.format(i, ll, cor))\n",
    "        valid_time = time.time()-st\n",
    "\n",
    "        epoch_stats = pd.DataFrame([[i, 0, ll, cor, lls[0], lls[1], lls[2], lls[3], lls[4], lls[5],\n",
    "                                     len(trn_ds), len(val_ds), bs, train_time, valid_time]], \n",
    "                                   columns = \n",
    "                                    ['epoch','fold','loss','cor',\n",
    "                                     'any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural',\n",
    "                                     'train_sz','val_sz','bs','train_time','valid_time'\n",
    "                                     ])\n",
    "\n",
    "        stats_filename = PATH_WORK/'stats.f{}.v{}'.format(0,VERSION)\n",
    "        if stats_filename.is_file():\n",
    "            epoch_stats = pd.concat([pd.read_csv(stats_filename), epoch_stats], sort=False)\n",
    "        if not DATA_SMALL:\n",
    "            epoch_stats.to_csv(stats_filename, index=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 3 starting now: 1\n",
      "loading model model.b3.f0.v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 55:30 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.051856</th>\n",
       "    <th>0.057619</th>\n",
       "    <th>55:30</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch 4, ll 0.1001, cor 0.7310\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "model = train_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 4 starting now: 1\n",
      "loading model model.b4.f0.v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:24 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.127215</th>\n",
       "    <th>147.537949</th>\n",
       "    <th>00:24</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, val ll: 1.4110, cor: -0.0124\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = True\n",
    "model = train_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fold</th>\n",
       "      <th>loss</th>\n",
       "      <th>cor</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>train_sz</th>\n",
       "      <th>val_sz</th>\n",
       "      <th>bs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>valid_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10014</td>\n",
       "      <td>0.731025</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.097562</td>\n",
       "      <td>0.048806</td>\n",
       "      <td>0.094238</td>\n",
       "      <td>0.115467</td>\n",
       "      <td>17577</td>\n",
       "      <td>1953</td>\n",
       "      <td>100</td>\n",
       "      <td>3330.288549</td>\n",
       "      <td>208.896577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  fold     loss       cor       any  epidural  intraparenchymal  \\\n",
       "0      4     0  0.10014  0.731025  0.164123  0.016662          0.097562   \n",
       "\n",
       "   intraventricular  subarachnoid  subdural  train_sz  val_sz   bs  \\\n",
       "0          0.048806      0.094238  0.115467     17577    1953  100   \n",
       "\n",
       "    train_time  valid_time  \n",
       "0  3330.288549  208.896577  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(PATH_WORK/'stats.f{}.v{}'.format(0,VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss 0.0462624751187673\n",
      "correlation 0.7656300002685762\n"
     ]
    }
   ],
   "source": [
    "val_sz = len(val_data.SeriesInstanceUID.unique())\n",
    "if DATA_SMALL: val_sz = int(0.01*val_sz)\n",
    "val_series = val_data.SeriesInstanceUID.unique()[:val_sz]\n",
    "val_target = np.zeros((val_sz,60,6))\n",
    "for i, series in enumerate(val_series):\n",
    "    mask = val_data.SeriesInstanceUID == series\n",
    "    val_target[i,:mask.sum()] = val_data.loc[mask, all_ich]\n",
    "\n",
    "print('Log-loss', log_loss(val_target.reshape(-1),predictions.reshape(-1),eps=1e-6))\n",
    "print('correlation', np.corrcoef(val_target.reshape(-1),predictions.reshape(-1))[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.059284, 0.003352, 0.018136, 0.016913, 0.017706, 0.028348], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2172510c208>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions.mean(0)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.077718, 0.001647, 0.026267, 0.019449, 0.024364, 0.033658])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_target.mean((0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SMALL = False\n",
    "predictions = np.array(model.get_preds(ds_type=DatasetType.Test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.087846, 0.004184, 0.029325, 0.030316, 0.041098, 0.029221], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "for i, series_id in enumerate(test_md.SeriesInstanceUID.unique()):\n",
    "    df = test_md.loc[test_md.SeriesInstanceUID == series_id]\n",
    "    id_column = [a + '_' + b for a in df.SOPInstanceUID for b in all_ich]\n",
    "    data_sub = pd.DataFrame({'ID':np.array(id_column), 'Label':predictions[i,:len(df)].reshape(-1)})\n",
    "    sub = pd.concat([sub,data_sub], axis=0, sort=False)\n",
    "\n",
    "sub = sub.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1471214"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1255341744607709"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499705853123557"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
