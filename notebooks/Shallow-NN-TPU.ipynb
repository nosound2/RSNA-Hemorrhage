{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate torch-xla-nightly\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;$10.0.101.2:8470\"\n",
    "#git init\n",
    "#git remote add origin https://github.com/nosound2/RSNA-Hemorrhage\n",
    "#git pull origin master\n",
    "#git config remote.origin.push HEAD\n",
    "#gcloud config set compute/zone europe-west4-a\n",
    "#gcloud auth login\n",
    "#gcloud config set project endless-empire-239015\n",
    "#pip install kaggle\n",
    "#mkdir .kaggle\n",
    "#gsutil cp gs://recursion-double-strand/kaggle-keys/kaggle.json ~/.kaggle\n",
    "#chmod 600 /home/zahar_chikishev/.kaggle/kaggle.json\n",
    "#kaggle competitions download rsna-intracranial-hemorrhage-detection -f stage_1_train.csv\n",
    "#sudo apt install unzip\n",
    "#unzip stage_1_train.csv.zip\n",
    "#kaggle kernels output xhlulu/rsna-generate-metadata-csvs -p .\n",
    "#gsutil cp gs://rsna-hemorrhage/yuvals/* .\n",
    "\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;10.0.101.2:8470\"; conda activate torch-xla-nightly; jupyter notebook\n",
    "\n",
    "# 35.204.242.164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from matplotlib import patches, patheffects\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import pdb\n",
    "\n",
    "import scipy as sp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "CLOUD = not torch.cuda.is_available()\n",
    "CLOUD_SINGLE = False\n",
    "\n",
    "if not CLOUD:\n",
    "    torch.cuda.current_device()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as M\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if CLOUD:\n",
    "    PATH = Path('/home/zahar_chikishev')\n",
    "    PATH_WORK = Path('/home/zahar_chikishev/running')\n",
    "else:\n",
    "    PATH = Path('C:/StudioProjects/Hemorrhage')\n",
    "    PATH_WORK = Path('C:/StudioProjects/Hemorrhage/running')\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import seaborn as sn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "all_ich = ['any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural']\n",
    "class_weights = 6.0*np.array([2,1,1,1,1,1])/7.0\n",
    "\n",
    "if CLOUD:\n",
    "    import torch_xla\n",
    "    import torch_xla.distributed.data_parallel as dp\n",
    "    import torch_xla.utils as xu\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    \n",
    "    from typing import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLOUD:\n",
    "    device = xm.xla_device()\n",
    "    #device = 'cpu'\n",
    "    MAX_DEVICES = 1 if CLOUD_SINGLE else 8\n",
    "    bs = 100\n",
    "else:\n",
    "    device = 'cuda'\n",
    "    #device = 'cpu'\n",
    "    MAX_DEVICES = 1\n",
    "    bs = 10\n",
    "\n",
    "if CLOUD and (not CLOUD_SINGLE):\n",
    "    devices = xm.get_xla_supported_devices(max_devices=MAX_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2351\n",
    "\n",
    "def setSeeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "setSeeds(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat, cols_float = pickle.load(open(PATH_WORK/'covs','rb'))\n",
    "meta_cols = cols_cat + cols_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = PATH_WORK/'indexes_file.pkl'\n",
    "    all_idx, train_ids, val_ids = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    train_md = pd.read_csv(PATH_WORK/'train_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "    train_md['img_id'] = train_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])\n",
    "\n",
    "    trn_data = train_md.loc[train_md.img_id.isin(all_idx[train_ids])].reset_index(drop=True)\n",
    "    val_data = train_md.loc[train_md.img_id.isin(all_idx[val_ids])].reset_index(drop=True)\n",
    "\n",
    "    assert len(trn_data.SeriesInstanceUID.unique()) + len(val_data.SeriesInstanceUID.unique()) \\\n",
    "        == len(train_md.SeriesInstanceUID.unique())\n",
    "\n",
    "    assert len(trn_data.PatientID.unique()) + len(val_data.PatientID.unique()) \\\n",
    "        >= len(train_md.PatientID.unique())\n",
    "\n",
    "    ids_df = pd.DataFrame(all_idx, columns = ['img_id'])\n",
    "    ids_df = ids_df.join(train_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "    assert len(ids_df.SeriesInstanceUID.unique()) == 19530\n",
    "    \n",
    "    pickle.dump((trn_data,val_data,ids_df), open(PATH_WORK/'train.post.processed.1','wb'))\n",
    "else:\n",
    "    trn_data,val_data,ids_df = pickle.load(open(PATH_WORK/'train.post.processed.1','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    test_md = pd.read_csv(PATH_WORK/'test_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "    test_md['img_id'] = test_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])\n",
    "\n",
    "    filename = PATH_WORK/'test_indexes.pkl'\n",
    "    test_ids = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    test_ids_df = pd.DataFrame(test_ids, columns = ['img_id'])\n",
    "    test_ids_df = test_ids_df.join(test_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "    assert len(test_ids_df.SeriesInstanceUID.unique()) == 2214\n",
    "    \n",
    "    pickle.dump((test_md,test_ids_df), open(PATH_WORK/'test.post.processed.1','wb'))\n",
    "else:\n",
    "    test_md,test_ids_df = pickle.load(open(PATH_WORK/'test.post.processed.1','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(pd.concat([test_md[meta_cols].mean(0),\n",
    "                     trn_data[meta_cols].mean(0),\n",
    "                     val_data[meta_cols].mean(0)], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = PATH_WORK/'model_Densenet161_3_vehrsion_basic_classifier_type_features_train_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/train/{}'.format(series_id),'wb'))\n",
    "\n",
    "\n",
    "    filename = PATH_WORK/'model_Densenet161_3_vehrsion_basic_classifier_type_features_test_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(test_ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(test_ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/test/{}'.format(series_id),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = PATH_WORK/'features/densenet161_v3/train/ID_000a935543'\n",
    "#feats1 = pickle.load(open(path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_black = '006d4432e'\n",
    "\n",
    "path = PATH_WORK/'features/densenet161_v3/train/ID_992b567eb6'\n",
    "black_feats = pickle.load(open(path,'rb'))[41]\n",
    "\n",
    "#black_feats = torch.zeros(black_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA_DataSet(D.Dataset):\n",
    "    def __init__(self, metadata, ids_df, mode='train', bs=None):\n",
    "        \n",
    "        super(RSNA_DataSet, self).__init__()\n",
    "        \n",
    "        md = metadata.copy()\n",
    "        md = md.reset_index(drop=True)\n",
    "        series = md.SeriesInstanceUID.unique()\n",
    "        \n",
    "        samples_add = 0\n",
    "        if (mode != 'train') and not DATA_SMALL:\n",
    "            batch_num = -((-len(series))//(bs*MAX_DEVICES))\n",
    "            samples_add = batch_num*bs*MAX_DEVICES - len(series)\n",
    "            print('adding dummy serieses', samples_add)\n",
    "        \n",
    "        #self.records = df.to_records(index=False)\n",
    "        self.mode = mode\n",
    "        self.real = np.concatenate([np.repeat(True,len(series)),np.repeat(False,samples_add)])\n",
    "        self.series = np.concatenate([series,np.repeat(series[0],samples_add)])\n",
    "        self.metadata = md\n",
    "        self.ids_df = ids_df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        series_id = self.series[index]\n",
    "        df = self.metadata.loc[self.metadata.SeriesInstanceUID == series_id].reset_index(drop=True)\n",
    "        \n",
    "        folder = 'test' if self.mode == 'test' else 'train'\n",
    "        path = PATH_WORK/'features/densenet161_v3/{}/{}'.format(folder,series_id)\n",
    "        feats = pickle.load(open(path,'rb'))\n",
    "        ids_df_sub = self.ids_df.loc[self.ids_df.SeriesInstanceUID.values == series_id]\n",
    "        \n",
    "        if feats.shape[0] > len(df):\n",
    "            mask_dup = ~ids_df_sub.img_id.duplicated().values\n",
    "            ids_df_sub = ids_df_sub.loc[mask_dup]\n",
    "            feats = feats[torch.BoolTensor(mask_dup)]\n",
    "        \n",
    "        assert feats.shape[0] == len(df)\n",
    "        assert len(ids_df_sub) == len(df)\n",
    "        assert np.all(ids_df_sub.img_id.isin(df.img_id).values)\n",
    "        order = np.argsort(ids_df_sub.pos_idx.values)\n",
    "        assert np.all(ids_df_sub.img_id.values[order] == df.img_id.values)\n",
    "        feats = feats[torch.LongTensor(order)]\n",
    "        \n",
    "        feats = torch.cat([feats, torch.Tensor(df[meta_cols].values)], dim=1)\n",
    "        target = torch.Tensor(df[all_ich].values)\n",
    "        \n",
    "        offset = np.random.randint(0, 61 - feats.shape[0])\n",
    "        #offset = 0\n",
    "        if offset > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.head(1)[meta_cols].values).squeeze()])\n",
    "            #dummy_row = torch.cat([black_feats, torch.zeros(len(meta_cols))])\n",
    "            feats = torch.cat([dummy_row.repeat(offset,1), feats], dim=0)\n",
    "            target = torch.cat([torch.zeros((offset, len(all_ich))), target], dim=0)\n",
    "        if (60 - len(df) - offset) > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.tail(1)[meta_cols].values).squeeze()])\n",
    "            #dummy_row = torch.cat([black_feats, torch.zeros(len(meta_cols))])\n",
    "            feats = torch.cat([feats, dummy_row.repeat(60 - len(df) - offset,1)], dim=0)\n",
    "            target = torch.cat([target, torch.zeros((60 - len(df) - offset, len(all_ich)))], dim=0)\n",
    "        \n",
    "        assert feats.shape[0] == 60\n",
    "        assert target.shape[0] == 60\n",
    "        \n",
    "        feats = feats.transpose(1,0)\n",
    "        \n",
    "        idx = index\n",
    "        if not self.real[index]: idx = -1\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return feats, target\n",
    "        else:\n",
    "            return feats, target, idx, offset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.series) if not DATA_SMALL else int(0.01*len(self.series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentBatch(fold=0):\n",
    "    sel_batch = None\n",
    "    for filename in os.listdir(PATH_WORK/'models'):\n",
    "        splits = filename.split('.')\n",
    "        if int(splits[2][1]) != fold: continue\n",
    "        if int(splits[3][1:]) != VERSION: continue\n",
    "        if sel_batch is None:\n",
    "            sel_batch = int(splits[1][1:])\n",
    "        else:\n",
    "            sel_batch = max(sel_batch, int(splits[1][1:]))\n",
    "    return sel_batch\n",
    "\n",
    "def modelFileName(fold=0, batch = 1, return_last = False, return_next = False):\n",
    "    sel_batch = batch\n",
    "    if return_last or return_next:\n",
    "        sel_batch = getCurrentBatch(fold)\n",
    "        if return_last and sel_batch is None:\n",
    "            return None\n",
    "        if return_next:\n",
    "            if sel_batch is None: sel_batch = 1\n",
    "            else: sel_batch += 1\n",
    "    \n",
    "    return 'model.b{}.f{}.v{}'.format(sel_batch, fold, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(nn.Module):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "\n",
    "class BCEWithLogitsLoss(_Loss):\n",
    "    __constants__ = ['weight', 'pos_weight', 'reduction']\n",
    "\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None):\n",
    "        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.register_buffer('pos_weight', pos_weight)\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        #((torch.log(1+torch.exp(input)) - target*input)*self.weight).mean()\n",
    "        return F.binary_cross_entropy_with_logits(input.squeeze(), target,\n",
    "                                                  self.weight,\n",
    "                                                  pos_weight=self.pos_weight,\n",
    "                                                  reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatProduct(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(FeatProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.uniform_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = F.linear(x, self.weight) + self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_drop_lin(n_in:int, n_out:int, bn:bool=True, p:float=0., actn=None):\n",
    "    \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n",
    "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "    if p != 0: layers.append(nn.Dropout(p))\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if actn is not None: layers.append(actn)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, n_cont:int, out_sz:int, layers, ps=None,\n",
    "                 emb_drop:float=0., use_bn:bool=True, bn_final:bool=False, feat_sz=2208, fc_drop_p=0.3):\n",
    "        super().__init__()\n",
    "        self.bn_cont = nn.BatchNorm1d(feat_sz + n_cont)\n",
    "        self.n_cont = n_cont\n",
    "        sizes = self.get_sizes(layers, out_sz)\n",
    "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.feat_product = FeatProduct(feat_sz + n_cont, 20)\n",
    "        self.fc_drop = nn.Dropout(p=fc_drop_p)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2D_1 = nn.Conv2d(1,32,(feat_sz + n_cont,1))\n",
    "        self.conv2D_2 = nn.Conv2d(1,32,(feat_sz + n_cont,5),padding=(0,2))\n",
    "        self.bn_cont1 = nn.BatchNorm1d(64)\n",
    "        self.conv1D_1 = nn.Conv1d(64,64,3,padding=1)\n",
    "        self.conv1D_2 = nn.Conv1d(64,6,3,padding=1)\n",
    "        self.bn_cont2 = nn.BatchNorm1d(64)\n",
    "        self.bn_cont3 = nn.BatchNorm1d(6)\n",
    "\n",
    "    def get_sizes(self, layers, out_sz):\n",
    "        return [1200] + layers + [out_sz]\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.bn_cont(x) # bs,2208,60\n",
    "        #x = x.transpose(1,2) # bs,60,2208\n",
    "        x = self.fc_drop(x)\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2]) # bs,1,2208,60\n",
    "        x = torch.cat([self.conv2D_1(x).squeeze(), self.conv2D_2(x).squeeze()], dim=1) # bs,64,60\n",
    "        x = self.relu(x)\n",
    "        x = self.bn_cont1(x)\n",
    "        x = self.fc_drop(x)\n",
    "        x = self.conv1D_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn_cont2(x)\n",
    "        x = self.fc_drop(x)\n",
    "        x = self.conv1D_2(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.bn_cont3(x) # bs,6,60\n",
    "        #x = self.fc_drop(x)\n",
    "        #x = self.feat_product(x)\n",
    "        #x = x.reshape(x.shape[0],-1)\n",
    "        #x = self.layers(x)\n",
    "        #x = x.reshape(x.shape[0],60,6)\n",
    "        x = x.transpose(1,2) # bs,60,6\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 5\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "        dataset = loader._loader._loader.dataset\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 10\n",
    "        OUT_TIME = 1\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "        dataset = loader.dataset\n",
    "    \n",
    "    #print('Start training {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss(weight = torch.Tensor(class_weights).to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=(0.9, 0.99))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    if CLOUD:\n",
    "        tracker = xm.RateTracker()\n",
    "\n",
    "    tloss = 0\n",
    "    tloss_count = 0\n",
    "    \n",
    "    st = time.time()\n",
    "    for i, (x, y) in generator:\n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        tloss += len(y)*loss.cpu().detach().item()\n",
    "        tloss_count += len(y)\n",
    "        \n",
    "        if CLOUD or CLOUD_SINGLE:\n",
    "            xm.optimizer_step(optimizer)\n",
    "            if CLOUD_SINGLE:\n",
    "                xm.mark_step()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        \n",
    "        if CLOUD:\n",
    "            tracker.add(len(y))\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            #print(torch_xla._XLAC._xla_metrics_report())\n",
    "            print('Batch {} device: {} time passed: {:.3f} time per batch: {:.3f}'\n",
    "                .format(i+1, device, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del loss, output, y, x\n",
    "    \n",
    "    return tloss, tloss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 1\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 10\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "    \n",
    "    #print('Start validating {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    indices = []\n",
    "    offsets = []\n",
    "    \n",
    "    for i, (x, y, idx, offset) in generator:\n",
    "        \n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "        \n",
    "        output = torch.sigmoid(model(x))\n",
    "        \n",
    "        mask = (idx >= 0)\n",
    "        results.append(output[mask].cpu().detach().numpy())\n",
    "        indices.append(idx[mask].cpu().detach().numpy())\n",
    "        offsets.append(offset[mask].cpu().detach().numpy())\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            print('Batch {} device: {} time passed: {:.3f} time per batch: {:.3f}'\n",
    "                  .format(i+1, device, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del output, y, x, idx, offset\n",
    "    \n",
    "    results = np.concatenate(results)\n",
    "    indices = np.concatenate(indices)\n",
    "    offsets = np.concatenate(offsets)\n",
    "    \n",
    "    return results, indices, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 100\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 10\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "    \n",
    "    #print('Start testing {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    indices = []\n",
    "    offsets = []\n",
    "    \n",
    "    for i, (x, y, idx, offset) in generator:\n",
    "        \n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "        \n",
    "        output = torch.sigmoid(model(x))\n",
    "        \n",
    "        mask = (idx >= 0)\n",
    "        results.append(output[mask].cpu().detach().numpy())\n",
    "        indices.append(idx[mask].cpu().detach().numpy())\n",
    "        offsets.append(offset[mask].cpu().detach().numpy())\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            print('B{} -> time passed: {:.3f} time per batch: {:.3f}'.format(i+1, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del output, x, y, idx, offset\n",
    "    \n",
    "    return np.concatenate(results), np.concatenate(indices), np.concatenate(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(weight=None, load_model=True, epochs=1, bs=100):\n",
    "    \n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch, 'starting now:', epochs)\n",
    "    \n",
    "    setSeeds(SEED + cur_epoch)\n",
    "    \n",
    "    trn_ds = RSNA_DataSet(trn_data, ids_df, mode='train', bs=bs)\n",
    "    loader = D.DataLoader(trn_ds, num_workers=16 if CLOUD else 0, batch_size=bs, shuffle=True)\n",
    "    val_ds = RSNA_DataSet(val_data, ids_df, mode='valid', bs=bs)\n",
    "    loader_val = D.DataLoader(val_ds, num_workers=16 if CLOUD else 0, batch_size=bs, shuffle=True)\n",
    "    #tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test')\n",
    "    print('dataset train:', len(trn_ds), 'valid:', len(val_ds), 'loader train:', len(loader), 'valid:', len(loader_val))\n",
    "    \n",
    "    model = TabularModel(n_cont = len(meta_cols), out_sz=360, layers=[500,200], ps=[0.5,0.5], bn_final=True)\n",
    "    \n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if model_file_name is not None:\n",
    "        print('loading model', model_file_name)\n",
    "        state_dict = torch.load(PATH_WORK/'models'/model_file_name)\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print('starting from scratch')\n",
    "    \n",
    "    if (not CLOUD) or CLOUD_SINGLE:\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        model_parallel = dp.DataParallel(model, device_ids=devices)\n",
    "    \n",
    "    for i in range(cur_epoch+1, cur_epoch+epochs+1):\n",
    "        st = time.time()\n",
    "\n",
    "        if CLOUD and (not CLOUD_SINGLE):\n",
    "            results = model_parallel(train_loop_fn, loader)\n",
    "            tloss, tloss_count = np.stack(results).sum(0)\n",
    "            state_dict = model_parallel._models[0].state_dict()\n",
    "        else:\n",
    "            tloss, tloss_count = train_loop_fn(model, loader, device)\n",
    "            state_dict = model.state_dict()\n",
    "        \n",
    "        state_dict = {k:v.to('cpu') for k,v in state_dict.items()}\n",
    "        tr_ll = tloss / tloss_count\n",
    "        \n",
    "        train_time = time.time()-st\n",
    "        \n",
    "        model_file_name = modelFileName(return_next=True)\n",
    "        if not DATA_SMALL:\n",
    "            torch.save(state_dict, PATH_WORK/'models'/model_file_name)\n",
    "        \n",
    "        st = time.time()\n",
    "        if CLOUD and (not CLOUD_SINGLE):\n",
    "            results = model_parallel(val_loop_fn, loader_val)\n",
    "            predictions = np.concatenate([results[i][0] for i in range(MAX_DEVICES)])\n",
    "            indices = np.concatenate([results[i][1] for i in range(MAX_DEVICES)])\n",
    "            offsets = np.concatenate([results[i][2] for i in range(MAX_DEVICES)])\n",
    "        else:\n",
    "            predictions, indices, offsets = val_loop_fn(model, loader_val, device)\n",
    "        \n",
    "        loc_data = val_data.copy()\n",
    "        if DATA_SMALL:\n",
    "            val_sz = int(0.01*len(val_data.SeriesInstanceUID.unique()))\n",
    "            val_series = val_data.SeriesInstanceUID.unique()[:val_sz]\n",
    "            loc_data = loc_data.loc[val_data.SeriesInstanceUID.isin(val_series)]\n",
    "        \n",
    "        predictions = predictions[np.argsort(indices)]\n",
    "        offsets = offsets[np.argsort(indices)]\n",
    "        assert len(predictions) == len(loc_data.SeriesInstanceUID.unique())\n",
    "        assert len(predictions) == len(offsets)\n",
    "        assert np.all(indices[np.argsort(indices)] == np.array(range(len(predictions))))\n",
    "        \n",
    "        valid_time = time.time()-st\n",
    "        \n",
    "        val_results = np.zeros((len(loc_data),6))\n",
    "        for k, series in enumerate(loc_data.SeriesInstanceUID.unique()):\n",
    "            mask = loc_data.SeriesInstanceUID == series\n",
    "            assert (offsets[k] + mask.sum()) <= 60\n",
    "            val_results[mask] = predictions[k,offsets[k]:(offsets[k] + mask.sum())]\n",
    "        \n",
    "        lls = [log_loss(loc_data[all_ich[k]].values, val_results[:,k], eps=1e-8, labels=[0,1]) for k in range(6)]\n",
    "        ll = (class_weights * np.array(lls)).mean()\n",
    "        cor = np.corrcoef(loc_data.loc[:,all_ich].values.reshape(-1), val_results.reshape(-1))[0,1]\n",
    "\n",
    "        print('epoch {}, train ll: {:.4f}, val ll: {:.4f}, cor: {:.4f}'.format(i, tr_ll, ll, cor))\n",
    "        valid_time = time.time()-st\n",
    "\n",
    "        epoch_stats = pd.DataFrame([[i, 0, tr_ll, ll, cor, lls[0], lls[1], lls[2], lls[3], lls[4], lls[5],\n",
    "                                     len(trn_ds), len(val_ds), bs, train_time, valid_time,\n",
    "                                     learning_rate, weight_decay]], \n",
    "                                   columns = \n",
    "                                    ['epoch','fold','train_loss','val_loss','cor',\n",
    "                                     'any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural',\n",
    "                                     'train_sz','val_sz','bs','train_time','valid_time','lr','wd'\n",
    "                                     ])\n",
    "\n",
    "        stats_filename = PATH_WORK/'stats.f{}.v{}'.format(0,VERSION)\n",
    "        if stats_filename.is_file():\n",
    "            epoch_stats = pd.concat([pd.read_csv(stats_filename), epoch_stats], sort=False)\n",
    "        #if not DATA_SMALL:\n",
    "        epoch_stats.to_csv(stats_filename, index=False)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 22 device: xla:1 time passed: 277.972 time per batch: 12.635 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 209.280 time per batch: 9.513  - 16 cores / 16 workers\n",
    "#Batch 22 device: xla:1 time passed: 213.209 time per batch: 9.691  - 16 cores / 32 workers\n",
    "#Batch 22 device: xla:1 time passed: 275.780 time per batch: 12.535 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 208.826 time per batch: 9.492  - 16 cores / 16 workers\n",
    "#Batch 22 device: xla:1 time passed: 245.750 time per batch: 11.170 - 16 cores / 12 workers\n",
    "#Batch 22 device: xla:1 time passed: 374.876 time per batch: 17.040 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 400.221 time per batch: 18.192 - 8 cores / 8 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixup\n",
    "# one-cycle\n",
    "# why test doesn't behave? Same stats for valid?\n",
    "# submit from TPU\n",
    "# copy latest model to GS code\n",
    "# add performance tracking, search for bottlenecks\n",
    "# label smoothing\n",
    "\n",
    "# Yuval: zoom in, squish, perspective wraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 0 starting now: 3\n",
      "adding dummy serieses 447\n",
      "dataset train: 17577 valid: 2400 loader train: 176 valid: 24\n",
      "starting from scratch\n",
      "Batch 5 device: xla:1 time passed: 59.865 time per batch: 11.973\n",
      "Batch 10 device: xla:1 time passed: 87.596 time per batch: 8.760\n",
      "Batch 15 device: xla:1 time passed: 115.308 time per batch: 7.687\n",
      "Batch 20 device: xla:1 time passed: 143.495 time per batch: 7.175\n",
      "Batch 1 device: xla:1 time passed: 21.510 time per batch: 21.510\n",
      "Batch 2 device: xla:1 time passed: 23.315 time per batch: 11.657\n",
      "Batch 3 device: xla:1 time passed: 25.099 time per batch: 8.366\n",
      "epoch 1, train ll: 0.2454, val ll: 0.3688, cor: 0.4575\n",
      "Batch 5 device: xla:1 time passed: 59.912 time per batch: 11.982\n",
      "Batch 10 device: xla:1 time passed: 87.641 time per batch: 8.764\n",
      "Batch 15 device: xla:1 time passed: 115.786 time per batch: 7.719\n",
      "Batch 20 device: xla:1 time passed: 143.320 time per batch: 7.166\n",
      "Batch 1 device: xla:1 time passed: 20.502 time per batch: 20.502\n",
      "Batch 2 device: xla:1 time passed: 21.913 time per batch: 10.956\n",
      "Batch 3 device: xla:1 time passed: 23.309 time per batch: 7.770\n",
      "epoch 2, train ll: 0.1117, val ll: 0.4254, cor: 0.5178\n",
      "Batch 5 device: xla:1 time passed: 59.811 time per batch: 11.962\n",
      "Batch 10 device: xla:1 time passed: 87.728 time per batch: 8.773\n",
      "Batch 15 device: xla:1 time passed: 115.219 time per batch: 7.681\n",
      "Batch 20 device: xla:1 time passed: 143.402 time per batch: 7.170\n",
      "Batch 1 device: xla:1 time passed: 20.481 time per batch: 20.481\n",
      "Batch 2 device: xla:1 time passed: 20.712 time per batch: 10.356\n",
      "Batch 3 device: xla:1 time passed: 20.886 time per batch: 6.962\n",
      "epoch 3, train ll: 0.0921, val ll: 0.1728, cor: 0.5843\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "learning_rate = 0.1\n",
    "weight_decay = 1e-4\n",
    "model, predictions = train_one(epochs=3, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 3 starting now: 3\n",
      "adding dummy serieses 447\n",
      "dataset train: 17577 valid: 2400 loader train: 176 valid: 24\n",
      "loading model model.b3.f0.v21\n",
      "Batch 5 device: xla:1 time passed: 60.672 time per batch: 12.134\n",
      "Batch 10 device: xla:1 time passed: 88.813 time per batch: 8.881\n",
      "Batch 15 device: xla:1 time passed: 116.543 time per batch: 7.770\n",
      "Batch 20 device: xla:1 time passed: 144.849 time per batch: 7.242\n",
      "Batch 1 device: xla:1 time passed: 19.220 time per batch: 19.220\n",
      "Batch 2 device: xla:1 time passed: 20.673 time per batch: 10.336\n",
      "Batch 3 device: xla:1 time passed: 22.337 time per batch: 7.446\n",
      "epoch 4, train ll: 0.1132, val ll: 0.5669, cor: 0.3091\n",
      "Batch 5 device: xla:1 time passed: 59.727 time per batch: 11.945\n",
      "Batch 10 device: xla:1 time passed: 87.664 time per batch: 8.766\n",
      "Batch 15 device: xla:1 time passed: 115.455 time per batch: 7.697\n",
      "Batch 20 device: xla:1 time passed: 143.015 time per batch: 7.151\n",
      "Batch 1 device: xla:1 time passed: 19.136 time per batch: 19.136\n",
      "Batch 2 device: xla:1 time passed: 19.348 time per batch: 9.674\n",
      "Batch 3 device: xla:1 time passed: 19.569 time per batch: 6.523\n",
      "epoch 5, train ll: 0.1421, val ll: 0.1227, cor: 0.6876\n",
      "Batch 5 device: xla:1 time passed: 59.703 time per batch: 11.941\n",
      "Batch 10 device: xla:1 time passed: 87.351 time per batch: 8.735\n",
      "Batch 15 device: xla:1 time passed: 114.763 time per batch: 7.651\n",
      "Batch 20 device: xla:1 time passed: 142.974 time per batch: 7.149\n",
      "Batch 1 device: xla:1 time passed: 18.959 time per batch: 18.959\n",
      "Batch 2 device: xla:1 time passed: 19.192 time per batch: 9.596\n",
      "Batch 3 device: xla:1 time passed: 19.416 time per batch: 6.472\n",
      "epoch 6, train ll: 0.1652, val ll: 0.1718, cor: 0.6818\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "learning_rate = 0.1\n",
    "weight_decay = 1e-4\n",
    "model, predictions = train_one(epochs=3, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 7 starting now: 3\n",
      "adding dummy serieses 447\n",
      "dataset train: 17577 valid: 2400 loader train: 176 valid: 24\n",
      "loading model model.b7.f0.v21\n",
      "Batch 5 device: xla:1 time passed: 60.318 time per batch: 12.064\n",
      "Batch 10 device: xla:1 time passed: 88.626 time per batch: 8.863\n",
      "Batch 15 device: xla:1 time passed: 116.683 time per batch: 7.779\n",
      "Batch 20 device: xla:1 time passed: 144.020 time per batch: 7.201\n",
      "Batch 1 device: xla:1 time passed: 19.161 time per batch: 19.161\n",
      "Batch 2 device: xla:1 time passed: 19.408 time per batch: 9.704\n",
      "Batch 3 device: xla:1 time passed: 19.672 time per batch: 6.557\n",
      "epoch 8, train ll: 0.0466, val ll: 0.1107, cor: 0.7359\n",
      "Batch 5 device: xla:1 time passed: 59.828 time per batch: 11.966\n",
      "Batch 10 device: xla:1 time passed: 87.742 time per batch: 8.774\n",
      "Batch 15 device: xla:1 time passed: 114.936 time per batch: 7.662\n",
      "Batch 20 device: xla:1 time passed: 143.150 time per batch: 7.157\n",
      "Batch 1 device: xla:1 time passed: 19.270 time per batch: 19.270\n",
      "Batch 2 device: xla:1 time passed: 19.531 time per batch: 9.765\n",
      "Batch 3 device: xla:1 time passed: 19.810 time per batch: 6.603\n",
      "epoch 9, train ll: 0.0436, val ll: 0.0757, cor: 0.8090\n",
      "Batch 5 device: xla:1 time passed: 59.965 time per batch: 11.993\n",
      "Batch 10 device: xla:1 time passed: 87.295 time per batch: 8.729\n",
      "Batch 15 device: xla:1 time passed: 115.654 time per batch: 7.710\n",
      "Batch 20 device: xla:1 time passed: 142.763 time per batch: 7.138\n",
      "Batch 1 device: xla:1 time passed: 19.248 time per batch: 19.248\n",
      "Batch 2 device: xla:1 time passed: 19.453 time per batch: 9.727\n",
      "Batch 3 device: xla:1 time passed: 19.727 time per batch: 6.576\n",
      "epoch 10, train ll: 0.0412, val ll: 0.0747, cor: 0.8104\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-4\n",
    "model, predictions = train_one(epochs=3, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 10 starting now: 2\n",
      "adding dummy serieses 447\n",
      "dataset train: 17577 valid: 2400 loader train: 176 valid: 24\n",
      "loading model model.b10.f0.v21\n",
      "Batch 5 device: xla:1 time passed: 60.795 time per batch: 12.159\n",
      "Batch 10 device: xla:1 time passed: 88.093 time per batch: 8.809\n",
      "Batch 15 device: xla:1 time passed: 116.097 time per batch: 7.740\n",
      "Batch 20 device: xla:1 time passed: 144.612 time per batch: 7.231\n",
      "Batch 1 device: xla:1 time passed: 19.200 time per batch: 19.200\n",
      "Batch 2 device: xla:1 time passed: 19.364 time per batch: 9.682\n",
      "Batch 3 device: xla:1 time passed: 19.621 time per batch: 6.540\n",
      "epoch 11, train ll: 0.0389, val ll: 0.0625, cor: 0.8353\n",
      "Batch 5 device: xla:1 time passed: 60.298 time per batch: 12.060\n",
      "Batch 10 device: xla:1 time passed: 88.549 time per batch: 8.855\n",
      "Batch 15 device: xla:1 time passed: 115.751 time per batch: 7.717\n",
      "Batch 20 device: xla:1 time passed: 143.797 time per batch: 7.190\n",
      "Batch 1 device: xla:1 time passed: 19.053 time per batch: 19.053\n",
      "Batch 2 device: xla:1 time passed: 19.334 time per batch: 9.667\n",
      "Batch 3 device: xla:1 time passed: 19.530 time per batch: 6.510\n",
      "epoch 12, train ll: 0.0382, val ll: 0.0602, cor: 0.8404\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "learning_rate = 0.002\n",
    "weight_decay = 1e-4\n",
    "model, predictions = train_one(epochs=2, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fold</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>cor</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>train_sz</th>\n",
       "      <th>val_sz</th>\n",
       "      <th>bs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>lr</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245414</td>\n",
       "      <td>0.368845</td>\n",
       "      <td>0.457550</td>\n",
       "      <td>0.514073</td>\n",
       "      <td>0.044114</td>\n",
       "      <td>0.229571</td>\n",
       "      <td>0.092236</td>\n",
       "      <td>0.201881</td>\n",
       "      <td>0.985966</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>160.251015</td>\n",
       "      <td>31.356178</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111711</td>\n",
       "      <td>0.425409</td>\n",
       "      <td>0.517751</td>\n",
       "      <td>0.835668</td>\n",
       "      <td>0.052879</td>\n",
       "      <td>0.300094</td>\n",
       "      <td>0.288142</td>\n",
       "      <td>0.345089</td>\n",
       "      <td>0.320320</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>155.015386</td>\n",
       "      <td>29.556167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.172839</td>\n",
       "      <td>0.584343</td>\n",
       "      <td>0.221234</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.128909</td>\n",
       "      <td>0.129850</td>\n",
       "      <td>0.149150</td>\n",
       "      <td>0.339859</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>154.879500</td>\n",
       "      <td>27.140476</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113210</td>\n",
       "      <td>0.566921</td>\n",
       "      <td>0.309114</td>\n",
       "      <td>1.084074</td>\n",
       "      <td>0.027198</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>0.448893</td>\n",
       "      <td>0.417427</td>\n",
       "      <td>0.414179</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>156.678311</td>\n",
       "      <td>28.908540</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>0.122733</td>\n",
       "      <td>0.687616</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.098498</td>\n",
       "      <td>0.110666</td>\n",
       "      <td>0.111207</td>\n",
       "      <td>0.133571</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>154.641192</td>\n",
       "      <td>26.106112</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.165164</td>\n",
       "      <td>0.171820</td>\n",
       "      <td>0.681821</td>\n",
       "      <td>0.330669</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.091962</td>\n",
       "      <td>0.113049</td>\n",
       "      <td>0.157081</td>\n",
       "      <td>0.161722</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>154.669446</td>\n",
       "      <td>25.977148</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108488</td>\n",
       "      <td>0.175178</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>0.314731</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.149549</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.148018</td>\n",
       "      <td>0.194026</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>155.439858</td>\n",
       "      <td>25.644034</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046603</td>\n",
       "      <td>0.110731</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.190573</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.076381</td>\n",
       "      <td>0.056579</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>0.127090</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>155.412679</td>\n",
       "      <td>26.197765</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043568</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.808988</td>\n",
       "      <td>0.121208</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.055995</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.080520</td>\n",
       "      <td>0.094944</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>154.755002</td>\n",
       "      <td>26.382353</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041196</td>\n",
       "      <td>0.074663</td>\n",
       "      <td>0.810396</td>\n",
       "      <td>0.121195</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>0.035701</td>\n",
       "      <td>0.075549</td>\n",
       "      <td>0.098022</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>154.682014</td>\n",
       "      <td>26.325155</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038925</td>\n",
       "      <td>0.062498</td>\n",
       "      <td>0.835334</td>\n",
       "      <td>0.101864</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.046009</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.062721</td>\n",
       "      <td>0.081797</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>155.851308</td>\n",
       "      <td>26.180528</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038245</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.840434</td>\n",
       "      <td>0.098347</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.044839</td>\n",
       "      <td>0.029394</td>\n",
       "      <td>0.059918</td>\n",
       "      <td>0.077898</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>154.850655</td>\n",
       "      <td>26.117462</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  fold  train_loss  val_loss       cor       any  epidural  \\\n",
       "0       1     0    0.245414  0.368845  0.457550  0.514073  0.044114   \n",
       "1       2     0    0.111711  0.425409  0.517751  0.835668  0.052879   \n",
       "2       3     0    0.092080  0.172839  0.584343  0.221234  0.019638   \n",
       "3       4     0    0.113210  0.566921  0.309114  1.084074  0.027198   \n",
       "4       5     0    0.142060  0.122733  0.687616  0.178393  0.048400   \n",
       "5       6     0    0.165164  0.171820  0.681821  0.330669  0.017591   \n",
       "6       7     0    0.108488  0.175178  0.442986  0.314731  0.015936   \n",
       "7       8     0    0.046603  0.110731  0.735936  0.190573  0.015797   \n",
       "8       9     0    0.043568  0.075700  0.808988  0.121208  0.015132   \n",
       "9      10     0    0.041196  0.074663  0.810396  0.121195  0.014108   \n",
       "10     11     0    0.038925  0.062498  0.835334  0.101864  0.013212   \n",
       "11     12     0    0.038245  0.060230  0.840434  0.098347  0.012866   \n",
       "\n",
       "    intraparenchymal  intraventricular  subarachnoid  subdural  train_sz  \\\n",
       "0           0.229571          0.092236      0.201881  0.985966     17577   \n",
       "1           0.300094          0.288142      0.345089  0.320320     17577   \n",
       "2           0.128909          0.129850      0.149150  0.339859     17577   \n",
       "3           0.492600          0.448893      0.417427  0.414179     17577   \n",
       "4           0.098498          0.110666      0.111207  0.133571     17577   \n",
       "5           0.091962          0.113049      0.157081  0.161722     17577   \n",
       "6           0.149549          0.089253      0.148018  0.194026     17577   \n",
       "7           0.076381          0.056579      0.118125  0.127090     17577   \n",
       "8           0.055995          0.040890      0.080520  0.094944     17577   \n",
       "9           0.056875          0.035701      0.075549  0.098022     17577   \n",
       "10          0.046009          0.030019      0.062721  0.081797     17577   \n",
       "11          0.044839          0.029394      0.059918  0.077898     17577   \n",
       "\n",
       "    val_sz   bs  train_time  valid_time     lr      wd  \n",
       "0     2400  100  160.251015   31.356178  0.100  0.0001  \n",
       "1     2400  100  155.015386   29.556167  0.100  0.0001  \n",
       "2     2400  100  154.879500   27.140476  0.100  0.0001  \n",
       "3     2400  100  156.678311   28.908540  0.100  0.0001  \n",
       "4     2400  100  154.641192   26.106112  0.100  0.0001  \n",
       "5     2400  100  154.669446   25.977148  0.100  0.0001  \n",
       "6     2400  100  155.439858   25.644034  0.100  0.0001  \n",
       "7     2400  100  155.412679   26.197765  0.010  0.0001  \n",
       "8     2400  100  154.755002   26.382353  0.010  0.0001  \n",
       "9     2400  100  154.682014   26.325155  0.010  0.0001  \n",
       "10    2400  100  155.851308   26.180528  0.002  0.0001  \n",
       "11    2400  100  154.850655   26.117462  0.002  0.0001  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(PATH_WORK/'stats.f{}.v{}'.format(0,VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07372823, 0.00197059, 0.02537991, 0.01791105, 0.02420867,\n",
       "       0.03091804], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fef8fd930b8>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions.mean(0)[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one(bs = 100):\n",
    "    st = time.time()\n",
    "\n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch)\n",
    "\n",
    "    model = TabularModel(n_cont = len(meta_cols), out_sz=360, layers=[500,200], ps=[0.5,0.5], bn_final=True)\n",
    "    \n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if model_file_name is not None:\n",
    "        print('loading model', model_file_name)\n",
    "        state_dict = torch.load(PATH_WORK/'models'/model_file_name)\n",
    "        model.load_state_dict(state_dict)\n",
    "    \n",
    "    if (not CLOUD) or CLOUD_SINGLE:\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        model_parallel = dp.DataParallel(model, device_ids=devices)\n",
    "\n",
    "    setSeeds(SEED + cur_epoch)\n",
    "\n",
    "    tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test', bs=bs)\n",
    "    loader_tst = D.DataLoader(tst_ds, num_workers=8 if CLOUD else 0, batch_size=bs, shuffle=False)\n",
    "    print('dataset test:', len(tst_ds), 'loader test:', len(loader_tst))\n",
    "\n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        results = model_parallel(test_loop_fn, loader_tst)\n",
    "        predictions = np.concatenate([results[i][0] for i in range(MAX_DEVICES)])\n",
    "        indices = np.concatenate([results[i][1] for i in range(MAX_DEVICES)])\n",
    "        offsets = np.concatenate([results[i][2] for i in range(MAX_DEVICES)])\n",
    "    else:\n",
    "        predictions, indices, offsets = test_loop_fn(model, loader_tst, device)\n",
    "\n",
    "    predictions = predictions[np.argsort(indices)]\n",
    "    offsets = offsets[np.argsort(indices)]\n",
    "    assert len(predictions) == len(test_md.SeriesInstanceUID.unique())\n",
    "    assert np.all(indices[np.argsort(indices)] == np.array(range(len(predictions))))\n",
    "    \n",
    "    print('test processing time:', time.time() - st)\n",
    "    \n",
    "    return predictions, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 12\n",
      "loading model model.b12.f0.v21\n",
      "adding dummy serieses 186\n",
      "dataset test: 2400 loader test: 24\n",
      "test processing time: 30.5324866771698\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "predictions, offsets = inference_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07360154, 0.00248027, 0.02532088, 0.01589688, 0.02495101,\n",
       "       0.03034116], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.087846, 0.004184, 0.029325, 0.030316, 0.041098, 0.029221], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "for i, series_id in enumerate(test_md.SeriesInstanceUID.unique()):\n",
    "    df = test_md.loc[test_md.SeriesInstanceUID == series_id]\n",
    "    id_column = [a + '_' + b for a in df.SOPInstanceUID for b in all_ich]\n",
    "    assert (offsets[i] + len(df)) <= 60\n",
    "    data_sub = pd.DataFrame({'ID':np.array(id_column), \n",
    "                             'Label':predictions[i,offsets[i]:(offsets[i] + len(df))].reshape(-1)})\n",
    "    sub = pd.concat([sub,data_sub], axis=0, sort=False)\n",
    "\n",
    "sub = sub.reset_index(drop=True)\n",
    "\n",
    "assert len(sub) == 6*len(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12431878596544266"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission_061.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13475628267250275"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794069716228754"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/bin/kaggle\", line 10, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/kaggle/cli.py\", line 51, in main\r\n",
      "    out = args.func(**command_args)\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/kaggle/api/kaggle_api_extended.py\", line 545, in competition_submit_cli\r\n",
      "    competition, quiet)\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/kaggle/api/kaggle_api_extended.py\", line 496, in competition_submit\r\n",
      "    content_length=os.path.getsize(file_name),\r\n",
      "  File \"/anaconda3/envs/torch-xla-nightly/lib/python3.6/genericpath.py\", line 50, in getsize\r\n",
      "    return os.stat(filename).st_size\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'sub.csv'\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit rsna-intracranial-hemorrhage-detection -f sub.csv -m \"TPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
