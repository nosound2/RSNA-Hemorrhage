{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD = True\n",
    "CLOUD_SINGLE = False\n",
    "\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from matplotlib import patches, patheffects\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import pdb\n",
    "\n",
    "import scipy as sp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "if not CLOUD:\n",
    "    torch.cuda.current_device()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as M\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if CLOUD:\n",
    "    PATH = Path('/home/zahar_chikishev')\n",
    "    PATH_WORK = Path('/home/zahar_chikishev/running')\n",
    "else:\n",
    "    PATH = Path('C:/StudioProjects/Hemorrhage')\n",
    "    PATH_WORK = Path('C:/StudioProjects/Hemorrhage/running')\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import seaborn as sn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "all_ich = ['any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural']\n",
    "class_weights = 6.0*np.array([2,1,1,1,1,1])/7.0\n",
    "\n",
    "if CLOUD:\n",
    "    import torch_xla\n",
    "    import torch_xla.distributed.data_parallel as dp\n",
    "    import torch_xla.utils as xu\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    \n",
    "    from typing import Collection\n",
    "\n",
    "VERSION = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLOUD:\n",
    "    device = xm.xla_device()\n",
    "    #device = 'cpu'\n",
    "    MAX_DEVICES = 1 if CLOUD_SINGLE else 8\n",
    "else:\n",
    "    device = 'cuda'\n",
    "    #device = 'cpu'\n",
    "    MAX_DEVICES = 1\n",
    "\n",
    "if CLOUD and (not CLOUD_SINGLE):\n",
    "    devices = xm.get_xla_supported_devices(max_devices=MAX_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2351\n",
    "\n",
    "def setSeeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "setSeeds(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate torch-xla-nightly\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;$10.0.101.2:8470\"\n",
    "#git init\n",
    "#git remote add origin https://github.com/nosound2/RSNA-Hemorrhage\n",
    "#git pull origin master\n",
    "#git config remote.origin.push HEAD\n",
    "#gcloud config set compute/zone europe-west4-a\n",
    "#gcloud auth login\n",
    "#gcloud config set project endless-empire-239015\n",
    "#pip install kaggle\n",
    "#mkdir .kaggle\n",
    "#gsutil cp gs://recursion-double-strand/kaggle-keys/kaggle.json ~/.kaggle\n",
    "#chmod 600 /home/zahar_chikishev/.kaggle/kaggle.json\n",
    "#kaggle competitions download rsna-intracranial-hemorrhage-detection -f stage_1_train.csv\n",
    "#sudo apt install unzip\n",
    "#unzip stage_1_train.csv.zip\n",
    "#kaggle kernels output xhlulu/rsna-generate-metadata-csvs -p .\n",
    "#gsutil cp gs://rsna-hemorrhage/yuvals/* .\n",
    "\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;10.0.101.2:8470\"; conda activate torch-xla-nightly; jupyter notebook\n",
    "\n",
    "# 35.204.242.164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat, cols_float = pickle.load(open(PATH_WORK/'covs','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_WORK/'indexes_file.pkl'\n",
    "all_idx, train_ids, val_ids = pickle.load(open(filename,'rb'))\n",
    "\n",
    "train_md = pd.read_csv(PATH_WORK/'train_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "train_md['img_id'] = train_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = train_md.loc[train_md.img_id.isin(all_idx[train_ids])]\n",
    "val_data = train_md.loc[train_md.img_id.isin(all_idx[val_ids])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trn_data.SeriesInstanceUID.unique()) + len(val_data.SeriesInstanceUID.unique()) \\\n",
    "    == len(train_md.SeriesInstanceUID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trn_data.PatientID.unique()) + len(val_data.PatientID.unique()) \\\n",
    "    >= len(train_md.PatientID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_df = pd.DataFrame(all_idx, columns = ['img_id'])\n",
    "ids_df = ids_df.join(train_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "assert len(ids_df.SeriesInstanceUID.unique()) == 19530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md = pd.read_csv(PATH_WORK/'test_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "test_md['img_id'] = test_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_WORK/'test_indexes.pkl'\n",
    "test_ids = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_df = pd.DataFrame(test_ids, columns = ['img_id'])\n",
    "test_ids_df = test_ids_df.join(test_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "assert len(test_ids_df.SeriesInstanceUID.unique()) == 2214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BitsStored</th>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.494393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PixelRepresentation</th>\n",
       "      <td>0.039672</td>\n",
       "      <td>0.489732</td>\n",
       "      <td>0.491567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>0.023441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowCenter_1_NAN</th>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.494393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_0</th>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>0.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_1</th>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_3</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_4</th>\n",
       "      <td>0.948793</td>\n",
       "      <td>0.973095</td>\n",
       "      <td>0.972877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageOrientationPatient_5</th>\n",
       "      <td>-0.285991</td>\n",
       "      <td>-0.154848</td>\n",
       "      <td>-0.156091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImagePositionPatient_0</th>\n",
       "      <td>-125.024699</td>\n",
       "      <td>-122.681411</td>\n",
       "      <td>-122.742795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImagePositionPatient_1</th>\n",
       "      <td>-113.426820</td>\n",
       "      <td>-59.968123</td>\n",
       "      <td>-60.116496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImagePositionPatient_2</th>\n",
       "      <td>106.356928</td>\n",
       "      <td>174.080145</td>\n",
       "      <td>174.857098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PixelSpacing_0</th>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.478824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PixelSpacing_1</th>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.478824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowCenter_0</th>\n",
       "      <td>30.759692</td>\n",
       "      <td>36.087277</td>\n",
       "      <td>35.437203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowCenter_1</th>\n",
       "      <td>37.988691</td>\n",
       "      <td>38.023234</td>\n",
       "      <td>37.974277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_max</th>\n",
       "      <td>192.955649</td>\n",
       "      <td>259.120051</td>\n",
       "      <td>259.991850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_min</th>\n",
       "      <td>31.319018</td>\n",
       "      <td>93.610421</td>\n",
       "      <td>94.324693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_size</th>\n",
       "      <td>36.440754</td>\n",
       "      <td>35.257130</td>\n",
       "      <td>35.150762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_idx</th>\n",
       "      <td>17.720377</td>\n",
       "      <td>17.128472</td>\n",
       "      <td>17.075381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_inc</th>\n",
       "      <td>4.522789</td>\n",
       "      <td>4.745734</td>\n",
       "      <td>4.763764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_range</th>\n",
       "      <td>161.636632</td>\n",
       "      <td>165.509630</td>\n",
       "      <td>165.667157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_rel</th>\n",
       "      <td>0.463977</td>\n",
       "      <td>0.485689</td>\n",
       "      <td>0.485599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_zeros</th>\n",
       "      <td>0.157375</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>0.020392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_inc_rng</th>\n",
       "      <td>1.915072</td>\n",
       "      <td>1.374015</td>\n",
       "      <td>1.376714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0           1           2\n",
       "BitsStored                   0.040435    0.493129    0.494393\n",
       "PixelRepresentation          0.039672    0.489732    0.491567\n",
       "RescaleIntercept             0.001884    0.025994    0.023441\n",
       "WindowCenter_1_NAN           0.040435    0.493129    0.494393\n",
       "ImageOrientationPatient_0    0.999491    0.999703    0.999969\n",
       "ImageOrientationPatient_1   -0.000509    0.000072    0.000118\n",
       "ImageOrientationPatient_2    0.000000    0.000015   -0.000118\n",
       "ImageOrientationPatient_3    0.000495   -0.000066   -0.000132\n",
       "ImageOrientationPatient_4    0.948793    0.973095    0.972877\n",
       "ImageOrientationPatient_5   -0.285991   -0.154848   -0.156091\n",
       "ImagePositionPatient_0    -125.024699 -122.681411 -122.742795\n",
       "ImagePositionPatient_1    -113.426820  -59.968123  -60.116496\n",
       "ImagePositionPatient_2     106.356928  174.080145  174.857098\n",
       "PixelSpacing_0               0.487562    0.478761    0.478824\n",
       "PixelSpacing_1               0.487562    0.478761    0.478824\n",
       "WindowCenter_0              30.759692   36.087277   35.437203\n",
       "WindowCenter_1              37.988691   38.023234   37.974277\n",
       "pos_max                    192.955649  259.120051  259.991850\n",
       "pos_min                     31.319018   93.610421   94.324693\n",
       "pos_size                    36.440754   35.257130   35.150762\n",
       "pos_idx                     17.720377   17.128472   17.075381\n",
       "pos_inc                      4.522789    4.745734    4.763764\n",
       "pos_range                  161.636632  165.509630  165.667157\n",
       "pos_rel                      0.463977    0.485689    0.485599\n",
       "pos_zeros                    0.157375    0.065163    0.020392\n",
       "pos_inc_rng                  1.915072    1.374015    1.376714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([test_md[cols_cat + cols_float].mean(0),\n",
    "           trn_data[cols_cat + cols_float].mean(0),\n",
    "           val_data[cols_cat + cols_float].mean(0)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['pos_size','pos_idx','pos_inc','pos_rel','pos_zeros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = cols_cat + cols_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = PATH_WORK/'model_Densenet161_3_vehrsion_basic_classifier_type_features_train_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/train/{}'.format(series_id),'wb'))\n",
    "\n",
    "\n",
    "    filename = PATH_WORK/'model_Densenet161_3_vehrsion_basic_classifier_type_features_test_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(test_ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(test_ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/test/{}'.format(series_id),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = PATH_WORK/'features/densenet161_v3/train/ID_000a935543'\n",
    "#feats1 = pickle.load(open(path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_black = '006d4432e'\n",
    "\n",
    "path = PATH_WORK/'features/densenet161_v3/train/ID_992b567eb6'\n",
    "black_feats = pickle.load(open(path,'rb'))[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA_DataSet(D.Dataset):\n",
    "    def __init__(self, metadata, ids_df, mode='train', bs=None):\n",
    "        \n",
    "        super(RSNA_DataSet, self).__init__()\n",
    "        \n",
    "        md = metadata.copy()\n",
    "        md = md.reset_index(drop=True)\n",
    "        series = md.SeriesInstanceUID.unique()\n",
    "        \n",
    "        samples_add = 0\n",
    "        if mode != 'train':\n",
    "            batch_num = -((-len(series))//(bs*MAX_DEVICES))\n",
    "            samples_add = batch_num*bs*MAX_DEVICES - len(series)\n",
    "            print('adding dummy serieses', samples_add)\n",
    "        \n",
    "        #self.records = df.to_records(index=False)\n",
    "        self.mode = mode\n",
    "        self.real = np.concatenate([np.repeat(True,len(series)),np.repeat(False,samples_add)])\n",
    "        self.series = np.concatenate([series,np.repeat(series[0],samples_add)])\n",
    "        self.metadata = md\n",
    "        self.ids_df = ids_df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        series_id = self.series[index]\n",
    "        df = self.metadata.loc[self.metadata.SeriesInstanceUID == series_id].reset_index(drop=True)\n",
    "        \n",
    "        folder = 'test' if self.mode == 'test' else 'train'\n",
    "        path = PATH_WORK/'features/densenet161_v3/{}/{}'.format(folder,series_id)\n",
    "        feats = pickle.load(open(path,'rb'))\n",
    "        ids_df_sub = self.ids_df.loc[self.ids_df.SeriesInstanceUID.values == series_id]\n",
    "        \n",
    "        if feats.shape[0] > len(df):\n",
    "            mask_dup = ~ids_df_sub.img_id.duplicated().values\n",
    "            ids_df_sub = ids_df_sub.loc[mask_dup]\n",
    "            feats = feats[torch.BoolTensor(mask_dup)]\n",
    "        \n",
    "        assert feats.shape[0] == len(df)\n",
    "        assert len(ids_df_sub) == len(df)\n",
    "        assert np.all(ids_df_sub.img_id.isin(df.img_id).values)\n",
    "        order = np.argsort(ids_df_sub.pos_idx.values)\n",
    "        assert np.all(ids_df_sub.img_id.values[order] == df.img_id.values)\n",
    "        feats = feats[torch.LongTensor(order)]\n",
    "        \n",
    "        feats = torch.cat([feats, torch.Tensor(df[meta_cols].values)], dim=1)\n",
    "        target = torch.Tensor(df[all_ich].values)\n",
    "        \n",
    "        offset = np.random.randint(0, 61 - feats.shape[0])\n",
    "        if offset > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.head(1)[meta_cols].values).squeeze()])\n",
    "            feats = torch.cat([dummy_row.repeat(offset,1), feats], dim=0)\n",
    "            target = torch.cat([torch.zeros((offset, len(all_ich))), target], dim=0)\n",
    "        if (60 - len(df) - offset) > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.tail(1)[meta_cols].values).squeeze()])\n",
    "            feats = torch.cat([feats, dummy_row.repeat(60 - len(df) - offset,1)], dim=0)\n",
    "            target = torch.cat([target, torch.zeros((60 - len(df) - offset, len(all_ich)))], dim=0)\n",
    "        \n",
    "        assert feats.shape[0] == 60\n",
    "        assert target.shape[0] == 60\n",
    "        \n",
    "        feats = feats.transpose(1,0)\n",
    "        \n",
    "        idx = index\n",
    "        if not self.real[index]: idx = -1\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return feats, target\n",
    "        else:\n",
    "            return feats, target, idx, offset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.series) if not DATA_SMALL else int(0.01*len(self.series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(nn.Module):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "\n",
    "class BCEWithLogitsLoss(_Loss):\n",
    "    __constants__ = ['weight', 'pos_weight', 'reduction']\n",
    "\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None):\n",
    "        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.register_buffer('pos_weight', pos_weight)\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        #((torch.log(1+torch.exp(input)) - target*input)*self.weight).mean()\n",
    "        return F.binary_cross_entropy_with_logits(input.squeeze(), target,\n",
    "                                                  self.weight,\n",
    "                                                  pos_weight=self.pos_weight,\n",
    "                                                  reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatProduct(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(FeatProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = F.linear(x, self.weight)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_drop_lin(n_in:int, n_out:int, bn:bool=True, p:float=0., actn=None):\n",
    "    \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n",
    "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "    if p != 0: layers.append(nn.Dropout(p))\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if actn is not None: layers.append(actn)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, n_cont:int, out_sz:int, layers, ps=None,\n",
    "                 emb_drop:float=0., use_bn:bool=True, bn_final:bool=False, feat_sz=2208, fc_drop_p=0.3):\n",
    "        super().__init__()\n",
    "        self.bn_cont = nn.BatchNorm1d(feat_sz + n_cont)\n",
    "        self.n_cont = n_cont\n",
    "        sizes = self.get_sizes(layers, out_sz)\n",
    "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.feat_product = FeatProduct(feat_sz + n_cont, 20)\n",
    "        self.fc_drop = nn.Dropout(p=fc_drop_p)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def get_sizes(self, layers, out_sz):\n",
    "        return [1200] + layers + [out_sz]\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.bn_cont(x)\n",
    "        x = x.transpose(1,2)\n",
    "        #x = self.fc_drop(x)\n",
    "        x = self.feat_product(x)\n",
    "        #x = self.relu(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x = self.layers(x)\n",
    "        x = x.reshape(x.shape[0],60,6)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentBatch(fold=0):\n",
    "    sel_batch = None\n",
    "    for filename in os.listdir(PATH_WORK/'models'):\n",
    "        splits = filename.split('.')\n",
    "        if int(splits[2][1]) != fold: continue\n",
    "        if int(splits[3][1:]) != VERSION: continue\n",
    "        if sel_batch is None:\n",
    "            sel_batch = int(splits[1][1:])\n",
    "        else:\n",
    "            sel_batch = max(sel_batch, int(splits[1][1:]))\n",
    "    return sel_batch\n",
    "\n",
    "def modelFileName(fold=0, batch = 1, return_last = False, return_next = False):\n",
    "    sel_batch = batch\n",
    "    if return_last or return_next:\n",
    "        sel_batch = getCurrentBatch(fold)\n",
    "        if return_last and sel_batch is None:\n",
    "            return None\n",
    "        if return_next:\n",
    "            if sel_batch is None: sel_batch = 1\n",
    "            else: sel_batch += 1\n",
    "    \n",
    "    return 'model.b{}.f{}.v{}'.format(sel_batch, fold, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 5\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "        dataset = loader._loader._loader.dataset\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 10\n",
    "        OUT_TIME = 1\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "        dataset = loader.dataset\n",
    "    \n",
    "    #print('Start training {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss(weight = torch.Tensor(class_weights).to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=(0.9, 0.99))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    if CLOUD:\n",
    "        tracker = xm.RateTracker()\n",
    "    \n",
    "    st = time.time()\n",
    "    for i, (x, y) in generator:\n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        if CLOUD or CLOUD_SINGLE:\n",
    "            xm.optimizer_step(optimizer)\n",
    "            if CLOUD_SINGLE:\n",
    "                xm.mark_step()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        \n",
    "        if CLOUD:\n",
    "            tracker.add(len(y))\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            #print(torch_xla._XLAC._xla_metrics_report())\n",
    "            print('Batch {} device: {} time passed: {:.3f} time per batch: {:.3f}'\n",
    "                .format(i+1, device, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del loss, output, y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 1\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 10\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "    \n",
    "    #print('Start validating {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    indices = []\n",
    "    offsets = []\n",
    "    \n",
    "    for i, (x, y, idx, offset) in generator:\n",
    "        \n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "        \n",
    "        output = torch.sigmoid(model(x))\n",
    "        \n",
    "        mask = (idx >= 0)\n",
    "        results.append(output[mask].cpu().detach().numpy())\n",
    "        indices.append(idx[mask].cpu().detach().numpy())\n",
    "        offsets.append(offset[mask].cpu().detach().numpy())\n",
    "                \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            print('Batch {} device: {} time passed: {:.3f} time per batch: {:.3f}'\n",
    "                  .format(i+1, device, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del output, y, x, idx, offset\n",
    "    \n",
    "    results = np.concatenate(results)\n",
    "    indices = np.concatenate(indices)\n",
    "    offsets = np.concatenate(offsets)\n",
    "    \n",
    "    return results, indices, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 100\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 10\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "    \n",
    "    #print('Start testing {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    indices = []\n",
    "    \n",
    "    for i, (x, y, idx) in generator:\n",
    "        \n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "        \n",
    "        output = torch.sigmoid(model(x))\n",
    "        \n",
    "        mask = (idx >= 0)\n",
    "        results.append(output[mask].cpu().detach().numpy())\n",
    "        indices.append(idx[mask].cpu().detach().numpy())\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            print('B{} -> time passed: {:.3f} time per batch: {:.3f}'.format(i+1, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del output, x, idx\n",
    "    \n",
    "    return np.concatenate(results), np.concatenate(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(weight=None, load_model=True, epochs=1, bs=100):\n",
    "    \n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch, 'starting now:', epochs)\n",
    "    \n",
    "    setSeeds(SEED + cur_epoch)\n",
    "    \n",
    "    trn_ds = RSNA_DataSet(trn_data, ids_df, mode='train', bs=bs)\n",
    "    loader = D.DataLoader(trn_ds, num_workers=16 if CLOUD else 0, batch_size=bs, shuffle=True)\n",
    "    val_ds = RSNA_DataSet(val_data, ids_df, mode='valid', bs=bs)\n",
    "    loader_val = D.DataLoader(val_ds, num_workers=16 if CLOUD else 0, batch_size=bs, shuffle=True)\n",
    "    #tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test')\n",
    "    print('dataset train:', len(trn_ds), 'valid:', len(val_ds), 'loader train:', len(loader), 'valid:', len(loader_val))\n",
    "    \n",
    "    model = TabularModel(n_cont = len(meta_cols), out_sz=360, layers=[500,200], ps=[0.5,0.5], bn_final=True)\n",
    "    if (not CLOUD) or CLOUD_SINGLE:\n",
    "        model = model.to(device)\n",
    "    \n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if model_file_name is not None:\n",
    "        print('loading model', model_file_name)\n",
    "        state_dict = torch.load(PATH_WORK/'models'/model_file_name)\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print('starting from scratch')\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        model_parallel = dp.DataParallel(model, device_ids=devices)\n",
    "    \n",
    "    for i in range(cur_epoch+1, cur_epoch+epochs+1):\n",
    "        st = time.time()\n",
    "\n",
    "        if CLOUD and (not CLOUD_SINGLE):\n",
    "            results = model_parallel(train_loop_fn, loader)\n",
    "            state_dict = model_parallel._models[0].state_dict()\n",
    "        else:\n",
    "            results = train_loop_fn(model, loader, device)\n",
    "            state_dict = model.state_dict()\n",
    "        \n",
    "        train_time = time.time()-st\n",
    "        \n",
    "        model_file_name = modelFileName(return_next=True)\n",
    "        if not DATA_SMALL:\n",
    "            torch.save(state_dict, PATH_WORK/'models'/model_file_name)\n",
    "        \n",
    "        st = time.time()\n",
    "        if CLOUD and (not CLOUD_SINGLE):\n",
    "            results = model_parallel(val_loop_fn, loader_val)\n",
    "            predictions = np.concatenate([results[i][0] for i in range(MAX_DEVICES)])\n",
    "            indices = np.concatenate([results[i][1] for i in range(MAX_DEVICES)])\n",
    "            offsets = np.concatenate([results[i][2] for i in range(MAX_DEVICES)])\n",
    "        else:\n",
    "            predictions, indices, offsets = val_loop_fn(model, loader_val, device)\n",
    "        \n",
    "        predictions = predictions[np.argsort(indices)]\n",
    "        offsets = offsets[np.argsort(indices)]\n",
    "        assert len(predictions) == len(val_data.SeriesInstanceUID.unique())\n",
    "        assert len(predictions) == len(offsets)\n",
    "        assert np.all(indices[np.argsort(indices)] == np.array(range(len(predictions))))\n",
    "        \n",
    "        valid_time = time.time()-st\n",
    "        \n",
    "        loc_data = val_data.copy()\n",
    "        if DATA_SMALL:\n",
    "            val_sz = int(0.01*len(val_data.SeriesInstanceUID.unique()))\n",
    "            val_series = val_data.SeriesInstanceUID.unique()[:val_sz]\n",
    "            loc_data = loc_data.loc[val_data.SeriesInstanceUID.isin(val_series)]\n",
    "        \n",
    "        val_results = np.zeros((len(loc_data),6))\n",
    "        for k, series in enumerate(loc_data.SeriesInstanceUID.unique()):\n",
    "            mask = loc_data.SeriesInstanceUID == series\n",
    "            assert (offsets[k] + mask.sum()) <= 60\n",
    "            val_results[mask] = predictions[k,offsets[k]:(offsets[k] + mask.sum())]\n",
    "        \n",
    "        lls = [log_loss(loc_data[all_ich[k]].values, val_results[:,k], eps=1e-8, labels=[0,1]) for k in range(6)]\n",
    "        ll = (class_weights * np.array(lls)).mean()\n",
    "        cor = np.corrcoef(loc_data.loc[:,all_ich].values.reshape(-1), val_results.reshape(-1))[0,1]\n",
    "\n",
    "        print('epoch {}, val ll: {:.4f}, cor: {:.4f}'.format(i, ll, cor))\n",
    "        valid_time = time.time()-st\n",
    "\n",
    "        epoch_stats = pd.DataFrame([[i, 0, ll, cor, lls[0], lls[1], lls[2], lls[3], lls[4], lls[5],\n",
    "                                     len(trn_ds), len(val_ds), bs, train_time, valid_time,\n",
    "                                     learning_rate, weight_decay]], \n",
    "                                   columns = \n",
    "                                    ['epoch','fold','loss','cor',\n",
    "                                     'any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural',\n",
    "                                     'train_sz','val_sz','bs','train_time','valid_time','lr','wd'\n",
    "                                     ])\n",
    "\n",
    "        stats_filename = PATH_WORK/'stats.f{}.v{}'.format(0,VERSION)\n",
    "        if stats_filename.is_file():\n",
    "            epoch_stats = pd.concat([pd.read_csv(stats_filename), epoch_stats], sort=False)\n",
    "        #if not DATA_SMALL:\n",
    "        epoch_stats.to_csv(stats_filename, index=False)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 22 device: xla:1 time passed: 277.972 time per batch: 12.635 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 209.280 time per batch: 9.513  - 16 cores / 16 workers\n",
    "#Batch 22 device: xla:1 time passed: 213.209 time per batch: 9.691  - 16 cores / 32 workers\n",
    "#Batch 22 device: xla:1 time passed: 275.780 time per batch: 12.535 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 208.826 time per batch: 9.492  - 16 cores / 16 workers\n",
    "#Batch 22 device: xla:1 time passed: 245.750 time per batch: 11.170 - 16 cores / 12 workers\n",
    "#Batch 22 device: xla:1 time passed: 374.876 time per batch: 17.040 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 400.221 time per batch: 18.192 - 8 cores / 8 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixup\n",
    "# position randomization\n",
    "# one-cycle\n",
    "# fill empty with all black features, and meta of the last\n",
    "\n",
    "# Yuval: zoom in, squish, perspective wraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 2 starting now: 2\n",
      "adding dummy serieses 447\n",
      "dataset train: 17577 valid: 2400 loader train: 176 valid: 24\n",
      "loading model model.b2.f0.v9\n",
      "Batch 5 device: xla:1 time passed: 84.205 time per batch: 16.841\n",
      "Batch 10 device: xla:1 time passed: 124.015 time per batch: 12.402\n",
      "Batch 15 device: xla:1 time passed: 164.572 time per batch: 10.971\n",
      "Batch 20 device: xla:1 time passed: 204.773 time per batch: 10.239\n",
      "Batch 1 device: xla:1 time passed: 21.843 time per batch: 21.843\n",
      "Batch 2 device: xla:1 time passed: 22.013 time per batch: 11.007\n",
      "Batch 3 device: xla:1 time passed: 22.222 time per batch: 7.407\n",
      "epoch 3, val ll: 0.2605, cor: 0.0746\n",
      "Batch 5 device: xla:1 time passed: 83.499 time per batch: 16.700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9a98cd4f4eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-2413e8dd4542>\u001b[0m in \u001b[0;36mtrain_one\u001b[0;34m(weight, load_model, epochs, bs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCLOUD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mCLOUD_SINGLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loop_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_parallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/torch-xla-nightly/lib/python3.6/site-packages/torch_xla/distributed/data_parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, loop_fn, loader, fixed_batch_size, batchdim)\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0mpara_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/torch-xla-nightly/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/torch-xla-nightly/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "learning_rate = 0.5\n",
    "weight_decay = 1e-4\n",
    "model, predictions = train_one(epochs=2, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fold</th>\n",
       "      <th>loss</th>\n",
       "      <th>cor</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>train_sz</th>\n",
       "      <th>val_sz</th>\n",
       "      <th>bs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>lr</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259910</td>\n",
       "      <td>0.081396</td>\n",
       "      <td>0.385425</td>\n",
       "      <td>0.110771</td>\n",
       "      <td>0.236980</td>\n",
       "      <td>0.209428</td>\n",
       "      <td>0.229393</td>\n",
       "      <td>0.261946</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>221.740387</td>\n",
       "      <td>40.232106</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238176</td>\n",
       "      <td>0.313776</td>\n",
       "      <td>0.347896</td>\n",
       "      <td>0.109068</td>\n",
       "      <td>0.219997</td>\n",
       "      <td>0.188093</td>\n",
       "      <td>0.210198</td>\n",
       "      <td>0.244083</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>222.574692</td>\n",
       "      <td>39.632468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  fold      loss       cor       any  epidural  intraparenchymal  \\\n",
       "0      1     0  0.259910  0.081396  0.385425  0.110771          0.236980   \n",
       "1      2     0  0.238176  0.313776  0.347896  0.109068          0.219997   \n",
       "\n",
       "   intraventricular  subarachnoid  subdural  train_sz  val_sz   bs  \\\n",
       "0          0.209428      0.229393  0.261946     17577    2400  100   \n",
       "1          0.188093      0.210198  0.244083     17577    2400  100   \n",
       "\n",
       "   train_time  valid_time   lr      wd  \n",
       "0  221.740387   40.232106  0.5  0.0001  \n",
       "1  222.574692   39.632468  0.5  0.0001  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(PATH_WORK/'stats.f{}.v{}'.format(0,VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.540385  , 0.30819952, 0.43251818, 0.3530488 , 0.43293434,\n",
       "       0.41421852], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x151b4944358>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions.mean(0)[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one(bs = 100):\n",
    "    st = time.time()\n",
    "\n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch)\n",
    "\n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if model_file_name is not None:\n",
    "        print('loading model', model_file_name)\n",
    "        state_dict = torch.load(PATH_WORK/'models'/model_file_name)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    setSeeds(SEED + cur_epoch)\n",
    "\n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        model_parallel = dp.DataParallel(model, device_ids=devices)\n",
    "\n",
    "    tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test', bs=bs)\n",
    "    loader_tst = D.DataLoader(tst_ds, num_workers=8 if CLOUD else 0, batch_size=bs, shuffle=False)\n",
    "    print('dataset test:', len(tst_ds), 'loader test:', len(loader_tst))\n",
    "\n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        results = model_parallel(test_loop_fn, loader_tst)\n",
    "        predictions, indices = np.stack(results)\n",
    "    else:\n",
    "        predictions, indices = test_loop_fn(model, loader_tst, device)\n",
    "\n",
    "    predictions = predictions[np.argsort(indices)]\n",
    "    assert len(predictions) == len(test_md.SeriesInstanceUID.unique())\n",
    "    assert np.all(indices[np.argsort(indices)] == np.array(range(len(predictions))))\n",
    "    \n",
    "    print('test processing time:', time.time() - st)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 2\n",
      "loading model model.b2.f0.v3\n",
      "adding test serieses 86\n",
      "dataset test: 2300 loader test: 23\n",
      "B10 -> time passed: 17.695 time per batch: 1.769\n",
      "B20 -> time passed: 35.067 time per batch: 1.753\n",
      "test processing time: 40.454989433288574\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "predictions = inference_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40144655, 0.42193368, 0.3991171 , 0.3763159 , 0.45404765,\n",
       "       0.4236126 ], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.087846, 0.004184, 0.029325, 0.030316, 0.041098, 0.029221], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "for i, series_id in enumerate(test_md.SeriesInstanceUID.unique()):\n",
    "    df = test_md.loc[test_md.SeriesInstanceUID == series_id]\n",
    "    id_column = [a + '_' + b for a in df.SOPInstanceUID for b in all_ich]\n",
    "    data_sub = pd.DataFrame({'ID':np.array(id_column), 'Label':predictions[i,:len(df)].reshape(-1)})\n",
    "    sub = pd.concat([sub,data_sub], axis=0, sort=False)\n",
    "\n",
    "sub = sub.reset_index(drop=True)\n",
    "\n",
    "assert len(sub) == 6*len(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40976402"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1471214"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1255341744607709"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499705853123557"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
