{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate torch-xla-nightly\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;$10.0.101.2:8470\"\n",
    "#git init\n",
    "#git remote add origin https://github.com/nosound2/RSNA-Hemorrhage\n",
    "#git pull origin master\n",
    "#git config remote.origin.push HEAD\n",
    "#gcloud config set compute/zone europe-west4-a\n",
    "#gcloud auth login\n",
    "#gcloud config set project endless-empire-239015\n",
    "#pip install kaggle\n",
    "#mkdir .kaggle\n",
    "#gsutil cp gs://recursion-double-strand/kaggle-keys/kaggle.json ~/.kaggle\n",
    "#chmod 600 /home/zahar_chikishev/.kaggle/kaggle.json\n",
    "#kaggle competitions download rsna-intracranial-hemorrhage-detection -f stage_1_train.csv\n",
    "#sudo apt install unzip\n",
    "#unzip stage_1_train.csv.zip\n",
    "#kaggle kernels output xhlulu/rsna-generate-metadata-csvs -p .\n",
    "#gsutil cp gs://rsna-hemorrhage/yuvals/* .\n",
    "\n",
    "#export XRT_TPU_CONFIG=\"tpu_worker;0;10.0.101.2:8470\"; conda activate torch-xla-nightly; jupyter notebook\n",
    "\n",
    "# 35.204.242.164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from matplotlib import patches, patheffects\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import pdb\n",
    "\n",
    "import scipy as sp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "CLOUD = not torch.cuda.is_available()\n",
    "CLOUD_SINGLE = False\n",
    "\n",
    "if not CLOUD:\n",
    "    torch.cuda.current_device()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as M\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if CLOUD:\n",
    "    PATH = Path('/home/zahar_chikishev')\n",
    "    PATH_WORK = Path('/home/zahar_chikishev/running')\n",
    "else:\n",
    "    PATH = Path('C:/StudioProjects/Hemorrhage')\n",
    "    PATH_WORK = Path('C:/StudioProjects/Hemorrhage/running')\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import seaborn as sn\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "all_ich = ['any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural']\n",
    "class_weights = 6.0*np.array([2,1,1,1,1,1])/7.0\n",
    "\n",
    "if CLOUD:\n",
    "    import torch_xla\n",
    "    import torch_xla.distributed.data_parallel as dp\n",
    "    import torch_xla.utils as xu\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    \n",
    "    from typing import Collection\n",
    "\n",
    "VERSION = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLOUD:\n",
    "    device = xm.xla_device()\n",
    "    #device = 'cpu'\n",
    "    MAX_DEVICES = 1 if CLOUD_SINGLE else 8\n",
    "    bs = 100\n",
    "else:\n",
    "    device = 'cuda'\n",
    "    #device = 'cpu'\n",
    "    MAX_DEVICES = 1\n",
    "    bs = 10\n",
    "\n",
    "if CLOUD and (not CLOUD_SINGLE):\n",
    "    devices = xm.get_xla_supported_devices(max_devices=MAX_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2351\n",
    "\n",
    "def setSeeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "setSeeds(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat, cols_float = pickle.load(open(PATH_WORK/'covs','rb'))\n",
    "meta_cols = cols_cat + cols_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = PATH_WORK/'indexes_file.pkl'\n",
    "    all_idx, train_ids, val_ids = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    train_md = pd.read_csv(PATH_WORK/'train_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "    train_md['img_id'] = train_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])\n",
    "\n",
    "    trn_data = train_md.loc[train_md.img_id.isin(all_idx[train_ids])].reset_index(drop=True)\n",
    "    val_data = train_md.loc[train_md.img_id.isin(all_idx[val_ids])].reset_index(drop=True)\n",
    "\n",
    "    assert len(trn_data.SeriesInstanceUID.unique()) + len(val_data.SeriesInstanceUID.unique()) \\\n",
    "        == len(train_md.SeriesInstanceUID.unique())\n",
    "\n",
    "    assert len(trn_data.PatientID.unique()) + len(val_data.PatientID.unique()) \\\n",
    "        >= len(train_md.PatientID.unique())\n",
    "\n",
    "    ids_df = pd.DataFrame(all_idx, columns = ['img_id'])\n",
    "    ids_df = ids_df.join(train_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "    assert len(ids_df.SeriesInstanceUID.unique()) == 19530\n",
    "    \n",
    "    pickle.dump((trn_data,val_data,ids_df), open(PATH_WORK/'train.post.processed.1','wb'))\n",
    "else:\n",
    "    trn_data,val_data,ids_df = pickle.load(open(PATH_WORK/'train.post.processed.1','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    test_md = pd.read_csv(PATH_WORK/'test_md.csv').sort_values(['SeriesInstanceUID','pos_idx'])\n",
    "    test_md['img_id'] = test_md.SOPInstanceUID.str.split('_').apply(lambda x: x[1])\n",
    "\n",
    "    filename = PATH_WORK/'test_indexes.pkl'\n",
    "    test_ids = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    test_ids_df = pd.DataFrame(test_ids, columns = ['img_id'])\n",
    "    test_ids_df = test_ids_df.join(test_md[['img_id','SeriesInstanceUID','pos_idx']].set_index('img_id'), on = 'img_id')\n",
    "\n",
    "    assert len(test_ids_df.SeriesInstanceUID.unique()) == 2214\n",
    "    \n",
    "    pickle.dump((test_md,test_ids_df), open(PATH_WORK/'test.post.processed.1','wb'))\n",
    "else:\n",
    "    test_md,test_ids_df = pickle.load(open(PATH_WORK/'test.post.processed.1','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(pd.concat([test_md[meta_cols].mean(0),\n",
    "                     trn_data[meta_cols].mean(0),\n",
    "                     val_data[meta_cols].mean(0)], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    filename = PATH_WORK/'model_Densenet161_3_vehrsion_basic_classifier_type_features_train_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/train/{}'.format(series_id),'wb'))\n",
    "\n",
    "\n",
    "    filename = PATH_WORK/'model_Densenet161_3_vehrsion_basic_classifier_type_features_test_split_2.pkl'\n",
    "    feats = pickle.load(open(filename,'rb'))\n",
    "\n",
    "    for series_id in tqdm(test_ids_df.SeriesInstanceUID.unique()):\n",
    "        mask = torch.BoolTensor(test_ids_df.SeriesInstanceUID.values == series_id)\n",
    "        feats_id = feats[mask]\n",
    "        pickle.dump(feats_id, open(PATH_WORK/'features/densenet161_v3/test/{}'.format(series_id),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = PATH_WORK/'features/densenet161_v3/train/ID_000a935543'\n",
    "#feats1 = pickle.load(open(path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_black = '006d4432e'\n",
    "\n",
    "path = PATH_WORK/'features/densenet161_v3/train/ID_992b567eb6'\n",
    "black_feats = pickle.load(open(path,'rb'))[41]\n",
    "\n",
    "#black_feats = torch.zeros(black_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA_DataSet(D.Dataset):\n",
    "    def __init__(self, metadata, ids_df, mode='train', bs=None):\n",
    "        \n",
    "        super(RSNA_DataSet, self).__init__()\n",
    "        \n",
    "        md = metadata.copy()\n",
    "        md = md.reset_index(drop=True)\n",
    "        series = md.SeriesInstanceUID.unique()\n",
    "        \n",
    "        samples_add = 0\n",
    "        if (mode != 'train') and not DATA_SMALL:\n",
    "            batch_num = -((-len(series))//(bs*MAX_DEVICES))\n",
    "            samples_add = batch_num*bs*MAX_DEVICES - len(series)\n",
    "            print('adding dummy serieses', samples_add)\n",
    "        \n",
    "        #self.records = df.to_records(index=False)\n",
    "        self.mode = mode\n",
    "        self.real = np.concatenate([np.repeat(True,len(series)),np.repeat(False,samples_add)])\n",
    "        self.series = np.concatenate([series,np.repeat(series[0],samples_add)])\n",
    "        self.metadata = md\n",
    "        self.ids_df = ids_df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        series_id = self.series[index]\n",
    "        df = self.metadata.loc[self.metadata.SeriesInstanceUID == series_id].reset_index(drop=True)\n",
    "        \n",
    "        folder = 'test' if self.mode == 'test' else 'train'\n",
    "        path = PATH_WORK/'features/densenet161_v3/{}/{}'.format(folder,series_id)\n",
    "        feats = pickle.load(open(path,'rb'))\n",
    "        ids_df_sub = self.ids_df.loc[self.ids_df.SeriesInstanceUID.values == series_id]\n",
    "        \n",
    "        if feats.shape[0] > len(df):\n",
    "            mask_dup = ~ids_df_sub.img_id.duplicated().values\n",
    "            ids_df_sub = ids_df_sub.loc[mask_dup]\n",
    "            feats = feats[torch.BoolTensor(mask_dup)]\n",
    "        \n",
    "        assert feats.shape[0] == len(df)\n",
    "        assert len(ids_df_sub) == len(df)\n",
    "        assert np.all(ids_df_sub.img_id.isin(df.img_id).values)\n",
    "        order = np.argsort(ids_df_sub.pos_idx.values)\n",
    "        assert np.all(ids_df_sub.img_id.values[order] == df.img_id.values)\n",
    "        feats = feats[torch.LongTensor(order)]\n",
    "        \n",
    "        feats = torch.cat([feats, torch.Tensor(df[meta_cols].values)], dim=1)\n",
    "        target = torch.Tensor(df[all_ich].values)\n",
    "        \n",
    "        offset = np.random.randint(0, 61 - feats.shape[0])\n",
    "        #offset = 0\n",
    "        if offset > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.head(1)[meta_cols].values).squeeze()])\n",
    "            #dummy_row = torch.cat([black_feats, torch.zeros(len(meta_cols))])\n",
    "            feats = torch.cat([dummy_row.repeat(offset,1), feats], dim=0)\n",
    "            target = torch.cat([torch.zeros((offset, len(all_ich))), target], dim=0)\n",
    "        if (60 - len(df) - offset) > 0:\n",
    "            dummy_row = torch.cat([black_feats, torch.Tensor(df.tail(1)[meta_cols].values).squeeze()])\n",
    "            #dummy_row = torch.cat([black_feats, torch.zeros(len(meta_cols))])\n",
    "            feats = torch.cat([feats, dummy_row.repeat(60 - len(df) - offset,1)], dim=0)\n",
    "            target = torch.cat([target, torch.zeros((60 - len(df) - offset, len(all_ich)))], dim=0)\n",
    "        \n",
    "        assert feats.shape[0] == 60\n",
    "        assert target.shape[0] == 60\n",
    "        \n",
    "        feats = feats.transpose(1,0)\n",
    "        \n",
    "        idx = index\n",
    "        if not self.real[index]: idx = -1\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return feats, target\n",
    "        else:\n",
    "            return feats, target, idx, offset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.series) if not DATA_SMALL else int(0.01*len(self.series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentBatch(fold=0):\n",
    "    sel_batch = None\n",
    "    for filename in os.listdir(PATH_WORK/'models'):\n",
    "        splits = filename.split('.')\n",
    "        if int(splits[2][1]) != fold: continue\n",
    "        if int(splits[3][1:]) != VERSION: continue\n",
    "        if sel_batch is None:\n",
    "            sel_batch = int(splits[1][1:])\n",
    "        else:\n",
    "            sel_batch = max(sel_batch, int(splits[1][1:]))\n",
    "    return sel_batch\n",
    "\n",
    "def modelFileName(fold=0, batch = 1, return_last = False, return_next = False):\n",
    "    sel_batch = batch\n",
    "    if return_last or return_next:\n",
    "        sel_batch = getCurrentBatch(fold)\n",
    "        if return_last and sel_batch is None:\n",
    "            return None\n",
    "        if return_next:\n",
    "            if sel_batch is None: sel_batch = 1\n",
    "            else: sel_batch += 1\n",
    "    \n",
    "    return 'model.b{}.f{}.v{}'.format(sel_batch, fold, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(nn.Module):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "\n",
    "class BCEWithLogitsLoss(_Loss):\n",
    "    __constants__ = ['weight', 'pos_weight', 'reduction']\n",
    "\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None):\n",
    "        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.register_buffer('pos_weight', pos_weight)\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        #((torch.log(1+torch.exp(input)) - target*input)*self.weight).mean()\n",
    "        return F.binary_cross_entropy_with_logits(input.squeeze(), target,\n",
    "                                                  self.weight,\n",
    "                                                  pos_weight=self.pos_weight,\n",
    "                                                  reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatProduct(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(FeatProduct, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_feature, in_feature))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_feature))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.uniform_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = F.linear(x, self.weight) + self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_drop_lin(n_in:int, n_out:int, bn:bool=True, p:float=0., actn=None):\n",
    "    \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n",
    "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "    if p != 0: layers.append(nn.Dropout(p))\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if actn is not None: layers.append(actn)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, n_cont:int, out_sz:int, layers, ps=None,\n",
    "                 emb_drop:float=0., use_bn:bool=True, bn_final:bool=False, feat_sz=2208, fc_drop_p=0.3):\n",
    "        super().__init__()\n",
    "        self.bn_cont = nn.BatchNorm1d(feat_sz + n_cont)\n",
    "        self.n_cont = n_cont\n",
    "        sizes = self.get_sizes(layers, out_sz)\n",
    "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+ps,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        if bn_final: layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.feat_product = FeatProduct(feat_sz + n_cont, 20)\n",
    "        self.fc_drop = nn.Dropout(p=fc_drop_p)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2D_1 = nn.Conv2d(1,32,(feat_sz + n_cont,1))\n",
    "        self.conv2D_2 = nn.Conv2d(1,32,(feat_sz + n_cont,5),padding=(0,2))\n",
    "        self.bn_cont1 = nn.BatchNorm1d(64)\n",
    "        self.conv1D_1 = nn.Conv1d(64,64,3,padding=1)\n",
    "        self.conv1D_2 = nn.Conv1d(64,6,3,padding=1)\n",
    "        self.bn_cont2 = nn.BatchNorm1d(64)\n",
    "        self.bn_cont3 = nn.BatchNorm1d(6)\n",
    "\n",
    "    def get_sizes(self, layers, out_sz):\n",
    "        return [1200] + layers + [out_sz]\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.bn_cont(x) # bs,2208,60\n",
    "        #x = x.transpose(1,2) # bs,60,2208\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2]) # bs,1,2208,60\n",
    "        x = torch.cat([self.conv2D_1(x).squeeze(), self.conv2D_2(x).squeeze()], dim=1) # bs,64,60\n",
    "        x = self.relu(x)\n",
    "        x = self.bn_cont1(x)\n",
    "        x = self.conv1D_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn_cont2(x)\n",
    "        x = self.conv1D_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn_cont3(x) # bs,6,60\n",
    "        #x = self.fc_drop(x)\n",
    "        #x = self.feat_product(x)\n",
    "        #x = x.reshape(x.shape[0],-1)\n",
    "        #x = self.layers(x)\n",
    "        #x = x.reshape(x.shape[0],60,6)\n",
    "        x = x.transpose(1,2) # bs,60,6\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 5\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "        dataset = loader._loader._loader.dataset\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 10\n",
    "        OUT_TIME = 1\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "        dataset = loader.dataset\n",
    "    \n",
    "    #print('Start training {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss(weight = torch.Tensor(class_weights).to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=(0.9, 0.99))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    if CLOUD:\n",
    "        tracker = xm.RateTracker()\n",
    "\n",
    "    tloss = 0\n",
    "    tloss_count = 0\n",
    "    \n",
    "    st = time.time()\n",
    "    for i, (x, y) in generator:\n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        tloss += len(y)*loss.cpu().detach().item()\n",
    "        tloss_count += len(y)\n",
    "        \n",
    "        if CLOUD or CLOUD_SINGLE:\n",
    "            xm.optimizer_step(optimizer)\n",
    "            if CLOUD_SINGLE:\n",
    "                xm.mark_step()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        \n",
    "        if CLOUD:\n",
    "            tracker.add(len(y))\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            #print(torch_xla._XLAC._xla_metrics_report())\n",
    "            print('Batch {} device: {} time passed: {:.3f} time per batch: {:.3f}'\n",
    "                .format(i+1, device, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del loss, output, y, x\n",
    "    \n",
    "    return tloss, tloss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 1\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 10\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "    \n",
    "    #print('Start validating {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    indices = []\n",
    "    offsets = []\n",
    "    \n",
    "    for i, (x, y, idx, offset) in generator:\n",
    "        \n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "        \n",
    "        output = torch.sigmoid(model(x))\n",
    "        \n",
    "        mask = (idx >= 0)\n",
    "        results.append(output[mask].cpu().detach().numpy())\n",
    "        indices.append(idx[mask].cpu().detach().numpy())\n",
    "        offsets.append(offset[mask].cpu().detach().numpy())\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            print('Batch {} device: {} time passed: {:.3f} time per batch: {:.3f}'\n",
    "                  .format(i+1, device, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del output, y, x, idx, offset\n",
    "    \n",
    "    results = np.concatenate(results)\n",
    "    indices = np.concatenate(indices)\n",
    "    offsets = np.concatenate(offsets)\n",
    "    \n",
    "    return results, indices, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_loop_fn(model, loader, device, context = None):\n",
    "    \n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        tlen = len(loader._loader._loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 100\n",
    "        generator = loader\n",
    "        device_num = int(str(device)[-1])\n",
    "    else:\n",
    "        tlen = len(loader)\n",
    "        OUT_LOSS = 1000\n",
    "        OUT_TIME = 10\n",
    "        generator = enumerate(loader)\n",
    "        device_num = 1\n",
    "    \n",
    "    #print('Start testing {}'.format(device), 'batches', tlen)\n",
    "    \n",
    "    st = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    indices = []\n",
    "    offsets = []\n",
    "    \n",
    "    for i, (x, y, idx, offset) in generator:\n",
    "        \n",
    "        if (not CLOUD) or CLOUD_SINGLE:\n",
    "            x = x.to(device)\n",
    "        \n",
    "        output = torch.sigmoid(model(x))\n",
    "        \n",
    "        mask = (idx >= 0)\n",
    "        results.append(output[mask].cpu().detach().numpy())\n",
    "        indices.append(idx[mask].cpu().detach().numpy())\n",
    "        offsets.append(offset[mask].cpu().detach().numpy())\n",
    "        \n",
    "        st_passed = time.time() - st\n",
    "        if (i+1)%OUT_TIME == 0 and device_num == 1:\n",
    "            print('B{} -> time passed: {:.3f} time per batch: {:.3f}'.format(i+1, st_passed, st_passed/(i+1)))\n",
    "        \n",
    "        del output, x, y, idx, offset\n",
    "    \n",
    "    return np.concatenate(results), np.concatenate(indices), np.concatenate(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(weight=None, load_model=True, epochs=1, bs=100):\n",
    "    \n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch, 'starting now:', epochs)\n",
    "    \n",
    "    setSeeds(SEED + cur_epoch)\n",
    "    \n",
    "    trn_ds = RSNA_DataSet(trn_data, ids_df, mode='train', bs=bs)\n",
    "    loader = D.DataLoader(trn_ds, num_workers=16 if CLOUD else 0, batch_size=bs, shuffle=True)\n",
    "    val_ds = RSNA_DataSet(val_data, ids_df, mode='valid', bs=bs)\n",
    "    loader_val = D.DataLoader(val_ds, num_workers=16 if CLOUD else 0, batch_size=bs, shuffle=True)\n",
    "    #tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test')\n",
    "    print('dataset train:', len(trn_ds), 'valid:', len(val_ds), 'loader train:', len(loader), 'valid:', len(loader_val))\n",
    "    \n",
    "    model = TabularModel(n_cont = len(meta_cols), out_sz=360, layers=[500,200], ps=[0.5,0.5], bn_final=True)\n",
    "    \n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if model_file_name is not None:\n",
    "        print('loading model', model_file_name)\n",
    "        state_dict = torch.load(PATH_WORK/'models'/model_file_name)\n",
    "        model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        print('starting from scratch')\n",
    "    \n",
    "    if (not CLOUD) or CLOUD_SINGLE:\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        model_parallel = dp.DataParallel(model, device_ids=devices)\n",
    "    \n",
    "    for i in range(cur_epoch+1, cur_epoch+epochs+1):\n",
    "        st = time.time()\n",
    "\n",
    "        if CLOUD and (not CLOUD_SINGLE):\n",
    "            results = model_parallel(train_loop_fn, loader)\n",
    "            tloss, tloss_count = np.stack(results).sum(0)\n",
    "            state_dict = model_parallel._models[0].state_dict()\n",
    "        else:\n",
    "            tloss, tloss_count = train_loop_fn(model, loader, device)\n",
    "            state_dict = model.state_dict()\n",
    "        \n",
    "        state_dict = {k:v.to('cpu') for k,v in state_dict.items()}\n",
    "        tr_ll = tloss / tloss_count\n",
    "        \n",
    "        train_time = time.time()-st\n",
    "        \n",
    "        model_file_name = modelFileName(return_next=True)\n",
    "        if not DATA_SMALL:\n",
    "            torch.save(state_dict, PATH_WORK/'models'/model_file_name)\n",
    "        \n",
    "        st = time.time()\n",
    "        if CLOUD and (not CLOUD_SINGLE):\n",
    "            results = model_parallel(val_loop_fn, loader_val)\n",
    "            predictions = np.concatenate([results[i][0] for i in range(MAX_DEVICES)])\n",
    "            indices = np.concatenate([results[i][1] for i in range(MAX_DEVICES)])\n",
    "            offsets = np.concatenate([results[i][2] for i in range(MAX_DEVICES)])\n",
    "        else:\n",
    "            predictions, indices, offsets = val_loop_fn(model, loader_val, device)\n",
    "        \n",
    "        loc_data = val_data.copy()\n",
    "        if DATA_SMALL:\n",
    "            val_sz = int(0.01*len(val_data.SeriesInstanceUID.unique()))\n",
    "            val_series = val_data.SeriesInstanceUID.unique()[:val_sz]\n",
    "            loc_data = loc_data.loc[val_data.SeriesInstanceUID.isin(val_series)]\n",
    "        \n",
    "        predictions = predictions[np.argsort(indices)]\n",
    "        offsets = offsets[np.argsort(indices)]\n",
    "        assert len(predictions) == len(loc_data.SeriesInstanceUID.unique())\n",
    "        assert len(predictions) == len(offsets)\n",
    "        assert np.all(indices[np.argsort(indices)] == np.array(range(len(predictions))))\n",
    "        \n",
    "        valid_time = time.time()-st\n",
    "        \n",
    "        val_results = np.zeros((len(loc_data),6))\n",
    "        for k, series in enumerate(loc_data.SeriesInstanceUID.unique()):\n",
    "            mask = loc_data.SeriesInstanceUID == series\n",
    "            assert (offsets[k] + mask.sum()) <= 60\n",
    "            val_results[mask] = predictions[k,offsets[k]:(offsets[k] + mask.sum())]\n",
    "        \n",
    "        lls = [log_loss(loc_data[all_ich[k]].values, val_results[:,k], eps=1e-8, labels=[0,1]) for k in range(6)]\n",
    "        ll = (class_weights * np.array(lls)).mean()\n",
    "        cor = np.corrcoef(loc_data.loc[:,all_ich].values.reshape(-1), val_results.reshape(-1))[0,1]\n",
    "\n",
    "        print('epoch {}, train ll: {:.4f}, val ll: {:.4f}, cor: {:.4f}'.format(i, tr_ll, ll, cor))\n",
    "        valid_time = time.time()-st\n",
    "\n",
    "        epoch_stats = pd.DataFrame([[i, 0, tr_ll, ll, cor, lls[0], lls[1], lls[2], lls[3], lls[4], lls[5],\n",
    "                                     len(trn_ds), len(val_ds), bs, train_time, valid_time,\n",
    "                                     learning_rate, weight_decay]], \n",
    "                                   columns = \n",
    "                                    ['epoch','fold','train_loss','val_loss','cor',\n",
    "                                     'any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural',\n",
    "                                     'train_sz','val_sz','bs','train_time','valid_time','lr','wd'\n",
    "                                     ])\n",
    "\n",
    "        stats_filename = PATH_WORK/'stats.f{}.v{}'.format(0,VERSION)\n",
    "        if stats_filename.is_file():\n",
    "            epoch_stats = pd.concat([pd.read_csv(stats_filename), epoch_stats], sort=False)\n",
    "        #if not DATA_SMALL:\n",
    "        epoch_stats.to_csv(stats_filename, index=False)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch 22 device: xla:1 time passed: 277.972 time per batch: 12.635 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 209.280 time per batch: 9.513  - 16 cores / 16 workers\n",
    "#Batch 22 device: xla:1 time passed: 213.209 time per batch: 9.691  - 16 cores / 32 workers\n",
    "#Batch 22 device: xla:1 time passed: 275.780 time per batch: 12.535 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 208.826 time per batch: 9.492  - 16 cores / 16 workers\n",
    "#Batch 22 device: xla:1 time passed: 245.750 time per batch: 11.170 - 16 cores / 12 workers\n",
    "#Batch 22 device: xla:1 time passed: 374.876 time per batch: 17.040 - 16 cores / 8 workers\n",
    "#Batch 22 device: xla:1 time passed: 400.221 time per batch: 18.192 - 8 cores / 8 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixup\n",
    "# one-cycle\n",
    "# why test doesn't behave? Same stats for valid?\n",
    "# submit from TPU\n",
    "# copy latest model to GS code\n",
    "# add performance tracking, search for bottlenecks\n",
    "\n",
    "# Yuval: zoom in, squish, perspective wraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 0 starting now: 6\n",
      "dataset train: 175 valid: 19 loader train: 18 valid: 2\n",
      "starting from scratch\n",
      "Batch 1 device: cuda time passed: 2.846 time per batch: 2.846\n",
      "Batch 2 device: cuda time passed: 4.796 time per batch: 2.398\n",
      "Batch 3 device: cuda time passed: 6.801 time per batch: 2.267\n",
      "Batch 4 device: cuda time passed: 8.820 time per batch: 2.205\n",
      "Batch 5 device: cuda time passed: 10.891 time per batch: 2.178\n",
      "Batch 6 device: cuda time passed: 12.881 time per batch: 2.147\n",
      "Batch 7 device: cuda time passed: 14.861 time per batch: 2.123\n",
      "Batch 8 device: cuda time passed: 16.855 time per batch: 2.107\n",
      "Batch 9 device: cuda time passed: 18.901 time per batch: 2.100\n",
      "Batch 10 device: cuda time passed: 20.854 time per batch: 2.085\n",
      "Batch 11 device: cuda time passed: 22.819 time per batch: 2.074\n",
      "Batch 12 device: cuda time passed: 24.825 time per batch: 2.069\n",
      "Batch 13 device: cuda time passed: 26.864 time per batch: 2.066\n",
      "Batch 14 device: cuda time passed: 28.838 time per batch: 2.060\n",
      "Batch 15 device: cuda time passed: 30.827 time per batch: 2.055\n",
      "Batch 16 device: cuda time passed: 32.967 time per batch: 2.060\n",
      "Batch 17 device: cuda time passed: 34.946 time per batch: 2.056\n",
      "Batch 18 device: cuda time passed: 36.397 time per batch: 2.022\n",
      "epoch 1, train ll: 0.6796, val ll: 0.6440, cor: 0.5773\n",
      "Batch 1 device: cuda time passed: 2.068 time per batch: 2.068\n",
      "Batch 2 device: cuda time passed: 4.067 time per batch: 2.034\n",
      "Batch 3 device: cuda time passed: 6.200 time per batch: 2.067\n",
      "Batch 4 device: cuda time passed: 8.210 time per batch: 2.053\n",
      "Batch 5 device: cuda time passed: 10.295 time per batch: 2.059\n",
      "Batch 6 device: cuda time passed: 12.320 time per batch: 2.053\n",
      "Batch 7 device: cuda time passed: 14.518 time per batch: 2.074\n",
      "Batch 8 device: cuda time passed: 16.739 time per batch: 2.092\n",
      "Batch 9 device: cuda time passed: 18.785 time per batch: 2.087\n",
      "Batch 10 device: cuda time passed: 21.022 time per batch: 2.102\n",
      "Batch 11 device: cuda time passed: 23.239 time per batch: 2.113\n",
      "Batch 12 device: cuda time passed: 25.602 time per batch: 2.133\n",
      "Batch 13 device: cuda time passed: 27.900 time per batch: 2.146\n",
      "Batch 14 device: cuda time passed: 30.193 time per batch: 2.157\n",
      "Batch 15 device: cuda time passed: 32.433 time per batch: 2.162\n",
      "Batch 16 device: cuda time passed: 34.765 time per batch: 2.173\n",
      "Batch 17 device: cuda time passed: 37.020 time per batch: 2.178\n",
      "Batch 18 device: cuda time passed: 38.619 time per batch: 2.145\n",
      "epoch 2, train ll: 0.6566, val ll: 0.6296, cor: 0.6188\n",
      "Batch 1 device: cuda time passed: 2.244 time per batch: 2.244\n",
      "Batch 2 device: cuda time passed: 4.475 time per batch: 2.237\n",
      "Batch 3 device: cuda time passed: 6.703 time per batch: 2.234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-d2e2557216f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.002\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-b2ee8f4775fb>\u001b[0m in \u001b[0;36mtrain_one\u001b[1;34m(weight, load_model, epochs, bs)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_parallel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mtloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtloss_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loop_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-90c23055aced>\u001b[0m in \u001b[0;36mtrain_loop_fn\u001b[1;34m(model, loader, device, context)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mCLOUD\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCLOUD_SINGLE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-cbe464d4ed4b>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPATH_WORK\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'features/densenet161_v3/{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseries_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mids_df_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mids_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mids_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeriesInstanceUID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseries_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[0m_exception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1486\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m             key = tuple(com.apply_if_callable(x, self.obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATA_SMALL = True\n",
    "learning_rate = 0.002\n",
    "weight_decay = 1e-4\n",
    "model, predictions = train_one(epochs=1, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fold</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>cor</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>train_sz</th>\n",
       "      <th>val_sz</th>\n",
       "      <th>bs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>lr</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726055</td>\n",
       "      <td>0.654224</td>\n",
       "      <td>0.414119</td>\n",
       "      <td>0.537666</td>\n",
       "      <td>0.831044</td>\n",
       "      <td>0.668126</td>\n",
       "      <td>0.682751</td>\n",
       "      <td>0.667103</td>\n",
       "      <td>0.655211</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.022163</td>\n",
       "      <td>41.464186</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.662932</td>\n",
       "      <td>0.674519</td>\n",
       "      <td>0.514514</td>\n",
       "      <td>0.578316</td>\n",
       "      <td>0.719485</td>\n",
       "      <td>0.711851</td>\n",
       "      <td>0.715650</td>\n",
       "      <td>0.720392</td>\n",
       "      <td>0.697626</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>228.483305</td>\n",
       "      <td>39.975267</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.633933</td>\n",
       "      <td>0.648172</td>\n",
       "      <td>0.479476</td>\n",
       "      <td>0.566560</td>\n",
       "      <td>0.660726</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>0.687668</td>\n",
       "      <td>0.668540</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.257986</td>\n",
       "      <td>39.098220</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611457</td>\n",
       "      <td>0.682113</td>\n",
       "      <td>0.356769</td>\n",
       "      <td>0.561410</td>\n",
       "      <td>0.878148</td>\n",
       "      <td>0.739269</td>\n",
       "      <td>0.713355</td>\n",
       "      <td>0.684427</td>\n",
       "      <td>0.636771</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.873778</td>\n",
       "      <td>40.031317</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585407</td>\n",
       "      <td>0.614437</td>\n",
       "      <td>0.528193</td>\n",
       "      <td>0.521548</td>\n",
       "      <td>0.662975</td>\n",
       "      <td>0.654410</td>\n",
       "      <td>0.680795</td>\n",
       "      <td>0.677488</td>\n",
       "      <td>0.582294</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>228.637324</td>\n",
       "      <td>39.288216</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564001</td>\n",
       "      <td>0.529510</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.596942</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.563447</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.522977</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>228.301473</td>\n",
       "      <td>40.051853</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486939</td>\n",
       "      <td>0.411729</td>\n",
       "      <td>0.335162</td>\n",
       "      <td>0.399373</td>\n",
       "      <td>0.406607</td>\n",
       "      <td>0.424034</td>\n",
       "      <td>0.423018</td>\n",
       "      <td>0.417937</td>\n",
       "      <td>0.411760</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.032700</td>\n",
       "      <td>39.974749</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340899</td>\n",
       "      <td>0.337961</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.400726</td>\n",
       "      <td>0.285021</td>\n",
       "      <td>0.321397</td>\n",
       "      <td>0.311885</td>\n",
       "      <td>0.317160</td>\n",
       "      <td>0.328810</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.735694</td>\n",
       "      <td>39.455041</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250203</td>\n",
       "      <td>0.258378</td>\n",
       "      <td>0.533501</td>\n",
       "      <td>0.315653</td>\n",
       "      <td>0.197216</td>\n",
       "      <td>0.249116</td>\n",
       "      <td>0.236317</td>\n",
       "      <td>0.240708</td>\n",
       "      <td>0.253983</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.778490</td>\n",
       "      <td>39.205365</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187833</td>\n",
       "      <td>0.210845</td>\n",
       "      <td>0.622747</td>\n",
       "      <td>0.274530</td>\n",
       "      <td>0.135765</td>\n",
       "      <td>0.200463</td>\n",
       "      <td>0.182215</td>\n",
       "      <td>0.196292</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>229.498681</td>\n",
       "      <td>39.769799</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150510</td>\n",
       "      <td>0.194010</td>\n",
       "      <td>0.644307</td>\n",
       "      <td>0.258254</td>\n",
       "      <td>0.101652</td>\n",
       "      <td>0.184333</td>\n",
       "      <td>0.166792</td>\n",
       "      <td>0.184810</td>\n",
       "      <td>0.203972</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.985014</td>\n",
       "      <td>39.704015</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141098</td>\n",
       "      <td>0.191259</td>\n",
       "      <td>0.655366</td>\n",
       "      <td>0.242016</td>\n",
       "      <td>0.107430</td>\n",
       "      <td>0.186905</td>\n",
       "      <td>0.169981</td>\n",
       "      <td>0.188142</td>\n",
       "      <td>0.202325</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.666923</td>\n",
       "      <td>39.402008</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135381</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.706193</td>\n",
       "      <td>0.195183</td>\n",
       "      <td>0.107976</td>\n",
       "      <td>0.173794</td>\n",
       "      <td>0.159163</td>\n",
       "      <td>0.178229</td>\n",
       "      <td>0.182473</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>226.741471</td>\n",
       "      <td>39.347892</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134283</td>\n",
       "      <td>0.165306</td>\n",
       "      <td>0.718682</td>\n",
       "      <td>0.182627</td>\n",
       "      <td>0.108101</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.157549</td>\n",
       "      <td>0.177537</td>\n",
       "      <td>0.178416</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.457470</td>\n",
       "      <td>39.059951</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133773</td>\n",
       "      <td>0.159426</td>\n",
       "      <td>0.729052</td>\n",
       "      <td>0.172215</td>\n",
       "      <td>0.107868</td>\n",
       "      <td>0.165714</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.173422</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>228.731226</td>\n",
       "      <td>39.297527</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133001</td>\n",
       "      <td>0.157288</td>\n",
       "      <td>0.742290</td>\n",
       "      <td>0.166722</td>\n",
       "      <td>0.108240</td>\n",
       "      <td>0.166768</td>\n",
       "      <td>0.152357</td>\n",
       "      <td>0.171589</td>\n",
       "      <td>0.168620</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.614152</td>\n",
       "      <td>39.416605</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132574</td>\n",
       "      <td>0.154858</td>\n",
       "      <td>0.748253</td>\n",
       "      <td>0.161730</td>\n",
       "      <td>0.108246</td>\n",
       "      <td>0.163659</td>\n",
       "      <td>0.152147</td>\n",
       "      <td>0.170027</td>\n",
       "      <td>0.166467</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>229.612436</td>\n",
       "      <td>39.114279</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132180</td>\n",
       "      <td>0.154183</td>\n",
       "      <td>0.749857</td>\n",
       "      <td>0.163352</td>\n",
       "      <td>0.107996</td>\n",
       "      <td>0.160458</td>\n",
       "      <td>0.150253</td>\n",
       "      <td>0.167002</td>\n",
       "      <td>0.166870</td>\n",
       "      <td>17577</td>\n",
       "      <td>2400</td>\n",
       "      <td>100</td>\n",
       "      <td>227.995234</td>\n",
       "      <td>39.228685</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  fold  train_loss  val_loss       cor       any  epidural  \\\n",
       "0       1     0    0.726055  0.654224  0.414119  0.537666  0.831044   \n",
       "1       2     0    0.662932  0.674519  0.514514  0.578316  0.719485   \n",
       "2       3     0    0.633933  0.648172  0.479476  0.566560  0.660726   \n",
       "3       4     0    0.611457  0.682113  0.356769  0.561410  0.878148   \n",
       "4       5     0    0.585407  0.614437  0.528193  0.521548  0.662975   \n",
       "5       6     0    0.564001  0.529510  0.623652  0.449664  0.596942   \n",
       "6       7     0    0.486939  0.411729  0.335162  0.399373  0.406607   \n",
       "7       8     0    0.340899  0.337961  0.018398  0.400726  0.285021   \n",
       "8       9     0    0.250203  0.258378  0.533501  0.315653  0.197216   \n",
       "9      10     0    0.187833  0.210845  0.622747  0.274530  0.135765   \n",
       "10     11     0    0.150510  0.194010  0.644307  0.258254  0.101652   \n",
       "11     12     0    0.141098  0.191259  0.655366  0.242016  0.107430   \n",
       "12     13     0    0.135381  0.170286  0.706193  0.195183  0.107976   \n",
       "13     14     0    0.134283  0.165306  0.718682  0.182627  0.108101   \n",
       "14     15     0    0.133773  0.159426  0.729052  0.172215  0.107868   \n",
       "15     16     0    0.133001  0.157288  0.742290  0.166722  0.108240   \n",
       "16     17     0    0.132574  0.154858  0.748253  0.161730  0.108246   \n",
       "17     18     0    0.132180  0.154183  0.749857  0.163352  0.107996   \n",
       "\n",
       "    intraparenchymal  intraventricular  subarachnoid  subdural  train_sz  \\\n",
       "0           0.668126          0.682751      0.667103  0.655211     17577   \n",
       "1           0.711851          0.715650      0.720392  0.697626     17577   \n",
       "2           0.692043          0.695106      0.687668  0.668540     17577   \n",
       "3           0.739269          0.713355      0.684427  0.636771     17577   \n",
       "4           0.654410          0.680795      0.677488  0.582294     17577   \n",
       "5           0.557778          0.563447      0.566100  0.522977     17577   \n",
       "6           0.424034          0.423018      0.417937  0.411760     17577   \n",
       "7           0.321397          0.311885      0.317160  0.328810     17577   \n",
       "8           0.249116          0.236317      0.240708  0.253983     17577   \n",
       "9           0.200463          0.182215      0.196292  0.212122     17577   \n",
       "10          0.184333          0.166792      0.184810  0.203972     17577   \n",
       "11          0.186905          0.169981      0.188142  0.202325     17577   \n",
       "12          0.173794          0.159163      0.178229  0.182473     17577   \n",
       "13          0.170286          0.157549      0.177537  0.178416     17577   \n",
       "14          0.165714          0.152500      0.173422  0.172047     17577   \n",
       "15          0.166768          0.152357      0.171589  0.168620     17577   \n",
       "16          0.163659          0.152147      0.170027  0.166467     17577   \n",
       "17          0.160458          0.150253      0.167002  0.166870     17577   \n",
       "\n",
       "    val_sz   bs  train_time  valid_time     lr      wd  \n",
       "0     2400  100  227.022163   41.464186  0.002  0.0001  \n",
       "1     2400  100  228.483305   39.975267  0.002  0.0001  \n",
       "2     2400  100  227.257986   39.098220  0.002  0.0001  \n",
       "3     2400  100  227.873778   40.031317  0.002  0.0001  \n",
       "4     2400  100  228.637324   39.288216  0.002  0.0001  \n",
       "5     2400  100  228.301473   40.051853  0.002  0.0001  \n",
       "6     2400  100  227.032700   39.974749  0.020  0.0001  \n",
       "7     2400  100  227.735694   39.455041  0.020  0.0001  \n",
       "8     2400  100  227.778490   39.205365  0.020  0.0001  \n",
       "9     2400  100  229.498681   39.769799  0.020  0.0001  \n",
       "10    2400  100  227.985014   39.704015  0.020  0.0001  \n",
       "11    2400  100  227.666923   39.402008  0.020  0.0001  \n",
       "12    2400  100  226.741471   39.347892  0.002  0.0001  \n",
       "13    2400  100  227.457470   39.059951  0.002  0.0001  \n",
       "14    2400  100  228.731226   39.297527  0.002  0.0001  \n",
       "15    2400  100  227.614152   39.416605  0.002  0.0001  \n",
       "16    2400  100  229.612436   39.114279  0.002  0.0001  \n",
       "17    2400  100  227.995234   39.228685  0.002  0.0001  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(PATH_WORK/'stats.f{}.v{}'.format(0,VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.540385  , 0.30819952, 0.43251818, 0.3530488 , 0.43293434,\n",
       "       0.41421852], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x151b4944358>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions.mean(0)[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one(bs = 100):\n",
    "    st = time.time()\n",
    "\n",
    "    cur_epoch = getCurrentBatch()\n",
    "    if cur_epoch is None: cur_epoch = 0\n",
    "    print('completed epochs:', cur_epoch)\n",
    "\n",
    "    model = TabularModel(n_cont = len(meta_cols), out_sz=360, layers=[500,200], ps=[0.5,0.5], bn_final=True)\n",
    "    \n",
    "    model_file_name = modelFileName(return_last=True)\n",
    "    if model_file_name is not None:\n",
    "        print('loading model', model_file_name)\n",
    "        state_dict = torch.load(PATH_WORK/'models'/model_file_name)\n",
    "        model.load_state_dict(state_dict)\n",
    "    \n",
    "    if (not CLOUD) or CLOUD_SINGLE:\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        model_parallel = dp.DataParallel(model, device_ids=devices)\n",
    "\n",
    "    setSeeds(SEED + cur_epoch)\n",
    "\n",
    "    tst_ds = RSNA_DataSet(test_md, test_ids_df, mode='test', bs=bs)\n",
    "    loader_tst = D.DataLoader(tst_ds, num_workers=8 if CLOUD else 0, batch_size=bs, shuffle=False)\n",
    "    print('dataset test:', len(tst_ds), 'loader test:', len(loader_tst))\n",
    "\n",
    "    if CLOUD and (not CLOUD_SINGLE):\n",
    "        results = model_parallel(test_loop_fn, loader_tst)\n",
    "        predictions = np.concatenate([results[i][0] for i in range(MAX_DEVICES)])\n",
    "        indices = np.concatenate([results[i][1] for i in range(MAX_DEVICES)])\n",
    "        offsets = np.concatenate([results[i][2] for i in range(MAX_DEVICES)])\n",
    "    else:\n",
    "        predictions, indices, offsets = test_loop_fn(model, loader_tst, device)\n",
    "\n",
    "    predictions = predictions[np.argsort(indices)]\n",
    "    offsets = offsets[np.argsort(indices)]\n",
    "    assert len(predictions) == len(test_md.SeriesInstanceUID.unique())\n",
    "    assert np.all(indices[np.argsort(indices)] == np.array(range(len(predictions))))\n",
    "    \n",
    "    print('test processing time:', time.time() - st)\n",
    "    \n",
    "    return predictions, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed epochs: 18\n",
      "loading model model.b18.f0.v19\n",
      "adding dummy serieses 186\n",
      "dataset test: 2400 loader test: 24\n",
      "B10 -> time passed: 4.704 time per batch: 0.470\n",
      "B20 -> time passed: 6.391 time per batch: 0.320\n",
      "test processing time: 7.932620048522949\n"
     ]
    }
   ],
   "source": [
    "DATA_SMALL = False\n",
    "predictions, offsets = inference_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11411642, 0.09599437, 0.11162667, 0.11051702, 0.11001215,\n",
       "       0.11129409], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.087846, 0.004184, 0.029325, 0.030316, 0.041098, 0.029221], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.mean((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "for i, series_id in enumerate(test_md.SeriesInstanceUID.unique()):\n",
    "    df = test_md.loc[test_md.SeriesInstanceUID == series_id]\n",
    "    id_column = [a + '_' + b for a in df.SOPInstanceUID for b in all_ich]\n",
    "    assert (offsets[i] + len(df)) <= 60\n",
    "    data_sub = pd.DataFrame({'ID':np.array(id_column), \n",
    "                             'Label':predictions[i,offsets[i]:(offsets[i] + len(df))].reshape(-1)})\n",
    "    sub = pd.concat([sub,data_sub], axis=0, sort=False)\n",
    "\n",
    "sub = sub.reset_index(drop=True)\n",
    "\n",
    "assert len(sub) == 6*len(test_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15127398073673248"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1471214"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sub = pd.read_csv(PATH/'submission_061.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-14ac154e51d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_sub' is not defined"
     ]
    }
   ],
   "source": [
    "best_sub.loc[range(0,len(sub),6), 'Label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499705853123557"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'], \n",
    "            best_sub.sort_values('ID').reset_index(drop=True).loc[range(0,len(sub),6), 'Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle competitions submit rsna-intracranial-hemorrhage-detection -f sub.csv -m \"TPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
