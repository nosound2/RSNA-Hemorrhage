{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reina/anaconda3/envs/RSNA/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/reina/anaconda3/envs/RSNA/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pydicom\n",
    "import time\n",
    "import gc\n",
    "import operator \n",
    "from apex import amp \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from skimage.io import imread,imshow\n",
    "from helper import *\n",
    "from apex import amp\n",
    "import helper\n",
    "import torchvision.models as models\n",
    "from torch.optim import Adam\n",
    "from defenitions import *\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 43564\n",
    "device=device_by_name(\"Tesla\")\n",
    "#device=device_by_name(\"RTX\")\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>any</th>\n",
       "      <th>PID</th>\n",
       "      <th>StudyI</th>\n",
       "      <th>SeriesI</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>ImagePositionZ</th>\n",
       "      <th>ImagePositionX</th>\n",
       "      <th>ImagePositionY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63eb1e259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a449357f</td>\n",
       "      <td>62d125e5b2</td>\n",
       "      <td>0be5c0d1b3</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>180.199951</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2669954a7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363d5865</td>\n",
       "      <td>a20b80c7bf</td>\n",
       "      <td>3564d584db</td>\n",
       "      <td>['00047', '00047']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>922.530821</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>45.572849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52c9913b1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9c2b4bd7</td>\n",
       "      <td>3e3634f8cf</td>\n",
       "      <td>973274ffc9</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>4.455000</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-115.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6ff6126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3ae81c2d</td>\n",
       "      <td>a1390c15c2</td>\n",
       "      <td>e5ccad8244</td>\n",
       "      <td>['00036', '00036']</td>\n",
       "      <td>['00080', '00080']</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-99.5</td>\n",
       "      <td>28.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7858edd88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1867feb</td>\n",
       "      <td>c73e81ed3a</td>\n",
       "      <td>28e0531b3a</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>145.793000</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-132.190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "0  63eb1e259         0                 0                 0             0   \n",
       "1  2669954a7         0                 0                 0             0   \n",
       "2  52c9913b1         0                 0                 0             0   \n",
       "3  4e6ff6126         0                 0                 0             0   \n",
       "4  7858edd88         0                 0                 0             0   \n",
       "\n",
       "   subdural  any       PID      StudyI     SeriesI        WindowCenter  \\\n",
       "0         0    0  a449357f  62d125e5b2  0be5c0d1b3  ['00036', '00036']   \n",
       "1         0    0  363d5865  a20b80c7bf  3564d584db  ['00047', '00047']   \n",
       "2         0    0  9c2b4bd7  3e3634f8cf  973274ffc9                  40   \n",
       "3         0    0  3ae81c2d  a1390c15c2  e5ccad8244  ['00036', '00036']   \n",
       "4         0    0  c1867feb  c73e81ed3a  28e0531b3a                  40   \n",
       "\n",
       "          WindowWidth  ImagePositionZ  ImagePositionX  ImagePositionY  \n",
       "0  ['00080', '00080']      180.199951          -125.0       -8.000000  \n",
       "1  ['00080', '00080']      922.530821          -156.0       45.572849  \n",
       "2                 150        4.455000          -125.0     -115.063000  \n",
       "3  ['00080', '00080']      100.000000           -99.5       28.500000  \n",
       "4                 100      145.793000          -125.0     -132.190000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_dir+'train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[~train_df.PatientID.isin(bad_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(KFold(n_splits=10,shuffle=True, random_state=SEED).split(train_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=MyTransform(flip=True,zoom=0.05,rotate=15,out_size=384,shift=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_pred,y_true,weights):\n",
    "    return F.binary_cross_entropy_with_logits(y_pred,y_true,weights.repeat(y_pred.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_parameters(model,klr):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    num_blocks=5\n",
    "    no_decay=['bias']\n",
    "    optimizer_grouped_parameters=[\n",
    "        {'params': [p for n, p in param_optimizer if (not any(nd in n for nd in no_decay) and ('classifier' in n))], 'lr':klr*1e-3,'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)  and ('classifier' in n)], 'lr':klr*1e-3, 'weight_decay': 0.0}\n",
    "        ]\n",
    "    for i in range(num_blocks):\n",
    "        optimizer_grouped_parameters.extend([\n",
    "        {'params': [p for n, p in param_optimizer if (not any(nd in n for nd in no_decay) and ('layer{}'.format(i) in n))], 'lr':klr*(2.0**i)*2e-5,'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)  and ('layer{}'.format(i) in n)], 'lr':klr*(2.0**i)*2e-5, 'weight_decay': 0.0}\n",
    "        ])\n",
    "    return(optimizer_grouped_parameters)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2d3f8e9170>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697fb7ee015946e7a470832ad75af9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855169cb92394bfe9357cda2b3a05a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3e4b25ef23c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                 \u001b[0mreturn_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                 \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                                 sampler=sampling)\n\u001b[0m",
      "\u001b[0;32m~/kaggle/RSNA/helper/mytraining.py\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(model, optimizer, train_dataset, batch_size, num_epochs, loss_func, weights, accumulation_steps, weights_func, do_apex, validate_dataset, validate_loss, metric, param_schedualer, weights_data, history, return_model, num_workers, sampler)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RSNA/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RSNA/lib/python3.6/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RSNA/lib/python3.6/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_no_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpost_backward_models_are_masters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RSNA/lib/python3.6/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_models_are_masters\u001b[0;34m(scaler, params, stashed_grads, scale_override)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mstashed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mgrads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Clear the stash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/RSNA/lib/python3.6/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                              \u001b[0mstashed_master_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                                              \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                                              out_scale/stashed_have_scale)\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "num_split=0\n",
    "np.random.seed(SEED+num_split)\n",
    "torch.manual_seed(SEED+num_split)\n",
    "torch.cuda.manual_seed(SEED+num_split)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "klr=1\n",
    "batch_size=64\n",
    "num_workers=12\n",
    "num_epochs=4\n",
    "model_name,version = 'se_resnext101_32x4d' , 'basic'\n",
    "model = MySENet(pretrainedmodels.__dict__['se_resnext101_32x4d'](pretrained='imagenet'),len(hemorrhage_types))\n",
    "_=model.to(device)\n",
    "weights = torch.tensor([1.,1.,1.,1.,1.,2.],device=device)\n",
    "loss_func=my_loss\n",
    "targets_dataset=D.TensorDataset(torch.tensor(train_df[hemorrhage_types].values,dtype=torch.float))\n",
    "transform=MyTransform(flip=True,zoom=0.05,rotate=15,out_size=384,shift=40)\n",
    "imagedataset = ImageDataset(train_df,transform=transform.random,base_path=train_images_dir)\n",
    "transform_val=MyTransform(out_size=384)\n",
    "imagedataset_val = ImageDataset(train_df,transform=transform_val.random,base_path=train_images_dir)\n",
    "combined_dataset=DatasetCat([imagedataset,targets_dataset])\n",
    "combined_dataset_val=DatasetCat([imagedataset_val,targets_dataset])\n",
    "#param_s=parameter_scheduler(model,num_epoch=0)\n",
    "optimizer_grouped_parameters=get_optimizer_parameters(model,klr)\n",
    "idx_train = splits[num_split][0]\n",
    "idx_validate = splits[num_split][1]\n",
    "sampling=sampler(train_df[hemorrhage_types].values[idx_train],0.2,[10,1,1,1,1,0])\n",
    "sample_ratio=1.02*float(sampling().shape[0])/idx_train.shape[0]\n",
    "train_dataset=D.Subset(combined_dataset,idx_train)\n",
    "validate_dataset=D.Subset(combined_dataset_val,idx_validate)\n",
    "num_train_optimization_steps = num_epochs*(sample_ratio*len(train_dataset)//batch_size+int(len(train_dataset)%batch_size>0))\n",
    "sched=WarmupExpCosineWithWarmupRestartsSchedule( t_total=num_train_optimization_steps, cycles=num_epochs,tau=1)\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,lr=klr*1e-3,schedule=sched)\n",
    "history,best_model= model_train(model,\n",
    "                                optimizer,\n",
    "                                train_dataset,\n",
    "                                batch_size,\n",
    "                                num_epochs,\n",
    "                                loss_func,\n",
    "                                weights=weights,\n",
    "                                do_apex=True,\n",
    "                                validate_dataset=validate_dataset,\n",
    "                                param_schedualer=None,\n",
    "                                weights_data=None,\n",
    "                                metric=None,\n",
    "                                return_model=True,\n",
    "                                num_workers=num_workers,\n",
    "                                sampler=sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.plot(np.array([[hist['val_loss'] for hist in history],[hist['loss'] for hist in history]]).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), models_dir+models_format.format(model_name,version,num_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split=0\n",
    "np.random.seed(SEED+num_split)\n",
    "torch.manual_seed(SEED+num_split)\n",
    "torch.cuda.manual_seed(SEED+num_split)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "klr=1\n",
    "batch_size=64\n",
    "num_workers=12\n",
    "num_epochs=2\n",
    "model_name,version = 'se_resnext101_32x4d' , 'basic_more'\n",
    "model = MySENet(pretrainedmodels.__dict__['se_resnext101_32x4d'](pretrained='imagenet'),len(hemorrhage_types))\n",
    "model.load_state_dict(torch.load(models_dir+models_format.format(model_name,'basic_classifier',num_split),map_location=torch.device(device)))\n",
    "_=model.to(device)\n",
    "weights = torch.tensor([1.,1.,1.,1.,1.,2.],device=device)\n",
    "loss_func=my_loss\n",
    "targets_dataset=D.TensorDataset(torch.tensor(train_df[hemorrhage_types].values,dtype=torch.float))\n",
    "transform=MyTransform(flip=True,zoom=0.05,rotate=15,out_size=384,shift=40)\n",
    "imagedataset = ImageDataset(train_df,transform=transform.random,base_path=train_images_dir)\n",
    "transform_val=MyTransform(out_size=384)\n",
    "imagedataset_val = ImageDataset(train_df,transform=transform_val.random,base_path=train_images_dir)\n",
    "combined_dataset=DatasetCat([imagedataset,targets_dataset])\n",
    "combined_dataset_val=DatasetCat([imagedataset_val,targets_dataset])\n",
    "#param_s=parameter_scheduler(model,num_epoch=0)\n",
    "optimizer_grouped_parameters=get_optimizer_parameters(model,klr)\n",
    "idx_train = splits[num_split][0]\n",
    "idx_validate = splits[num_split][1]\n",
    "#sampling=sampler(train_df[hemorrhage_types].values[idx_train],0.2,[10,1,1,1,1,0])\n",
    "sample_ratio=1.0 #1.02*float(sampling().shape[0])/idx_train.shape[0]\n",
    "train_dataset=D.Subset(combined_dataset,idx_train)\n",
    "validate_dataset=D.Subset(combined_dataset_val,idx_validate)\n",
    "num_train_optimization_steps = num_epochs*(sample_ratio*len(train_dataset)//batch_size+int(len(train_dataset)%batch_size>0))\n",
    "sched=WarmupExpCosineWithWarmupRestartsSchedule( t_total=num_train_optimization_steps, cycles=num_epochs*2,tau=1)\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,lr=klr*1e-3,schedule=sched)\n",
    "history,best_model= model_train(model,\n",
    "                                optimizer,\n",
    "                                train_dataset,\n",
    "                                batch_size,\n",
    "                                num_epochs,\n",
    "                                loss_func,\n",
    "                                weights=weights,\n",
    "                                do_apex=True,\n",
    "                                validate_dataset=validate_dataset,\n",
    "                                param_schedualer=None,\n",
    "                                weights_data=None,\n",
    "                                metric=None,\n",
    "                                return_model=True,\n",
    "                                num_workers=num_workers,\n",
    "                                sampler=None)\n",
    "\n",
    "torch.save(best_model.state_dict(), models_dir+models_format.format(model_name,version,num_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff9b86a4110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got some error with pid {}.format(pid)\n",
      "huston is the an empty picture e20bf3f8a\n",
      "huston is the an empty picture 470e639ae\n",
      "huston is the an empty picture d91d52bdc\n",
      "huston is the an empty picture 0e21abf7a\n",
      "huston is the an empty picture 8da38f2e4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2108), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got some error with pid {}.format(pid)\n",
      "huston is the an empty picture 6431af929\n",
      "{'loss': 0.011510233211503544, 'val_loss': 0.01142682346834119}\n",
      "\n",
      "0.01142682346834119\n"
     ]
    }
   ],
   "source": [
    "num_split=0\n",
    "np.random.seed(SEED+num_split)\n",
    "torch.manual_seed(SEED+num_split)\n",
    "torch.cuda.manual_seed(SEED+num_split)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "klr=3\n",
    "batch_size=32\n",
    "num_workers=12\n",
    "num_epochs=1\n",
    "model_name,version = 'Densenet161' , 'basic_more'\n",
    "model1 = MyDenseNet(models.densenet161(pretrained=True),len(hemorrhage_types))\n",
    "model1.load_state_dict(torch.load(models_dir+models_format.format(model_name,'basic',num_split),map_location=torch.device(device)))\n",
    "model = MyDenseNet(models.densenet161(pretrained=True),len(hemorrhage_types))\n",
    "model.features = model1.features\n",
    "_=model.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay=['bias']\n",
    "optimizer_grouped_parameters=[\n",
    "    {'params': [p for n, p in param_optimizer if (not any(nd in n for nd in no_decay) and ('classifier' in n))], 'lr':klr*1e-3,'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)  and ('classifier' in n)], 'lr':klr*1e-3, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "weights = torch.tensor([1.,1.,1.,1.,1.,2.],device=device)\n",
    "loss_func=my_loss\n",
    "targets_dataset=D.TensorDataset(torch.tensor(train_df[hemorrhage_types].values,dtype=torch.float))\n",
    "transform=MyTransform(flip=True,zoom=0.05,rotate=15,out_size=384,shift=40)\n",
    "imagedataset = ImageDataset(train_df,transform=transform.random,base_path=train_images_dir)\n",
    "transform_val=MyTransform(out_size=384)\n",
    "imagedataset_val = ImageDataset(train_df,transform=transform_val.random,base_path=train_images_dir)\n",
    "combined_dataset=DatasetCat([imagedataset,targets_dataset])\n",
    "combined_dataset_val=DatasetCat([imagedataset_val,targets_dataset])\n",
    "#param_s=parameter_scheduler(model,num_epoch=0)\n",
    "optimizer_grouped_parameters=get_optimizer_parameters(model,klr)\n",
    "idx_train = splits[num_split][0]\n",
    "idx_validate = splits[num_split][1]\n",
    "#sampling=sampler(train_df[hemorrhage_types].values[idx_train],0.2,[10,1,1,1,1,0])\n",
    "sample_ratio=1.0 #1.02*float(sampling().shape[0])/idx_train.shape[0]\n",
    "train_dataset=D.Subset(combined_dataset,idx_train)\n",
    "validate_dataset=D.Subset(combined_dataset_val,idx_validate)\n",
    "num_train_optimization_steps = num_epochs*(sample_ratio*len(train_dataset)//batch_size+int(len(train_dataset)%batch_size>0))\n",
    "sched=WarmupExpCosineWithWarmupRestartsSchedule( t_total=num_train_optimization_steps, cycles=num_epochs//1,tau=0)\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,lr=klr*1e-3,schedule=sched)\n",
    "history,best_model= model_train(model,\n",
    "                                optimizer,\n",
    "                                train_dataset,\n",
    "                                batch_size,\n",
    "                                num_epochs,\n",
    "                                loss_func,\n",
    "                                weights=weights,\n",
    "                                do_apex=True,\n",
    "                                validate_dataset=validate_dataset,\n",
    "                                param_schedualer=None,\n",
    "                                weights_data=None,\n",
    "                                metric=None,\n",
    "                                return_model=True,\n",
    "                                num_workers=num_workers,\n",
    "                                sampler=None)\n",
    "\n",
    "torch.save(best_model.state_dict(), models_dir+models_format.format(model_name,version,num_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff9b86a4110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got some error with pid {}.format(pid)\n",
      "huston is the an empty picture e20bf3f8a\n",
      "huston is the an empty picture 470e639ae\n",
      "huston is the an empty picture d91d52bdc\n",
      "huston is the an empty picture 0e21abf7a\n",
      "huston is the an empty picture 8da38f2e4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2108), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got some error with pid {}.format(pid)\n",
      "huston is the an empty picture 6431af929\n",
      "{'loss': 0.011510233211503544, 'val_loss': 0.01142682346834119}\n",
      "\n",
      "0.01142682346834119\n"
     ]
    }
   ],
   "source": [
    "num_split=0\n",
    "np.random.seed(SEED+num_split)\n",
    "torch.manual_seed(SEED+num_split)\n",
    "torch.cuda.manual_seed(SEED+num_split)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "klr=3\n",
    "batch_size=32\n",
    "num_workers=12\n",
    "num_epochs=1\n",
    "model_name,version = 'Densenet161' , 'basic_classifier'\n",
    "model1 = MyDenseNet(models.densenet161(pretrained=True),len(hemorrhage_types))\n",
    "model1.load_state_dict(torch.load(models_dir+models_format.format(model_name,'basic',num_split),map_location=torch.device(device)))\n",
    "model = MyDenseNet(models.densenet161(pretrained=True),len(hemorrhage_types))\n",
    "model.features = model1.features\n",
    "_=model.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay=['bias']\n",
    "optimizer_grouped_parameters=[\n",
    "    {'params': [p for n, p in param_optimizer if (not any(nd in n for nd in no_decay) and ('classifier' in n))], 'lr':klr*1e-3,'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)  and ('classifier' in n)], 'lr':klr*1e-3, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "weights = torch.tensor([1.,1.,1.,1.,1.,2.],device=device)\n",
    "loss_func=my_loss\n",
    "targets_dataset=D.TensorDataset(torch.tensor(train_df[hemorrhage_types].values,dtype=torch.float))\n",
    "transform=MyTransform(flip=True,zoom=0.05,rotate=15,out_size=384,shift=40)\n",
    "imagedataset = ImageDataset(train_df,transform=transform.random,base_path=train_images_dir)\n",
    "transform_val=MyTransform(out_size=384)\n",
    "imagedataset_val = ImageDataset(train_df,transform=transform_val.random,base_path=train_images_dir)\n",
    "combined_dataset=DatasetCat([imagedataset,targets_dataset])\n",
    "combined_dataset_val=DatasetCat([imagedataset_val,targets_dataset])\n",
    "#param_s=parameter_scheduler(model,num_epoch=0)\n",
    "optimizer_grouped_parameters=get_optimizer_parameters(model,klr)\n",
    "idx_train = splits[num_split][0]\n",
    "idx_validate = splits[num_split][1]\n",
    "#sampling=sampler(train_df[hemorrhage_types].values[idx_train],0.2,[10,1,1,1,1,0])\n",
    "sample_ratio=1.0 #1.02*float(sampling().shape[0])/idx_train.shape[0]\n",
    "train_dataset=D.Subset(combined_dataset,idx_train)\n",
    "validate_dataset=D.Subset(combined_dataset_val,idx_validate)\n",
    "num_train_optimization_steps = num_epochs*(sample_ratio*len(train_dataset)//batch_size+int(len(train_dataset)%batch_size>0))\n",
    "sched=WarmupExpCosineWithWarmupRestartsSchedule( t_total=num_train_optimization_steps, cycles=num_epochs//1,tau=0)\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,lr=klr*1e-3,schedule=sched)\n",
    "history,best_model= model_train(model,\n",
    "                                optimizer,\n",
    "                                train_dataset,\n",
    "                                batch_size,\n",
    "                                num_epochs,\n",
    "                                loss_func,\n",
    "                                weights=weights,\n",
    "                                do_apex=True,\n",
    "                                validate_dataset=validate_dataset,\n",
    "                                param_schedualer=None,\n",
    "                                weights_data=None,\n",
    "                                metric=None,\n",
    "                                return_model=True,\n",
    "                                num_workers=num_workers,\n",
    "                                sampler=None)\n",
    "\n",
    "torch.save(best_model.state_dict(), models_dir+models_format.format(model_name,version,num_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07998776427838833"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_28fbab7eb_epidural</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_28fbab7eb_intraparenchymal</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_28fbab7eb_intraventricular</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_28fbab7eb_subarachnoid</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_28fbab7eb_subdural</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label\n",
       "0          ID_28fbab7eb_epidural    0.5\n",
       "1  ID_28fbab7eb_intraparenchymal    0.5\n",
       "2  ID_28fbab7eb_intraventricular    0.5\n",
       "3      ID_28fbab7eb_subarachnoid    0.5\n",
       "4          ID_28fbab7eb_subdural    0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sub_type</th>\n",
       "      <th>PatientID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_28fbab7eb_epidural</td>\n",
       "      <td>0.5</td>\n",
       "      <td>epidural</td>\n",
       "      <td>28fbab7eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_28fbab7eb_intraparenchymal</td>\n",
       "      <td>0.5</td>\n",
       "      <td>intraparenchymal</td>\n",
       "      <td>28fbab7eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_28fbab7eb_intraventricular</td>\n",
       "      <td>0.5</td>\n",
       "      <td>intraventricular</td>\n",
       "      <td>28fbab7eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_28fbab7eb_subarachnoid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>subarachnoid</td>\n",
       "      <td>28fbab7eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_28fbab7eb_subdural</td>\n",
       "      <td>0.5</td>\n",
       "      <td>subdural</td>\n",
       "      <td>28fbab7eb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label          Sub_type  PatientID\n",
       "0          ID_28fbab7eb_epidural    0.5          epidural  28fbab7eb\n",
       "1  ID_28fbab7eb_intraparenchymal    0.5  intraparenchymal  28fbab7eb\n",
       "2  ID_28fbab7eb_intraventricular    0.5  intraventricular  28fbab7eb\n",
       "3      ID_28fbab7eb_subarachnoid    0.5      subarachnoid  28fbab7eb\n",
       "4          ID_28fbab7eb_subdural    0.5          subdural  28fbab7eb"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission=pd.read_csv(data_dir+'stage_1_sample_submission.csv')\n",
    "sample_submission.head()\n",
    "test_df=sample_submission.copy()\n",
    "test_df['Sub_type'] = test_df['ID'].str.split(\"_\", n = 3, expand = True)[2]\n",
    "test_df['PatientID'] = test_df['ID'].str.split(\"_\", n = 3, expand = True)[1]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28fbab7eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>877923b8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a591477cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42217c898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a130c4d2f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID\n",
       "0  28fbab7eb\n",
       "1  877923b8b\n",
       "2  a591477cb\n",
       "3  42217c898\n",
       "4  a130c4d2f"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Id_df = pd.DataFrame(data={'PatientID':test_df.PatientID.unique()})\n",
    "test_Id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d77c5630af1495dbef5594d0e96b7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1228), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(models_dir+models_format.format(model_name,'basic_more',num_split),map_location=torch.device(device)))\n",
    "_=model.to(device)\n",
    "imagedataset_test=ImageDataset(test_Id_df,transform=transform_val.random,base_path=test_images_dir)\n",
    "pred = model_run(model,imagedataset_test,do_apex=True,batch_size=64,num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_28fbab7eb_epidural</td>\n",
       "      <td>3.033406e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_28fbab7eb_intraparenchymal</td>\n",
       "      <td>6.375548e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_28fbab7eb_intraventricular</td>\n",
       "      <td>1.966767e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_28fbab7eb_subarachnoid</td>\n",
       "      <td>5.399497e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_28fbab7eb_subdural</td>\n",
       "      <td>1.490849e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_28fbab7eb_any</td>\n",
       "      <td>1.532611e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_877923b8b_epidural</td>\n",
       "      <td>4.363462e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID_877923b8b_intraparenchymal</td>\n",
       "      <td>1.888572e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID_877923b8b_intraventricular</td>\n",
       "      <td>4.644881e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID_877923b8b_subarachnoid</td>\n",
       "      <td>8.013500e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID         Label\n",
       "0          ID_28fbab7eb_epidural  3.033406e-11\n",
       "1  ID_28fbab7eb_intraparenchymal  6.375548e-07\n",
       "2  ID_28fbab7eb_intraventricular  1.966767e-09\n",
       "3      ID_28fbab7eb_subarachnoid  5.399497e-08\n",
       "4          ID_28fbab7eb_subdural  1.490849e-07\n",
       "5               ID_28fbab7eb_any  1.532611e-05\n",
       "6          ID_877923b8b_epidural  4.363462e-09\n",
       "7  ID_877923b8b_intraparenchymal  1.888572e-06\n",
       "8  ID_877923b8b_intraventricular  4.644881e-09\n",
       "9      ID_877923b8b_subarachnoid  8.013500e-06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_num=5\n",
    "\n",
    "epidural_df=pd.DataFrame(data={'ID':'ID_'+test_Id_df.PatientID.values+'_epidural','Label':torch.sigmoid(pred[:,0])})\n",
    "intraparenchymal_df=pd.DataFrame(data={'ID':'ID_'+test_Id_df.PatientID.values+'_intraparenchymal','Label':torch.sigmoid(pred[:,1])})\n",
    "intraventricular_df=pd.DataFrame(data={'ID':'ID_'+test_Id_df.PatientID.values+'_intraventricular','Label':torch.sigmoid(pred[:,2])})\n",
    "subarachnoid_df=pd.DataFrame(data={'ID':'ID_'+test_Id_df.PatientID.values+'_subarachnoid','Label':torch.sigmoid(pred[:,3])})\n",
    "subdural_df=pd.DataFrame(data={'ID':'ID_'+test_Id_df.PatientID.values+'_subdural','Label':torch.sigmoid(pred[:,4])})\n",
    "any_df=pd.DataFrame(data={'ID':'ID_'+test_Id_df.PatientID.values+'_any','Label':torch.sigmoid(pred[:,5])})\n",
    "\n",
    "test_res_df = pd.concat([epidural_df,\n",
    "                        intraparenchymal_df,\n",
    "                        intraventricular_df,\n",
    "                        subarachnoid_df,\n",
    "                        subdural_df,\n",
    "                        any_df]).reset_index(drop=True)\n",
    "trd=test_res_df.sort_values('ID')\n",
    "sample_submission[['ID','Label']]=trd.values[np.argsort(np.argsort(sample_submission.ID.values))]\n",
    "sample_submission.to_csv('/media/hd/notebooks/data/RSNA/submissions/submission{}.csv'.format(sub_num),\n",
    "                                                                  index=False, columns=['ID','Label'])\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_121=pd.read_csv('/media/hd/notebooks/data/RSNA/submissions/submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_28fbab7eb_epidural</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_28fbab7eb_intraparenchymal</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_28fbab7eb_intraventricular</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_28fbab7eb_subarachnoid</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_28fbab7eb_subdural</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID     Label\n",
       "0          ID_28fbab7eb_epidural  0.000001\n",
       "1  ID_28fbab7eb_intraparenchymal  0.000016\n",
       "2  ID_28fbab7eb_intraventricular  0.000003\n",
       "3      ID_28fbab7eb_subarachnoid  0.000103\n",
       "4          ID_28fbab7eb_subdural  0.000105"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.Label=(sample_submission.Label+submission_121.Label)/2\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_num=4\n",
    "sample_submission.to_csv('/media/hd/notebooks/data/RSNA/submissions/submission{}.csv'.format(sub_num),\n",
    "                                                                  index=False, columns=['ID','Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
